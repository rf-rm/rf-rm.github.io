{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Remove Everything with rm-rf / \u00b6 Linux \u00b6 \u0110i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y - Cloud Computing \u00b6 Openstack \u00b6 Networking \u00b6","title":"Remove Everything with `rm-rf /`"},{"location":"#remove_everything_with_rm-rf","text":"","title":"Remove Everything with rm-rf /"},{"location":"#linux","text":"","title":"Linux"},{"location":"#ien_toan_am_may_-_cloud_computing","text":"","title":"\u0110i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y - Cloud Computing"},{"location":"#openstack","text":"","title":"Openstack"},{"location":"#networking","text":"","title":"Networking"},{"location":"Openstack_Research/1. Intro Cloud Computing/","text":"Cloud Computing and Openstack \u00b6 1.Cloud Computing \u00b6 1.1 : Kh\u00e1i ni\u1ec7m Cloud Computing \u00b6 Kh\u00e1i ni\u1ec7m Cloud Computing, t\u1ea1i Vi\u1ec7t Nam th\u00ec \u0111a s\u1ed1 hi\u1ec3u l\u00e0 \u0110i\u1ec7n To\u00e1n \u0110\u00e1m M\u00e2y. M\u1ed9t trong c\u00e1c c\u00f4ng ngh\u1ec7 \u201chot\u201d trong v\u00e0i n\u0103m tr\u1edf l\u1ea1i \u0111\u00e2y. \u0110\u00e2y c\u0169ng l\u00e0 m\u1ed9t c\u1ee5m t\u1eeb \u0111\u01b0\u1ee3c nh\u1eafc \u0111\u1ebfn nhi\u1ec1u trong c\u00e1c b\u00e0i b\u00e1o, b\u00e0i vi\u1ebft c\u1ee7a c\u00e1c h\u00e3ng c\u00f4ng ngh\u1ec7. N\u00f3 c\u0169ng c\u00f3 nguy\u00ean m\u1ed9t \u0111\u1ecbnh ngh\u0129a c\u1ee7a Vi\u1ec7n ti\u00eau chu\u1ea9n v\u00e0 c\u00f4ng ngh\u1ec7 qu\u1ed1c gia c\u1ee7a M\u1ef9 (NIST) , th\u01b0\u1eddng \u0111\u01b0\u1ee3c tr\u00edch ra trong c\u00e1c b\u00e0i thuy\u1ebft tr\u00ecnh c\u1ee7a c\u00e1c chuy\u00ean gia (ngo\u00e0i ra, c\u00f3 nhi\u1ec1u \u0111\u1ecbnh ngh\u0129a c\u1ee7a c\u00e1c h\u00e3ng t\u00ean tu\u1ed5i kh\u00e1c nh\u01b0ng t\u00f4i kh\u00f4ng \u0111\u01b0a v\u00e0o \u0111\u00e2y). B\u1ea1n c\u00f3 th\u1ec3 xem n\u00f3 t\u1ea1i \u0111\u00e2y: \u0110\u1ecbnh ngh\u0129a v\u1ec1 Cloud Computing c\u1ee7a NIST \u0110\u1ecbnh ngh\u0129a l\u01b0\u1ee3c d\u1ecbch t\u1eeb NIST Cloud Computing l\u00e0 m\u00f4 h\u00ecnh cho ph\u00e9p truy c\u1eadp qua m\u1ea1ng \u0111\u1ec3 l\u1ef1a ch\u1ecdn v\u00e0 s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n (v\u00ed d\u1ee5: m\u1ea1ng, m\u00e1y ch\u1ee7, l\u01b0u tr\u1eef, \u1ee9ng d\u1ee5ng v\u00e0 d\u1ecbch v\u1ee5) theo nhu c\u1ea7u m\u1ed9t c\u00e1ch thu\u1eadn ti\u1ec7n v\u00e0 nhanh ch\u00f3ng; \u0111\u1ed3ng th\u1eddi cho ph\u00e9p k\u1ebft th\u00fac s\u1eed d\u1ee5ng d\u1ecbch v\u1ee5, gi\u1ea3i ph\u00f3ng t\u00e0i nguy\u00ean d\u1ec5 d\u00e0ng, gi\u1ea3m thi\u1ec3u c\u00e1c giao ti\u1ebfp v\u1edbi nh\u00e0 cung c\u1ea5p\u201d 1.2. M\u00f4 h\u00ecnh 5 - 4 - 3 trong Cloud Computing \u00b6 5 \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a cloud computing: * Kh\u1ea3 n\u0103ng thu h\u1ed3i v\u00e0 c\u1ea5p ph\u00e1t t\u00e0i nguy\u00ean (Rapid elasticity) Truy nh\u1eadp qua c\u00e1c chu\u1ea9n m\u1ea1ng (Broad network access) D\u1ecbch v\u1ee5 s\u1eed d\u1ee5ng \u0111o \u0111\u1ebfm \u0111\u01b0\u1ee3c (Measured service,) hay l\u00e0 chi tr\u1ea3 theo m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng pay as you go. Kh\u1ea3 n\u0103ng t\u1ef1 ph\u1ee5c v\u1ee5 (On-demand self-service). Chia s\u1ebb t\u00e0i nguy\u00ean (Resource pooling). _4 m\u00f4 h\u00ecnh tri\u1ec3n khai (m\u00f4 h\u00ecnh s\u1ea3n ph\u1ea9m) : Public Cloud: \u0110\u00e1m m\u00e2y c\u00f4ng c\u1ed9ng (l\u00e0 c\u00e1c d\u1ecbch v\u1ee5 tr\u00ean n\u1ec1n t\u1ea3ng Cloud Computing \u0111\u1ec3 cho c\u00e1c c\u00e1 nh\u00e2n v\u00e0 t\u1ed5 ch\u1ee9c thu\u00ea, h\u1ecd d\u00f9ng chung t\u00e0i nguy\u00ean). Private Cloud: \u0110\u00e1m m\u00e2y ri\u00eang (d\u00f9ng trong m\u1ed9t doanh nghi\u1ec7p v\u00e0 kh\u00f4ng chia s\u1ebb v\u1edbi ng\u01b0\u1eddi d\u00f9ng ngo\u00e0i doanh nghi\u1ec7p \u0111\u00f3) . \u0110i\u1ec1u n\u00e0y gi\u00fap cho doanh nghi\u1ec7p c\u00f3 th\u1ec3 ch\u1ee7 \u0111\u1ed9ng ki\u1ec3m so\u00e1t t\u1ed1i \u0111a \u0111\u1ed1i v\u1edbi d\u1eef li\u1ec7u, b\u1ea3o m\u1eadt v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1ecbch v\u1ee5. Doanh nghi\u1ec7p s\u1edf h\u1eefu c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng v\u00e0 qu\u1ea3n l\u00fd c\u00e1c \u1ee9ng d\u1ee5ng \u0111\u01b0\u1ee3c tri\u1ec3n khai tr\u00ean \u0111\u00f3. Community Cloud: \u0110\u00e1m m\u00e2y c\u1ed9ng \u0111\u1ed3ng (l\u00e0 c\u00e1c d\u1ecbch v\u1ee5 tr\u00ean n\u1ec1n t\u1ea3ng Cloud computing do c\u00e1c c\u00f4ng ty c\u00f9ng h\u1ee3p t\u00e1c x\u00e2y d\u1ef1ng v\u00e0 cung c\u1ea5p c\u00e1c d\u1ecbch v\u1ee5 cho c\u1ed9ng \u0111\u1ed3ng. ) Hybrid Cloud : L\u00e0 m\u00f4 h\u00ecnh k\u1ebft h\u1ee3p (lai) gi\u1eefa c\u00e1c m\u00f4 h\u00ecnh Public Cloud v\u00e0 Private Cloud 3 m\u00f4 h\u00ecnh d\u1ecbch v\u1ee5:: H\u1ea1 t\u1ea7ng nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Infrastructure as a Service) : Cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng h\u1ea1 t\u1ea7ng th\u00f4 - c\u00e1c server, resource l\u00e0: RAM, CPU, Storage (th\u01b0\u1eddng l\u00e0 d\u01b0\u1edbi h\u00ecnh th\u1ee9c c\u00e1c m\u00e1y \u1ea3o) nh\u01b0 l\u00e0 m\u1ed9t d\u1ecbch v\u1ee5 D\u1ecbch v\u1ee5 IaaS ph\u1ed5 bi\u1ebfn hi\u1ec7n nay tr\u00ean th\u1ebf gi\u1edbi nh\u01b0 Amazon Cloud, Google Cloud, Microsoft N\u1ec1n t\u1ea3ng nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Platform as a Service) Cung c\u1ea5p d\u1ecbch v\u1ee5 m\u00e0 kh\u00e1ch h\u00e0ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng ng\u00f4n ng\u1eef l\u1eadp tr\u00ecnh, c\u00f4ng c\u1ee5, n\u1ec1n t\u1ea3ng \u0111\u1ec3 ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai \u1ee9ng d\u1ee5ng tr\u00ean n\u1ec1n t\u1ea3ng d\u00f9ng chung v\u1edbi kh\u1ea3 n\u0103ng ki\u1ec3m so\u00e1t m\u00f4i tr\u01b0\u1eddng v\u00e0 \u1ee9ng d\u1ee5ng \u0111\u00e3 tri\u1ec3n khai. IBM Workload Deployer, Google App Engine, Windows Azure, Force.com t\u1eeb Salesforce l\u00e0 nh\u1eefng v\u00ed d\u1ee5 v\u1ec1 PaaS Ph\u1ea7n m\u1ec1m nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Software as a Service) M\u00f4 h\u00ecnh ph\u1ed5 bi\u1ebfn m\u00e0 kh\u00e1ch h\u00e0ng s\u1eed d\u1ee5ng c\u00e1c \u1ee9ng d\u1ee5ng chuy\u00ean m\u00f4n t\u1eeb c\u00e1c thi\u1ebft b\u1ecb kh\u00e1c kh\u00e1c nhau qua m\u1ed9t tr\u00ecnh duy\u1ec7t Web tr\u00ean n\u1ec1n t\u1ea3ng d\u00f9ng chung m\u00e0 kh\u00f4ng c\u1ea7n qu\u1ea3n l\u00fd hay ki\u1ec3m so\u00e1t t\u00e0i nguy\u00ean c\u01a1 s\u1edf. V\u00ed d\u1ee5, Gmail, Google Docs, IBM LotusLive. Nh\u00e0 cung c\u1ea5p d\u1ecbch v\u1ee5 tri\u1ec3n khai g\u1ea7n nh\u01b0 to\u00e0n b\u1ed9 ho\u00e0n to\u00e0n h\u1ec7 th\u1ed1ng, c\u00e1c user s\u1ebd s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c cung c\u1ea5p. 2. Openstack \u00b6 2.1. Introduction \u00b6 Openstack l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng m\u00e3 ngu\u1ed3n m\u1edf s\u1eed d\u1ee5ng trong \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y, m\u00f4 h\u00ecnh tri\u1ec3n khai m\u00e0 Openstack h\u01b0\u1edbng \u0111\u1ebfn ch\u1ee7 y\u1ebfu l\u00e0 Private Cloud v\u00e0 Private Cloud, nh\u1edd Openstack m\u00e0 c\u00e1c m\u00e1y \u1ea3o , ho\u1eb7c storage \u0111\u01b0\u1ee3c \u0111\u01b0a ra d\u1ef1a v\u00e0o y\u00eau c\u1ea7u c\u1ee7a nh\u1edd d\u00f9ng. N\u1ec1n t\u1ea3ng n\u00e0y bao g\u1ed3m r\u1ea5t nhi\u1ec1u th\u00e0nh ph\u1ea7n nh\u01b0 hardware process, networking resource, storage. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi Openstack qu\u00e1 Web-base, Resfull API v\u00e0 CLI Openstack \u0111\u01b0\u1ee3c kh\u1edfi x\u01b0\u1edfng b\u1edfi Nasa v\u00e0 Rackspace hosting v\u00e0o n\u0103m 2010. \u0110\u1ebfn n\u0103m 2016. Openstack \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi Openstack Foundation, m\u1ed9t c\u00f4ng ty phi l\u1ee3i nhu\u1eadn nh\u1eafm ph\u00e1t tri\u1ec3n Openstack v\u00e0 nh\u1eadn \u0111\u01b0\u1ee3c s\u1ef1 \u0111\u00f3ng g\u00f3p t\u1eeb h\u01a1n 500 c\u00f4ng ty l\u1edbn nh\u1ecf v\u00e0o d\u1ef1 \u00e1n 2.1. \u0110\u1eb7c \u0111i\u1ec3m c\u1ee7a Openstack \u00b6 \u0110\u01b0\u1ee3c ph\u00e1t tri\u1ec3n theo m\u00f4 h\u00ecnh c\u1ee7a Amazon Web Service Openstack l\u00e0 m\u1ed9t d\u1ef1 \u00e1n n\u00f3i chung , ph\u00e1t tri\u1ec3n nh\u1edd s\u1ef1 h\u1ebft h\u1ee3p c\u1ee7a c\u00e1c project con : nova, glance, neutron , swift.... Openstack c\u00f3 chu k\u1ef3 6 th\u00e1ng release m\u1ed9t phi\u00ean b\u1ea3n m\u1edbi 2.2. . Ki\u1ebfn tr\u00fac Openstack Core \u00b6 S\u01a1 \u0111\u1ed3 sau \u0111\u00e2y cung c\u1ea5p m\u1ed9t c\u00e1i nh\u00ecn t\u1ed5ng quan v\u1ec1 project core trong OpenStack v\u00e0 m\u1ed1i quan h\u1ec7 c\u1ee7a ch\u00fang v\u1edbi nhau. 2.3 : C\u00e1c th\u00e0nh ph\u1ea7n c\u01a1 b\u1ea3n trong Openstack \u00b6","title":"Cloud Computing and Openstack"},{"location":"Openstack_Research/1. Intro Cloud Computing/#cloud_computing_and_openstack","text":"","title":"Cloud Computing and Openstack"},{"location":"Openstack_Research/1. Intro Cloud Computing/#1cloud_computing","text":"","title":"1.Cloud Computing"},{"location":"Openstack_Research/1. Intro Cloud Computing/#11_khai_niem_cloud_computing","text":"Kh\u00e1i ni\u1ec7m Cloud Computing, t\u1ea1i Vi\u1ec7t Nam th\u00ec \u0111a s\u1ed1 hi\u1ec3u l\u00e0 \u0110i\u1ec7n To\u00e1n \u0110\u00e1m M\u00e2y. M\u1ed9t trong c\u00e1c c\u00f4ng ngh\u1ec7 \u201chot\u201d trong v\u00e0i n\u0103m tr\u1edf l\u1ea1i \u0111\u00e2y. \u0110\u00e2y c\u0169ng l\u00e0 m\u1ed9t c\u1ee5m t\u1eeb \u0111\u01b0\u1ee3c nh\u1eafc \u0111\u1ebfn nhi\u1ec1u trong c\u00e1c b\u00e0i b\u00e1o, b\u00e0i vi\u1ebft c\u1ee7a c\u00e1c h\u00e3ng c\u00f4ng ngh\u1ec7. N\u00f3 c\u0169ng c\u00f3 nguy\u00ean m\u1ed9t \u0111\u1ecbnh ngh\u0129a c\u1ee7a Vi\u1ec7n ti\u00eau chu\u1ea9n v\u00e0 c\u00f4ng ngh\u1ec7 qu\u1ed1c gia c\u1ee7a M\u1ef9 (NIST) , th\u01b0\u1eddng \u0111\u01b0\u1ee3c tr\u00edch ra trong c\u00e1c b\u00e0i thuy\u1ebft tr\u00ecnh c\u1ee7a c\u00e1c chuy\u00ean gia (ngo\u00e0i ra, c\u00f3 nhi\u1ec1u \u0111\u1ecbnh ngh\u0129a c\u1ee7a c\u00e1c h\u00e3ng t\u00ean tu\u1ed5i kh\u00e1c nh\u01b0ng t\u00f4i kh\u00f4ng \u0111\u01b0a v\u00e0o \u0111\u00e2y). B\u1ea1n c\u00f3 th\u1ec3 xem n\u00f3 t\u1ea1i \u0111\u00e2y: \u0110\u1ecbnh ngh\u0129a v\u1ec1 Cloud Computing c\u1ee7a NIST \u0110\u1ecbnh ngh\u0129a l\u01b0\u1ee3c d\u1ecbch t\u1eeb NIST Cloud Computing l\u00e0 m\u00f4 h\u00ecnh cho ph\u00e9p truy c\u1eadp qua m\u1ea1ng \u0111\u1ec3 l\u1ef1a ch\u1ecdn v\u00e0 s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n (v\u00ed d\u1ee5: m\u1ea1ng, m\u00e1y ch\u1ee7, l\u01b0u tr\u1eef, \u1ee9ng d\u1ee5ng v\u00e0 d\u1ecbch v\u1ee5) theo nhu c\u1ea7u m\u1ed9t c\u00e1ch thu\u1eadn ti\u1ec7n v\u00e0 nhanh ch\u00f3ng; \u0111\u1ed3ng th\u1eddi cho ph\u00e9p k\u1ebft th\u00fac s\u1eed d\u1ee5ng d\u1ecbch v\u1ee5, gi\u1ea3i ph\u00f3ng t\u00e0i nguy\u00ean d\u1ec5 d\u00e0ng, gi\u1ea3m thi\u1ec3u c\u00e1c giao ti\u1ebfp v\u1edbi nh\u00e0 cung c\u1ea5p\u201d","title":"1.1 : Kh\u00e1i ni\u1ec7m Cloud Computing"},{"location":"Openstack_Research/1. Intro Cloud Computing/#12_mo_hinh_5_-_4_-_3_trong_cloud_computing","text":"5 \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a cloud computing: * Kh\u1ea3 n\u0103ng thu h\u1ed3i v\u00e0 c\u1ea5p ph\u00e1t t\u00e0i nguy\u00ean (Rapid elasticity) Truy nh\u1eadp qua c\u00e1c chu\u1ea9n m\u1ea1ng (Broad network access) D\u1ecbch v\u1ee5 s\u1eed d\u1ee5ng \u0111o \u0111\u1ebfm \u0111\u01b0\u1ee3c (Measured service,) hay l\u00e0 chi tr\u1ea3 theo m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng pay as you go. Kh\u1ea3 n\u0103ng t\u1ef1 ph\u1ee5c v\u1ee5 (On-demand self-service). Chia s\u1ebb t\u00e0i nguy\u00ean (Resource pooling). _4 m\u00f4 h\u00ecnh tri\u1ec3n khai (m\u00f4 h\u00ecnh s\u1ea3n ph\u1ea9m) : Public Cloud: \u0110\u00e1m m\u00e2y c\u00f4ng c\u1ed9ng (l\u00e0 c\u00e1c d\u1ecbch v\u1ee5 tr\u00ean n\u1ec1n t\u1ea3ng Cloud Computing \u0111\u1ec3 cho c\u00e1c c\u00e1 nh\u00e2n v\u00e0 t\u1ed5 ch\u1ee9c thu\u00ea, h\u1ecd d\u00f9ng chung t\u00e0i nguy\u00ean). Private Cloud: \u0110\u00e1m m\u00e2y ri\u00eang (d\u00f9ng trong m\u1ed9t doanh nghi\u1ec7p v\u00e0 kh\u00f4ng chia s\u1ebb v\u1edbi ng\u01b0\u1eddi d\u00f9ng ngo\u00e0i doanh nghi\u1ec7p \u0111\u00f3) . \u0110i\u1ec1u n\u00e0y gi\u00fap cho doanh nghi\u1ec7p c\u00f3 th\u1ec3 ch\u1ee7 \u0111\u1ed9ng ki\u1ec3m so\u00e1t t\u1ed1i \u0111a \u0111\u1ed1i v\u1edbi d\u1eef li\u1ec7u, b\u1ea3o m\u1eadt v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1ecbch v\u1ee5. Doanh nghi\u1ec7p s\u1edf h\u1eefu c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng v\u00e0 qu\u1ea3n l\u00fd c\u00e1c \u1ee9ng d\u1ee5ng \u0111\u01b0\u1ee3c tri\u1ec3n khai tr\u00ean \u0111\u00f3. Community Cloud: \u0110\u00e1m m\u00e2y c\u1ed9ng \u0111\u1ed3ng (l\u00e0 c\u00e1c d\u1ecbch v\u1ee5 tr\u00ean n\u1ec1n t\u1ea3ng Cloud computing do c\u00e1c c\u00f4ng ty c\u00f9ng h\u1ee3p t\u00e1c x\u00e2y d\u1ef1ng v\u00e0 cung c\u1ea5p c\u00e1c d\u1ecbch v\u1ee5 cho c\u1ed9ng \u0111\u1ed3ng. ) Hybrid Cloud : L\u00e0 m\u00f4 h\u00ecnh k\u1ebft h\u1ee3p (lai) gi\u1eefa c\u00e1c m\u00f4 h\u00ecnh Public Cloud v\u00e0 Private Cloud 3 m\u00f4 h\u00ecnh d\u1ecbch v\u1ee5:: H\u1ea1 t\u1ea7ng nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Infrastructure as a Service) : Cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng h\u1ea1 t\u1ea7ng th\u00f4 - c\u00e1c server, resource l\u00e0: RAM, CPU, Storage (th\u01b0\u1eddng l\u00e0 d\u01b0\u1edbi h\u00ecnh th\u1ee9c c\u00e1c m\u00e1y \u1ea3o) nh\u01b0 l\u00e0 m\u1ed9t d\u1ecbch v\u1ee5 D\u1ecbch v\u1ee5 IaaS ph\u1ed5 bi\u1ebfn hi\u1ec7n nay tr\u00ean th\u1ebf gi\u1edbi nh\u01b0 Amazon Cloud, Google Cloud, Microsoft N\u1ec1n t\u1ea3ng nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Platform as a Service) Cung c\u1ea5p d\u1ecbch v\u1ee5 m\u00e0 kh\u00e1ch h\u00e0ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng ng\u00f4n ng\u1eef l\u1eadp tr\u00ecnh, c\u00f4ng c\u1ee5, n\u1ec1n t\u1ea3ng \u0111\u1ec3 ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai \u1ee9ng d\u1ee5ng tr\u00ean n\u1ec1n t\u1ea3ng d\u00f9ng chung v\u1edbi kh\u1ea3 n\u0103ng ki\u1ec3m so\u00e1t m\u00f4i tr\u01b0\u1eddng v\u00e0 \u1ee9ng d\u1ee5ng \u0111\u00e3 tri\u1ec3n khai. IBM Workload Deployer, Google App Engine, Windows Azure, Force.com t\u1eeb Salesforce l\u00e0 nh\u1eefng v\u00ed d\u1ee5 v\u1ec1 PaaS Ph\u1ea7n m\u1ec1m nh\u01b0 m\u1ed9t d\u1ecbch v\u1ee5 (Software as a Service) M\u00f4 h\u00ecnh ph\u1ed5 bi\u1ebfn m\u00e0 kh\u00e1ch h\u00e0ng s\u1eed d\u1ee5ng c\u00e1c \u1ee9ng d\u1ee5ng chuy\u00ean m\u00f4n t\u1eeb c\u00e1c thi\u1ebft b\u1ecb kh\u00e1c kh\u00e1c nhau qua m\u1ed9t tr\u00ecnh duy\u1ec7t Web tr\u00ean n\u1ec1n t\u1ea3ng d\u00f9ng chung m\u00e0 kh\u00f4ng c\u1ea7n qu\u1ea3n l\u00fd hay ki\u1ec3m so\u00e1t t\u00e0i nguy\u00ean c\u01a1 s\u1edf. V\u00ed d\u1ee5, Gmail, Google Docs, IBM LotusLive. Nh\u00e0 cung c\u1ea5p d\u1ecbch v\u1ee5 tri\u1ec3n khai g\u1ea7n nh\u01b0 to\u00e0n b\u1ed9 ho\u00e0n to\u00e0n h\u1ec7 th\u1ed1ng, c\u00e1c user s\u1ebd s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c cung c\u1ea5p.","title":"1.2. M\u00f4 h\u00ecnh  5 - 4 - 3 trong Cloud Computing"},{"location":"Openstack_Research/1. Intro Cloud Computing/#2_openstack","text":"","title":"2. Openstack"},{"location":"Openstack_Research/1. Intro Cloud Computing/#21_introduction","text":"Openstack l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng m\u00e3 ngu\u1ed3n m\u1edf s\u1eed d\u1ee5ng trong \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y, m\u00f4 h\u00ecnh tri\u1ec3n khai m\u00e0 Openstack h\u01b0\u1edbng \u0111\u1ebfn ch\u1ee7 y\u1ebfu l\u00e0 Private Cloud v\u00e0 Private Cloud, nh\u1edd Openstack m\u00e0 c\u00e1c m\u00e1y \u1ea3o , ho\u1eb7c storage \u0111\u01b0\u1ee3c \u0111\u01b0a ra d\u1ef1a v\u00e0o y\u00eau c\u1ea7u c\u1ee7a nh\u1edd d\u00f9ng. N\u1ec1n t\u1ea3ng n\u00e0y bao g\u1ed3m r\u1ea5t nhi\u1ec1u th\u00e0nh ph\u1ea7n nh\u01b0 hardware process, networking resource, storage. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi Openstack qu\u00e1 Web-base, Resfull API v\u00e0 CLI Openstack \u0111\u01b0\u1ee3c kh\u1edfi x\u01b0\u1edfng b\u1edfi Nasa v\u00e0 Rackspace hosting v\u00e0o n\u0103m 2010. \u0110\u1ebfn n\u0103m 2016. Openstack \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi Openstack Foundation, m\u1ed9t c\u00f4ng ty phi l\u1ee3i nhu\u1eadn nh\u1eafm ph\u00e1t tri\u1ec3n Openstack v\u00e0 nh\u1eadn \u0111\u01b0\u1ee3c s\u1ef1 \u0111\u00f3ng g\u00f3p t\u1eeb h\u01a1n 500 c\u00f4ng ty l\u1edbn nh\u1ecf v\u00e0o d\u1ef1 \u00e1n","title":"2.1. Introduction"},{"location":"Openstack_Research/1. Intro Cloud Computing/#21_ac_iem_cua_openstack","text":"\u0110\u01b0\u1ee3c ph\u00e1t tri\u1ec3n theo m\u00f4 h\u00ecnh c\u1ee7a Amazon Web Service Openstack l\u00e0 m\u1ed9t d\u1ef1 \u00e1n n\u00f3i chung , ph\u00e1t tri\u1ec3n nh\u1edd s\u1ef1 h\u1ebft h\u1ee3p c\u1ee7a c\u00e1c project con : nova, glance, neutron , swift.... Openstack c\u00f3 chu k\u1ef3 6 th\u00e1ng release m\u1ed9t phi\u00ean b\u1ea3n m\u1edbi","title":"2.1. \u0110\u1eb7c \u0111i\u1ec3m c\u1ee7a Openstack"},{"location":"Openstack_Research/1. Intro Cloud Computing/#22_kien_truc_openstack_core","text":"S\u01a1 \u0111\u1ed3 sau \u0111\u00e2y cung c\u1ea5p m\u1ed9t c\u00e1i nh\u00ecn t\u1ed5ng quan v\u1ec1 project core trong OpenStack v\u00e0 m\u1ed1i quan h\u1ec7 c\u1ee7a ch\u00fang v\u1edbi nhau.","title":"2.2. . Ki\u1ebfn tr\u00fac Openstack Core"},{"location":"Openstack_Research/1. Intro Cloud Computing/#23_cac_thanh_phan_co_ban_trong_openstack","text":"","title":"2.3 : C\u00e1c th\u00e0nh ph\u1ea7n c\u01a1 b\u1ea3n trong Openstack"},{"location":"Openstack_Research/2.install-pack-stack/","text":"Packstack - Openstack \u00b6 1. Gi\u1edbi thi\u1ec7u Packstack \u00b6 Packstack l\u00e0 m\u1ed9t b\u1ed9 command-line s\u1eed d\u1ee5ng Puppet ( http://www.puppetlabs.com/ ) module \u0111\u1ec3 tri\u1ec3n khai nhanh Openstack th\u00f4ng qua k\u1ebft n\u1ed1i SSH. Packstack r\u1ea5t th\u00edch h\u1ee3p tri\u1ec3n khai cho c\u1ea3 single node v\u00e0 multi node. Hi\u1ec7n t\u1ea1i Packstack ch\u1ec9 h\u1ed7 tr\u1ee3 Centos v\u00e0 Redhat Enterprise Linux [RHEL] . \u01afu \u0111i\u1ec3m l\u1edbn nh\u1ea5t c\u1ee7a Packstack l\u00e0 tri\u1ec3n khai h\u1ea1 t\u1ea7ng nhanh ch\u00f3ng , s\u1eed d\u1ee5ng \u0111\u1ec3 demo , ph\u00e1t tri\u1ec3n ch\u1ee9c n\u0103ng, nh\u01b0ng \u01b0u \u0111i\u1ec3m c\u1ee7a packstack l\u00e0 trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng, vi\u1ec7c tri\u1ec3n khai ho\u00e0n to\u00e0n t\u1ef1 \u0111\u1ed9ng. 2. Tri\u1ec3n khai Packstack \u00b6 2.1 . M\u00f4 h\u00ecnh, ph\u00e2n b\u1ed5 IP, m\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai \u00b6 M\u00f4i tr\u01b0\u1eddng - OS : Centos 7.5 - Version : Openstack Queens 2.2 . Y\u00eau c\u1ea7u ph\u1ea7n c\u1ee9ng t\u1ed1i thi\u1ec3u \u00b6 Controller Node 2GB RAM 50GB disk avaliable 2 NIC Compute Node Ki\u1ec3m tra extension \u1ea3o h\u00f3a grep -E 'svm|vmx' /proc/cpuinfo | grep nx N\u1ebfu c\u00f3 ouput th\u00ec server \u0111\u00e3 h\u1ed7 tr\u1ee3 \u1ea3o h\u00f3a 2GB RAM 50GB Disk avaliable 2 NIC 2.3 . C\u1ea5u h\u00ecnh IP cho c\u00e1c Compute node \u00b6 Login v\u00e0o Controller Node , th\u1ef1c hi\u1ec7n l\u1ec7nh sau d\u01b0\u1edbi root account Thi\u1ebft l\u1eadp hostname , IP tr\u00ean t\u1ea5t c\u1ea3 Node #!/bin/bash -ex controller_name=\"controller\" host1_name=\"host1\" host2_name=\"hosts2\" controller=(\"ens192\" \"ens224\" \"192.168.30.130\" \"192.168.30.1\" \"192.168.69.130\") host1=(\"ens192\" \"ens224\" \"192.168.30.131\" \"192.168.30.1\" \"192.168.69.131\") host2=(\"ens192\" \"ens224\" \"192.168.30.132\" \"192.168.30.1\" \"192.168.69.132\") echo \"${controller[0]}\" function set_controller(){ # nmcli d modify ${controller[0]} ipv4.address ${controller[2]} # nmcli d modify ${controller[0]} ipv4.gateway ${controller[3]} # nmcli d modify ${controller[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${controller[0]} ipv4.method manual # nmcli d modify ${controller[0]} down # nmcli d modify ${controller[0]} up # nmcli d modify ${controller[0]} connection.autoconnect yes echo \"Setup IP Management Card\" systemctl start NetworkManager ip link set ${host1[1]} up nmcli d modify ${controller[1]} ipv4.address ${controller[4]} nmcli d modify ${controller[1]} ipv4.method manual nmcli d modify ${controller[1]} connection.autoconnect yes systemctl stop NetworkManager service network restart echo \"Done Set IP controller\" } function set_host1 { # echo \"Setup IP External Card ${host1_name}\" # ip link set ${host1[1]} up # nmcli d modify ${host1[0]} ipv4.address ${host1[2]}/24 # nmcli d modify ${host1[0]} ipv4.gateway ${host1[3]} # nmcli d modify ${host1[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${host1[0]} ipv4.method manual # nmcli d modify ${host1[0]} connection.autoconnect yes echo \"Setup IP Management Card ${host1_name} \" systemctl start NetworkManager ip addr flush ${host1[1]} ip link set ${host1[1]} up nmcli d modify ${host1[1]} ipv4.address ${host1[4]}/24 nmcli d modify ${host1[1]} ipv4.method manual nmcli d modify ${host1[1]} connection.autoconnect yes systemctl disable firewalld systemctl stop firewalld systemctl stop NetworkManager service network restart sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux } function set_host2 { # echo \"Setup IP External Card ${host2_name}\" # ip link set ${host2[0]} up # nmcli d modify ${host2[0]} ipv4.address ${host2[2]}/24 # nmcli d modify ${host2[0]} ipv4.gateway ${host2[3]} # nmcli d modify ${host2[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${host2[0]} ipv4.method manual # nmcli d modify ${host2[0]} connection.autoconnect yes echo \"Setup IP Management Card ${host2_name}\" ip addr flush ${host2[1]} ip link set ${host2[1]} up nmcli d modify ${host2[1]} ipv4.address ${host2[4]}/24 nmcli d modify ${host2[1]} ipv4.method manual nmcli d modify ${host2[1]} connection.autoconnect yes sudo systemctl disable firewalld sudo systemctl stop firewalld systemctl stop NetworkManager service network restart sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux reboot } echo \"------------- Setting Controller ------------- \" set_controller echo \"------------- Connect To Host 1 ------------- \" echo \"------------- Done ---------------------------\" ssh root@192.168.30.131 -t \"$(typeset -f);\\ host1_name=\"host1\" ; host1=(\"ens192\" \"ens224\" \"192.168.30.131\" \"192.168.30.1\" \"192.168.69.131\"); set_host1\" echo \"------------- Done ---------------------------\" echo \"------------- Connect To Host 2 ------------- \" ssh root@192.168.30.132 -t \"$(typeset -f);\\ host1_name=\"host1\" ; host2=(\"ens192\" \"ens224\" \"192.168.30.132\" \"192.168.30.1\" \"192.168.69.132\"); set_host2\" echo \"------------- Done ---------------------------\" 2.4. C\u00e0i \u0111\u1eb7t Packstack \u00b6 M\u1ed9t s\u1ed1 l\u01b0u \u00fd khi c\u00e0i \u0111\u1eb7t - S\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n, t\u00e0i kho\u1ea3n root \u0111\u1ec3 th\u1ef1c hi\u1ec7n - Th\u1ef1c hi\u1ec7n tr\u00ean Controller Node - Trong l\u00fac th\u1ef1c hi\u1ec7n, s\u1ebd y\u00eau c\u1ea7u password c\u1ee7a c\u00e1c Compute Node tham giaf - Qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t s\u1ebd t\u1ef1 \u0111\u1ed9ng ho\u00e0n to\u00e0n - C\u00e0i \u0111\u1eb7t packstack Queens yum install -y centos-release-openstack-queens epel-release yum install -y openstack-packstack python-pip echo \"------------------Cau hinh tong quan------------------\" packstack --gen-answer-file=/root/queens-answer.txt sed -i \"s/CONFIG_COMPUTE_HOSTS=.*/CONFIG_COMPUTE_HOSTS=192.168.69.131,192.168.69.132/g\" /root/queens-answer.txt sed -i \"s/CONFIG_PROVISION_DEMO=.*/CONFIG_PROVISION_DEMO=n/g\" /root/queens-answer.txt sed -i \"s/CONFIG_KEYSTONE_ADMIN_PW=.*/CONFIG_KEYSTONE_ADMIN_PW=123@123Aa/g\" /root/queens-answer.txt sed -i \"s/CONFIG_DEFAULT_PASSWORD=.*/CONFIG_DEFAULT_PASSWORD=123@123/g\" /root/queens-answer.txt echo \"------------------Cau hinh external network-----------\" sed -i \"s/CONFIG_NEUTRON_OVS_BRIDGE_IFACES=.*/CONFIG_NEUTRON_OVS_BRIDGE_IFACES=br-ex:ens192/g\" /root/queens-answer.txt sed -i \"s/CONFIG_HORIZON_SSL=.*/CONFIG_HORIZON_SSL=y/g\" /root/queens-answer.txt sed -i \"s/192.168.30.130/192.168.69.130/g\" /root/queens-answer.txt echo \"-----------------------DONE---------------------------\" echo \"-----------------------Cai dat------------------------\" packstack --answer-file=/root/queens-answer.txt Sau khi ch\u1ea1y script, qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t t\u1ef1 \u0111\u1ed9ng b\u1eaft \u0111\u1ea7u Sau khi c\u00e0i \u0111\u1eb7t xong, truy c\u1eadp v\u00e0o IP MGT c\u1ee7a Controller \u0111\u1ec3 s\u1eed d\u1ee5ng Horizon 2.5. L\u00e0m vi\u1ec7c v\u1edbi command-line \u00b6 Sau khi c\u00e0i \u0111\u1eb7t th\u00e0nh c\u00f4ng packstack, t\u1ea1i th\u01b0 m\u1ee5c root s\u1ebd c\u00f3 2 file openrc, cung c\u1ea5p 2 t\u00e0i kho\u1ea3n admin v\u00e0 demo . \u0110\u1ec3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin \u0111\u1ec3 x\u00e1c th\u1ef1c ta c\u1ea7n th\u1ef1c thi c\u00e1c bi\u1ebfn m\u00f4i tr\u01b0\u1eddng [root@controller ~] source ~/keystonerc_admin [root@controller ~(keystone_admin)]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-31T05:35:02+0000 | | id | gAAAAABb2TD2l-Uwo_lwKNce9tny9FkhVUi--Toar88dWJ8LgmjYNF20EbnmQgF9yImqfQt0B6cvfgzw9EapVRkzVbx7DW0LK57jtiFtnT9_G34Lx5Y9oNGE0EcaEdIepBH_j5FQ2xXSnzApCrR1sa0KqR8ikRxpZWaWJnVAsq9Kq9bEns2qb3A | | project_id | fc2293ba8d44415b8cdbf86d0e70216a | | user_id | 0dc173d110e4435ab74440adcfdd505f | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ [root@controller ~(keystone_admin)]# Upload image l\u00ean glance wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img openstack image create \"cirros\" \\ --file cirros-0.3.4-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --public Kh\u1edfi t\u1ea1o network external neutron net-create external_network --provider:network_type flat \\ --provider:physical_network extnet \\ --router:external \\ --shared Kh\u1edfi t\u1ea1o subnet cho network external neutron subnet-create --name ex_subnet --gateway 192.168.30.1 \\ --allocation-pool start=192.168.30.140,end=192.168.30.150 \\ --enable-dhcp=True external_network 192.168.30.0/24 Kh\u1edfi t\u1ea1i self-servivce nework v\u00e0 subnet neutron net-create self-net neutron subnet-create --name self-subnet self-net 10.20.20.0/24 Kh\u1edfi t\u1ea1o router neutron router-create ex_router neutron router-gateway-set ex_router external_network neutron router-interface-add ex_router self_subnet Ki\u1ec3m tra Port List tr\u00ean c\u00e1c network v\u1eeba t\u1ea1o [root@controller ~(keystone_admin)]# neutron port-list neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +--------------------------------------+------+----------------------------------+-------------------+---------------------------------------------------------------------------------------+ | id | name | tenant_id | mac_address | fixed_ips | +--------------------------------------+------+----------------------------------+-------------------+---------------------------------------------------------------------------------------+ | 03a5b603-ead6-4ace-826e-ff4fa5ee1412 | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:61:ec:72 | {\"subnet_id\": \"34dc94de-4884-45fb-9732-2705a79fb798\", \"ip_address\": \"10.20.20.1\"} | | 9075b501-104d-4215-845c-ba5ce8f2a060 | | | fa:16:3e:bf:4f:dc | {\"subnet_id\": \"449db0ad-6e9f-4b96-9927-09b4006e98d8\", \"ip_address\": \"192.168.30.148\"} | | aef9a689-f270-4a0c-9f3c-5e4b9028269b | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:bd:8d:18 | {\"subnet_id\": \"34dc94de-4884-45fb-9732-2705a79fb798\", \"ip_address\": \"10.20.20.2\"} | | d9f6cbee-2307-4b4d-bdcc-a3b440290edb | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:f0:ed:31 | {\"subnet_id\": \"449db0ad-6e9f-4b96-9927-09b4006e98d8\", \"ip_address\": \"192.168.30.140\"} | +--------------------------------------+------+----------------------------------+-------------------+------------------------------------------ Ping \u0111\u1ebfn IP trong port list provider [root@controller ~(keystone_admin)]# ping 192.168.30.140 PING 192.168.30.140 (192.168.30.140) 56(84) bytes of data. 64 bytes from 192.168.30.140: icmp_seq=1 ttl=64 time=0.673 ms 64 bytes from 192.168.30.140: icmp_seq=2 ttl=64 time=0.111 ms 64 bytes from 192.168.30.140: icmp_seq=3 ttl=64 time=0.085 ms 64 bytes from 192.168.30.140: icmp_seq=4 ttl=64 time=0.079 ms 64 bytes from 192.168.30.140: icmp_seq=5 ttl=64 time=0.082 ms 64 bytes from 192.168.30.140: icmp_seq=6 ttl=64 time=0.101 ms 64 bytes from 192.168.30.140: icmp_seq=7 ttl=64 time=0.058 ms 64 bytes from 192.168.30.140: icmp_seq=8 ttl=64 time=0.043 ms 2.56. Thao t\u00e1c v\u1edbi Dashboard \u00b6 Dashboard c\u1ee7a Packstack c\u00f3 th\u1ec3 truy c\u1eadp t\u1ea1i 192.168.30.130/dashboard T\u1ea1o m\u00e1y \u1ea3o","title":"2.install pack stack"},{"location":"Openstack_Research/2.install-pack-stack/#packstack_-_openstack","text":"","title":"Packstack - Openstack"},{"location":"Openstack_Research/2.install-pack-stack/#1_gioi_thieu_packstack","text":"Packstack l\u00e0 m\u1ed9t b\u1ed9 command-line s\u1eed d\u1ee5ng Puppet ( http://www.puppetlabs.com/ ) module \u0111\u1ec3 tri\u1ec3n khai nhanh Openstack th\u00f4ng qua k\u1ebft n\u1ed1i SSH. Packstack r\u1ea5t th\u00edch h\u1ee3p tri\u1ec3n khai cho c\u1ea3 single node v\u00e0 multi node. Hi\u1ec7n t\u1ea1i Packstack ch\u1ec9 h\u1ed7 tr\u1ee3 Centos v\u00e0 Redhat Enterprise Linux [RHEL] . \u01afu \u0111i\u1ec3m l\u1edbn nh\u1ea5t c\u1ee7a Packstack l\u00e0 tri\u1ec3n khai h\u1ea1 t\u1ea7ng nhanh ch\u00f3ng , s\u1eed d\u1ee5ng \u0111\u1ec3 demo , ph\u00e1t tri\u1ec3n ch\u1ee9c n\u0103ng, nh\u01b0ng \u01b0u \u0111i\u1ec3m c\u1ee7a packstack l\u00e0 trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng, vi\u1ec7c tri\u1ec3n khai ho\u00e0n to\u00e0n t\u1ef1 \u0111\u1ed9ng.","title":"1. Gi\u1edbi thi\u1ec7u Packstack"},{"location":"Openstack_Research/2.install-pack-stack/#2_trien_khai_packstack","text":"","title":"2. Tri\u1ec3n khai Packstack"},{"location":"Openstack_Research/2.install-pack-stack/#21_mo_hinh_phan_bo_ip_moi_truong_trien_khai","text":"M\u00f4i tr\u01b0\u1eddng - OS : Centos 7.5 - Version : Openstack Queens","title":"2.1 . M\u00f4 h\u00ecnh, ph\u00e2n b\u1ed5 IP, m\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai"},{"location":"Openstack_Research/2.install-pack-stack/#22_yeu_cau_phan_cung_toi_thieu","text":"Controller Node 2GB RAM 50GB disk avaliable 2 NIC Compute Node Ki\u1ec3m tra extension \u1ea3o h\u00f3a grep -E 'svm|vmx' /proc/cpuinfo | grep nx N\u1ebfu c\u00f3 ouput th\u00ec server \u0111\u00e3 h\u1ed7 tr\u1ee3 \u1ea3o h\u00f3a 2GB RAM 50GB Disk avaliable 2 NIC","title":"2.2 . Y\u00eau c\u1ea7u ph\u1ea7n c\u1ee9ng t\u1ed1i thi\u1ec3u"},{"location":"Openstack_Research/2.install-pack-stack/#23_cau_hinh_ip_cho_cac_compute_node","text":"Login v\u00e0o Controller Node , th\u1ef1c hi\u1ec7n l\u1ec7nh sau d\u01b0\u1edbi root account Thi\u1ebft l\u1eadp hostname , IP tr\u00ean t\u1ea5t c\u1ea3 Node #!/bin/bash -ex controller_name=\"controller\" host1_name=\"host1\" host2_name=\"hosts2\" controller=(\"ens192\" \"ens224\" \"192.168.30.130\" \"192.168.30.1\" \"192.168.69.130\") host1=(\"ens192\" \"ens224\" \"192.168.30.131\" \"192.168.30.1\" \"192.168.69.131\") host2=(\"ens192\" \"ens224\" \"192.168.30.132\" \"192.168.30.1\" \"192.168.69.132\") echo \"${controller[0]}\" function set_controller(){ # nmcli d modify ${controller[0]} ipv4.address ${controller[2]} # nmcli d modify ${controller[0]} ipv4.gateway ${controller[3]} # nmcli d modify ${controller[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${controller[0]} ipv4.method manual # nmcli d modify ${controller[0]} down # nmcli d modify ${controller[0]} up # nmcli d modify ${controller[0]} connection.autoconnect yes echo \"Setup IP Management Card\" systemctl start NetworkManager ip link set ${host1[1]} up nmcli d modify ${controller[1]} ipv4.address ${controller[4]} nmcli d modify ${controller[1]} ipv4.method manual nmcli d modify ${controller[1]} connection.autoconnect yes systemctl stop NetworkManager service network restart echo \"Done Set IP controller\" } function set_host1 { # echo \"Setup IP External Card ${host1_name}\" # ip link set ${host1[1]} up # nmcli d modify ${host1[0]} ipv4.address ${host1[2]}/24 # nmcli d modify ${host1[0]} ipv4.gateway ${host1[3]} # nmcli d modify ${host1[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${host1[0]} ipv4.method manual # nmcli d modify ${host1[0]} connection.autoconnect yes echo \"Setup IP Management Card ${host1_name} \" systemctl start NetworkManager ip addr flush ${host1[1]} ip link set ${host1[1]} up nmcli d modify ${host1[1]} ipv4.address ${host1[4]}/24 nmcli d modify ${host1[1]} ipv4.method manual nmcli d modify ${host1[1]} connection.autoconnect yes systemctl disable firewalld systemctl stop firewalld systemctl stop NetworkManager service network restart sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux } function set_host2 { # echo \"Setup IP External Card ${host2_name}\" # ip link set ${host2[0]} up # nmcli d modify ${host2[0]} ipv4.address ${host2[2]}/24 # nmcli d modify ${host2[0]} ipv4.gateway ${host2[3]} # nmcli d modify ${host2[0]} ipv4.dns 1.1.1.1 # nmcli d modify ${host2[0]} ipv4.method manual # nmcli d modify ${host2[0]} connection.autoconnect yes echo \"Setup IP Management Card ${host2_name}\" ip addr flush ${host2[1]} ip link set ${host2[1]} up nmcli d modify ${host2[1]} ipv4.address ${host2[4]}/24 nmcli d modify ${host2[1]} ipv4.method manual nmcli d modify ${host2[1]} connection.autoconnect yes sudo systemctl disable firewalld sudo systemctl stop firewalld systemctl stop NetworkManager service network restart sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux reboot } echo \"------------- Setting Controller ------------- \" set_controller echo \"------------- Connect To Host 1 ------------- \" echo \"------------- Done ---------------------------\" ssh root@192.168.30.131 -t \"$(typeset -f);\\ host1_name=\"host1\" ; host1=(\"ens192\" \"ens224\" \"192.168.30.131\" \"192.168.30.1\" \"192.168.69.131\"); set_host1\" echo \"------------- Done ---------------------------\" echo \"------------- Connect To Host 2 ------------- \" ssh root@192.168.30.132 -t \"$(typeset -f);\\ host1_name=\"host1\" ; host2=(\"ens192\" \"ens224\" \"192.168.30.132\" \"192.168.30.1\" \"192.168.69.132\"); set_host2\" echo \"------------- Done ---------------------------\"","title":"2.3 . C\u1ea5u h\u00ecnh IP  cho c\u00e1c Compute node"},{"location":"Openstack_Research/2.install-pack-stack/#24_cai_at_packstack","text":"M\u1ed9t s\u1ed1 l\u01b0u \u00fd khi c\u00e0i \u0111\u1eb7t - S\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n, t\u00e0i kho\u1ea3n root \u0111\u1ec3 th\u1ef1c hi\u1ec7n - Th\u1ef1c hi\u1ec7n tr\u00ean Controller Node - Trong l\u00fac th\u1ef1c hi\u1ec7n, s\u1ebd y\u00eau c\u1ea7u password c\u1ee7a c\u00e1c Compute Node tham giaf - Qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t s\u1ebd t\u1ef1 \u0111\u1ed9ng ho\u00e0n to\u00e0n - C\u00e0i \u0111\u1eb7t packstack Queens yum install -y centos-release-openstack-queens epel-release yum install -y openstack-packstack python-pip echo \"------------------Cau hinh tong quan------------------\" packstack --gen-answer-file=/root/queens-answer.txt sed -i \"s/CONFIG_COMPUTE_HOSTS=.*/CONFIG_COMPUTE_HOSTS=192.168.69.131,192.168.69.132/g\" /root/queens-answer.txt sed -i \"s/CONFIG_PROVISION_DEMO=.*/CONFIG_PROVISION_DEMO=n/g\" /root/queens-answer.txt sed -i \"s/CONFIG_KEYSTONE_ADMIN_PW=.*/CONFIG_KEYSTONE_ADMIN_PW=123@123Aa/g\" /root/queens-answer.txt sed -i \"s/CONFIG_DEFAULT_PASSWORD=.*/CONFIG_DEFAULT_PASSWORD=123@123/g\" /root/queens-answer.txt echo \"------------------Cau hinh external network-----------\" sed -i \"s/CONFIG_NEUTRON_OVS_BRIDGE_IFACES=.*/CONFIG_NEUTRON_OVS_BRIDGE_IFACES=br-ex:ens192/g\" /root/queens-answer.txt sed -i \"s/CONFIG_HORIZON_SSL=.*/CONFIG_HORIZON_SSL=y/g\" /root/queens-answer.txt sed -i \"s/192.168.30.130/192.168.69.130/g\" /root/queens-answer.txt echo \"-----------------------DONE---------------------------\" echo \"-----------------------Cai dat------------------------\" packstack --answer-file=/root/queens-answer.txt Sau khi ch\u1ea1y script, qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t t\u1ef1 \u0111\u1ed9ng b\u1eaft \u0111\u1ea7u Sau khi c\u00e0i \u0111\u1eb7t xong, truy c\u1eadp v\u00e0o IP MGT c\u1ee7a Controller \u0111\u1ec3 s\u1eed d\u1ee5ng Horizon","title":"2.4.  C\u00e0i \u0111\u1eb7t Packstack"},{"location":"Openstack_Research/2.install-pack-stack/#25_lam_viec_voi_command-line","text":"Sau khi c\u00e0i \u0111\u1eb7t th\u00e0nh c\u00f4ng packstack, t\u1ea1i th\u01b0 m\u1ee5c root s\u1ebd c\u00f3 2 file openrc, cung c\u1ea5p 2 t\u00e0i kho\u1ea3n admin v\u00e0 demo . \u0110\u1ec3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin \u0111\u1ec3 x\u00e1c th\u1ef1c ta c\u1ea7n th\u1ef1c thi c\u00e1c bi\u1ebfn m\u00f4i tr\u01b0\u1eddng [root@controller ~] source ~/keystonerc_admin [root@controller ~(keystone_admin)]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-31T05:35:02+0000 | | id | gAAAAABb2TD2l-Uwo_lwKNce9tny9FkhVUi--Toar88dWJ8LgmjYNF20EbnmQgF9yImqfQt0B6cvfgzw9EapVRkzVbx7DW0LK57jtiFtnT9_G34Lx5Y9oNGE0EcaEdIepBH_j5FQ2xXSnzApCrR1sa0KqR8ikRxpZWaWJnVAsq9Kq9bEns2qb3A | | project_id | fc2293ba8d44415b8cdbf86d0e70216a | | user_id | 0dc173d110e4435ab74440adcfdd505f | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ [root@controller ~(keystone_admin)]# Upload image l\u00ean glance wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img openstack image create \"cirros\" \\ --file cirros-0.3.4-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --public Kh\u1edfi t\u1ea1o network external neutron net-create external_network --provider:network_type flat \\ --provider:physical_network extnet \\ --router:external \\ --shared Kh\u1edfi t\u1ea1o subnet cho network external neutron subnet-create --name ex_subnet --gateway 192.168.30.1 \\ --allocation-pool start=192.168.30.140,end=192.168.30.150 \\ --enable-dhcp=True external_network 192.168.30.0/24 Kh\u1edfi t\u1ea1i self-servivce nework v\u00e0 subnet neutron net-create self-net neutron subnet-create --name self-subnet self-net 10.20.20.0/24 Kh\u1edfi t\u1ea1o router neutron router-create ex_router neutron router-gateway-set ex_router external_network neutron router-interface-add ex_router self_subnet Ki\u1ec3m tra Port List tr\u00ean c\u00e1c network v\u1eeba t\u1ea1o [root@controller ~(keystone_admin)]# neutron port-list neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +--------------------------------------+------+----------------------------------+-------------------+---------------------------------------------------------------------------------------+ | id | name | tenant_id | mac_address | fixed_ips | +--------------------------------------+------+----------------------------------+-------------------+---------------------------------------------------------------------------------------+ | 03a5b603-ead6-4ace-826e-ff4fa5ee1412 | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:61:ec:72 | {\"subnet_id\": \"34dc94de-4884-45fb-9732-2705a79fb798\", \"ip_address\": \"10.20.20.1\"} | | 9075b501-104d-4215-845c-ba5ce8f2a060 | | | fa:16:3e:bf:4f:dc | {\"subnet_id\": \"449db0ad-6e9f-4b96-9927-09b4006e98d8\", \"ip_address\": \"192.168.30.148\"} | | aef9a689-f270-4a0c-9f3c-5e4b9028269b | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:bd:8d:18 | {\"subnet_id\": \"34dc94de-4884-45fb-9732-2705a79fb798\", \"ip_address\": \"10.20.20.2\"} | | d9f6cbee-2307-4b4d-bdcc-a3b440290edb | | fc2293ba8d44415b8cdbf86d0e70216a | fa:16:3e:f0:ed:31 | {\"subnet_id\": \"449db0ad-6e9f-4b96-9927-09b4006e98d8\", \"ip_address\": \"192.168.30.140\"} | +--------------------------------------+------+----------------------------------+-------------------+------------------------------------------ Ping \u0111\u1ebfn IP trong port list provider [root@controller ~(keystone_admin)]# ping 192.168.30.140 PING 192.168.30.140 (192.168.30.140) 56(84) bytes of data. 64 bytes from 192.168.30.140: icmp_seq=1 ttl=64 time=0.673 ms 64 bytes from 192.168.30.140: icmp_seq=2 ttl=64 time=0.111 ms 64 bytes from 192.168.30.140: icmp_seq=3 ttl=64 time=0.085 ms 64 bytes from 192.168.30.140: icmp_seq=4 ttl=64 time=0.079 ms 64 bytes from 192.168.30.140: icmp_seq=5 ttl=64 time=0.082 ms 64 bytes from 192.168.30.140: icmp_seq=6 ttl=64 time=0.101 ms 64 bytes from 192.168.30.140: icmp_seq=7 ttl=64 time=0.058 ms 64 bytes from 192.168.30.140: icmp_seq=8 ttl=64 time=0.043 ms","title":"2.5. L\u00e0m vi\u1ec7c v\u1edbi command-line"},{"location":"Openstack_Research/2.install-pack-stack/#256_thao_tac_voi_dashboard","text":"Dashboard c\u1ee7a Packstack c\u00f3 th\u1ec3 truy c\u1eadp t\u1ea1i 192.168.30.130/dashboard T\u1ea1o m\u00e1y \u1ea3o","title":"2.56. Thao t\u00e1c v\u1edbi Dashboard"},{"location":"Openstack_Research/Readme/","text":"Ghi ch\u00e9p qu\u00e1 tr\u00ecnh t\u00ecm hi\u1ec3u OpenStack - Creator : Nguyen Trong Hung - M\u00f4i tr\u01b0\u1eddng : Centos 7.5 - Phi\u00ean b\u1ea3n : Openstack Queens - Hypervisor : KVM/QEMU - C\u00f3 s\u1eed d\u1ee5ng FirewallD, kh\u00f4ng s\u1eed d\u1ee5ng SeLinux ( permissive mode ) M\u1ee5c L\u1ee5c \u00b6 1. Gi\u1edbi thi\u1ec7u \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Cloud Computing v\u00e0 Openstack C\u00e0i th\u1eed nghi\u1ec7m Openstack s\u1eed d\u1ee5ng Packstack 2. Keystone \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Identity C\u00e0i \u0111\u1eb7t Keystone C\u00e1c t\u00f9y ch\u1ecdn trong Keystone L\u00e0m vi\u1ec7c v\u1edbi Keystone L\u00e0m vi\u1ec7c v\u1edbi Keystone (2) Token trong Keystone 3. Glance \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Image Service C\u00e0i \u0111\u1eb7t Glance L\u00e0m vi\u1ec7c v\u1edbi Glance C\u00e1c t\u00f9y ch\u1ecdn trong Glance C\u00e1c qu\u00e1 tr\u00ecnh trong Glance 4. Nova \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Compute Service C\u00e0i \u0111\u1eb7t Nova L\u00e0m vi\u1ec7c v\u1edbi Nova C\u00e1c qu\u00e1 tr\u00ecnh trong Nova Debug C\u00e1c c\u1ea5u h\u00ecnh trong Nova 5. Neutron \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Neutron C\u00e0i \u0111\u1eb7t Neutron Linux Bridge - Self-Service C\u00e0i \u0111\u1eb7t Neutro OVS - Self-Service C\u00e0i \u0111\u1eb7t Neutron OVS - Provider L\u00e0m vi\u1ec7c v\u1edbi Neutron T\u00ecm hi\u1ec3u c\u00e1c Namespace, Agent trong Neutron Packet Flow s\u1eed d\u1ee5ng Linux Bridge C\u1ea5u h\u00ecnh Bonding T\u00ecm hi\u1ec3u VXLAN T\u00ecm hi\u1ec3u OpenvSwitch trong OPS Packet Flow s\u1eed d\u1ee5ng OpenvSwitch - Self Service Packet Flow s\u1eed dung OpenvSwitch - Provider 6. Cinder \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 Cinder M\u1ed1i quan h\u1ec7 gi\u1eefa instance v\u00e0 disk C\u00e0i \u0111\u1eb7t Cinder s\u1eed d\u1ee5ng LVM backend C\u00e0i \u0111\u1eb7t Cinder s\u1eed d\u1ee5ng LVM v\u00e0 NFS S\u1eed d\u1ee5ng Cinder c\u01a1 b\u1ea3n Filter trong Multi Backend Cinder 7. HA Proxy v\u00e0 KeepAlived \u00b6 Gi\u1edbi thi\u1ec7u v\u1ec1 HA, HA Proxy v\u00e0 Keep Alived C\u00e0i \u0111\u1eb7t HA Proxy v\u00e0 Keep Alived C\u00e0i \u0111\u1eb7t HA Proxy v\u00e0 Keep Alived tr\u00ean Openstack VM 8. Barbican \u00b6 Gi\u1edbi thi\u1ec7u v\u00e0 c\u00e0i \u0111\u1eb7t Barbican Thao t\u00e1c c\u01a1 b\u1ea3n v\u1edbi Barbican 9. Octavia \u00b6 Gi\u1edbi thi\u1ec7u v\u00e0 c\u00e0i \u0111\u1eb7t Octavia Single S\u1eed d\u1ee5ng Octavia Self-Service C\u00e0i \u0111\u1eb7t , s\u1eed d\u1ee5ng Octavia Provider && Deep Dive Amphora VM S\u1eed d\u1ee5ng Octaiva VIP QOS L\u00fd thuy\u1ebft Octavia L7 Policy S\u1eed d\u1ee5ng Octavia L7 Policy 10. M\u1edf r\u1ed9ng \u00b6 Key Rorate v\u00e0 Decrypt trong Keystone S\u1eed d\u1ee5ng RabbitMQ v\u00e0 Endpoint trong Openstack Log trong Openstack C\u1ea5u h\u00ecnh noVNC Node Li\u00ean h\u1ec7 gi\u1eefa Nova-Compute v\u00e0 RabbitMQ Placment API v\u00e0 Nova Conductor trong Openstack Qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean trong Nova Nova-Scheduler v\u00e0 Filter trong Nova Host Aggregate trong Nova-Scheduler Resize instance Recuse instnace Gi\u1edbi h\u1ea1n CPU Resource trong Nova Metadata C\u1ea5u h\u00ecnh VXLAN OVS Tunnel C\u1ea5u h\u00ecnh join VXLAN Tunnel Openstack T\u00ecm hi\u1ec3u Cloud Init T\u00ecm hi\u1ec3u Cloud INIT -2 T\u00ecm hi\u1ec3u QOS trong Neutron T\u00ecm hi\u1ec3u QOS trong Cinder T\u00ecm hi\u1ec3u Cinder Backup s\u1eed d\u1ee5ng NFS T\u00ecm hi\u1ec3u Transfer v\u00e0 Extend Volume T\u00ecm hi\u1ec3u c\u1ea5u h\u00ecnh HA L3 Agent tr\u00ean c\u00e1c Compute Node","title":"Readme"},{"location":"Openstack_Research/Readme/#muc_luc","text":"","title":"M\u1ee5c L\u1ee5c"},{"location":"Openstack_Research/Readme/#1_gioi_thieu","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Cloud Computing v\u00e0 Openstack C\u00e0i th\u1eed nghi\u1ec7m Openstack s\u1eed d\u1ee5ng Packstack","title":"1. Gi\u1edbi thi\u1ec7u"},{"location":"Openstack_Research/Readme/#2_keystone","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Identity C\u00e0i \u0111\u1eb7t Keystone C\u00e1c t\u00f9y ch\u1ecdn trong Keystone L\u00e0m vi\u1ec7c v\u1edbi Keystone L\u00e0m vi\u1ec7c v\u1edbi Keystone (2) Token trong Keystone","title":"2. Keystone"},{"location":"Openstack_Research/Readme/#3_glance","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Image Service C\u00e0i \u0111\u1eb7t Glance L\u00e0m vi\u1ec7c v\u1edbi Glance C\u00e1c t\u00f9y ch\u1ecdn trong Glance C\u00e1c qu\u00e1 tr\u00ecnh trong Glance","title":"3. Glance"},{"location":"Openstack_Research/Readme/#4_nova","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Openstack Compute Service C\u00e0i \u0111\u1eb7t Nova L\u00e0m vi\u1ec7c v\u1edbi Nova C\u00e1c qu\u00e1 tr\u00ecnh trong Nova Debug C\u00e1c c\u1ea5u h\u00ecnh trong Nova","title":"4. Nova"},{"location":"Openstack_Research/Readme/#5_neutron","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Neutron C\u00e0i \u0111\u1eb7t Neutron Linux Bridge - Self-Service C\u00e0i \u0111\u1eb7t Neutro OVS - Self-Service C\u00e0i \u0111\u1eb7t Neutron OVS - Provider L\u00e0m vi\u1ec7c v\u1edbi Neutron T\u00ecm hi\u1ec3u c\u00e1c Namespace, Agent trong Neutron Packet Flow s\u1eed d\u1ee5ng Linux Bridge C\u1ea5u h\u00ecnh Bonding T\u00ecm hi\u1ec3u VXLAN T\u00ecm hi\u1ec3u OpenvSwitch trong OPS Packet Flow s\u1eed d\u1ee5ng OpenvSwitch - Self Service Packet Flow s\u1eed dung OpenvSwitch - Provider","title":"5. Neutron"},{"location":"Openstack_Research/Readme/#6_cinder","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 Cinder M\u1ed1i quan h\u1ec7 gi\u1eefa instance v\u00e0 disk C\u00e0i \u0111\u1eb7t Cinder s\u1eed d\u1ee5ng LVM backend C\u00e0i \u0111\u1eb7t Cinder s\u1eed d\u1ee5ng LVM v\u00e0 NFS S\u1eed d\u1ee5ng Cinder c\u01a1 b\u1ea3n Filter trong Multi Backend Cinder","title":"6. Cinder"},{"location":"Openstack_Research/Readme/#7_ha_proxy_va_keepalived","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 HA, HA Proxy v\u00e0 Keep Alived C\u00e0i \u0111\u1eb7t HA Proxy v\u00e0 Keep Alived C\u00e0i \u0111\u1eb7t HA Proxy v\u00e0 Keep Alived tr\u00ean Openstack VM","title":"7. HA Proxy v\u00e0 KeepAlived"},{"location":"Openstack_Research/Readme/#8_barbican","text":"Gi\u1edbi thi\u1ec7u v\u00e0 c\u00e0i \u0111\u1eb7t Barbican Thao t\u00e1c c\u01a1 b\u1ea3n v\u1edbi Barbican","title":"8. Barbican"},{"location":"Openstack_Research/Readme/#9_octavia","text":"Gi\u1edbi thi\u1ec7u v\u00e0 c\u00e0i \u0111\u1eb7t Octavia Single S\u1eed d\u1ee5ng Octavia Self-Service C\u00e0i \u0111\u1eb7t , s\u1eed d\u1ee5ng Octavia Provider && Deep Dive Amphora VM S\u1eed d\u1ee5ng Octaiva VIP QOS L\u00fd thuy\u1ebft Octavia L7 Policy S\u1eed d\u1ee5ng Octavia L7 Policy","title":"9. Octavia"},{"location":"Openstack_Research/Readme/#10_mo_rong","text":"Key Rorate v\u00e0 Decrypt trong Keystone S\u1eed d\u1ee5ng RabbitMQ v\u00e0 Endpoint trong Openstack Log trong Openstack C\u1ea5u h\u00ecnh noVNC Node Li\u00ean h\u1ec7 gi\u1eefa Nova-Compute v\u00e0 RabbitMQ Placment API v\u00e0 Nova Conductor trong Openstack Qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean trong Nova Nova-Scheduler v\u00e0 Filter trong Nova Host Aggregate trong Nova-Scheduler Resize instance Recuse instnace Gi\u1edbi h\u1ea1n CPU Resource trong Nova Metadata C\u1ea5u h\u00ecnh VXLAN OVS Tunnel C\u1ea5u h\u00ecnh join VXLAN Tunnel Openstack T\u00ecm hi\u1ec3u Cloud Init T\u00ecm hi\u1ec3u Cloud INIT -2 T\u00ecm hi\u1ec3u QOS trong Neutron T\u00ecm hi\u1ec3u QOS trong Cinder T\u00ecm hi\u1ec3u Cinder Backup s\u1eed d\u1ee5ng NFS T\u00ecm hi\u1ec3u Transfer v\u00e0 Extend Volume T\u00ecm hi\u1ec3u c\u1ea5u h\u00ecnh HA L3 Agent tr\u00ean c\u00e1c Compute Node","title":"10. M\u1edf r\u1ed9ng"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/","text":"Fernet v\u00e0 Rotate trong OPS \u00b6 1. Key Rotation Tooling \u00b6 Key Rotate xem x\u00e9t c\u00e1c key \u0111\u1ec3 c\u00f3 m\u1ed9t trong 2 m\u1ee5c \u0111\u00edch v\u00e0 1 trong 3 tr\u1ea1ng th\u00e1i . M\u1ed7i key trong key repo c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 encrypt v\u00e0 decrypt ho\u1eb7c ch\u1ec9 c\u00f3 th\u1ec3 ch\u1ec9 d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3 ( c\u00f3 th\u1ec3 ch\u1ee7 \u0111\u1ed9ng ho\u1eb7c th\u1ee5 \u0111\u1ed9ng ) Ph\u00e2n bi\u1ec7t c\u00e1c lo\u1ea1i key : Primary key : s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o token ( encrypt ) v\u00e0 \u0111\u1ec3 validation . C\u00f3 th\u1ec3 n\u00f3i \u0111\u00e2y l\u00e0 active key . M\u1ed7i khi m\u1ed9t user c\u1ea7n x\u00e1c th\u1ef1c ho\u1eb7c \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c API , key n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng . Ch\u1ec9 c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i m\u1ed9t primry key v\u00e0 ph\u1ea3i t\u1ed3n t\u1ea1i tr\u00ean c\u00e1c node d\u00f9ng Keystone \u0111\u1ec3 x\u00e1c th\u1ef1c . Primary key lu\u00f4n c\u00f3 index cao nh\u1ea5t Secondary key : s\u1eed d\u1ee5ng \u0111\u1ec3 validation token . Nh\u1eefng key n\u00e0y \u0111\u01b0\u1ee3c chuy\u1ec3n t\u1eeb primary key, do \u0111\u00f3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ec3 validate token, c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i sau khi m\u1ed9t primary key m\u1edbi \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o. C\u00f3 th\u1ec3 c\u00f3 nhi\u1ec1u primary key, t\u00f9y v\u00e0o max_active_key \u0111\u1ec3x\u00e1c \u0111\u1ecbnh s\u1ed1 secondary key c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i c\u00f9ng 1 th\u1eddi \u0111i\u1ec3m Staged key : Nh\u1eefng key n\u00e0y s\u1ebd c\u00f3 index nh\u1ecf nh\u1ea5t ( 0 ) . Khi key repo \u0111\u01b0\u1ee3c rotate, nh\u1eefng key n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n nhi\u1ec7m v\u1ee5 th\u00e0nh primary key v\u1edbi ch\u1ec9 s\u1ed1 index cao nh\u1ea5t . Nh\u1eefng key n\u00e0y cho ph\u00e9p sao ch\u00e9p gi\u1eefa c\u00e1c node trong cluster ch\u1ee9c khi n\u00f3 th\u00e0nh primary key . Key n\u00e0y cho ph\u00e9p keystone tr\u00e1nh \u0111\u01b0\u1ee3c khi x\u00e1c th\u1ef1c m\u00e0 kh\u00f4ng c\u00f3 encrypt key . Qu\u00e1 tr\u00ecnh rotate key repo v\u1edbi max_active_keys = 4 B1 : Sau khi thi\u1ebft l\u1eadp m\u1ed9t key repo m\u1edbi s\u1ebd c\u00f3 2 key . Key file c\u00f3 index cao h\u01a1n s\u1ebd l\u00e0 primaray key ( 1) , c\u00f2n l\u1ea1i s\u1ebd l\u00e0 staged key ( 0 ) 0 ( staged : the next primary key) 1 ( primary : token generation & validation) B2 : Khi rotate ( 0 ) s\u1ebd l\u00ean l\u00e0m primary key ( 2 ) m\u1edbi , trong khi \u0111\u00f3 primaray key ( 1 ) s\u1ebd v\u1ec1 l\u00e0m secondary ( 1 ) m\u1edbi 0 ( staged : the next primary key) 1 (secondary: token validation) 2 ( primary : token generation & validation) B3 : Staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key ( 3 ) , primary key c\u0169 ( 3 ) s\u1ebd tr\u1edf th\u00e0nh seconday key ( 2 ) , seconday c\u0169 ( 1 ) v\u1eabn l\u00e0 kh\u00f3a ph\u1ee5 0 ( staged : the next primary key) : 1 (secondary: token validation) : 2 (secondary: token validation)- : 3 ( primary : token generation & validation) B4 : L\u1ea7n rotate ti\u1ebfp theo , s\u1ed1 key \u0111\u00e3 \u0111\u1ebfn ng\u01b0\u1ee1ng max_active_keys . Secondary key c\u0169 nh\u1ea5t ( 1 ) s\u1ebd b\u1ecb x\u00f3a . Staged key ( 0 ) s\u1ebd th\u00e0nh primary key ( 3 ) . Primary key ( 3 ) c\u0169 s\u1ebd th\u00e0nh secondary key ( 2 ) 0 ( staged : the next primary key) 1 (deleted) 2 (secondary: token validation) 3 (secondary: token validation) - 4 ( primary : token generation & validation C\u00f4ng th\u01b0c t\u00ednh max_active_key fernet-keys = ( token-validity(hours) / rotation-time(hours) ) + 2 Rotate key m\u1ed7i 30 ph\u00fat yum -y install cronie-noanacron service crond start cat << EOF >> /etc/crontab 30 * * * * root keystone-manage fernet_rotate --keystone-user keystone --keystone-group keystone EOF Cron Tab MAP Example of job definition: .---------------- minute (0 - 59) | .------------- hour (0 - 23) | | .---------- day of month (1 - 31) | | | .------- month (1 - 12) OR jan,feb,mar,apr ... | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat | | | | |# * * * * * user-name command to be executed 2. Decrypt Keystone Token \u00b6 C\u00e0i \u0111\u1eb7t python cryptography pip install ryptography Code Decrypt from cryptography.fernet import Fernet import sys import binascii import base64 cipher_suite = Fernet(\"j_Hhlxn8VmJDTjdAweSVfrS7A9e8NPvxhGrENrRW2XQ=\") token = \"gAAAAABb7jmviEf4K_5mnvfJ47p-_xC3XFqEehjLqLEhMRQ159YW0eex9xH6H7XKCCDOV-V1qoUxyMBfqVy2P0AOept_vnLZgHdbqmjO0iPu3YAF4QOnc73cR2jzjcmN9RIi7JJzi93e8y0-7i9DfDnjtuTLEr7cgxTuRBW1d966gg0GGFIPlZY\" plain_text = cipher_suite.decrypt(token) print \"Plain text: \"+plain_text \u0110ang b\u1ecb l\u1ed7i \u00b6 3. Tham kh\u1ea3o th\u00eam \u00b6 [1 ] : https://docs.openstack.org/newton/admin-guide/identity-fernet-token-faq.html [2] : https://redhatstackblog.redhat.com/2017/12/20/using-ansible-for-fernet-key-rotation-on-red-hat-openstack-platform-11/ [3]","title":"Fernet v\u00e0 Rotate trong OPS"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/#fernet_va_rotate_trong_ops","text":"","title":"Fernet v\u00e0 Rotate trong OPS"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/#1_key_rotation_tooling","text":"Key Rotate xem x\u00e9t c\u00e1c key \u0111\u1ec3 c\u00f3 m\u1ed9t trong 2 m\u1ee5c \u0111\u00edch v\u00e0 1 trong 3 tr\u1ea1ng th\u00e1i . M\u1ed7i key trong key repo c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 encrypt v\u00e0 decrypt ho\u1eb7c ch\u1ec9 c\u00f3 th\u1ec3 ch\u1ec9 d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3 ( c\u00f3 th\u1ec3 ch\u1ee7 \u0111\u1ed9ng ho\u1eb7c th\u1ee5 \u0111\u1ed9ng ) Ph\u00e2n bi\u1ec7t c\u00e1c lo\u1ea1i key : Primary key : s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o token ( encrypt ) v\u00e0 \u0111\u1ec3 validation . C\u00f3 th\u1ec3 n\u00f3i \u0111\u00e2y l\u00e0 active key . M\u1ed7i khi m\u1ed9t user c\u1ea7n x\u00e1c th\u1ef1c ho\u1eb7c \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c API , key n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng . Ch\u1ec9 c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i m\u1ed9t primry key v\u00e0 ph\u1ea3i t\u1ed3n t\u1ea1i tr\u00ean c\u00e1c node d\u00f9ng Keystone \u0111\u1ec3 x\u00e1c th\u1ef1c . Primary key lu\u00f4n c\u00f3 index cao nh\u1ea5t Secondary key : s\u1eed d\u1ee5ng \u0111\u1ec3 validation token . Nh\u1eefng key n\u00e0y \u0111\u01b0\u1ee3c chuy\u1ec3n t\u1eeb primary key, do \u0111\u00f3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ec3 validate token, c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i sau khi m\u1ed9t primary key m\u1edbi \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o. C\u00f3 th\u1ec3 c\u00f3 nhi\u1ec1u primary key, t\u00f9y v\u00e0o max_active_key \u0111\u1ec3x\u00e1c \u0111\u1ecbnh s\u1ed1 secondary key c\u00f3 th\u1ec3 t\u1ed3n t\u1ea1i c\u00f9ng 1 th\u1eddi \u0111i\u1ec3m Staged key : Nh\u1eefng key n\u00e0y s\u1ebd c\u00f3 index nh\u1ecf nh\u1ea5t ( 0 ) . Khi key repo \u0111\u01b0\u1ee3c rotate, nh\u1eefng key n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n nhi\u1ec7m v\u1ee5 th\u00e0nh primary key v\u1edbi ch\u1ec9 s\u1ed1 index cao nh\u1ea5t . Nh\u1eefng key n\u00e0y cho ph\u00e9p sao ch\u00e9p gi\u1eefa c\u00e1c node trong cluster ch\u1ee9c khi n\u00f3 th\u00e0nh primary key . Key n\u00e0y cho ph\u00e9p keystone tr\u00e1nh \u0111\u01b0\u1ee3c khi x\u00e1c th\u1ef1c m\u00e0 kh\u00f4ng c\u00f3 encrypt key . Qu\u00e1 tr\u00ecnh rotate key repo v\u1edbi max_active_keys = 4 B1 : Sau khi thi\u1ebft l\u1eadp m\u1ed9t key repo m\u1edbi s\u1ebd c\u00f3 2 key . Key file c\u00f3 index cao h\u01a1n s\u1ebd l\u00e0 primaray key ( 1) , c\u00f2n l\u1ea1i s\u1ebd l\u00e0 staged key ( 0 ) 0 ( staged : the next primary key) 1 ( primary : token generation & validation) B2 : Khi rotate ( 0 ) s\u1ebd l\u00ean l\u00e0m primary key ( 2 ) m\u1edbi , trong khi \u0111\u00f3 primaray key ( 1 ) s\u1ebd v\u1ec1 l\u00e0m secondary ( 1 ) m\u1edbi 0 ( staged : the next primary key) 1 (secondary: token validation) 2 ( primary : token generation & validation) B3 : Staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key ( 3 ) , primary key c\u0169 ( 3 ) s\u1ebd tr\u1edf th\u00e0nh seconday key ( 2 ) , seconday c\u0169 ( 1 ) v\u1eabn l\u00e0 kh\u00f3a ph\u1ee5 0 ( staged : the next primary key) : 1 (secondary: token validation) : 2 (secondary: token validation)- : 3 ( primary : token generation & validation) B4 : L\u1ea7n rotate ti\u1ebfp theo , s\u1ed1 key \u0111\u00e3 \u0111\u1ebfn ng\u01b0\u1ee1ng max_active_keys . Secondary key c\u0169 nh\u1ea5t ( 1 ) s\u1ebd b\u1ecb x\u00f3a . Staged key ( 0 ) s\u1ebd th\u00e0nh primary key ( 3 ) . Primary key ( 3 ) c\u0169 s\u1ebd th\u00e0nh secondary key ( 2 ) 0 ( staged : the next primary key) 1 (deleted) 2 (secondary: token validation) 3 (secondary: token validation) - 4 ( primary : token generation & validation C\u00f4ng th\u01b0c t\u00ednh max_active_key fernet-keys = ( token-validity(hours) / rotation-time(hours) ) + 2 Rotate key m\u1ed7i 30 ph\u00fat yum -y install cronie-noanacron service crond start cat << EOF >> /etc/crontab 30 * * * * root keystone-manage fernet_rotate --keystone-user keystone --keystone-group keystone EOF Cron Tab MAP Example of job definition: .---------------- minute (0 - 59) | .------------- hour (0 - 23) | | .---------- day of month (1 - 31) | | | .------- month (1 - 12) OR jan,feb,mar,apr ... | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat | | | | |# * * * * * user-name command to be executed","title":"1. Key Rotation Tooling"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/#2_decrypt_keystone_token","text":"C\u00e0i \u0111\u1eb7t python cryptography pip install ryptography Code Decrypt from cryptography.fernet import Fernet import sys import binascii import base64 cipher_suite = Fernet(\"j_Hhlxn8VmJDTjdAweSVfrS7A9e8NPvxhGrENrRW2XQ=\") token = \"gAAAAABb7jmviEf4K_5mnvfJ47p-_xC3XFqEehjLqLEhMRQ159YW0eex9xH6H7XKCCDOV-V1qoUxyMBfqVy2P0AOept_vnLZgHdbqmjO0iPu3YAF4QOnc73cR2jzjcmN9RIi7JJzi93e8y0-7i9DfDnjtuTLEr7cgxTuRBW1d966gg0GGFIPlZY\" plain_text = cipher_suite.decrypt(token) print \"Plain text: \"+plain_text","title":"2. Decrypt Keystone Token"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/#ang_bi_loi","text":"","title":"\u0110ang b\u1ecb l\u1ed7i"},{"location":"Openstack_Research/Advance/1. Key-Rotate-&-Decrypt/#3_tham_khao_them","text":"[1 ] : https://docs.openstack.org/newton/admin-guide/identity-fernet-token-faq.html [2] : https://redhatstackblog.redhat.com/2017/12/20/using-ansible-for-fernet-key-rotation-on-red-hat-openstack-platform-11/ [3]","title":"3. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Advance/10. Limit-CPU-Resource/","text":"1. Stress CPU v\u00e0 CGroup \u00b6 Strees CPU tr\u00ean m\u00e1y \u1ea3o yum install epel-release stress stress --cpu 1 --timeout 180 Ki\u1ec3m tra tr\u00ean compute node. Process QEMU \u0111ang chi\u1ebfm 100% c\u1ee7a 1 CPU C\u00e0i \u0111\u1eb7t Cgroup tr\u00ean Compute node yum install install libcgroup libcgroup-tools systemctl start cgconfig systemctl enable cgconfig Cgroup s\u1ebd qu\u1ea3n l\u00fd c\u00e1c process theo c\u00e1c control group. Theo d\u1ea1ng ph\u00e2n c\u1ea5p t\u1eeb . ( root ) slice xu\u1ed1ng c\u00e1c slice con, nh\u1eb1m m\u1ee5c \u0111\u00edch qu\u1ea3n l\u00fd c\u00e1c process c\u00f9ng m\u1ed9t m\u1ee5c group process . System Slice : qu\u1ea3n l\u00fd c\u00e1c system service Machine Slice : qu\u1ea3n l\u00fd c\u00e1c virtual machie User slice : qu\u1ea3n l\u00fd c\u00e1c user session \u0110\u1ec3 xem c\u1ea5u tr\u00fac ph\u00e2n c\u1ea5p trong Cgroup : systemd-cgls C\u1ea5u h\u00ecnh Cgroup limit %CPU c\u1ee7a c\u00e1c service trong Machie Slice systemctl set-property machine.slice CPUQuota=80% systemctl daemon-reload Stress m\u00e1y \u1ea3o v\u00e0 ki\u1ec3m tra l\u1ea1i tr\u00ean Compute Node 2. Stress CPU v\u00e0 Flavor property \u00b6 CPU period : ch\u1ec9 \u0111\u1ecbnh th\u1eddi gian th\u1ef1c ( micro gi\u00e2y ) cho c\u00e1c process QEMU CPU Quota : ch\u1ec9 \u0111\u1ecbnh b\u0103ng th\u00f4ng t\u1ed1i \u0111a tr\u00ean m\u1ed7i cpu-period C\u1ea5u h\u00ecnh flavor : gi\u1edbi h\u1ea1n instance s\u1eed d\u1ee5ng 80% CPU v\u1eadt l\u00fd openstack flavor set ssd.small \\ --property quota:cpu_quota=16000 \\ --property quota:cpu_period=20000 Stress tr\u00ean m\u00e1y \u1ea3o Ki\u1ec3m tra tr\u00ean Compute Node","title":"10. Limit CPU Resource"},{"location":"Openstack_Research/Advance/10. Limit-CPU-Resource/#1_stress_cpu_va_cgroup","text":"Strees CPU tr\u00ean m\u00e1y \u1ea3o yum install epel-release stress stress --cpu 1 --timeout 180 Ki\u1ec3m tra tr\u00ean compute node. Process QEMU \u0111ang chi\u1ebfm 100% c\u1ee7a 1 CPU C\u00e0i \u0111\u1eb7t Cgroup tr\u00ean Compute node yum install install libcgroup libcgroup-tools systemctl start cgconfig systemctl enable cgconfig Cgroup s\u1ebd qu\u1ea3n l\u00fd c\u00e1c process theo c\u00e1c control group. Theo d\u1ea1ng ph\u00e2n c\u1ea5p t\u1eeb . ( root ) slice xu\u1ed1ng c\u00e1c slice con, nh\u1eb1m m\u1ee5c \u0111\u00edch qu\u1ea3n l\u00fd c\u00e1c process c\u00f9ng m\u1ed9t m\u1ee5c group process . System Slice : qu\u1ea3n l\u00fd c\u00e1c system service Machine Slice : qu\u1ea3n l\u00fd c\u00e1c virtual machie User slice : qu\u1ea3n l\u00fd c\u00e1c user session \u0110\u1ec3 xem c\u1ea5u tr\u00fac ph\u00e2n c\u1ea5p trong Cgroup : systemd-cgls C\u1ea5u h\u00ecnh Cgroup limit %CPU c\u1ee7a c\u00e1c service trong Machie Slice systemctl set-property machine.slice CPUQuota=80% systemctl daemon-reload Stress m\u00e1y \u1ea3o v\u00e0 ki\u1ec3m tra l\u1ea1i tr\u00ean Compute Node","title":"1. Stress CPU v\u00e0 CGroup"},{"location":"Openstack_Research/Advance/10. Limit-CPU-Resource/#2_stress_cpu_va_flavor_property","text":"CPU period : ch\u1ec9 \u0111\u1ecbnh th\u1eddi gian th\u1ef1c ( micro gi\u00e2y ) cho c\u00e1c process QEMU CPU Quota : ch\u1ec9 \u0111\u1ecbnh b\u0103ng th\u00f4ng t\u1ed1i \u0111a tr\u00ean m\u1ed7i cpu-period C\u1ea5u h\u00ecnh flavor : gi\u1edbi h\u1ea1n instance s\u1eed d\u1ee5ng 80% CPU v\u1eadt l\u00fd openstack flavor set ssd.small \\ --property quota:cpu_quota=16000 \\ --property quota:cpu_period=20000 Stress tr\u00ean m\u00e1y \u1ea3o Ki\u1ec3m tra tr\u00ean Compute Node","title":"2. Stress CPU v\u00e0 Flavor property"},{"location":"Openstack_Research/Advance/11. Metadata/","text":"T\u00ecm hi\u1ec3u Metadata Service \u00b6 1. Metadata Service l\u00e0 g\u00ec ? \u00b6 Openstack Compute s\u1eed d\u1ee5ng metadata service \u0111\u1ec3 g\u1eedi m\u1ed9t th\u00f4ng tin b\u1ed5 sung t\u1edbi c\u00e1c instance th\u00f4ng qua \u0111\u1ecba ch\u1ec9 link-local adress Link-local address l\u00e0 m\u1ed9t \u0111\u1ecba ch\u1ec9 Unicast s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi c\u00e1c host trong c\u00f9ng m\u1ed9t network ho\u1eb7c segment. Link local IPv4 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh trong network 169.254.0.0/16 \u0110\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh t\u1eeb Metadata, c\u00e1c instance c\u1ea7n g\u1eedi m\u1ed9t HTTP Request t\u1edbi link-local IP adress. Sau \u0111\u00f3 m\u1ed9t metadata agent s\u1ebd x\u1eed l\u00fd request , th\u01b0\u1eddng s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea3m nhi\u1ec7m b\u1edfi m\u1ed9t NovaService C\u00e1c instance c\u00f3 th\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u00e1c th\u00f4ng tin sau : Public IP Public Hostname Ramdom Seed SSH Public Key Cloud_init User-data cho qu\u00e1 tr\u00ecnh Nova-boot \u0110\u1ecbnh tuy\u1ebfn t\u0129nh C\u00e1c instance s\u1ebd g\u1eedi m\u1ed9t HTTP Request \u0111\u1ebfn link-local address : 168.254.169.254. Sau \u0111\u00f3 service l\u1eafng nghe s\u1ebd th\u00eam v\u00e0o request c\u00e1c HTTP Request v\u00e0 chuy\u1ec3n ti\u1ebfp request \u0111\u1ebfn nova service. C\u00e1c Header bao g\u1ed3m : X-instance-ID : UUID c\u1ee7 instance X-instance-ID-Signature : m\u1ed9t ID m\u00e3 h\u00f3a c\u1ee7a instance X-tenant-ID : UUID c\u1ee7a instance X-forwarder-For : \u0111\u1ecba ch\u1ec9 IP c\u1ee7a instance. 2. C\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a Metadata \u00b6 Nova-api-metadata : ch\u1ecbu tr\u00e1ch nhi\u1ec7m cung c\u1ea5p metadata cho c\u00e1c instance. C\u00e1c instance g\u1eedi c\u00e1c HTTP Request . Nova-api-meta ch\u1ea1y tr\u00ean nova-node v\u00e0 s\u1ebd l\u1eafng nghe tr\u00ean port : 8775 Neuton-metadata-agent : C\u00e1c instance s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p g\u1eedi c\u00e1c HTTP request tr\u1ef1c ti\u1ebfp \u0111\u1ebfn nova-api-metata . Thay v\u00ec \u0111\u00f3 s\u1ebd s\u1eed d\u1ee5ng neutron-data-agent ch\u1ea1y tr\u00ean neutron node \u0111\u1ec3 nh\u1eadn c\u00e1c request t\u1eeb c\u00e1c instance. Sau \u0111\u00f3 neutron-metata-agent s\u1ebd forward request \u0111\u1ebfn neutron-api-metadata. Neutron-metadata-agent ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t proxy trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y. Nh\u01b0ng c\u00e1c instance v\u1eabn kh\u00f4ng th\u1ec3 li\u00ean h\u1ec7 \u0111\u01b0\u1ee3c t\u1edbi neutron-metadata-agent do agent n\u00e0y trong \u1edf trong OpenStack internal management network . Tuy nhi\u00ean c\u00f3 dhcp agent v\u00e0 l3 agent \u0111\u1ec3 t\u1ea1o ra m\u1ed9t proxy \u0111\u1ec3 thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i n\u00e0y. Neutron-ns-metadata-proxy : \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi dhcp-agent ho\u1eb7c l3-agent ( tr\u00ean network node ) Trong tr\u01b0\u1eddng h\u1ee3p n\u1ebfu DHCP Agent \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o th\u00ec proxy s\u1ebd \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean namspace dhcp-agent . Trong tr\u01b0\u1eddng h\u1ee3p n\u1ebfu l3-agent \u0111\u01b0\u1ee3c t\u1ea1o th\u00ec proxy s\u1ebd ch\u1ea1y tr\u00ean namespace router Neutron-ns-metadata-proxy k\u1ebft n\u1ed1i tr\u1ef1c t\u1ebfp \u0111\u1ebfn neutron-metadata-agent th\u00f4ng qua unix domain socket. Neutron-ns-metadata-proxy n\u1ebfu ch\u1ea1y tr\u00ean namespace dhcp-agent s\u1ebd l\u1eafng nghe tr\u00ean port 80. - Neutron-ns-metadata-proxy n\u1ebfu ch\u1ea1y tr\u00ean namespace c\u1ee7a neutron router s\u1ebd l\u1eafng nghe tr\u00ean port 9697. 3. Lu\u1ed3ng \u0111i c\u1ee7a metadata trong OPS \u00b6 3.1 . Instance g\u1eedi request metadata \u00b6 B1 : Instance g\u1eedi HTTP request t\u1edbi neutron-ms-metadata-proxy th\u00f4ng qua project network B2 : Neutron-ms-metata-proxy s\u1ebd g\u1eedi request t\u1edbi neutron-metata-agent th\u00f4ng qua unix domain socket B3 : Neutron-metadata-agent s\u1ebd g\u1eedi request t\u1edbi nova-api-metata Khi m\u1ed9t m\u00e1y \u1ea3o g\u1eedi m\u1ed9t request metadata, request s\u1ebd \u0111\u1ebfn router (v\u00ec n\u00f3 l\u00e0 default gateway). L\u00fac n\u00e0y t\u1ea1i router namspace s\u1ebd c\u00f3 m\u1ed9t iptables rule \u0111\u1ec3 redirect traffic t\u1edbi \u0111\u00edch l\u00e0 m\u1ed9t metadata server v\u1edbi local port l\u00e0 9697 . Trong request s\u1ebd c\u00f3 c\u00e1c th\u00f4ng tin sau : IP c\u1ee7a m\u00e1y \u1ea3o \u0111\u00e3 g\u1eedi request, Router ID c\u1ee7a c\u00e1i router \u0111\u00e3 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ea1ng m\u00e0 m\u00e1y \u1ea3o \u0111ang s\u1eed d\u1ee5ng. Sau khi c\u00f3 \u0111\u01b0\u1ee3c c\u00e1c th\u00f4ng tin nh\u01b0 tr\u00ean metadata proxy s\u1ebd th\u00eam c\u00e1c th\u00f4ng tin ( IP c\u1ee7a VM v\u00e0 Router ID) v\u00e0o trong HTTP Header v\u00e0 forward request t\u1edbi metadata agent. Metadata agent s\u1ebd s\u1eed d\u1ee5ng router ID \u0111\u1ec3 li\u1ec7t k\u00ea ra t\u1ea5t c\u1ea3 c\u00e1c network \u0111\u00e3 k\u1ebft n\u1ed1i t\u1edbi router v\u00e0 x\u00e1c \u0111\u1ecbnh network n\u00e0o l\u00e0 network m\u00e0 m\u00e1y \u1ea3o g\u1eedi request \u0111ang s\u1eed d\u1ee5ng. T\u1ea1i sao l\u1ea1i c\u00f3 b\u01b0\u1edbc n\u00e0y, \u0111\u01a1n gi\u1ea3n b\u1edfi v\u00ec v\u1edbi c\u00f4ng ngh\u1ec7 network namespace m\u00e0 openstack s\u1eed d\u1ee5ng th\u00ec c\u00e1c tenant network l\u00e0 ho\u00e0n to\u00e0n isolate, ta c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c Instances c\u00f3 IP ho\u00e0n to\u00e0n gi\u1ed1ng nhau \u1edf c\u00e1c network kh\u00e1c nhau, n\u00ean ph\u1ea3i ta ph\u1ea3i c\u00f3 c\u01a1 ch\u1ebf \u0111\u1ec3 bi\u1ebft ch\u00ednh x\u00e1c ngu\u1ed3n g\u1eedi request ( N\u00f3 l\u00e0 VM n\u00e0o thu\u1ed9c network n\u00e0o). Ti\u1ebfp theo, matadata agent s\u1ebd query t\u1edbi neutron server \u0111\u1ec3 l\u1ea5y instance ID c\u1ee7a VM b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng IP v\u00e0 Network ID \u0111\u1ec3 l\u1ecdc. Cu\u1ed1i c\u00f9ng n\u00f3 s\u1ebd th\u00eam instance ID v\u00e0o HTTP request v\u00e0 forward request t\u1edbi NOVA. 3.2. Metadata s\u1eed d\u1ee5ng router namespace \u00b6 Y\u00eau c\u1ea7u m\u1ed9t L3-Agent \u0111\u1ec3 kh\u1edfi t\u1ea1o metadata service , c\u00f3 ngh\u0129a l\u00e0 c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t project network . Trong router namespace, metadata proxy \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c metadata request , iptable rules s\u1ebd \u0111\u1ecbnh tuy\u1ebfn \u0111\u1ec3 chuy\u1ec3n ti\u1ebfp c\u00e1c request t\u1edbi metadata proxy. neutron-ns-metadata-proxy : s\u1ebd ch\u1ea1y tr\u00ean router namspache v\u00e0 nghe tr\u00ean c\u1ed5ng 9697 IPtable s\u1ebd chuy\u1ec3n ti\u1ebfp c\u00e1c metadata request t\u1edbi http://169.254.169.254:80 v\u00e0o c\u1ed5ng 9697 [root@controller ~]# ip netns exec qrouter-d8faa3e7-ec12-45cc-8a33-a215356adbd0 iptables-save | grep REDIRECT -A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697 3.2 Metadata s\u1eed d\u1ee5ng DHCP Namespace \u00b6 Openstack c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh s\u1eed d\u1ee5ng Metadata proxy tr\u00ean DHCP namespace. , v\u00ec v\u1eady metadata service c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng trong tr\u00ean m\u1ed9t tenant project v\u00e0 kh\u00f4ng c\u1ea7n k\u1ebft n\u1ed1i t\u1edbi router. Ki\u1ec3m tra tr\u00ean m\u1ed9t dhcp namespace , s\u1ebd th\u1ea5y metadata server IP : 169.254.169.254 [root@controller ~]# ip netns exec qdhcp-91027e46-6e22-4d80-a9ee-da8bbe133c80 ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 47: tap0005380b-07: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000 link/ether fa:16:3e:9d:35:1e brd ff:ff:ff:ff:ff:ff inet 192.168.30.140/24 brd 192.168.30.255 scope global tap0005380b-07 valid_lft forever preferred_lft forever inet 169.254.169.254/16 brd 169.254.255.255 scope global tap0005380b-07 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe9d:351e/64 scope link valid_lft forever preferred_lft forever Metadata-proxy ch\u1ea1y tr\u00ean namespace n\u00e0y s\u1ebd nghe tr\u00ean c\u1ed5ng 80, v\u00e0 metadata request c\u0169ng \u0111\u01b0\u1ee3c namespace n\u00e0y l\u1eafng nghe tr\u00ean c\u1ed5ng 80. Khi c\u1ea5p DHCP , th\u00ec DHCP server \u0111\u00e3 kh\u1edfi t\u1ea1o m\u1ed9t static route t\u1edbi \u0111\u1ecba ch\u1ec9 169.254.169.254 . C\u00e1c instance l\u00e0 c\u00e1c dhclient s\u1ebd s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c b\u1ea3ng \u0111\u1ecbnh tuy\u1ebfn n\u00e0y., v\u00ec v\u1eady c\u00e1c metadata request s\u1ebd \u0111\u01b0\u1ee3c route t\u1edbi dhcp-namespace. Meta-proxy s\u1ebd l\u1eafng nghe c\u00e1c request m\u00e0 c\u00e1c instance g\u1eedi \u0111\u1ebfn.","title":"11. Metadata"},{"location":"Openstack_Research/Advance/11. Metadata/#tim_hieu_metadata_service","text":"","title":"T\u00ecm hi\u1ec3u Metadata Service"},{"location":"Openstack_Research/Advance/11. Metadata/#1_metadata_service_la_gi","text":"Openstack Compute s\u1eed d\u1ee5ng metadata service \u0111\u1ec3 g\u1eedi m\u1ed9t th\u00f4ng tin b\u1ed5 sung t\u1edbi c\u00e1c instance th\u00f4ng qua \u0111\u1ecba ch\u1ec9 link-local adress Link-local address l\u00e0 m\u1ed9t \u0111\u1ecba ch\u1ec9 Unicast s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi c\u00e1c host trong c\u00f9ng m\u1ed9t network ho\u1eb7c segment. Link local IPv4 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh trong network 169.254.0.0/16 \u0110\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh t\u1eeb Metadata, c\u00e1c instance c\u1ea7n g\u1eedi m\u1ed9t HTTP Request t\u1edbi link-local IP adress. Sau \u0111\u00f3 m\u1ed9t metadata agent s\u1ebd x\u1eed l\u00fd request , th\u01b0\u1eddng s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea3m nhi\u1ec7m b\u1edfi m\u1ed9t NovaService C\u00e1c instance c\u00f3 th\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u00e1c th\u00f4ng tin sau : Public IP Public Hostname Ramdom Seed SSH Public Key Cloud_init User-data cho qu\u00e1 tr\u00ecnh Nova-boot \u0110\u1ecbnh tuy\u1ebfn t\u0129nh C\u00e1c instance s\u1ebd g\u1eedi m\u1ed9t HTTP Request \u0111\u1ebfn link-local address : 168.254.169.254. Sau \u0111\u00f3 service l\u1eafng nghe s\u1ebd th\u00eam v\u00e0o request c\u00e1c HTTP Request v\u00e0 chuy\u1ec3n ti\u1ebfp request \u0111\u1ebfn nova service. C\u00e1c Header bao g\u1ed3m : X-instance-ID : UUID c\u1ee7 instance X-instance-ID-Signature : m\u1ed9t ID m\u00e3 h\u00f3a c\u1ee7a instance X-tenant-ID : UUID c\u1ee7a instance X-forwarder-For : \u0111\u1ecba ch\u1ec9 IP c\u1ee7a instance.","title":"1. Metadata Service l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/Advance/11. Metadata/#2_cac_thanh_phan_cua_metadata","text":"Nova-api-metadata : ch\u1ecbu tr\u00e1ch nhi\u1ec7m cung c\u1ea5p metadata cho c\u00e1c instance. C\u00e1c instance g\u1eedi c\u00e1c HTTP Request . Nova-api-meta ch\u1ea1y tr\u00ean nova-node v\u00e0 s\u1ebd l\u1eafng nghe tr\u00ean port : 8775 Neuton-metadata-agent : C\u00e1c instance s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p g\u1eedi c\u00e1c HTTP request tr\u1ef1c ti\u1ebfp \u0111\u1ebfn nova-api-metata . Thay v\u00ec \u0111\u00f3 s\u1ebd s\u1eed d\u1ee5ng neutron-data-agent ch\u1ea1y tr\u00ean neutron node \u0111\u1ec3 nh\u1eadn c\u00e1c request t\u1eeb c\u00e1c instance. Sau \u0111\u00f3 neutron-metata-agent s\u1ebd forward request \u0111\u1ebfn neutron-api-metadata. Neutron-metadata-agent ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t proxy trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y. Nh\u01b0ng c\u00e1c instance v\u1eabn kh\u00f4ng th\u1ec3 li\u00ean h\u1ec7 \u0111\u01b0\u1ee3c t\u1edbi neutron-metadata-agent do agent n\u00e0y trong \u1edf trong OpenStack internal management network . Tuy nhi\u00ean c\u00f3 dhcp agent v\u00e0 l3 agent \u0111\u1ec3 t\u1ea1o ra m\u1ed9t proxy \u0111\u1ec3 thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i n\u00e0y. Neutron-ns-metadata-proxy : \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi dhcp-agent ho\u1eb7c l3-agent ( tr\u00ean network node ) Trong tr\u01b0\u1eddng h\u1ee3p n\u1ebfu DHCP Agent \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o th\u00ec proxy s\u1ebd \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean namspace dhcp-agent . Trong tr\u01b0\u1eddng h\u1ee3p n\u1ebfu l3-agent \u0111\u01b0\u1ee3c t\u1ea1o th\u00ec proxy s\u1ebd ch\u1ea1y tr\u00ean namespace router Neutron-ns-metadata-proxy k\u1ebft n\u1ed1i tr\u1ef1c t\u1ebfp \u0111\u1ebfn neutron-metadata-agent th\u00f4ng qua unix domain socket. Neutron-ns-metadata-proxy n\u1ebfu ch\u1ea1y tr\u00ean namespace dhcp-agent s\u1ebd l\u1eafng nghe tr\u00ean port 80. - Neutron-ns-metadata-proxy n\u1ebfu ch\u1ea1y tr\u00ean namespace c\u1ee7a neutron router s\u1ebd l\u1eafng nghe tr\u00ean port 9697.","title":"2. C\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a Metadata"},{"location":"Openstack_Research/Advance/11. Metadata/#3_luong_i_cua_metadata_trong_ops","text":"","title":"3. Lu\u1ed3ng \u0111i c\u1ee7a metadata trong OPS"},{"location":"Openstack_Research/Advance/11. Metadata/#31_instance_gui_request_metadata","text":"B1 : Instance g\u1eedi HTTP request t\u1edbi neutron-ms-metadata-proxy th\u00f4ng qua project network B2 : Neutron-ms-metata-proxy s\u1ebd g\u1eedi request t\u1edbi neutron-metata-agent th\u00f4ng qua unix domain socket B3 : Neutron-metadata-agent s\u1ebd g\u1eedi request t\u1edbi nova-api-metata Khi m\u1ed9t m\u00e1y \u1ea3o g\u1eedi m\u1ed9t request metadata, request s\u1ebd \u0111\u1ebfn router (v\u00ec n\u00f3 l\u00e0 default gateway). L\u00fac n\u00e0y t\u1ea1i router namspace s\u1ebd c\u00f3 m\u1ed9t iptables rule \u0111\u1ec3 redirect traffic t\u1edbi \u0111\u00edch l\u00e0 m\u1ed9t metadata server v\u1edbi local port l\u00e0 9697 . Trong request s\u1ebd c\u00f3 c\u00e1c th\u00f4ng tin sau : IP c\u1ee7a m\u00e1y \u1ea3o \u0111\u00e3 g\u1eedi request, Router ID c\u1ee7a c\u00e1i router \u0111\u00e3 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ea1ng m\u00e0 m\u00e1y \u1ea3o \u0111ang s\u1eed d\u1ee5ng. Sau khi c\u00f3 \u0111\u01b0\u1ee3c c\u00e1c th\u00f4ng tin nh\u01b0 tr\u00ean metadata proxy s\u1ebd th\u00eam c\u00e1c th\u00f4ng tin ( IP c\u1ee7a VM v\u00e0 Router ID) v\u00e0o trong HTTP Header v\u00e0 forward request t\u1edbi metadata agent. Metadata agent s\u1ebd s\u1eed d\u1ee5ng router ID \u0111\u1ec3 li\u1ec7t k\u00ea ra t\u1ea5t c\u1ea3 c\u00e1c network \u0111\u00e3 k\u1ebft n\u1ed1i t\u1edbi router v\u00e0 x\u00e1c \u0111\u1ecbnh network n\u00e0o l\u00e0 network m\u00e0 m\u00e1y \u1ea3o g\u1eedi request \u0111ang s\u1eed d\u1ee5ng. T\u1ea1i sao l\u1ea1i c\u00f3 b\u01b0\u1edbc n\u00e0y, \u0111\u01a1n gi\u1ea3n b\u1edfi v\u00ec v\u1edbi c\u00f4ng ngh\u1ec7 network namespace m\u00e0 openstack s\u1eed d\u1ee5ng th\u00ec c\u00e1c tenant network l\u00e0 ho\u00e0n to\u00e0n isolate, ta c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c Instances c\u00f3 IP ho\u00e0n to\u00e0n gi\u1ed1ng nhau \u1edf c\u00e1c network kh\u00e1c nhau, n\u00ean ph\u1ea3i ta ph\u1ea3i c\u00f3 c\u01a1 ch\u1ebf \u0111\u1ec3 bi\u1ebft ch\u00ednh x\u00e1c ngu\u1ed3n g\u1eedi request ( N\u00f3 l\u00e0 VM n\u00e0o thu\u1ed9c network n\u00e0o). Ti\u1ebfp theo, matadata agent s\u1ebd query t\u1edbi neutron server \u0111\u1ec3 l\u1ea5y instance ID c\u1ee7a VM b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng IP v\u00e0 Network ID \u0111\u1ec3 l\u1ecdc. Cu\u1ed1i c\u00f9ng n\u00f3 s\u1ebd th\u00eam instance ID v\u00e0o HTTP request v\u00e0 forward request t\u1edbi NOVA.","title":"3.1 . Instance g\u1eedi request metadata"},{"location":"Openstack_Research/Advance/11. Metadata/#32_metadata_su_dung_router_namespace","text":"Y\u00eau c\u1ea7u m\u1ed9t L3-Agent \u0111\u1ec3 kh\u1edfi t\u1ea1o metadata service , c\u00f3 ngh\u0129a l\u00e0 c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t project network . Trong router namespace, metadata proxy \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c metadata request , iptable rules s\u1ebd \u0111\u1ecbnh tuy\u1ebfn \u0111\u1ec3 chuy\u1ec3n ti\u1ebfp c\u00e1c request t\u1edbi metadata proxy. neutron-ns-metadata-proxy : s\u1ebd ch\u1ea1y tr\u00ean router namspache v\u00e0 nghe tr\u00ean c\u1ed5ng 9697 IPtable s\u1ebd chuy\u1ec3n ti\u1ebfp c\u00e1c metadata request t\u1edbi http://169.254.169.254:80 v\u00e0o c\u1ed5ng 9697 [root@controller ~]# ip netns exec qrouter-d8faa3e7-ec12-45cc-8a33-a215356adbd0 iptables-save | grep REDIRECT -A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697","title":"3.2. Metadata s\u1eed d\u1ee5ng router namespace"},{"location":"Openstack_Research/Advance/11. Metadata/#32_metadata_su_dung_dhcp_namespace","text":"Openstack c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh s\u1eed d\u1ee5ng Metadata proxy tr\u00ean DHCP namespace. , v\u00ec v\u1eady metadata service c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng trong tr\u00ean m\u1ed9t tenant project v\u00e0 kh\u00f4ng c\u1ea7n k\u1ebft n\u1ed1i t\u1edbi router. Ki\u1ec3m tra tr\u00ean m\u1ed9t dhcp namespace , s\u1ebd th\u1ea5y metadata server IP : 169.254.169.254 [root@controller ~]# ip netns exec qdhcp-91027e46-6e22-4d80-a9ee-da8bbe133c80 ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 47: tap0005380b-07: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000 link/ether fa:16:3e:9d:35:1e brd ff:ff:ff:ff:ff:ff inet 192.168.30.140/24 brd 192.168.30.255 scope global tap0005380b-07 valid_lft forever preferred_lft forever inet 169.254.169.254/16 brd 169.254.255.255 scope global tap0005380b-07 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe9d:351e/64 scope link valid_lft forever preferred_lft forever Metadata-proxy ch\u1ea1y tr\u00ean namespace n\u00e0y s\u1ebd nghe tr\u00ean c\u1ed5ng 80, v\u00e0 metadata request c\u0169ng \u0111\u01b0\u1ee3c namespace n\u00e0y l\u1eafng nghe tr\u00ean c\u1ed5ng 80. Khi c\u1ea5p DHCP , th\u00ec DHCP server \u0111\u00e3 kh\u1edfi t\u1ea1o m\u1ed9t static route t\u1edbi \u0111\u1ecba ch\u1ec9 169.254.169.254 . C\u00e1c instance l\u00e0 c\u00e1c dhclient s\u1ebd s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c b\u1ea3ng \u0111\u1ecbnh tuy\u1ebfn n\u00e0y., v\u00ec v\u1eady c\u00e1c metadata request s\u1ebd \u0111\u01b0\u1ee3c route t\u1edbi dhcp-namespace. Meta-proxy s\u1ebd l\u1eafng nghe c\u00e1c request m\u00e0 c\u00e1c instance g\u1eedi \u0111\u1ebfn.","title":"3.2 Metadata s\u1eed d\u1ee5ng DHCP Namespace"},{"location":"Openstack_Research/Advance/12. Cloud-init/","text":"T\u00ecm hi\u1ec3u Cloud INIT \u00b6 1. Cloud init l\u00e0 g\u00ec ? \u00b6 Cloud init m\u00e0 m\u1ed9t packet t\u1eadp h\u1ee3p c\u00e1c python script v\u00e0 c\u00e1c ti\u1ec7n \u00edch \u0111i k\u00e8m . Cloud init th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho m\u00f4i tr\u01b0\u1eddng \u1ea3o h\u00f3a, m\u1ee5c \u0111\u00edch nh\u1eb1m thi\u1ebft l\u1eadp c\u00e1c k\u1ecbch b\u1ea3n t\u1ef1 \u0111\u1ed9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh b\u01b0\u1edbc \u0111\u1ea7u cho m\u00e1y \u1ea3o bao g\u1ed3m network, SSH key, timezone , m\u1eadt kh\u1ea9u, kh\u1edfi t\u1ea1o ng\u01b0\u1eddi d\u00f9ng v\u00e0 nh\u00f3m ng\u01b0\u1eddi d\u00f9ngv\u00e0 c\u00e1c thi\u1ebft l\u1eadp n\u00e2ng cao kh\u00e1c. Cloud init l\u00e0 m\u1ed9t service \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng s\u1edbm trong qu\u00e1 tr\u00ecnh boot , cho ph\u00e9p nh\u1eadn c\u00e1c userdata t\u1eeb m\u1ea1ng ngo\u00e0i v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng t\u01b0\u01a1ng \u1ee9ng \u0110\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u00e1c user data , c\u00e1c image c\u1ee7a m\u00e1y \u1ea3o ph\u1ea3i c\u1ea5u h\u00ecnh cloud init\u0111\u1ec3 nh\u1eadn c\u00e1c userdata t\u1eeb metadata service khi kh\u1edfi \u0111\u1ed9ng v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng d\u1ef1a v\u00e0o userdata. Hi\u1ec7n nay Cloud init \u0111\u00e3 \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t tr\u00ean c\u00e1c b\u1ea3n Image Cloud : Ubuntu, Ferodat, Debian, RHEL, CentOS Cloud-init kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t c\u00f4ng ngh\u1ec7 c\u1ee7a OpenStack, m\u00e0 n\u00f3 l\u00e0 m\u1ed9t g\u00f3i ph\u1ea7n m\u1ec1m \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 h\u1ed7 tr\u1ee3 nhi\u1ec1u cloud providers, \u0111\u1ec3 c\u00e1c VM image c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong c\u00e1c cloud kh\u00e1c nhau m\u00e0 kh\u00f4ng c\u1ea7n s\u1eeda \u0111\u1ed5i. Cloud-init l\u00e0 m\u1ed9t d\u1ef1 \u00e1n m\u00e3 ngu\u1ed3n m\u1edf v\u00e0 source code c\u00f3 s\u1eb5n tr\u00ean Launchpad.( http://launchpad.net/cloud-init ) Hi\u1ec7n nay Cloud init \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c \u0111\u1ecbnh d\u1ea1ng user data g\u1ed3m : Type \u0110\u1ecbnh d\u1ea1ng Mi\u00eau t\u1ea3 Cloud Config File B\u1eaft \u0111\u1ea7u b\u1eb1ng #cloud-config ho\u1eb7c Content-Type: text/cloud-config S\u1ebd ch\u1ee9a c\u00e1c cloud-config data Shell Script #! ho\u1eb7c Content-Type: text/x-shellscript Script s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c thi gi\u1ed1ng nh\u01b0 file rc.local trong l\u1ea7 n boot \u0111\u1ea7u ti\u00ean Include File #include ho\u1eb7c Content-Type: text/x-include-url M\u1ed9t file ch\u1ee9a c\u00e1c URL . M\u1ed7i URL s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ecdc n\u1ed9i dung trong file v\u00e0 s\u1ebd th\u1ef1c thi theo m\u1ed9t quy t\u1eafc Gzip Compressed Content C\u00e1ch file gzip s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i n\u00e9n \u0111\u1ec3 th\u1ef1c thi Mime Multi Part archive S\u1eed d\u1ee5ng nhi\u1ec1u lo\u1ea1i d\u1eef li\u1ec7u , \u0111\u1ed3ng th\u1eddi cloud-config v\u00e0 shell script Upstart Job #upstart-job ho\u1eb7c Content-Type: text/upstart-job Cloud Boothook #cloud-boothook ho\u1eb7c Content-Type: text/cloud-boothook Part Handler #part-handler ho\u1eb7c Content-Type: text/part-handler 2. Metadata trong Cloud INIT \u00b6 Instance metadata \u0111\u1ea3m nhi\u1ec7m t\u1eadp h\u1ee3p c\u00e1c userdata m\u00e0 cloud-init d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh c\u00e1c instance. Th\u01b0 m\u1ee5c c\u1ee7a cloud-init \u0111\u01b0\u1ee3c t\u1ea1i /var/lib/cloud \u0110\u1ec3 xem userdata \u0111\u01b0\u1ee3i g\u1eedi : /var/lib/cloud/instance/user-data.txt [root@cent-cloudinit instance]# cat /var/lib/cloud/instance/user-data.txt #cloud-config user: root password: password123 chpasswd: {expire: False} ssh_pwauth: True Cloud ini trong Openstack : Cloud-init service s\u1ebd nh\u1eadn c\u00e1c metada t\u1eeb : http://169.254.169.254/latest/meta-data v\u00e0 http://169.254.169.254/latest/user-data, sau \u0111\u00f3 d\u00f9ng c\u00e1c python script \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c trong metadata d\u1ef1a v\u00e0o format userdata Nova-API s\u1ebd \u0111\u1ea3m nhi\u1ec7m g\u1eedi c\u00e1c Metadata v\u1ec1 c\u00e1c instance Tham kh\u1ea3o th\u00eam qu\u00e1 tr\u00ecnh Medata : https://github.com/nguyenhungsync/Report-Intern-Meditech/blob/master/Openstack/Advance/11.%20Metadata.md","title":"12. Cloud init"},{"location":"Openstack_Research/Advance/12. Cloud-init/#tim_hieu_cloud_init","text":"","title":"T\u00ecm hi\u1ec3u Cloud INIT"},{"location":"Openstack_Research/Advance/12. Cloud-init/#1_cloud_init_la_gi","text":"Cloud init m\u00e0 m\u1ed9t packet t\u1eadp h\u1ee3p c\u00e1c python script v\u00e0 c\u00e1c ti\u1ec7n \u00edch \u0111i k\u00e8m . Cloud init th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho m\u00f4i tr\u01b0\u1eddng \u1ea3o h\u00f3a, m\u1ee5c \u0111\u00edch nh\u1eb1m thi\u1ebft l\u1eadp c\u00e1c k\u1ecbch b\u1ea3n t\u1ef1 \u0111\u1ed9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh b\u01b0\u1edbc \u0111\u1ea7u cho m\u00e1y \u1ea3o bao g\u1ed3m network, SSH key, timezone , m\u1eadt kh\u1ea9u, kh\u1edfi t\u1ea1o ng\u01b0\u1eddi d\u00f9ng v\u00e0 nh\u00f3m ng\u01b0\u1eddi d\u00f9ngv\u00e0 c\u00e1c thi\u1ebft l\u1eadp n\u00e2ng cao kh\u00e1c. Cloud init l\u00e0 m\u1ed9t service \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng s\u1edbm trong qu\u00e1 tr\u00ecnh boot , cho ph\u00e9p nh\u1eadn c\u00e1c userdata t\u1eeb m\u1ea1ng ngo\u00e0i v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng t\u01b0\u01a1ng \u1ee9ng \u0110\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c c\u00e1c user data , c\u00e1c image c\u1ee7a m\u00e1y \u1ea3o ph\u1ea3i c\u1ea5u h\u00ecnh cloud init\u0111\u1ec3 nh\u1eadn c\u00e1c userdata t\u1eeb metadata service khi kh\u1edfi \u0111\u1ed9ng v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng d\u1ef1a v\u00e0o userdata. Hi\u1ec7n nay Cloud init \u0111\u00e3 \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t tr\u00ean c\u00e1c b\u1ea3n Image Cloud : Ubuntu, Ferodat, Debian, RHEL, CentOS Cloud-init kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t c\u00f4ng ngh\u1ec7 c\u1ee7a OpenStack, m\u00e0 n\u00f3 l\u00e0 m\u1ed9t g\u00f3i ph\u1ea7n m\u1ec1m \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 h\u1ed7 tr\u1ee3 nhi\u1ec1u cloud providers, \u0111\u1ec3 c\u00e1c VM image c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong c\u00e1c cloud kh\u00e1c nhau m\u00e0 kh\u00f4ng c\u1ea7n s\u1eeda \u0111\u1ed5i. Cloud-init l\u00e0 m\u1ed9t d\u1ef1 \u00e1n m\u00e3 ngu\u1ed3n m\u1edf v\u00e0 source code c\u00f3 s\u1eb5n tr\u00ean Launchpad.( http://launchpad.net/cloud-init ) Hi\u1ec7n nay Cloud init \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c \u0111\u1ecbnh d\u1ea1ng user data g\u1ed3m : Type \u0110\u1ecbnh d\u1ea1ng Mi\u00eau t\u1ea3 Cloud Config File B\u1eaft \u0111\u1ea7u b\u1eb1ng #cloud-config ho\u1eb7c Content-Type: text/cloud-config S\u1ebd ch\u1ee9a c\u00e1c cloud-config data Shell Script #! ho\u1eb7c Content-Type: text/x-shellscript Script s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c thi gi\u1ed1ng nh\u01b0 file rc.local trong l\u1ea7 n boot \u0111\u1ea7u ti\u00ean Include File #include ho\u1eb7c Content-Type: text/x-include-url M\u1ed9t file ch\u1ee9a c\u00e1c URL . M\u1ed7i URL s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ecdc n\u1ed9i dung trong file v\u00e0 s\u1ebd th\u1ef1c thi theo m\u1ed9t quy t\u1eafc Gzip Compressed Content C\u00e1ch file gzip s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i n\u00e9n \u0111\u1ec3 th\u1ef1c thi Mime Multi Part archive S\u1eed d\u1ee5ng nhi\u1ec1u lo\u1ea1i d\u1eef li\u1ec7u , \u0111\u1ed3ng th\u1eddi cloud-config v\u00e0 shell script Upstart Job #upstart-job ho\u1eb7c Content-Type: text/upstart-job Cloud Boothook #cloud-boothook ho\u1eb7c Content-Type: text/cloud-boothook Part Handler #part-handler ho\u1eb7c Content-Type: text/part-handler","title":"1. Cloud init l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/Advance/12. Cloud-init/#2_metadata_trong_cloud_init","text":"Instance metadata \u0111\u1ea3m nhi\u1ec7m t\u1eadp h\u1ee3p c\u00e1c userdata m\u00e0 cloud-init d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh c\u00e1c instance. Th\u01b0 m\u1ee5c c\u1ee7a cloud-init \u0111\u01b0\u1ee3c t\u1ea1i /var/lib/cloud \u0110\u1ec3 xem userdata \u0111\u01b0\u1ee3i g\u1eedi : /var/lib/cloud/instance/user-data.txt [root@cent-cloudinit instance]# cat /var/lib/cloud/instance/user-data.txt #cloud-config user: root password: password123 chpasswd: {expire: False} ssh_pwauth: True Cloud ini trong Openstack : Cloud-init service s\u1ebd nh\u1eadn c\u00e1c metada t\u1eeb : http://169.254.169.254/latest/meta-data v\u00e0 http://169.254.169.254/latest/user-data, sau \u0111\u00f3 d\u00f9ng c\u00e1c python script \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c trong metadata d\u1ef1a v\u00e0o format userdata Nova-API s\u1ebd \u0111\u1ea3m nhi\u1ec7m g\u1eedi c\u00e1c Metadata v\u1ec1 c\u00e1c instance Tham kh\u1ea3o th\u00eam qu\u00e1 tr\u00ecnh Medata : https://github.com/nguyenhungsync/Report-Intern-Meditech/blob/master/Openstack/Advance/11.%20Metadata.md","title":"2. Metadata trong Cloud INIT"},{"location":"Openstack_Research/Advance/13. Cloud-init-Script/","text":"LAB Cloud INIT : G\u1eedi th\u00f4ng tin m\u00e1y \u1ea3o v\u1ec1 Cloud \u00b6 1. C\u1ea5u h\u00ecnh Slack \u00b6 Kh\u1edfi t\u1ea1o APP tr\u00ean Slack API C\u00e0i \u0111\u1eb7t APP v\u00e0o Workspace t\u1ea1i # Basic Information Ch\u1ecdn Channel nh\u1eadn th\u00f4ng b\u00e1o B\u1eadt ch\u1ee9c n\u0103ng Webhook Tham kh\u1ea3o c\u1ea5u tr\u00fac Request v\u00e0 s\u1eed d\u1ee5ng Token Ki\u1ec3m th\u1eed Request 2. Script kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o \u00b6 function check_pre() { ## Notifi slack using curl - only for testing env curl --retry-max-time 5 -X POST -H 'Content-type: application/json' --data '{\"text\": \"- Virutal Machine create at : '\"$(date -R )\"' \\n - IP su dung : '\"${PUBLIC_IPV4} \"' - M\u1eadt kh\u1ea9u : '\"${list}\"' \" }' https://hooks.slack.com/services/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 if [ -f \"/etc/redhat-release\" ]; then echo \"------------------Centos - Redhat OS------------------\" FS='-' read -ra packs <<< \"$2\" #Convert string to array echo \"root:${list}\" | chpasswd #Print all packages for pack in \"${packs[@]}\"; do $pack\"_centos\" done else echo \"------------------Ubuntu OS------------------\" FS='-' read -ra packs <<< \"$2\" #Convert string to array echo \"root:${list}\" | chpasswd #Print all packages for pack in \"${packs[@]}\"; do $pack\"_ubuntu\" done echo $list fi } function nginx_ubuntu() { export DEBIAN_FRONTEND=noninteractive export HOST=$(curl -s http://169.254.169.254/latest/meta-data/hostname) export PUBLIC_IPV4=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4) # Install Nginx apt-get -y install nginx # Write hostname and IP address to index.html mkdir -p /var/www/html sed -i -e \"s|/usr/share/nginx/html|/var/www/html|g\" /etc/nginx/sites-available/default echo -e \"<html><body><strong>HOSTNAME:</strong> $HOST<br><strong>IP PUBLIC:</strong> $PUBLIC_IPV4</html></body>\" \\ > /var/www/html/index.html service nginx restart } function nginx_centos() { ## Get metadata info export HOST=$(curl -s http://169.254.169.254/latest/meta-data/hostname) export PUBLIC_IPV4=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4) # Install Nginx yum install -y epel-release nginx systemctl enable nginx service nginx start } function nodejs_centos() { curl -sL https://rpm.nodesource.com/setup_10.x | sudo bash - yum install -y nodejs } function nodejs_ubuntu() { curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash - apt-get install -y nodejs } function wordpress_centos() { ## call install nginx nginx_centos ## install package yum install -y yum-utils yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm yum-config-manager --enable remi-php72 yum install -y unzip wget php-cli php-fpm php-mysql php-json php-opcache php-mbstring php-xml php-gd php-curl mariadb-server sed -i -e \"s/;cgi.fix_pathinfo=1/cgi.fix_pathinfo=0/\" /etc/php.ini sed -i -e \"s|user = apache|user = nginx|\" /etc/php-fpm.d/www.conf sed -i -e \"s|group = apache|group = nginx|\" /etc/php-fpm.d/www.conf semanage permissive -a httpd_t systemctl enable php-fpm.service systemctl start php-fpm.service wget https://wordpress.org/latest.zip -O /tmp/wordpress.zip unzip /tmp/wordpress.zip -d /tmp/ cd /tmp/wordpress cp wp-config-sample.php wp-config.php systemctl start mariadb systemctl enable mariadb MYSQLPW=`openssl rand -base64 14` WPDB=`openssl rand -base64 14` echo -e \"Mat khau ROOT MYSQL : ${MYSQLPW}\\n Mat khau MYSQL WORDPRESS : ${WPDB}\" > /root/passwd.txt sed -i -e \"s/database_name_here/wordpress/\" /tmp/wordpress/wp-config.php sed -i -e \"s/username_here/admin/\" /tmp/wordpress/wp-config.php sed -i -e \"s/password_here/$WPDB/\" /tmp/wordpress/wp-config.php /usr/bin/mysqladmin -u root -h localhost password $MYSQLPW mysql -u root --password=$MYSQLPW <<EOF CREATE DATABASE wordpress; CREATE USER admin IDENTIFIED BY '\"$WPDB\"'; GRANT ALL PRIVILEGES ON wordpress.* TO admin@localhost EOF Create user 'sys_hung'@'localhost' IDENTIFIED BY 'nguyenhung' ; ## cau hinh thu muc cd /usr/share/nginx/html/ && rm -rf * cd /tmp/wordpress && cp -af * /usr/share/nginx/html service nginx reload ## cau hinh nginx cat <<EOF > /etc/nginx/nginx.conf user www-data; pid /run/nginx.pid; worker_processes auto; worker_rlimit_nofile 65535; events { multi_accept on; worker_connections 65535; } http { charset utf-8; sendfile on; tcp_nopush on; tcp_nodelay on; server_tokens off; log_not_found off; types_hash_max_size 2048; client_max_body_size 16M; # MIME include mime.types; default_type application/octet-stream; # logging access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log warn; # SSL ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; # modern configuration ssl_protocols TLSv1.2; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256; ssl_prefer_server_ciphers on; # OCSP Stapling ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1 8.8.8.8 8.8.4.4 208.67.222.222 208.67.220.220 valid=60s; resolver_timeout 2s; # load configs include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } EOF } list=(`openssl rand -base64 14` \"nginx\") check_pre ${list[@]} echo $list","title":"13. Cloud init Script"},{"location":"Openstack_Research/Advance/13. Cloud-init-Script/#lab_cloud_init_gui_thong_tin_may_ao_ve_cloud","text":"","title":"LAB Cloud INIT : G\u1eedi th\u00f4ng tin m\u00e1y \u1ea3o v\u1ec1 Cloud"},{"location":"Openstack_Research/Advance/13. Cloud-init-Script/#1_cau_hinh_slack","text":"Kh\u1edfi t\u1ea1o APP tr\u00ean Slack API C\u00e0i \u0111\u1eb7t APP v\u00e0o Workspace t\u1ea1i # Basic Information Ch\u1ecdn Channel nh\u1eadn th\u00f4ng b\u00e1o B\u1eadt ch\u1ee9c n\u0103ng Webhook Tham kh\u1ea3o c\u1ea5u tr\u00fac Request v\u00e0 s\u1eed d\u1ee5ng Token Ki\u1ec3m th\u1eed Request","title":"1. C\u1ea5u h\u00ecnh Slack"},{"location":"Openstack_Research/Advance/13. Cloud-init-Script/#2_script_khoi_tao_may_ao","text":"function check_pre() { ## Notifi slack using curl - only for testing env curl --retry-max-time 5 -X POST -H 'Content-type: application/json' --data '{\"text\": \"- Virutal Machine create at : '\"$(date -R )\"' \\n - IP su dung : '\"${PUBLIC_IPV4} \"' - M\u1eadt kh\u1ea9u : '\"${list}\"' \" }' https://hooks.slack.com/services/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 if [ -f \"/etc/redhat-release\" ]; then echo \"------------------Centos - Redhat OS------------------\" FS='-' read -ra packs <<< \"$2\" #Convert string to array echo \"root:${list}\" | chpasswd #Print all packages for pack in \"${packs[@]}\"; do $pack\"_centos\" done else echo \"------------------Ubuntu OS------------------\" FS='-' read -ra packs <<< \"$2\" #Convert string to array echo \"root:${list}\" | chpasswd #Print all packages for pack in \"${packs[@]}\"; do $pack\"_ubuntu\" done echo $list fi } function nginx_ubuntu() { export DEBIAN_FRONTEND=noninteractive export HOST=$(curl -s http://169.254.169.254/latest/meta-data/hostname) export PUBLIC_IPV4=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4) # Install Nginx apt-get -y install nginx # Write hostname and IP address to index.html mkdir -p /var/www/html sed -i -e \"s|/usr/share/nginx/html|/var/www/html|g\" /etc/nginx/sites-available/default echo -e \"<html><body><strong>HOSTNAME:</strong> $HOST<br><strong>IP PUBLIC:</strong> $PUBLIC_IPV4</html></body>\" \\ > /var/www/html/index.html service nginx restart } function nginx_centos() { ## Get metadata info export HOST=$(curl -s http://169.254.169.254/latest/meta-data/hostname) export PUBLIC_IPV4=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4) # Install Nginx yum install -y epel-release nginx systemctl enable nginx service nginx start } function nodejs_centos() { curl -sL https://rpm.nodesource.com/setup_10.x | sudo bash - yum install -y nodejs } function nodejs_ubuntu() { curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash - apt-get install -y nodejs } function wordpress_centos() { ## call install nginx nginx_centos ## install package yum install -y yum-utils yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm yum-config-manager --enable remi-php72 yum install -y unzip wget php-cli php-fpm php-mysql php-json php-opcache php-mbstring php-xml php-gd php-curl mariadb-server sed -i -e \"s/;cgi.fix_pathinfo=1/cgi.fix_pathinfo=0/\" /etc/php.ini sed -i -e \"s|user = apache|user = nginx|\" /etc/php-fpm.d/www.conf sed -i -e \"s|group = apache|group = nginx|\" /etc/php-fpm.d/www.conf semanage permissive -a httpd_t systemctl enable php-fpm.service systemctl start php-fpm.service wget https://wordpress.org/latest.zip -O /tmp/wordpress.zip unzip /tmp/wordpress.zip -d /tmp/ cd /tmp/wordpress cp wp-config-sample.php wp-config.php systemctl start mariadb systemctl enable mariadb MYSQLPW=`openssl rand -base64 14` WPDB=`openssl rand -base64 14` echo -e \"Mat khau ROOT MYSQL : ${MYSQLPW}\\n Mat khau MYSQL WORDPRESS : ${WPDB}\" > /root/passwd.txt sed -i -e \"s/database_name_here/wordpress/\" /tmp/wordpress/wp-config.php sed -i -e \"s/username_here/admin/\" /tmp/wordpress/wp-config.php sed -i -e \"s/password_here/$WPDB/\" /tmp/wordpress/wp-config.php /usr/bin/mysqladmin -u root -h localhost password $MYSQLPW mysql -u root --password=$MYSQLPW <<EOF CREATE DATABASE wordpress; CREATE USER admin IDENTIFIED BY '\"$WPDB\"'; GRANT ALL PRIVILEGES ON wordpress.* TO admin@localhost EOF Create user 'sys_hung'@'localhost' IDENTIFIED BY 'nguyenhung' ; ## cau hinh thu muc cd /usr/share/nginx/html/ && rm -rf * cd /tmp/wordpress && cp -af * /usr/share/nginx/html service nginx reload ## cau hinh nginx cat <<EOF > /etc/nginx/nginx.conf user www-data; pid /run/nginx.pid; worker_processes auto; worker_rlimit_nofile 65535; events { multi_accept on; worker_connections 65535; } http { charset utf-8; sendfile on; tcp_nopush on; tcp_nodelay on; server_tokens off; log_not_found off; types_hash_max_size 2048; client_max_body_size 16M; # MIME include mime.types; default_type application/octet-stream; # logging access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log warn; # SSL ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; # modern configuration ssl_protocols TLSv1.2; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256; ssl_prefer_server_ciphers on; # OCSP Stapling ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1 8.8.8.8 8.8.4.4 208.67.222.222 208.67.220.220 valid=60s; resolver_timeout 2s; # load configs include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } EOF } list=(`openssl rand -base64 14` \"nginx\") check_pre ${list[@]} echo $list","title":"2. Script kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/","text":"Quality of Service (QoS) \u00b6 1. Introduction \u00b6 QoS \u0111\u01b0\u1ee3c hi\u1ec3u \u0111\u1ea3m b\u1ea3o c\u00e1c y\u00eau c\u1ea7u m\u1ea1ng nh\u01b0 b\u0103ng th\u00f4ng, \u0111\u1ed9 tr\u1ec5 , t\u1ed1c \u0111\u1ed9 c\u1ea5p \u1ee9ng \u0111\u1ec3 \u0111\u00e1p \u1ee9ng Service Level Agreement (SLA) gi\u1eefa nh\u00e0 cung c\u1ea5p m\u00e0 ng\u01b0\u1eddi d\u00f9ng C\u1ee5 th\u1ec3 h\u01a1n, QoS s\u1ebd th\u1ec3 hi\u1ec7n r\u00f5 t\u00e1c d\u1ee5ng \u1edf nh\u1eefng v\u1ecb tr\u00ed th\u01b0\u1eddng x\u1ea3y ra hi\u1ec7n t\u01b0\u1ee3ng bottleneck(hay th\u01b0\u1eddng g\u1ecdi n\u00f4m n\u00e0 l\u00e0 th\u1eaft n\u00fat c\u1ed5 chai), \u0111\u1ed3ng th\u1eddi quy\u1ebft \u0111\u1ecbnh ph\u1ea7n traffic n\u00e0o quan tr\u1ecdng h\u01a1n c\u00e1c ph\u1ea7n c\u00f2n l\u1ea1i, d\u1ef1a tr\u00ean quy lu\u1eadt m\u00e0 ng\u01b0\u1eddi s\u1eed d\u1ee5ng thi\u1ebft l\u1eadp c\u00f3 li\u00ean quan t\u1edbi nhi\u1ec1u kh\u00eda c\u1ea1nh t\u00f9y v\u00e0o t\u1eebng d\u1ecbch v\u1ee5 Trong m\u00f4i tr\u01b0\u1eddng Network : Network Quality of Service l\u00e0 m\u1ed9t c\u00f4ng c\u1ee5 t\u1ed5ng th\u1ec3 \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 b\u1ea3o v\u1ec7, \u01b0u ti\u00ean m\u1ed9t s\u1ed1 traffic quan tr\u1ecdng ho\u1eb7c c\u00e1c traffic \u0111\u00f2i h\u1ecfi x\u1eed l\u00fd nhanh v\u1ec1 th\u1eddi gian. QoS s\u1ebd m\u00f4 t\u1ea3 c\u00e1ch th\u1ee9c packet \u0111\u01b0\u1ee3c chuy\u1ec3n m\u1ea1ch nh\u01b0 th\u1ebf n\u00e0o (y\u1ebfu t\u1ed1 how). N\u1ebfu kh\u00f4ng c\u00f3 QuoS, c\u00e1c router ho\u1eb7c switch ch\u1ec9 \u0111\u01a1n thu\u1ea7n quy\u1ebft \u0111\u1ecbnh l\u00e0 m\u1ed9t packet c\u00f3 \u0111\u01b0\u1ee3c fw hay kh\u00f4ng. (y\u1ebfu t\u1ed1 if) . Khi m\u1ed9t packets \u0111i t\u1eeb host n\u00e0y \u0111\u1ebfn host kia, m\u1ed9t g\u00f3i tin (packet) c\u00f3 th\u1ec3 g\u1eb7p c\u00e1c v\u1ea5n \u0111\u1ec1: Delay: do routers x\u1eed l\u00fd t\u00ecm ki\u1ebfm trong b\u1ea3ng routing table, th\u1eddi gian packet truy\u1ec1n tr\u00ean \u0111\u01b0\u1eddng truy\u1ec1n. Jitter: c\u00e1c packets kh\u00f4ng \u0111\u1ebfn \u0111\u00fang nh\u01b0 th\u1eddi gian d\u1ef1 \u0111\u1ecb nh. C\u00e1c d\u1eef li\u1ec7u d\u1ea1ng audio s\u1ebd b\u1ecb \u1ea3nh h\u01b0\u1edfng nhi\u1ec1u b \u1edfi v\u1ea5n \u0111\u1ec1 n\u00e0y. Loss: m\u1ea5t packets Trong m\u00f4i tr\u01b0\u1eddng Storage : Storage Quality of Service cho ph\u00e9p c\u00e1c ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb c\u00f3 th\u1ec3 monitor c\u0169ng nh\u01b0 qu\u1ea3n l\u00fd v\u00e0 thi\u1ebft l\u1eadp rule \u01b0u ti\u00ean theo t\u1eebng lo\u1ea1i h\u00ecnh access v\u00e0 resource use trong m\u1ed9t Storage Cluser .C\u00e1c policy gi\u00fap vi\u1ec7c gi\u1edbi h\u1ea1n I/O storage v\u00e0 c\u00e1c Vitual Machine \u0111\u1ea3m b\u1ea3o kh\u00f4ng v\u01b0\u1ee3t qu\u00e1 ng\u01b0\u1ee1ng cho ph\u00e9p. 2. QOS trong Neutron \u00b6 Trong Neutron hi\u1ec7n \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c Rule QOS sau : banwitth_limit : h\u1ed7 tr\u1ee3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng t\u1ed1i \u0111a tr\u00ean t\u1eebng network, port v\u00e0 IP floating dhcp_marking : h\u1ed7 tr\u1ee3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng d\u1ef1a tr\u00ean DSCP value. - V\u1edbi QoS. Marking l\u00e0 1 task nh\u1ecf trong Classtifycation, (v\u00e0 t\u1ea5t nhi\u00ean marking l\u00fac n\u00e0y l\u00e0 DSCP cho Difserv). Classtifycation c\u00f3 2 task l\u00e0 identify g\u00f3i tin v\u00e0 marking g\u00f3i tin. sau \u0111\u00f3 \u0111\u1ea9y v\u00e0o c\u00e1c queuing. d\u00f9ng scheduling \u0111\u1ec3 quy\u1ebft \u0111\u1ecbnh g\u00f3i n\u00e0o VIP ra tr\u01b0\u1edbc, g\u00f3i n\u00e0o d\u00e2n \u0111en th\u00ec \"ch\u1edd \u0111i m\u00e0y\". ) minimum_bandwidth : gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng t\u1ed1i \u0111a d\u1ef1a l\u00ean ki\u1ec3u k\u1ebft n\u1ed1i . B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y hi\u1ec3n th\u1ecb QOS support rule tr\u00ean t\u1eebng Network Back-end 2.2 C\u1ea5u h\u00ecnh QOS tr\u00ean Compute Node \u00b6 Warning : c\u1ea9n th\u1eadn ki\u1ec3m tra t\u1eadp tin c\u1ea5u h\u00ecnh tr\u01b0\u1edbc khi tao t\u00e1c C\u1ea5u h\u00ecnh QOS extension cho agent layer 2 yum install -y crudini cp -p /etc/neutron/plugins/ml2/openvswitch_agent.ini /etc/neutron/plugins/ml2/openvswitch_agent.ini.bak crudini --set /etc/neutron/plugins/ml2/openvswitch_agent.ini agent extensions qos ho\u1eb7c [agent] extensions = qos Kh\u1edfi \u0111\u1ed9ng l\u1ea1i Agent systemctl restart neutron-openvswitch-agent.service 2.2 . C\u1ea5u h\u00ecnh QOS tr\u00ean Network Node ( Controller Node ) \u00b6 C\u1ea5u h\u00ecnh QOS service trong /etc/neutron/neutron.conf cp -p /etc/neutron/neutron.conf /etc/neutron/neutron.conf.bak yum install -y crudini crudini --set /etc/neutron/neutron.conf DEFAULT service_plugins \\ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.qos.qos_plugin.QoSPlugin ho\u1eb7c [DEFAULT] service_plugins = \\ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin, neutron.services.metering.metering_plugin.MeteringPlugin, neutron.services.qos.qos_plugin.QoSPlugin C\u1ea5u h\u00ecnh QOS extension cho ML2 Driver cp -p /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugins/ml2/ml2_conf.ini.bak crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers port_security,qos ho\u1eb7c [ml2] extension_drivers = port_security,qos Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server 2.3 . Kh\u1edfi t\u1ea1o QOS policy \u00b6 M\u1eb7c \u0111\u1ecbnh , ch\u1ec9 Admin m\u1edbi c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c QOS policy ,c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ec3 cho c\u00e1c t\u00e0i kho\u1ea3n th\u01b0\u1eddng c\u00f3 th\u1ec3 t\u1ea1o QOS t\u1ea1i /etc/neutron/policy.json \"get_policy\": \"rule:regular_user\", \"create_policy\": \"rule:regular_user\", \"update_policy\": \"rule:regular_user\", \"delete_policy\": \"rule:regular_auser\", \"get_rule_type\": \"rule:regular_user\", Cho ph\u00e9p User th\u01b0\u1eddng kh\u1edfi t\u1ea1o bandwidth limit rule t\u1ea1i /etc/neutron/policy.json \"get_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"create_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"delete_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"update_policy_bandwidth_limit_rule\": \"rule:regular_user\", Kh\u1edfi t\u1ea1o m\u1ed9t QOS policy [root@localhost neutron]# openstack network qos policy create bw-limiter +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | description | | | id | d321eb61-032a-4a70-ae1b-6e81545781c4 | | is_default | False | | name | bw-limiter | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | rules | [] | | shared | False | +-------------+--------------------------------------+ Set Rule gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng [root@localhost neutron]# openstack network qos rule create --type bandwidth-limit --max-kbps 500 --max-burst-kbits 340 --egress bw-limiter +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | direction | egress | | id | 6c4c1496-7541-496e-a4cb-668c667a270d | | max_burst_kbps | 2400 | | max_kbps | 3000 | | name | None | | project_id | | +----------------+--------------------------------------+ [root@localhost ~]# openstack network qos rule list bw-limiter +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ | ID | QoS Policy ID | Type | Max Kbps | Max Burst Kbits | Min Kbps | DSCP mark | Direction | +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ | 6c4c1496-7541-496e-a4cb-668c667a270d | d321eb61-032a-4a70-ae1b-6e81545781c4 | bandwidth_limit | 3000 | 2400 | | | egress | +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ Note : QOS y\u00eau c\u1ea7u ch\u1ec9 s\u1ed1 burst \u0111\u1ec3 ch\u1eafc ch\u1eafn s\u1ef1 \u0111\u00fang \u0111\u1eafnc\u00e1c c\u00e1c rule set bandwith tr\u00ean c\u00e1c OpenvSwitch v\u00e0 Linux Bridge. N\u1ebfu kh\u00f4ng set trong qu\u00e1 tr\u00ecnh \u0111\u1eb7t rule th\u00ec m\u1eb7c \u0111\u1ecbnh ch\u1ec9 s\u1ed1 n\u00e0y s\u1ebd v\u1ec1 80% bandwidth c\u1ee7a c\u00e1c g\u00f3i TCP th\u00f4ng th\u01b0\u1eddng. N\u1ebfu gi\u00e1 tr\u1ecb burst qu\u00e1 th\u1ea5p s\u1ebd g\u00e2y ra vi\u1ec7c gi\u1ea3m b\u0103ng th\u00f4ng so v\u1edbi th\u00f4ng s\u1ed1 c\u1ea5u h\u00ecnh C\u00e1c QOS policy c\u00f3 th\u1ec3 g\u1eafn v\u00e0o port ho\u1eb7c c\u1ea3 network c\u1ee5 th\u1ec3 [root@localhost ~]# openstack network list +--------------------------------------+----------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------+--------------------------------------+ | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | provider | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | +--------------------------------------+----------+--------------------------------------+ [root@localhost ~]# openstack network set --qos-policy bw-limiter provider [root@localhost ~]# openstack network show provider +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-12-25T09:08:35Z | | description | | | dns_domain | None | | id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | provider | | port_security_enabled | True | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | None | | qos_policy_id | d321eb61-032a-4a70-ae1b-6e81545781c4 | | revision_number | 6 | | router:external | External | | segments | None | | shared | False | | status | ACTIVE | | subnets | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | | tags | | | updated_at | 2018-12-26T02:20:09Z | +---------------------------+--------------------------------------+ Tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y 2.4. Ki\u1ec3m th\u1eed QOS Policy \u00b6 C\u00e0i bwctl tr\u00ean T\u1ea0I \u0110\u00c2Y M\u00e1y \u1ea3o g\u1eedi Request v\u1ec1 Host v\u1eadt l\u00fd [root@centos-7-volume ~]# bwctl -c 192.168.30.133 bwctl: NTP: STA_NANO should be set. Make sure ntpd is running, and your NTP configuration is good. bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.133, port 5666 [ 16] local 192.168.30.143 port 60453 connected to 192.168.30.133 port 5666 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 140 KBytes 1.14 Mbits/sec 42 2.83 KBytes [ 16] 1.00-2.00 sec 50.9 KBytes 0.42 Mbits/sec 18 4.24 KBytes [ 16] 2.00-3.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 3.00-4.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 4.00-5.00 sec 53.7 KBytes 0.44 Mbits/sec 19 4.24 KBytes [ 16] 5.00-6.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 6.00-7.00 sec 50.9 KBytes 0.42 Mbits/sec 17 4.24 KBytes [ 16] 7.00-8.00 sec 56.6 KBytes 0.46 Mbits/sec 19 4.24 KBytes [ 16] 8.00-9.00 sec 73.5 KBytes 0.60 Mbits/sec 20 4.24 KBytes [ 16] 9.00-10.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 663 KBytes 0.54 Mbits/sec 207 sender [ 16] 0.00-10.04 sec 620 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END Tr\u00ean m\u1ed9t Host v\u1eadt l\u00fd kh\u00e1c m\u1ea1ng send v\u1ec1 m\u00e1y \u1ea3o, do ch\u1ec9 gi\u1edbi h\u1ea1n egress , n\u00ean ingress v\u1eabn \u0111\u1ea1t b\u0103ng th\u00f4ng t\u1ed1i \u0111a c\u1ee7a h\u1ea1 t\u1ea7ng ^C[root@cinder cinder]# bwctl -c 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.143, port 5351 [ 16] local 192.168.30.133 port 56268 connected to 192.168.30.143 port 5351 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 110 MBytes 922 Mbits/sec 0 308 KBytes [ 16] 1.00-2.00 sec 110 MBytes 923 Mbits/sec 0 339 KBytes [ 16] 2.00-3.00 sec 112 MBytes 936 Mbits/sec 0 359 KBytes [ 16] 3.00-4.00 sec 110 MBytes 919 Mbits/sec 0 402 KBytes [ 16] 4.00-5.00 sec 111 MBytes 933 Mbits/sec 0 414 KBytes [ 16] 5.00-6.00 sec 111 MBytes 932 Mbits/sec 0 424 KBytes [ 16] 6.00-7.00 sec 111 MBytes 930 Mbits/sec 0 433 KBytes [ 16] 7.00-8.00 sec 112 MBytes 937 Mbits/sec 0 448 KBytes [ 16] 8.00-9.00 sec 111 MBytes 928 Mbits/sec 0 464 KBytes [ 16] 9.00-10.00 sec 112 MBytes 936 Mbits/sec 0 479 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 1.08 GBytes 930 Mbits/sec 0 sender [ 16] 0.00-10.01 sec 1.08 GBytes 927 Mbits/sec receiver iperf Done. SENDER END Gi\u1eefa c\u00e1c m\u00e1y \u1ea3o li\u00ean h\u1ec7 v\u1edbi nhau [root@centos-7-volume-2 ~]# bwctl -c 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.143, port 5352 [ 16] local 192.168.30.144 port 52946 connected to 192.168.30.143 port 5352 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 130 KBytes 1.06 Mbits/sec 35 4.24 KBytes [ 16] 1.00-2.00 sec 59.4 KBytes 0.49 Mbits/sec 20 4.24 KBytes [ 16] 2.00-3.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 3.00-4.00 sec 45.2 KBytes 0.37 Mbits/sec 16 4.24 KBytes [ 16] 4.00-5.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 5.00-6.00 sec 48.1 KBytes 0.39 Mbits/sec 16 4.24 KBytes [ 16] 6.00-7.00 sec 82.0 KBytes 0.67 Mbits/sec 20 4.24 KBytes [ 16] 7.00-8.00 sec 50.9 KBytes 0.42 Mbits/sec 19 4.24 KBytes [ 16] 8.00-9.00 sec 45.2 KBytes 0.37 Mbits/sec 17 4.24 KBytes [ 16] 9.00-10.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 665 KBytes 0.54 Mbits/sec 203 sender [ 16] 0.00-10.00 sec 626 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END [root@centos-7-volume-2 ~]# bwctl -s 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.144, port 5528 [ 16] local 192.168.30.143 port 47536 connected to 192.168.30.144 port 5528 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 156 KBytes 1.28 Mbits/sec 39 4.24 KBytes [ 16] 1.00-2.00 sec 45.2 KBytes 0.37 Mbits/sec 21 4.24 KBytes [ 16] 2.00-3.00 sec 45.2 KBytes 0.37 Mbits/sec 16 4.24 KBytes [ 16] 3.00-4.00 sec 70.7 KBytes 0.58 Mbits/sec 19 4.24 KBytes [ 16] 4.00-5.00 sec 73.5 KBytes 0.60 Mbits/sec 20 4.24 KBytes [ 16] 5.00-6.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 6.00-7.00 sec 50.9 KBytes 0.42 Mbits/sec 20 4.24 KBytes [ 16] 7.00-8.00 sec 76.4 KBytes 0.63 Mbits/sec 20 4.24 KBytes [ 16] 8.00-9.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 9.00-10.00 sec 50.9 KBytes 0.42 Mbits/sec 20 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 671 KBytes 0.55 Mbits/sec 207 sender [ 16] 0.00-10.04 sec 626 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END End","title":"14. QOS   Neutron"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#quality_of_service_qos","text":"","title":"Quality of Service (QoS)"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#1_introduction","text":"QoS \u0111\u01b0\u1ee3c hi\u1ec3u \u0111\u1ea3m b\u1ea3o c\u00e1c y\u00eau c\u1ea7u m\u1ea1ng nh\u01b0 b\u0103ng th\u00f4ng, \u0111\u1ed9 tr\u1ec5 , t\u1ed1c \u0111\u1ed9 c\u1ea5p \u1ee9ng \u0111\u1ec3 \u0111\u00e1p \u1ee9ng Service Level Agreement (SLA) gi\u1eefa nh\u00e0 cung c\u1ea5p m\u00e0 ng\u01b0\u1eddi d\u00f9ng C\u1ee5 th\u1ec3 h\u01a1n, QoS s\u1ebd th\u1ec3 hi\u1ec7n r\u00f5 t\u00e1c d\u1ee5ng \u1edf nh\u1eefng v\u1ecb tr\u00ed th\u01b0\u1eddng x\u1ea3y ra hi\u1ec7n t\u01b0\u1ee3ng bottleneck(hay th\u01b0\u1eddng g\u1ecdi n\u00f4m n\u00e0 l\u00e0 th\u1eaft n\u00fat c\u1ed5 chai), \u0111\u1ed3ng th\u1eddi quy\u1ebft \u0111\u1ecbnh ph\u1ea7n traffic n\u00e0o quan tr\u1ecdng h\u01a1n c\u00e1c ph\u1ea7n c\u00f2n l\u1ea1i, d\u1ef1a tr\u00ean quy lu\u1eadt m\u00e0 ng\u01b0\u1eddi s\u1eed d\u1ee5ng thi\u1ebft l\u1eadp c\u00f3 li\u00ean quan t\u1edbi nhi\u1ec1u kh\u00eda c\u1ea1nh t\u00f9y v\u00e0o t\u1eebng d\u1ecbch v\u1ee5 Trong m\u00f4i tr\u01b0\u1eddng Network : Network Quality of Service l\u00e0 m\u1ed9t c\u00f4ng c\u1ee5 t\u1ed5ng th\u1ec3 \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 b\u1ea3o v\u1ec7, \u01b0u ti\u00ean m\u1ed9t s\u1ed1 traffic quan tr\u1ecdng ho\u1eb7c c\u00e1c traffic \u0111\u00f2i h\u1ecfi x\u1eed l\u00fd nhanh v\u1ec1 th\u1eddi gian. QoS s\u1ebd m\u00f4 t\u1ea3 c\u00e1ch th\u1ee9c packet \u0111\u01b0\u1ee3c chuy\u1ec3n m\u1ea1ch nh\u01b0 th\u1ebf n\u00e0o (y\u1ebfu t\u1ed1 how). N\u1ebfu kh\u00f4ng c\u00f3 QuoS, c\u00e1c router ho\u1eb7c switch ch\u1ec9 \u0111\u01a1n thu\u1ea7n quy\u1ebft \u0111\u1ecbnh l\u00e0 m\u1ed9t packet c\u00f3 \u0111\u01b0\u1ee3c fw hay kh\u00f4ng. (y\u1ebfu t\u1ed1 if) . Khi m\u1ed9t packets \u0111i t\u1eeb host n\u00e0y \u0111\u1ebfn host kia, m\u1ed9t g\u00f3i tin (packet) c\u00f3 th\u1ec3 g\u1eb7p c\u00e1c v\u1ea5n \u0111\u1ec1: Delay: do routers x\u1eed l\u00fd t\u00ecm ki\u1ebfm trong b\u1ea3ng routing table, th\u1eddi gian packet truy\u1ec1n tr\u00ean \u0111\u01b0\u1eddng truy\u1ec1n. Jitter: c\u00e1c packets kh\u00f4ng \u0111\u1ebfn \u0111\u00fang nh\u01b0 th\u1eddi gian d\u1ef1 \u0111\u1ecb nh. C\u00e1c d\u1eef li\u1ec7u d\u1ea1ng audio s\u1ebd b\u1ecb \u1ea3nh h\u01b0\u1edfng nhi\u1ec1u b \u1edfi v\u1ea5n \u0111\u1ec1 n\u00e0y. Loss: m\u1ea5t packets Trong m\u00f4i tr\u01b0\u1eddng Storage : Storage Quality of Service cho ph\u00e9p c\u00e1c ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb c\u00f3 th\u1ec3 monitor c\u0169ng nh\u01b0 qu\u1ea3n l\u00fd v\u00e0 thi\u1ebft l\u1eadp rule \u01b0u ti\u00ean theo t\u1eebng lo\u1ea1i h\u00ecnh access v\u00e0 resource use trong m\u1ed9t Storage Cluser .C\u00e1c policy gi\u00fap vi\u1ec7c gi\u1edbi h\u1ea1n I/O storage v\u00e0 c\u00e1c Vitual Machine \u0111\u1ea3m b\u1ea3o kh\u00f4ng v\u01b0\u1ee3t qu\u00e1 ng\u01b0\u1ee1ng cho ph\u00e9p.","title":"1. Introduction"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#2_qos_trong_neutron","text":"Trong Neutron hi\u1ec7n \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c Rule QOS sau : banwitth_limit : h\u1ed7 tr\u1ee3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng t\u1ed1i \u0111a tr\u00ean t\u1eebng network, port v\u00e0 IP floating dhcp_marking : h\u1ed7 tr\u1ee3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng d\u1ef1a tr\u00ean DSCP value. - V\u1edbi QoS. Marking l\u00e0 1 task nh\u1ecf trong Classtifycation, (v\u00e0 t\u1ea5t nhi\u00ean marking l\u00fac n\u00e0y l\u00e0 DSCP cho Difserv). Classtifycation c\u00f3 2 task l\u00e0 identify g\u00f3i tin v\u00e0 marking g\u00f3i tin. sau \u0111\u00f3 \u0111\u1ea9y v\u00e0o c\u00e1c queuing. d\u00f9ng scheduling \u0111\u1ec3 quy\u1ebft \u0111\u1ecbnh g\u00f3i n\u00e0o VIP ra tr\u01b0\u1edbc, g\u00f3i n\u00e0o d\u00e2n \u0111en th\u00ec \"ch\u1edd \u0111i m\u00e0y\". ) minimum_bandwidth : gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng t\u1ed1i \u0111a d\u1ef1a l\u00ean ki\u1ec3u k\u1ebft n\u1ed1i . B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y hi\u1ec3n th\u1ecb QOS support rule tr\u00ean t\u1eebng Network Back-end","title":"2. QOS trong Neutron"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#22_cau_hinh_qos_tren_compute_node","text":"Warning : c\u1ea9n th\u1eadn ki\u1ec3m tra t\u1eadp tin c\u1ea5u h\u00ecnh tr\u01b0\u1edbc khi tao t\u00e1c C\u1ea5u h\u00ecnh QOS extension cho agent layer 2 yum install -y crudini cp -p /etc/neutron/plugins/ml2/openvswitch_agent.ini /etc/neutron/plugins/ml2/openvswitch_agent.ini.bak crudini --set /etc/neutron/plugins/ml2/openvswitch_agent.ini agent extensions qos ho\u1eb7c [agent] extensions = qos Kh\u1edfi \u0111\u1ed9ng l\u1ea1i Agent systemctl restart neutron-openvswitch-agent.service","title":"2.2 C\u1ea5u h\u00ecnh QOS tr\u00ean Compute Node"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#22_cau_hinh_qos_tren_network_node_controller_node","text":"C\u1ea5u h\u00ecnh QOS service trong /etc/neutron/neutron.conf cp -p /etc/neutron/neutron.conf /etc/neutron/neutron.conf.bak yum install -y crudini crudini --set /etc/neutron/neutron.conf DEFAULT service_plugins \\ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.qos.qos_plugin.QoSPlugin ho\u1eb7c [DEFAULT] service_plugins = \\ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin, neutron.services.metering.metering_plugin.MeteringPlugin, neutron.services.qos.qos_plugin.QoSPlugin C\u1ea5u h\u00ecnh QOS extension cho ML2 Driver cp -p /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugins/ml2/ml2_conf.ini.bak crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers port_security,qos ho\u1eb7c [ml2] extension_drivers = port_security,qos Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server","title":"2.2 . C\u1ea5u h\u00ecnh QOS tr\u00ean Network Node ( Controller Node )"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#23_khoi_tao_qos_policy","text":"M\u1eb7c \u0111\u1ecbnh , ch\u1ec9 Admin m\u1edbi c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c QOS policy ,c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ec3 cho c\u00e1c t\u00e0i kho\u1ea3n th\u01b0\u1eddng c\u00f3 th\u1ec3 t\u1ea1o QOS t\u1ea1i /etc/neutron/policy.json \"get_policy\": \"rule:regular_user\", \"create_policy\": \"rule:regular_user\", \"update_policy\": \"rule:regular_user\", \"delete_policy\": \"rule:regular_auser\", \"get_rule_type\": \"rule:regular_user\", Cho ph\u00e9p User th\u01b0\u1eddng kh\u1edfi t\u1ea1o bandwidth limit rule t\u1ea1i /etc/neutron/policy.json \"get_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"create_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"delete_policy_bandwidth_limit_rule\": \"rule:regular_user\", \"update_policy_bandwidth_limit_rule\": \"rule:regular_user\", Kh\u1edfi t\u1ea1o m\u1ed9t QOS policy [root@localhost neutron]# openstack network qos policy create bw-limiter +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | description | | | id | d321eb61-032a-4a70-ae1b-6e81545781c4 | | is_default | False | | name | bw-limiter | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | rules | [] | | shared | False | +-------------+--------------------------------------+ Set Rule gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng [root@localhost neutron]# openstack network qos rule create --type bandwidth-limit --max-kbps 500 --max-burst-kbits 340 --egress bw-limiter +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | direction | egress | | id | 6c4c1496-7541-496e-a4cb-668c667a270d | | max_burst_kbps | 2400 | | max_kbps | 3000 | | name | None | | project_id | | +----------------+--------------------------------------+ [root@localhost ~]# openstack network qos rule list bw-limiter +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ | ID | QoS Policy ID | Type | Max Kbps | Max Burst Kbits | Min Kbps | DSCP mark | Direction | +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ | 6c4c1496-7541-496e-a4cb-668c667a270d | d321eb61-032a-4a70-ae1b-6e81545781c4 | bandwidth_limit | 3000 | 2400 | | | egress | +--------------------------------------+--------------------------------------+-----------------+----------+-----------------+----------+-----------+-----------+ Note : QOS y\u00eau c\u1ea7u ch\u1ec9 s\u1ed1 burst \u0111\u1ec3 ch\u1eafc ch\u1eafn s\u1ef1 \u0111\u00fang \u0111\u1eafnc\u00e1c c\u00e1c rule set bandwith tr\u00ean c\u00e1c OpenvSwitch v\u00e0 Linux Bridge. N\u1ebfu kh\u00f4ng set trong qu\u00e1 tr\u00ecnh \u0111\u1eb7t rule th\u00ec m\u1eb7c \u0111\u1ecbnh ch\u1ec9 s\u1ed1 n\u00e0y s\u1ebd v\u1ec1 80% bandwidth c\u1ee7a c\u00e1c g\u00f3i TCP th\u00f4ng th\u01b0\u1eddng. N\u1ebfu gi\u00e1 tr\u1ecb burst qu\u00e1 th\u1ea5p s\u1ebd g\u00e2y ra vi\u1ec7c gi\u1ea3m b\u0103ng th\u00f4ng so v\u1edbi th\u00f4ng s\u1ed1 c\u1ea5u h\u00ecnh C\u00e1c QOS policy c\u00f3 th\u1ec3 g\u1eafn v\u00e0o port ho\u1eb7c c\u1ea3 network c\u1ee5 th\u1ec3 [root@localhost ~]# openstack network list +--------------------------------------+----------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------+--------------------------------------+ | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | provider | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | +--------------------------------------+----------+--------------------------------------+ [root@localhost ~]# openstack network set --qos-policy bw-limiter provider [root@localhost ~]# openstack network show provider +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-12-25T09:08:35Z | | description | | | dns_domain | None | | id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | provider | | port_security_enabled | True | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | None | | qos_policy_id | d321eb61-032a-4a70-ae1b-6e81545781c4 | | revision_number | 6 | | router:external | External | | segments | None | | shared | False | | status | ACTIVE | | subnets | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | | tags | | | updated_at | 2018-12-26T02:20:09Z | +---------------------------+--------------------------------------+ Tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y","title":"2.3 . Kh\u1edfi t\u1ea1o QOS policy"},{"location":"Openstack_Research/Advance/14. QOS - Neutron/#24_kiem_thu_qos_policy","text":"C\u00e0i bwctl tr\u00ean T\u1ea0I \u0110\u00c2Y M\u00e1y \u1ea3o g\u1eedi Request v\u1ec1 Host v\u1eadt l\u00fd [root@centos-7-volume ~]# bwctl -c 192.168.30.133 bwctl: NTP: STA_NANO should be set. Make sure ntpd is running, and your NTP configuration is good. bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.133, port 5666 [ 16] local 192.168.30.143 port 60453 connected to 192.168.30.133 port 5666 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 140 KBytes 1.14 Mbits/sec 42 2.83 KBytes [ 16] 1.00-2.00 sec 50.9 KBytes 0.42 Mbits/sec 18 4.24 KBytes [ 16] 2.00-3.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 3.00-4.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 4.00-5.00 sec 53.7 KBytes 0.44 Mbits/sec 19 4.24 KBytes [ 16] 5.00-6.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 6.00-7.00 sec 50.9 KBytes 0.42 Mbits/sec 17 4.24 KBytes [ 16] 7.00-8.00 sec 56.6 KBytes 0.46 Mbits/sec 19 4.24 KBytes [ 16] 8.00-9.00 sec 73.5 KBytes 0.60 Mbits/sec 20 4.24 KBytes [ 16] 9.00-10.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 663 KBytes 0.54 Mbits/sec 207 sender [ 16] 0.00-10.04 sec 620 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END Tr\u00ean m\u1ed9t Host v\u1eadt l\u00fd kh\u00e1c m\u1ea1ng send v\u1ec1 m\u00e1y \u1ea3o, do ch\u1ec9 gi\u1edbi h\u1ea1n egress , n\u00ean ingress v\u1eabn \u0111\u1ea1t b\u0103ng th\u00f4ng t\u1ed1i \u0111a c\u1ee7a h\u1ea1 t\u1ea7ng ^C[root@cinder cinder]# bwctl -c 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.143, port 5351 [ 16] local 192.168.30.133 port 56268 connected to 192.168.30.143 port 5351 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 110 MBytes 922 Mbits/sec 0 308 KBytes [ 16] 1.00-2.00 sec 110 MBytes 923 Mbits/sec 0 339 KBytes [ 16] 2.00-3.00 sec 112 MBytes 936 Mbits/sec 0 359 KBytes [ 16] 3.00-4.00 sec 110 MBytes 919 Mbits/sec 0 402 KBytes [ 16] 4.00-5.00 sec 111 MBytes 933 Mbits/sec 0 414 KBytes [ 16] 5.00-6.00 sec 111 MBytes 932 Mbits/sec 0 424 KBytes [ 16] 6.00-7.00 sec 111 MBytes 930 Mbits/sec 0 433 KBytes [ 16] 7.00-8.00 sec 112 MBytes 937 Mbits/sec 0 448 KBytes [ 16] 8.00-9.00 sec 111 MBytes 928 Mbits/sec 0 464 KBytes [ 16] 9.00-10.00 sec 112 MBytes 936 Mbits/sec 0 479 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 1.08 GBytes 930 Mbits/sec 0 sender [ 16] 0.00-10.01 sec 1.08 GBytes 927 Mbits/sec receiver iperf Done. SENDER END Gi\u1eefa c\u00e1c m\u00e1y \u1ea3o li\u00ean h\u1ec7 v\u1edbi nhau [root@centos-7-volume-2 ~]# bwctl -c 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.143, port 5352 [ 16] local 192.168.30.144 port 52946 connected to 192.168.30.143 port 5352 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 130 KBytes 1.06 Mbits/sec 35 4.24 KBytes [ 16] 1.00-2.00 sec 59.4 KBytes 0.49 Mbits/sec 20 4.24 KBytes [ 16] 2.00-3.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 3.00-4.00 sec 45.2 KBytes 0.37 Mbits/sec 16 4.24 KBytes [ 16] 4.00-5.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes [ 16] 5.00-6.00 sec 48.1 KBytes 0.39 Mbits/sec 16 4.24 KBytes [ 16] 6.00-7.00 sec 82.0 KBytes 0.67 Mbits/sec 20 4.24 KBytes [ 16] 7.00-8.00 sec 50.9 KBytes 0.42 Mbits/sec 19 4.24 KBytes [ 16] 8.00-9.00 sec 45.2 KBytes 0.37 Mbits/sec 17 4.24 KBytes [ 16] 9.00-10.00 sec 67.9 KBytes 0.56 Mbits/sec 20 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 665 KBytes 0.54 Mbits/sec 203 sender [ 16] 0.00-10.00 sec 626 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END [root@centos-7-volume-2 ~]# bwctl -s 192.168.30.143 bwctl: Using tool: iperf3 bwctl: 15 seconds until test results available SENDER START Connecting to host 192.168.30.144, port 5528 [ 16] local 192.168.30.143 port 47536 connected to 192.168.30.144 port 5528 [ ID] Interval Transfer Bitrate Retr Cwnd [ 16] 0.00-1.00 sec 156 KBytes 1.28 Mbits/sec 39 4.24 KBytes [ 16] 1.00-2.00 sec 45.2 KBytes 0.37 Mbits/sec 21 4.24 KBytes [ 16] 2.00-3.00 sec 45.2 KBytes 0.37 Mbits/sec 16 4.24 KBytes [ 16] 3.00-4.00 sec 70.7 KBytes 0.58 Mbits/sec 19 4.24 KBytes [ 16] 4.00-5.00 sec 73.5 KBytes 0.60 Mbits/sec 20 4.24 KBytes [ 16] 5.00-6.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 6.00-7.00 sec 50.9 KBytes 0.42 Mbits/sec 20 4.24 KBytes [ 16] 7.00-8.00 sec 76.4 KBytes 0.63 Mbits/sec 20 4.24 KBytes [ 16] 8.00-9.00 sec 50.9 KBytes 0.42 Mbits/sec 16 4.24 KBytes [ 16] 9.00-10.00 sec 50.9 KBytes 0.42 Mbits/sec 20 4.24 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 16] 0.00-10.00 sec 671 KBytes 0.55 Mbits/sec 207 sender [ 16] 0.00-10.04 sec 626 KBytes 0.51 Mbits/sec receiver iperf Done. SENDER END End","title":"2.4. Ki\u1ec3m th\u1eed QOS Policy"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/","text":"3. QOS Storage \u00b6 3.1 . M\u1edf \u0111\u1ea7u \u00b6 Cinder QOS cho ph\u00e9p gi\u1edbi h\u1ea1n c\u00e1c hi\u1ec7u n\u0103ng ph\u1ea7n c\u1ee9ng tr\u00ean c\u00e1c volume C\u00e1c tham s\u1ed1 hi\u1ec7u su\u1ed1t cho c\u00e1c volume th\u01b0\u1eddng l\u00e0 c\u00e1c th\u00f4ng s\u1ed1 extrac spec tr\u00ean c\u00e1c volume type. M\u1ed7i QOS spec s\u1ebd c\u00f3 m\u1ed9t tr\u01b0\u1eddng Consumer. Consumer c\u00f3 th\u1ec3 l\u00e0 front-end (Compute back-end), \"back-end\" (Block Storage back-end), ho\u1eb7c c\u1ea3 hai. Cinder hi\u1ec7n \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c ch\u1ec9 s\u1ed1 sau \u0111\u1ec3 ki\u1ec3m so\u00e1t ch\u1ea5t l\u01b0\u1ee3ng d\u1ecbch v\u1ee5 : read_iops_sec write_iops_sec total_iops_sec read_bytes_sec write_bytes_sec total_bytes_sec read_iops_sec_max write_iops_sec_max total_iops_sec_max read_bytes_sec_max write_bytes_sec_max total_bytes_sec_max size_iops_sec Thu\u1eadt ng\u1eef b\u1ed5 sung : IOPS vi\u1ebft t\u1eaft t\u1eeb Input \u2013 output operation per second (N\u00f4m na l\u00e0 1 truy c\u1eadp \u0111\u1ecdc ho\u1eb7c vi\u1ebft m\u1ed7i gi\u00e2y). \u1ede c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef file th\u00ec b\u0103ng th\u00f4ng (MBps) l\u00e0 th\u00f4ng s\u1ed1 quan tr\u1ecdng nh\u1ea5t. C\u00f2n \u0111\u1ed1i v\u1edbi c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef cho \u0111\u00e1m m\u00e2y CLOUD th\u00ec IOPS quy\u1ebft \u0111\u1ecbnh \u0111\u1ed9 \u201cnh\u1ea1y\u201d v\u00e0 \u0111\u1ed9 \u201cNHANH\u201d c\u1ee7a m\u00e1y \u1ea3o. \u0110\u00e2y l\u00e0 gi\u00e1 tr\u1ecb cho ph\u00e9p x\u00e1c \u0111\u1ecbnh tr\u01b0\u1edbc m\u00e1y \u1ea3o c\u1ee7a b\u1ea1n ki\u1ec3m so\u00e1t \u0111\u01b0\u1ee3c bao nhi\u00eau ho\u1ea1t \u0111\u1ed9ng nh\u1eadp/xu\u1ea5t \u0111\u01b0\u1ee3c ph\u00e9p c\u00f9ng m\u1ed9t l\u00fac tr\u00ean m\u00e1y \u1ea3o c\u1ee7a b\u1ea1n. Sau khi \u0111\u1ea1t \u0111\u1ebfn ng\u01b0\u1ee1ng cho ph\u00e9p, m\u00e1y ch\u1ee7 \u1ea3o c\u00f3 th\u1ec3 b\u1eaft \u0111\u1ea7u \u0111i\u1ec1u ti\u1ebft c\u00e1c ho\u1ea1t \u0111\u1ed9ng n\u00e0y, t\u1ea1o ra c\u00e1c y\u00eau c\u1ea7u v\u00e0 qu\u00e1 tr\u00ecnh ch\u1edd \u0111\u1ee3i. \u0110i\u1ec1u n\u00e0y l\u1ea7n l\u01b0\u1ee3t g\u00e2y ra t\u00ecnh tr\u1ea1ng \u201cng\u1ee7\u201d, l\u00e0m t\u0103ng t\u1ea3i m\u00e1y ch\u1ee7 cho \u0111\u1ebfn khi c\u00e1c y\u00eau c\u1ea7u \u0111\u01b0\u1ee3c x\u1eed l\u00fd h\u1ebft. C\u00e1c qu\u00e1 tr\u00ecnh ch\u1edd \u0111\u1ee3i trong th\u1eddi gian n\u00e0y b\u1ecb \u1ea3nh h\u01b0\u1edfng b\u1edfi \u201cIOWait\u201d. \u0110\u1ed1i v\u1edbi IOPS, th\u1ee9 quan tr\u1ecdng nh\u1ea5t c\u1ea7n \u0111\u01b0\u1ee3c ch\u00fa \u00fd \u0111\u1ebfn l\u00e0 t\u1ec9 l\u1ec7 Read v\u00e0 Write (th\u00f4ng th\u01b0\u1eddng t\u1ec9 l\u1ec7 n\u00e0y l\u00e0 70% (read) v\u00e0 30 (Write) - c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh \u0111\u01b0\u1ee3c). 3.2 . C\u00e1ch t\u00ednh IOPS \u00b6 Tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y C\u00e1ch t\u00ednh IOPS v\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng: Gi\u1ea3 s\u1eed h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef c\u1ee7a b\u1ea1n s\u1eed d\u1ee5ng \u1ed5 SAS 15k Dung l\u01b0\u1ee3ng m\u1ed7i \u1ed5 l\u00e0 900Gb. T\u1ec9 l\u1ec7 Read/Write t\u01b0\u01a1ng \u1ee9ng: 7:3 C\u1ea5u h\u00ecnh RAID 10 IOPS per Disk l\u00e0 176 Y\u00eau c\u1ea7u \u0111\u1eb7t ra l\u00e0 IOPS th\u1ef1c ph\u1ea3i tr\u00ean 1000 L\u00fac n\u00e0y, h\u1ec7 th\u1ed1ng c\u1ee7a b\u1ea1n ch\u1ec9 c\u1ea7n 8 c\u1ee9ng l\u00e0 \u0111\u1ee7, s\u1ed1 IOPS c\u1ee7a h\u1ec7 th\u1ed1ng l\u00fac n\u00e0y l\u00e0 1200. C\u00f2n n\u1ebfu ch\u00fang ta mu\u1ed1n t\u1ec9 l\u1ec7 Read/Write l\u00e0 3:7 th\u00ec sao? C\u00f9ng c\u00e1c \u0111i\u1ec1u ki\u1ec7n nh\u01b0 tr\u00ean, v\u1edbi 8 \u1ed5 HDD th\u00ec s\u1ed1 IOPS ch\u1ec9 l\u00e0 918, n\u1ebfu 9 \u1ed5 th\u00ec IOPS s\u1ebd l\u00e0 1032, c\u00f2n 11 \u1ed5 th\u00ec s\u1ebd l\u00e0 1262. Ch\u00fang ta c\u0169ng c\u00f3 th\u1ec3 th\u1ea5y l\u00e0 khi c\u1ea5u h\u00ecnh c\u00e1c RAID level kh\u00e1c nhau, IOPS v\u00e0 capacity thay \u0111\u1ed5i \u0111\u00e1ng k\u1ec3: IOPS cao th\u00ec capacity s\u1ebd b\u1ecb gi\u1ea3m xu\u1ed1ng, v\u00e0 ng\u01b0\u1ee3c l\u1ea1i. L\u00fd do l\u00e0 v\u00ec t\u1eebng RAID level c\u00f3 s\u1ef1 kh\u00e1c bi\u1ec7t v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng t\u1ed1i thi\u1ec3u (Raid Penalty). V\u00ec th\u1ebf, \u0111\u1ec3 setup 1 h\u1ec7 th\u1ed1ng s\u00e1t v\u1edbi nhu c\u1ea7u, Sys Admin c\u1ea7n ph\u1ea3i x\u00e1c \u0111\u1ecbnh r\u00f5 \u01b0u ti\u00ean h\u1ec7 th\u1ed1ng c\u1ee7a m\u00ecnh l\u00e0 g\u00ec: \u1ee8ng d\u1ee5ng ch\u1ea1y nhanh? M\u1ee9c \u0111\u1ed9 b\u1ea3o m\u1eadt ? dung l\u01b0\u1ee3ng l\u01b0u tr\u1eef? B\u1ea3ng y\u00eau c\u1ea7u RAID Penalty \u2013 l\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng t\u1ed1i thi\u1ec3u t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed7i RAID level C\u00e1c c\u00f4ng th\u1ee9c t\u00ednh trong b\u00e0i: T\u1ed5ng IOPS = IOPS per Disk * S\u1ed1 \u1ed5 c\u1ee9ng IOPS th\u1ef1c = (T\u1ed5ng IOPS * Write%)/(Raid Penalty) + (T\u1ed5ng IOPS * Read %) S\u1ed1 \u1ed5 c\u1ee9ng = ((Read IOPS) + (Write IOPS*Raid Penalty))/ IOPS per Disk 3.3 . Kh\u1edfi t\u1ea1o QOS Policy \u00b6 Ki\u1ec3m tra IOPS hi\u1ec7n t\u1ea1i tr\u00ean m\u00e1y \u1ea3o yum install -y epel-release && yum install -y fio fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=testrw --filename=testrw --bs=4k --iodepth=64 --size=1GB --readwrite=randrw --rwmixread=75 K\u1ebft qu\u1ea3 test Kh\u1edfi t\u1ea1o QOS policy cinder qos-create low-iops consumer=\"front-end\" \\ read_iops_sec=210 write_iops_sec=90 Ki\u1ec3m tranh danh s\u00e1ch QOS [root@localhost /]# cinder qos-list +--------------------------------------+----------+-----------+--------------------------------------------------+ | ID | Name | Consumer | specs | +--------------------------------------+----------+-----------+--------------------------------------------------+ | 85d574d5-e835-48f3-a203-3ab8e40a5eb6 | low-iops | front-end | {'write_iops_sec': '90', 'read_iops_sec': '210'} | +--------------------------------------+----------+-----------+--------------------------------------------------+ Sau khi kh\u1edfi t\u1ea1o Policy c\u00f3 th\u1ec3 g\u1eafn v\u00e0o c\u00e1c volume type , nh\u01b0 c\u00e1c th\u00f4ng s\u1ed1 extra spec cinder qos-associate QOS_ID VOLUME_TYPE_ID openstack volume qos associate QOS_ID VOLUME_TYPE_ID G\u1eafn Policy v\u00e0o Volume Type \"LVM\" openstack volume qos associate 85d574d5-e835-48f3-a203-3ab8e40a5eb6 536c7a2e-5c10-4e7f-8417-22b0e85425c3 Test l\u1ea1i tr\u00ean m\u00e1y \u1ea3o 3.4. Tham kh\u1ea3o th\u00eam \u00b6 https://docs.openstack.org/cinder/latest/admin/blockstorage-capacity-based-qos.html https://viettelidc.com.vn/tin-tuc/huong-dan-cach-tinh-iops END.","title":"15. QOS   Cinder"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/#3_qos_storage","text":"","title":"3. QOS Storage"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/#31_mo_au","text":"Cinder QOS cho ph\u00e9p gi\u1edbi h\u1ea1n c\u00e1c hi\u1ec7u n\u0103ng ph\u1ea7n c\u1ee9ng tr\u00ean c\u00e1c volume C\u00e1c tham s\u1ed1 hi\u1ec7u su\u1ed1t cho c\u00e1c volume th\u01b0\u1eddng l\u00e0 c\u00e1c th\u00f4ng s\u1ed1 extrac spec tr\u00ean c\u00e1c volume type. M\u1ed7i QOS spec s\u1ebd c\u00f3 m\u1ed9t tr\u01b0\u1eddng Consumer. Consumer c\u00f3 th\u1ec3 l\u00e0 front-end (Compute back-end), \"back-end\" (Block Storage back-end), ho\u1eb7c c\u1ea3 hai. Cinder hi\u1ec7n \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c ch\u1ec9 s\u1ed1 sau \u0111\u1ec3 ki\u1ec3m so\u00e1t ch\u1ea5t l\u01b0\u1ee3ng d\u1ecbch v\u1ee5 : read_iops_sec write_iops_sec total_iops_sec read_bytes_sec write_bytes_sec total_bytes_sec read_iops_sec_max write_iops_sec_max total_iops_sec_max read_bytes_sec_max write_bytes_sec_max total_bytes_sec_max size_iops_sec Thu\u1eadt ng\u1eef b\u1ed5 sung : IOPS vi\u1ebft t\u1eaft t\u1eeb Input \u2013 output operation per second (N\u00f4m na l\u00e0 1 truy c\u1eadp \u0111\u1ecdc ho\u1eb7c vi\u1ebft m\u1ed7i gi\u00e2y). \u1ede c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef file th\u00ec b\u0103ng th\u00f4ng (MBps) l\u00e0 th\u00f4ng s\u1ed1 quan tr\u1ecdng nh\u1ea5t. C\u00f2n \u0111\u1ed1i v\u1edbi c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef cho \u0111\u00e1m m\u00e2y CLOUD th\u00ec IOPS quy\u1ebft \u0111\u1ecbnh \u0111\u1ed9 \u201cnh\u1ea1y\u201d v\u00e0 \u0111\u1ed9 \u201cNHANH\u201d c\u1ee7a m\u00e1y \u1ea3o. \u0110\u00e2y l\u00e0 gi\u00e1 tr\u1ecb cho ph\u00e9p x\u00e1c \u0111\u1ecbnh tr\u01b0\u1edbc m\u00e1y \u1ea3o c\u1ee7a b\u1ea1n ki\u1ec3m so\u00e1t \u0111\u01b0\u1ee3c bao nhi\u00eau ho\u1ea1t \u0111\u1ed9ng nh\u1eadp/xu\u1ea5t \u0111\u01b0\u1ee3c ph\u00e9p c\u00f9ng m\u1ed9t l\u00fac tr\u00ean m\u00e1y \u1ea3o c\u1ee7a b\u1ea1n. Sau khi \u0111\u1ea1t \u0111\u1ebfn ng\u01b0\u1ee1ng cho ph\u00e9p, m\u00e1y ch\u1ee7 \u1ea3o c\u00f3 th\u1ec3 b\u1eaft \u0111\u1ea7u \u0111i\u1ec1u ti\u1ebft c\u00e1c ho\u1ea1t \u0111\u1ed9ng n\u00e0y, t\u1ea1o ra c\u00e1c y\u00eau c\u1ea7u v\u00e0 qu\u00e1 tr\u00ecnh ch\u1edd \u0111\u1ee3i. \u0110i\u1ec1u n\u00e0y l\u1ea7n l\u01b0\u1ee3t g\u00e2y ra t\u00ecnh tr\u1ea1ng \u201cng\u1ee7\u201d, l\u00e0m t\u0103ng t\u1ea3i m\u00e1y ch\u1ee7 cho \u0111\u1ebfn khi c\u00e1c y\u00eau c\u1ea7u \u0111\u01b0\u1ee3c x\u1eed l\u00fd h\u1ebft. C\u00e1c qu\u00e1 tr\u00ecnh ch\u1edd \u0111\u1ee3i trong th\u1eddi gian n\u00e0y b\u1ecb \u1ea3nh h\u01b0\u1edfng b\u1edfi \u201cIOWait\u201d. \u0110\u1ed1i v\u1edbi IOPS, th\u1ee9 quan tr\u1ecdng nh\u1ea5t c\u1ea7n \u0111\u01b0\u1ee3c ch\u00fa \u00fd \u0111\u1ebfn l\u00e0 t\u1ec9 l\u1ec7 Read v\u00e0 Write (th\u00f4ng th\u01b0\u1eddng t\u1ec9 l\u1ec7 n\u00e0y l\u00e0 70% (read) v\u00e0 30 (Write) - c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh \u0111\u01b0\u1ee3c).","title":"3.1 . M\u1edf \u0111\u1ea7u"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/#32_cach_tinh_iops","text":"Tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y C\u00e1ch t\u00ednh IOPS v\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng: Gi\u1ea3 s\u1eed h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef c\u1ee7a b\u1ea1n s\u1eed d\u1ee5ng \u1ed5 SAS 15k Dung l\u01b0\u1ee3ng m\u1ed7i \u1ed5 l\u00e0 900Gb. T\u1ec9 l\u1ec7 Read/Write t\u01b0\u01a1ng \u1ee9ng: 7:3 C\u1ea5u h\u00ecnh RAID 10 IOPS per Disk l\u00e0 176 Y\u00eau c\u1ea7u \u0111\u1eb7t ra l\u00e0 IOPS th\u1ef1c ph\u1ea3i tr\u00ean 1000 L\u00fac n\u00e0y, h\u1ec7 th\u1ed1ng c\u1ee7a b\u1ea1n ch\u1ec9 c\u1ea7n 8 c\u1ee9ng l\u00e0 \u0111\u1ee7, s\u1ed1 IOPS c\u1ee7a h\u1ec7 th\u1ed1ng l\u00fac n\u00e0y l\u00e0 1200. C\u00f2n n\u1ebfu ch\u00fang ta mu\u1ed1n t\u1ec9 l\u1ec7 Read/Write l\u00e0 3:7 th\u00ec sao? C\u00f9ng c\u00e1c \u0111i\u1ec1u ki\u1ec7n nh\u01b0 tr\u00ean, v\u1edbi 8 \u1ed5 HDD th\u00ec s\u1ed1 IOPS ch\u1ec9 l\u00e0 918, n\u1ebfu 9 \u1ed5 th\u00ec IOPS s\u1ebd l\u00e0 1032, c\u00f2n 11 \u1ed5 th\u00ec s\u1ebd l\u00e0 1262. Ch\u00fang ta c\u0169ng c\u00f3 th\u1ec3 th\u1ea5y l\u00e0 khi c\u1ea5u h\u00ecnh c\u00e1c RAID level kh\u00e1c nhau, IOPS v\u00e0 capacity thay \u0111\u1ed5i \u0111\u00e1ng k\u1ec3: IOPS cao th\u00ec capacity s\u1ebd b\u1ecb gi\u1ea3m xu\u1ed1ng, v\u00e0 ng\u01b0\u1ee3c l\u1ea1i. L\u00fd do l\u00e0 v\u00ec t\u1eebng RAID level c\u00f3 s\u1ef1 kh\u00e1c bi\u1ec7t v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng t\u1ed1i thi\u1ec3u (Raid Penalty). V\u00ec th\u1ebf, \u0111\u1ec3 setup 1 h\u1ec7 th\u1ed1ng s\u00e1t v\u1edbi nhu c\u1ea7u, Sys Admin c\u1ea7n ph\u1ea3i x\u00e1c \u0111\u1ecbnh r\u00f5 \u01b0u ti\u00ean h\u1ec7 th\u1ed1ng c\u1ee7a m\u00ecnh l\u00e0 g\u00ec: \u1ee8ng d\u1ee5ng ch\u1ea1y nhanh? M\u1ee9c \u0111\u1ed9 b\u1ea3o m\u1eadt ? dung l\u01b0\u1ee3ng l\u01b0u tr\u1eef? B\u1ea3ng y\u00eau c\u1ea7u RAID Penalty \u2013 l\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u1ed5 c\u1ee9ng t\u1ed1i thi\u1ec3u t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed7i RAID level C\u00e1c c\u00f4ng th\u1ee9c t\u00ednh trong b\u00e0i: T\u1ed5ng IOPS = IOPS per Disk * S\u1ed1 \u1ed5 c\u1ee9ng IOPS th\u1ef1c = (T\u1ed5ng IOPS * Write%)/(Raid Penalty) + (T\u1ed5ng IOPS * Read %) S\u1ed1 \u1ed5 c\u1ee9ng = ((Read IOPS) + (Write IOPS*Raid Penalty))/ IOPS per Disk","title":"3.2 . C\u00e1ch t\u00ednh IOPS"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/#33_khoi_tao_qos_policy","text":"Ki\u1ec3m tra IOPS hi\u1ec7n t\u1ea1i tr\u00ean m\u00e1y \u1ea3o yum install -y epel-release && yum install -y fio fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=testrw --filename=testrw --bs=4k --iodepth=64 --size=1GB --readwrite=randrw --rwmixread=75 K\u1ebft qu\u1ea3 test Kh\u1edfi t\u1ea1o QOS policy cinder qos-create low-iops consumer=\"front-end\" \\ read_iops_sec=210 write_iops_sec=90 Ki\u1ec3m tranh danh s\u00e1ch QOS [root@localhost /]# cinder qos-list +--------------------------------------+----------+-----------+--------------------------------------------------+ | ID | Name | Consumer | specs | +--------------------------------------+----------+-----------+--------------------------------------------------+ | 85d574d5-e835-48f3-a203-3ab8e40a5eb6 | low-iops | front-end | {'write_iops_sec': '90', 'read_iops_sec': '210'} | +--------------------------------------+----------+-----------+--------------------------------------------------+ Sau khi kh\u1edfi t\u1ea1o Policy c\u00f3 th\u1ec3 g\u1eafn v\u00e0o c\u00e1c volume type , nh\u01b0 c\u00e1c th\u00f4ng s\u1ed1 extra spec cinder qos-associate QOS_ID VOLUME_TYPE_ID openstack volume qos associate QOS_ID VOLUME_TYPE_ID G\u1eafn Policy v\u00e0o Volume Type \"LVM\" openstack volume qos associate 85d574d5-e835-48f3-a203-3ab8e40a5eb6 536c7a2e-5c10-4e7f-8417-22b0e85425c3 Test l\u1ea1i tr\u00ean m\u00e1y \u1ea3o","title":"3.3 . Kh\u1edfi t\u1ea1o QOS Policy"},{"location":"Openstack_Research/Advance/15. QOS - Cinder/#34_tham_khao_them","text":"https://docs.openstack.org/cinder/latest/admin/blockstorage-capacity-based-qos.html https://viettelidc.com.vn/tin-tuc/huong-dan-cach-tinh-iops END.","title":"3.4. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/","text":"Cinder Backup s\u1eed d\u1ee5ng NFS \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean NFS Node \u00b6 C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh NFS yum install -y install nfs-utils mkdir /var/lib/nfs-backup echo \"/var/lib/nfs-backup 192.168.69.0/24(rw,no_root_squash)\" >> /etc/exports systemctl restart rpcbind nfs-server systemctl enable rpcbind nfs-server C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-service=nfs --permanent firewall-cmd --reload 2. C\u1ea5u h\u00ecnh tr\u00ean Storage Node \u00b6 Qu\u00e1 tr\u00ecnh setup cinder node tham kh\u1ea3o T\u1ea0I \u0110\u00c2Y D\u01b0\u1edbi \u0111\u00e2y ch\u1ec9 l\u00e0 c\u00e1c c\u1ea5u h\u00ecnh b\u1ed5 sung cho d\u1ecbch v\u1ee5 backup C\u00e0i \u0111\u1eb7t NFS yum -y install nfs-utils systemctl start rpcbind systemctl enable rpcbind Th\u00eam c\u00e1c c\u1ea5u h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y v\u00e0o section DEFAULT t\u1ea1i /etc/cinder/cinder.conf Ch\u00fa \u00fd tr\u01b0\u1eddng IP backup_driver = cinder.backup.drivers.nfs backup_mount_point_base = $state_path/backup_nfs backup_share = 192.168.69.134:/var/lib/nfs-backup Ph\u00e2n quy\u1ec1n v\u00e0 kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start openstack-cinder-backup systemctl enable openstack-cinder-backup chown -R cinder. /var/lib/cinder/backup_nfs 3. Thao t\u00e1c tr\u00ean Controller Node \u00b6 Ki\u1ec3m tra c\u00e1c service [root@localhost images]# openstack volume service list +------------------+-----------------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-----------------------+------+---------+-------+----------------------------+ | cinder-scheduler | localhost.localdomain | nova | enabled | up | 2018-12-26T08:58:54.000000 | | cinder-volume | cinder@lvm | nova | enabled | up | 2018-12-26T08:58:51.000000 | | cinder-scheduler | cinder | nova | enabled | up | 2018-12-26T08:58:48.000000 | | cinder-backup | cinder | nova | enabled | up | 2018-12-26T08:58:54.000000 | +------------------+-----------------------+------+---------+-------+----------------------------+ \u0110\u1ec3 hi\u1ec3n th\u1ecb ch\u1ee9c n\u0103ng Cinder Backup tr\u00ean Horizon c\u1ea7n c\u1ea5u h\u00ecnh t\u1ea1i file /etc/openstack-dashboard/local_settings.py . Sau \u0111\u00f3 restart httpd OPENSTACK_CINDER_FEATURES = { 'enable_backup': True,} Ki\u1ec3m tra danh s\u00e1ch volume [root@localhost nova]# openstack volume list +--------------------------------------+------------+-----------+------+----------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------------+-----------+------+----------------------------------+ | 00f92eb3-6c5c-4d42-9030-1bd11306c5c5 | cirros-new | available | 5 | | | 7e144e3d-422e-4fdd-acb6-73120213999f | | in-use | 1 | Attached to cirrors on /dev/vda | +--------------------------------------+------------+-----------+------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t b\u1ea3n backup [root@localhost nova]# openstack volume backup create --force --name cirros-backup 7e144e3d-422e-4fdd-acb6-73120213999f +-------+--------------------------------------+ | Field | Value | +-------+--------------------------------------+ | id | a7dfa241-140a-4a66-85f3-61c05295a0ee | | name | cirros-backup | +-------+--------------------------------------+ Ki\u1ec3m tra danh s\u00e1ch backup [root@localhost nova]# openstack volume backup list +--------------------------------------+---------------+-------------+-----------+------+ | ID | Name | Description | Status | Size | +--------------------------------------+---------------+-------------+-----------+------+ | a7dfa241-140a-4a66-85f3-61c05295a0ee | cirros-backup | None | available | 1 | +--------------------------------------+---------------+-------------+-----------+------+ Restore Backup sang m\u1ed9t Volume m\u1edbi [root@localhost nova]# openstack volume backup restore cirros-backup cirros-new 'VolumeBackupsRestore' object is not iterable Kh\u1edfi t\u1ea1o m\u00e1y \u1edf t\u1edbi v\u1eeba volume \u0111\u01b0\u1ee3c restore Hi\u1ec7n t\u1ea1i m\u00e1y \u1ea3o \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c 1GB filesystem t\u1eeb b\u1ea3n backup, c\u00f3 ngh\u0129a partion hi\u1ec7n t\u1ea1i \u0111ang ch\u1ec9 d\u00f9ng 1GB cho filesystem Ki\u1ec3m tra l\u1ea1i tr\u00ean fdisk s\u1ebd th\u1ea5y partion c\u00f3 5GB nh\u01b0ng ch\u01b0a \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o \u0111\u1ec3 d\u00f9ng chung v\u1edbi filesystem S\u1eed d\u1ee5ng resize \u0111\u1ec3 repartion v\u00e0 ki\u1ec3m tra l\u1ea1i filsystem size More You have to distinguish the partition from the filesystem on the partition. The partition sizes and offsets are specified in the partition table, and you can view them with cat /proc/partitions . Paritions are created with a tool like fdisk (or when you're using Buildroot, it's often created by genimage ). The filesystem size is specified in the filesystem superblock, a piece of metadata that specifies the size of the filesystem, any options (e.g. if journalling is used), cluster sizes, etc. This is created by a tool like mke2fs . When you use mke2fs directly on a partition, it will use the full space of the partition for the filesystem, which is typically what you want. However, when you create the filesystem before partitioning the SD card (as is often the case when you generate an image with e.g. Buildroot), you have to specify the size to mke2fs (cfr. the man page : the second argument is blocks-count ). 4. Tham kh\u1ea3o th\u00eam \u00b6 https://docs.openstack.org/python-openstackclient/queens/cli/command-objects/volume-backup.html https://docs.openstack.org/cinder/queens/configuration/block-storage/backup/nfs-backup-driver.html https://docs.openstack.org/cinder/queens/admin/blockstorage-volume-backups.html","title":"16. Cinder Backup NFS"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/#cinder_backup_su_dung_nfs","text":"","title":"Cinder Backup s\u1eed d\u1ee5ng NFS"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/#1_cau_hinh_tren_nfs_node","text":"C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh NFS yum install -y install nfs-utils mkdir /var/lib/nfs-backup echo \"/var/lib/nfs-backup 192.168.69.0/24(rw,no_root_squash)\" >> /etc/exports systemctl restart rpcbind nfs-server systemctl enable rpcbind nfs-server C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-service=nfs --permanent firewall-cmd --reload","title":"1. C\u1ea5u h\u00ecnh tr\u00ean NFS Node"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/#2_cau_hinh_tren_storage_node","text":"Qu\u00e1 tr\u00ecnh setup cinder node tham kh\u1ea3o T\u1ea0I \u0110\u00c2Y D\u01b0\u1edbi \u0111\u00e2y ch\u1ec9 l\u00e0 c\u00e1c c\u1ea5u h\u00ecnh b\u1ed5 sung cho d\u1ecbch v\u1ee5 backup C\u00e0i \u0111\u1eb7t NFS yum -y install nfs-utils systemctl start rpcbind systemctl enable rpcbind Th\u00eam c\u00e1c c\u1ea5u h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y v\u00e0o section DEFAULT t\u1ea1i /etc/cinder/cinder.conf Ch\u00fa \u00fd tr\u01b0\u1eddng IP backup_driver = cinder.backup.drivers.nfs backup_mount_point_base = $state_path/backup_nfs backup_share = 192.168.69.134:/var/lib/nfs-backup Ph\u00e2n quy\u1ec1n v\u00e0 kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start openstack-cinder-backup systemctl enable openstack-cinder-backup chown -R cinder. /var/lib/cinder/backup_nfs","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Storage Node"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/#3_thao_tac_tren_controller_node","text":"Ki\u1ec3m tra c\u00e1c service [root@localhost images]# openstack volume service list +------------------+-----------------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-----------------------+------+---------+-------+----------------------------+ | cinder-scheduler | localhost.localdomain | nova | enabled | up | 2018-12-26T08:58:54.000000 | | cinder-volume | cinder@lvm | nova | enabled | up | 2018-12-26T08:58:51.000000 | | cinder-scheduler | cinder | nova | enabled | up | 2018-12-26T08:58:48.000000 | | cinder-backup | cinder | nova | enabled | up | 2018-12-26T08:58:54.000000 | +------------------+-----------------------+------+---------+-------+----------------------------+ \u0110\u1ec3 hi\u1ec3n th\u1ecb ch\u1ee9c n\u0103ng Cinder Backup tr\u00ean Horizon c\u1ea7n c\u1ea5u h\u00ecnh t\u1ea1i file /etc/openstack-dashboard/local_settings.py . Sau \u0111\u00f3 restart httpd OPENSTACK_CINDER_FEATURES = { 'enable_backup': True,} Ki\u1ec3m tra danh s\u00e1ch volume [root@localhost nova]# openstack volume list +--------------------------------------+------------+-----------+------+----------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------------+-----------+------+----------------------------------+ | 00f92eb3-6c5c-4d42-9030-1bd11306c5c5 | cirros-new | available | 5 | | | 7e144e3d-422e-4fdd-acb6-73120213999f | | in-use | 1 | Attached to cirrors on /dev/vda | +--------------------------------------+------------+-----------+------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t b\u1ea3n backup [root@localhost nova]# openstack volume backup create --force --name cirros-backup 7e144e3d-422e-4fdd-acb6-73120213999f +-------+--------------------------------------+ | Field | Value | +-------+--------------------------------------+ | id | a7dfa241-140a-4a66-85f3-61c05295a0ee | | name | cirros-backup | +-------+--------------------------------------+ Ki\u1ec3m tra danh s\u00e1ch backup [root@localhost nova]# openstack volume backup list +--------------------------------------+---------------+-------------+-----------+------+ | ID | Name | Description | Status | Size | +--------------------------------------+---------------+-------------+-----------+------+ | a7dfa241-140a-4a66-85f3-61c05295a0ee | cirros-backup | None | available | 1 | +--------------------------------------+---------------+-------------+-----------+------+ Restore Backup sang m\u1ed9t Volume m\u1edbi [root@localhost nova]# openstack volume backup restore cirros-backup cirros-new 'VolumeBackupsRestore' object is not iterable Kh\u1edfi t\u1ea1o m\u00e1y \u1edf t\u1edbi v\u1eeba volume \u0111\u01b0\u1ee3c restore Hi\u1ec7n t\u1ea1i m\u00e1y \u1ea3o \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c 1GB filesystem t\u1eeb b\u1ea3n backup, c\u00f3 ngh\u0129a partion hi\u1ec7n t\u1ea1i \u0111ang ch\u1ec9 d\u00f9ng 1GB cho filesystem Ki\u1ec3m tra l\u1ea1i tr\u00ean fdisk s\u1ebd th\u1ea5y partion c\u00f3 5GB nh\u01b0ng ch\u01b0a \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o \u0111\u1ec3 d\u00f9ng chung v\u1edbi filesystem S\u1eed d\u1ee5ng resize \u0111\u1ec3 repartion v\u00e0 ki\u1ec3m tra l\u1ea1i filsystem size More You have to distinguish the partition from the filesystem on the partition. The partition sizes and offsets are specified in the partition table, and you can view them with cat /proc/partitions . Paritions are created with a tool like fdisk (or when you're using Buildroot, it's often created by genimage ). The filesystem size is specified in the filesystem superblock, a piece of metadata that specifies the size of the filesystem, any options (e.g. if journalling is used), cluster sizes, etc. This is created by a tool like mke2fs . When you use mke2fs directly on a partition, it will use the full space of the partition for the filesystem, which is typically what you want. However, when you create the filesystem before partitioning the SD card (as is often the case when you generate an image with e.g. Buildroot), you have to specify the size to mke2fs (cfr. the man page : the second argument is blocks-count ).","title":"3. Thao t\u00e1c tr\u00ean Controller Node"},{"location":"Openstack_Research/Advance/16. Cinder-Backup-NFS/#4_tham_khao_them","text":"https://docs.openstack.org/python-openstackclient/queens/cli/command-objects/volume-backup.html https://docs.openstack.org/cinder/queens/configuration/block-storage/backup/nfs-backup-driver.html https://docs.openstack.org/cinder/queens/admin/blockstorage-volume-backups.html","title":"4. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/","text":"1. Transfer Volume \u00b6 1.1 Tr\u00ean Project ngu\u1ed3n \u00b6 Ki\u1ec3m tra danh s\u00e1ch Volume [root@controller nova]# openstack volume list +--------------------------------------+-----------------+--------+------+-------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+--------+------+-------------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | in-use | 8 | Attached to bootable-rebuild on /dev/vda | | 00f92eb3-6c5c-4d42-9030-1bd11306c5c5 | cirros-new | in-use | 5 | Attached to cirros-new-vm on /dev/vda | | 7e144e3d-422e-4fdd-acb6-73120213999f | | in-use | 1 | Attached to cirrors on /dev/vda | +--------------------------------------+-----------------+--------+------+-------------------------------------------+ Volume \u0111\u1ec3 c\u00f3 th\u1ec3 transfer c\u1ea7n \u1edf tr\u1ea1ng th\u00e1i available ( n\u1ebfu \u0111ang attack m\u00e1y \u1ea3o th\u00ec shutdown m\u00e1y \u1ea3o tr\u01b0\u1edbc khi transfer ) , sau \u0111\u00f3 th\u1ef1c hi\u1ec7n kh\u1edfi t\u1ea1o m\u1ed9t request transfer [root@controller nova]# cinder reset-state --state available 37d7e771-6509-4d14-9cd6-f8ec7c103daf [root@controller nova]# openstack volume transfer request create --name transfer-bootable 37d7e771-6509-4d14-9cd6-f8ec7c103daf +------------+--------------------------------------+ | Field | Value | +------------+--------------------------------------+ | auth_key | 3e86cb7bf3e6d53c | | created_at | 2018-12-28T02:13:21.257970 | | id | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | | name | transfer-bootable | | volume_id | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | +------------+--------------------------------------+ Sau khi th\u1ef1c hi\u1ec7n 1 request s\u1ebd xu\u1ea5t hi\u1ec7n auth_key id d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c \u1edf project \u0111\u00edch Li\u1ec7t k\u00ea c\u00e1c request transfer [root@controller ~]# openstack volume transfer request list +--------------------------------------+-------------------+--------------------------------------+ | ID | Name | Volume | +--------------------------------------+-------------------+--------------------------------------+ | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | transfer-bootable | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | 1.2. Tr\u00ean Project \u0111\u00edch \u00b6 S\u1eed d\u1ee5ng auth key v\u00e0 id \u0111\u1ec3 l\u00e0m input [root@controller ~]# openstack volume transfer request accept --auth-key 3e86cb7bf3e6d53c 846baa1c-0be6-475e-9fbe-ce3276e33d06 +-----------+--------------------------------------+ | Field | Value | +-----------+--------------------------------------+ | id | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | | name | transfer-bootable | | volume_id | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | +-----------+--------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch volume [root@controller ~]# openstack volume list +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | available | 8 | Attached to 7beb95ca-29da-415f-951c-b0132d400480 on /dev/vda | +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o t\u1eeb volume [root@controller ~]# openstack server create --flavor small --network provider --volume volume-bootable test-vm +-----------------------------+----------------------------------------------+ | Field | Value | +-----------------------------+----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | | | OS-EXT-STS:power_state | NOSTATE | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | nBLrgMEh24zT | | config_drive | | | created | 2018-12-28T02:33:06Z | | flavor | small (9f756b35-4b31-4416-bcb1-aea6595b0c5f) | | hostId | | | id | 76beed3d-27c9-4761-9313-3ed3fec52392 | | image | | | key_name | None | | name | test-vm | | progress | 0 | | project_id | 438de521107643ee8348114ba022de1b | | properties | | | security_groups | name='default' | | status | BUILD | | updated | 2018-12-28T02:33:06Z | | user_id | 3dd58da375244ac8b898d673bfb3e29b | | volumes_attached | | +-----------------------------+----------------------------------------------+ 2. Extend Volume \u00b6 2.1 . Extend Volume Root Instance \u00b6 Li\u1ec7t k\u00ea danh s\u00e1ch volume [root@compute1 ~]# openstack volume list +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ | 885882e5-8b9f-42e9-927a-bb8817214055 | volume-normal | available | 5 | | | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | in-use | 8 | Attached to os-volume-bootable on /dev/vda | +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ Poweroff Instance \u0111ang s\u1eed d\u1ee5ng volume v\u00e0o root volume nova stop os-volume-bootable Chuy\u1ec3n state volume v\u1ec1 available [root@compute1 ~]# cinder show 37d7e771-6509-4d14-9cd6-f8ec7c103daf | grep status | migration_status | None | | os-vol-mig-status-attr:migstat | None | | os-vol-mig-status-attr:name_id | None | | replication_status | None | | status | available | Extend Volume v\u00e0 chuy\u1ec3n v\u1ec1 tr\u1ea1ng th\u00e1i in-use [root@compute1 ~]# cinder extend 37d7e771-6509-4d14-9cd6-f8ec7c103daf 10 [root@compute1 ~]# cinder reset-state --state in-use 37d7e771-6509-4d14-9cd6-f8ec7c103daf [root@compute1 ~]# cinder list +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ | ID | Status | Name | Size | Volume Type | Bootable | Attached to | +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | in-use | volume-bootable | 10 | - | true | f39a1d84-3b16-47a0-a87c-e5b2b789b102 | | 885882e5-8b9f-42e9-927a-bb8817214055 | available | volume-normal | 5 | - | false | | +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ Kh\u1edfi \u0111\u1ed9ng instance [root@compute1 ~]# nova start os-volume-bootable Request to start server os-volume-bootable has been accepted. Ki\u1ec3m tra l\u1ea1i size , hi\u1ec7n \u0111\u00e3 c\u00f3 \u0111\u00e3 partion nh\u1eadn block m\u1edbi nh\u01b0ng system v\u1eabn ch\u01b0a s\u1eed d\u1ee5ng h\u1ebft partion \u0111\u1ec3 l\u00e0m filesystem S\u1eed d\u1ee5ng resize2fs /dev/va1 \u0111\u1ec3 partion s\u1eed d\u1ee5ng ho\u00e0n to\u00e0n cho filesystem","title":"17. Transfer & Extend Root Volume"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/#1_transfer_volume","text":"","title":"1. Transfer Volume"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/#11_tren_project_nguon","text":"Ki\u1ec3m tra danh s\u00e1ch Volume [root@controller nova]# openstack volume list +--------------------------------------+-----------------+--------+------+-------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+--------+------+-------------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | in-use | 8 | Attached to bootable-rebuild on /dev/vda | | 00f92eb3-6c5c-4d42-9030-1bd11306c5c5 | cirros-new | in-use | 5 | Attached to cirros-new-vm on /dev/vda | | 7e144e3d-422e-4fdd-acb6-73120213999f | | in-use | 1 | Attached to cirrors on /dev/vda | +--------------------------------------+-----------------+--------+------+-------------------------------------------+ Volume \u0111\u1ec3 c\u00f3 th\u1ec3 transfer c\u1ea7n \u1edf tr\u1ea1ng th\u00e1i available ( n\u1ebfu \u0111ang attack m\u00e1y \u1ea3o th\u00ec shutdown m\u00e1y \u1ea3o tr\u01b0\u1edbc khi transfer ) , sau \u0111\u00f3 th\u1ef1c hi\u1ec7n kh\u1edfi t\u1ea1o m\u1ed9t request transfer [root@controller nova]# cinder reset-state --state available 37d7e771-6509-4d14-9cd6-f8ec7c103daf [root@controller nova]# openstack volume transfer request create --name transfer-bootable 37d7e771-6509-4d14-9cd6-f8ec7c103daf +------------+--------------------------------------+ | Field | Value | +------------+--------------------------------------+ | auth_key | 3e86cb7bf3e6d53c | | created_at | 2018-12-28T02:13:21.257970 | | id | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | | name | transfer-bootable | | volume_id | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | +------------+--------------------------------------+ Sau khi th\u1ef1c hi\u1ec7n 1 request s\u1ebd xu\u1ea5t hi\u1ec7n auth_key id d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c \u1edf project \u0111\u00edch Li\u1ec7t k\u00ea c\u00e1c request transfer [root@controller ~]# openstack volume transfer request list +--------------------------------------+-------------------+--------------------------------------+ | ID | Name | Volume | +--------------------------------------+-------------------+--------------------------------------+ | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | transfer-bootable | 37d7e771-6509-4d14-9cd6-f8ec7c103daf |","title":"1.1 Tr\u00ean Project ngu\u1ed3n"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/#12_tren_project_ich","text":"S\u1eed d\u1ee5ng auth key v\u00e0 id \u0111\u1ec3 l\u00e0m input [root@controller ~]# openstack volume transfer request accept --auth-key 3e86cb7bf3e6d53c 846baa1c-0be6-475e-9fbe-ce3276e33d06 +-----------+--------------------------------------+ | Field | Value | +-----------+--------------------------------------+ | id | 846baa1c-0be6-475e-9fbe-ce3276e33d06 | | name | transfer-bootable | | volume_id | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | +-----------+--------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch volume [root@controller ~]# openstack volume list +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | available | 8 | Attached to 7beb95ca-29da-415f-951c-b0132d400480 on /dev/vda | +--------------------------------------+-----------------+-----------+------+---------------------------------------------------------------+ Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o t\u1eeb volume [root@controller ~]# openstack server create --flavor small --network provider --volume volume-bootable test-vm +-----------------------------+----------------------------------------------+ | Field | Value | +-----------------------------+----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | | | OS-EXT-STS:power_state | NOSTATE | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | nBLrgMEh24zT | | config_drive | | | created | 2018-12-28T02:33:06Z | | flavor | small (9f756b35-4b31-4416-bcb1-aea6595b0c5f) | | hostId | | | id | 76beed3d-27c9-4761-9313-3ed3fec52392 | | image | | | key_name | None | | name | test-vm | | progress | 0 | | project_id | 438de521107643ee8348114ba022de1b | | properties | | | security_groups | name='default' | | status | BUILD | | updated | 2018-12-28T02:33:06Z | | user_id | 3dd58da375244ac8b898d673bfb3e29b | | volumes_attached | | +-----------------------------+----------------------------------------------+","title":"1.2. Tr\u00ean Project \u0111\u00edch"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/#2_extend_volume","text":"","title":"2. Extend Volume"},{"location":"Openstack_Research/Advance/17. Transfer-&-Extend-Root-Volume/#21_extend_volume_root_instance","text":"Li\u1ec7t k\u00ea danh s\u00e1ch volume [root@compute1 ~]# openstack volume list +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ | 885882e5-8b9f-42e9-927a-bb8817214055 | volume-normal | available | 5 | | | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | volume-bootable | in-use | 8 | Attached to os-volume-bootable on /dev/vda | +--------------------------------------+-----------------+-----------+------+---------------------------------------------+ Poweroff Instance \u0111ang s\u1eed d\u1ee5ng volume v\u00e0o root volume nova stop os-volume-bootable Chuy\u1ec3n state volume v\u1ec1 available [root@compute1 ~]# cinder show 37d7e771-6509-4d14-9cd6-f8ec7c103daf | grep status | migration_status | None | | os-vol-mig-status-attr:migstat | None | | os-vol-mig-status-attr:name_id | None | | replication_status | None | | status | available | Extend Volume v\u00e0 chuy\u1ec3n v\u1ec1 tr\u1ea1ng th\u00e1i in-use [root@compute1 ~]# cinder extend 37d7e771-6509-4d14-9cd6-f8ec7c103daf 10 [root@compute1 ~]# cinder reset-state --state in-use 37d7e771-6509-4d14-9cd6-f8ec7c103daf [root@compute1 ~]# cinder list +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ | ID | Status | Name | Size | Volume Type | Bootable | Attached to | +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ | 37d7e771-6509-4d14-9cd6-f8ec7c103daf | in-use | volume-bootable | 10 | - | true | f39a1d84-3b16-47a0-a87c-e5b2b789b102 | | 885882e5-8b9f-42e9-927a-bb8817214055 | available | volume-normal | 5 | - | false | | +--------------------------------------+-----------+-----------------+------+-------------+----------+--------------------------------------+ Kh\u1edfi \u0111\u1ed9ng instance [root@compute1 ~]# nova start os-volume-bootable Request to start server os-volume-bootable has been accepted. Ki\u1ec3m tra l\u1ea1i size , hi\u1ec7n \u0111\u00e3 c\u00f3 \u0111\u00e3 partion nh\u1eadn block m\u1edbi nh\u01b0ng system v\u1eabn ch\u01b0a s\u1eed d\u1ee5ng h\u1ebft partion \u0111\u1ec3 l\u00e0m filesystem S\u1eed d\u1ee5ng resize2fs /dev/va1 \u0111\u1ec3 partion s\u1eed d\u1ee5ng ho\u00e0n to\u00e0n cho filesystem","title":"2.1 . Extend Volume Root Instance"},{"location":"Openstack_Research/Advance/18. L3-Agent-HA-Compute/","text":"C\u1ea5u h\u00ecnh L3 Agent HA tr\u00ean Compute Node \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean c\u00e1c Compute Node \u00b6 C\u00e0i \u0111\u1eb7t c\u00e1c Package y\u00eau c\u1ea7u yum install -y openstack-neutron-openvswitch openstack-neutron-ml2 C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone C\u1ea5u h\u00ecnh L3 Agent /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = openvswitch external_network_bridge = br-provider C\u1ea5u h\u00ecnh /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider local_ip = 192.168.69.131/192.168.69.132 ( example ) [agent] tunnel_types = vxlan l2_population = True tunnel_types = vxlan [securitygroup] firewall_driver = iptables_hybrid Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-openvswitch-agent systemctl restart neutron-l3-agent 2. C\u1ea5u h\u00ecnh tr\u00ean Controller Node \u00b6 Note : c\u00e1c c\u1ea5u h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y d\u00f9ng \u0111\u1ec3 b\u1ed5 sung v\u00e0o c\u00e1c c\u1ea5u h\u00ecnh c\u00f3 s\u1eb5n C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] service_plugins = router allow_overlapping_ips = True l3_ha = True max_l3_agents_per_router = 2 min_l3_agents_per_router = 2 N\u1ebfu \u0111ang s\u1eed d\u1ee5ng QOS th\u00ec c\u1ea5u h\u00ecnh service_plugins = neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.qos.qos_plugin.QoSPlugin C\u1ea5u h\u00ecnh Ml2 driver /etc/neutron/plugins/ml2/ml2_conf.in [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan [ml2] mechanism_drivers = openvswitch,l2population [ml2_type_vxlan] vni_ranges = 1:300 Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron systemctl restart neutron-server.service Ki\u1ec3m tra network agent [root@localhost ~]# openstack network agent list +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ | 043cb890-1d34-4a7c-b0bb-72eaff74308c | L3 agent | compute2 | nova | :-) | UP | neutron-l3-agent | | 189e60a1-3405-4201-91a8-82e475cc9c25 | L3 agent | compute1 | nova | :-) | UP | neutron-l3-agent | | 283d0c3c-f4f3-46c5-9021-da1d61a4cb95 | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | 6b877e43-b475-4606-874b-75edec7b8b2b | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | 76e2b1e7-9654-44bf-ac17-46f587f56a97 | DHCP agent | compute1 | nova | :-) | UP | neutron-dhcp-agent | | 7f91ab5b-8d83-45de-9f2f-37a50caba9c6 | Metadata agent | compute2 | None | :-) | UP | neutron-metadata-agent | | bc585e17-c659-4fbc-a3f8-4a7bb61626b8 | DHCP agent | compute2 | nova | :-) | UP | neutron-dhcp-agent | | deeafabd-332b-4fd3-bb1d-17519d5fcb3c | Metadata agent | compute1 | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ Sau khi kh\u1edfi t\u1ea1o router m\u1edbi s\u1ebd th\u1ea5y HA tentant , va Ki\u1ec3m tra ping tr\u00ean m\u00e1y \u1ea3o","title":"18. L3 Agent HA Compute"},{"location":"Openstack_Research/Advance/18. L3-Agent-HA-Compute/#cau_hinh_l3_agent_ha_tren_compute_node","text":"","title":"C\u1ea5u h\u00ecnh L3 Agent HA tr\u00ean Compute Node"},{"location":"Openstack_Research/Advance/18. L3-Agent-HA-Compute/#1_cau_hinh_tren_cac_compute_node","text":"C\u00e0i \u0111\u1eb7t c\u00e1c Package y\u00eau c\u1ea7u yum install -y openstack-neutron-openvswitch openstack-neutron-ml2 C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone C\u1ea5u h\u00ecnh L3 Agent /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = openvswitch external_network_bridge = br-provider C\u1ea5u h\u00ecnh /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider local_ip = 192.168.69.131/192.168.69.132 ( example ) [agent] tunnel_types = vxlan l2_population = True tunnel_types = vxlan [securitygroup] firewall_driver = iptables_hybrid Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-openvswitch-agent systemctl restart neutron-l3-agent","title":"1. C\u1ea5u h\u00ecnh tr\u00ean c\u00e1c Compute Node"},{"location":"Openstack_Research/Advance/18. L3-Agent-HA-Compute/#2_cau_hinh_tren_controller_node","text":"Note : c\u00e1c c\u1ea5u h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y d\u00f9ng \u0111\u1ec3 b\u1ed5 sung v\u00e0o c\u00e1c c\u1ea5u h\u00ecnh c\u00f3 s\u1eb5n C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] service_plugins = router allow_overlapping_ips = True l3_ha = True max_l3_agents_per_router = 2 min_l3_agents_per_router = 2 N\u1ebfu \u0111ang s\u1eed d\u1ee5ng QOS th\u00ec c\u1ea5u h\u00ecnh service_plugins = neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.qos.qos_plugin.QoSPlugin C\u1ea5u h\u00ecnh Ml2 driver /etc/neutron/plugins/ml2/ml2_conf.in [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan [ml2] mechanism_drivers = openvswitch,l2population [ml2_type_vxlan] vni_ranges = 1:300 Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron systemctl restart neutron-server.service Ki\u1ec3m tra network agent [root@localhost ~]# openstack network agent list +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ | 043cb890-1d34-4a7c-b0bb-72eaff74308c | L3 agent | compute2 | nova | :-) | UP | neutron-l3-agent | | 189e60a1-3405-4201-91a8-82e475cc9c25 | L3 agent | compute1 | nova | :-) | UP | neutron-l3-agent | | 283d0c3c-f4f3-46c5-9021-da1d61a4cb95 | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | 6b877e43-b475-4606-874b-75edec7b8b2b | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | 76e2b1e7-9654-44bf-ac17-46f587f56a97 | DHCP agent | compute1 | nova | :-) | UP | neutron-dhcp-agent | | 7f91ab5b-8d83-45de-9f2f-37a50caba9c6 | Metadata agent | compute2 | None | :-) | UP | neutron-metadata-agent | | bc585e17-c659-4fbc-a3f8-4a7bb61626b8 | DHCP agent | compute2 | nova | :-) | UP | neutron-dhcp-agent | | deeafabd-332b-4fd3-bb1d-17519d5fcb3c | Metadata agent | compute1 | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+ Sau khi kh\u1edfi t\u1ea1o router m\u1edbi s\u1ebd th\u1ea5y HA tentant , va Ki\u1ec3m tra ping tr\u00ean m\u00e1y \u1ea3o","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Controller Node"},{"location":"Openstack_Research/Advance/2.RabbitMQ-&-API-Endpoint/","text":"RabbitMQ v\u00e0 API trong Nova OPS \u00b6 1. RabbitMQ v\u00e0 API \u00b6 AMQP \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u1ea3m nhi\u1ec7m qu\u1ea3n l\u00fd message trong Openstack Cloud . Rabbitmq s\u1eed d\u1ee5ng AMQP broker cho d\u1ecbch v\u1ee5 message queue c\u1ee7a m\u00ecnh . Rabbitmq n\u1eafm nhi\u1ec7m v\u1ee5 ng\u1ed3i gi\u1eefa b\u1ea5t 2 compoment trong nova cho ph\u00e9p ch\u00fang li\u00ean l\u1ea1c v\u1edbi nhau m\u00e0 kh\u00f4ng c\u1ea7n x\u00e1c th\u1ef1c. Trong OPS t\u1eadn d\u1ee5ng publish/subscribe \u0111\u1ec3 qu\u1ea3n l\u00fd h\u00e0ng ch\u1edd : Cung c\u1ea5p kh\u1ea3 n\u0103ng t\u00e1ch bi\u1ec7t c\u00e1c message gi\u1eefa nhi\u1ec1u producer v\u00e0 consumer \u0110\u1ed3ng b\u1ed9 to\u00e0n ph\u1ea7n gi\u1eefa producer v\u00e0 consumer. Trong rabbit mq cung c\u1ea5p kh\u1ea3 n\u0103ng one-way messaging. Consumer g\u1eedi m\u1ed9t request k\u00e8m theo m\u1ed9t message . Client s\u1ebd kh\u00f4ng ch\u1edd reply t\u1eeb server m\u00e0 v\u1eabn s\u1ebd ti\u1ebfp t\u1ee5c x\u1eed l\u00fd . Request s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn h\u00e0ng ch\u1edd n\u01a1i producer s\u1ebd message . Y\u00eau c\u1ea7u s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c x\u1eed l\u00fd ngay l\u1eadp t\u1ee9c nh\u01b0ng v\u1eabn s\u1ebd \u1edf trong h\u00e0ng ch\u1edd cho \u0111\u1ebfn khi message \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn server . Khi message \u0111\u00e3 \u0111\u01b0\u1ee3c chuy\u1ec3n v\u00e0o h\u00e0ng ch\u1edd th\u00ec , consumer s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c nh\u1eadn c\u00e1c th\u00f4ng b\u00e1o v\u1ec1 state b\u00ean prodcuer. Trong khi \u0111\u00f3 khi m\u1ed9t request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn API , c\u00e1c HTTP request g\u1eedi \u0111\u1ebfn y\u00eau c\u1ea7u \u0111\u01b0\u1ee3c reply t\u1eeb server.. Gi\u1eefa Client v\u00e0 Server c\u1ea7n thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i tr\u01b0\u1edbc khi truy\u1ec1n t\u1ea3i . \u0110\u1ed1i v\u1edbi c\u00e1c Request API s\u1ebd y\u00eau c\u1ea7u c\u00e1c service tr\u1ea3 v\u1ec1 response ngay l\u1eadp t\u1ee9c, nh\u01b0ng v\u1edbi rabbitmq s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o h\u00e0ng ch\u1edd cho \u0111\u1ebfn khi producer th\u1ef1c hi\u1ec7n task theo m\u1ed9t message , cung c\u1ea5p kh\u1ea3 n\u0103ng ch\u1ecbu khi m\u1ed9t compoment b\u1ecb l\u1ed7i t\u1ea1i 1 th\u1eddi \u0111i\u1ec3m, kh\u00f4ng b\u1ecb m\u1ea5t m\u00e1t c\u00e1c tassk \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u t\u1eeb API Connection neutron-linux-bridge-agent t\u1eeb compute node t\u1edb controller node","title":"2.RabbitMQ & API Endpoint"},{"location":"Openstack_Research/Advance/2.RabbitMQ-&-API-Endpoint/#rabbitmq_va_api_trong_nova_ops","text":"","title":"RabbitMQ v\u00e0 API trong Nova OPS"},{"location":"Openstack_Research/Advance/2.RabbitMQ-&-API-Endpoint/#1_rabbitmq_va_api","text":"AMQP \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u1ea3m nhi\u1ec7m qu\u1ea3n l\u00fd message trong Openstack Cloud . Rabbitmq s\u1eed d\u1ee5ng AMQP broker cho d\u1ecbch v\u1ee5 message queue c\u1ee7a m\u00ecnh . Rabbitmq n\u1eafm nhi\u1ec7m v\u1ee5 ng\u1ed3i gi\u1eefa b\u1ea5t 2 compoment trong nova cho ph\u00e9p ch\u00fang li\u00ean l\u1ea1c v\u1edbi nhau m\u00e0 kh\u00f4ng c\u1ea7n x\u00e1c th\u1ef1c. Trong OPS t\u1eadn d\u1ee5ng publish/subscribe \u0111\u1ec3 qu\u1ea3n l\u00fd h\u00e0ng ch\u1edd : Cung c\u1ea5p kh\u1ea3 n\u0103ng t\u00e1ch bi\u1ec7t c\u00e1c message gi\u1eefa nhi\u1ec1u producer v\u00e0 consumer \u0110\u1ed3ng b\u1ed9 to\u00e0n ph\u1ea7n gi\u1eefa producer v\u00e0 consumer. Trong rabbit mq cung c\u1ea5p kh\u1ea3 n\u0103ng one-way messaging. Consumer g\u1eedi m\u1ed9t request k\u00e8m theo m\u1ed9t message . Client s\u1ebd kh\u00f4ng ch\u1edd reply t\u1eeb server m\u00e0 v\u1eabn s\u1ebd ti\u1ebfp t\u1ee5c x\u1eed l\u00fd . Request s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn h\u00e0ng ch\u1edd n\u01a1i producer s\u1ebd message . Y\u00eau c\u1ea7u s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c x\u1eed l\u00fd ngay l\u1eadp t\u1ee9c nh\u01b0ng v\u1eabn s\u1ebd \u1edf trong h\u00e0ng ch\u1edd cho \u0111\u1ebfn khi message \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn server . Khi message \u0111\u00e3 \u0111\u01b0\u1ee3c chuy\u1ec3n v\u00e0o h\u00e0ng ch\u1edd th\u00ec , consumer s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c nh\u1eadn c\u00e1c th\u00f4ng b\u00e1o v\u1ec1 state b\u00ean prodcuer. Trong khi \u0111\u00f3 khi m\u1ed9t request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn API , c\u00e1c HTTP request g\u1eedi \u0111\u1ebfn y\u00eau c\u1ea7u \u0111\u01b0\u1ee3c reply t\u1eeb server.. Gi\u1eefa Client v\u00e0 Server c\u1ea7n thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i tr\u01b0\u1edbc khi truy\u1ec1n t\u1ea3i . \u0110\u1ed1i v\u1edbi c\u00e1c Request API s\u1ebd y\u00eau c\u1ea7u c\u00e1c service tr\u1ea3 v\u1ec1 response ngay l\u1eadp t\u1ee9c, nh\u01b0ng v\u1edbi rabbitmq s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o h\u00e0ng ch\u1edd cho \u0111\u1ebfn khi producer th\u1ef1c hi\u1ec7n task theo m\u1ed9t message , cung c\u1ea5p kh\u1ea3 n\u0103ng ch\u1ecbu khi m\u1ed9t compoment b\u1ecb l\u1ed7i t\u1ea1i 1 th\u1eddi \u0111i\u1ec3m, kh\u00f4ng b\u1ecb m\u1ea5t m\u00e1t c\u00e1c tassk \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u t\u1eeb API Connection neutron-linux-bridge-agent t\u1eeb compute node t\u1edb controller node","title":"1. RabbitMQ v\u00e0 API"},{"location":"Openstack_Research/Advance/3. Log/","text":"Log trong OPS \u00b6 1. Th\u01b0 m\u1ee5c log m\u1eb7c \u0111\u1ecbnh \u00b6 Tr\u00ean Controller Node Compute nova- * /var/log/nova Image Service glance- * /var/log/glance Block Storage cinder- * /var/log/cinder Identity service keystone- * /var/log/keystone Networking neutron- * /var/log/neutron Dashboard horizon /var/log/apache2 ho\u1eb7c /var/log/httpd Orchestration service heat /var/log/heat Telemetry service ceilometer /var/log/ceilometer Tr\u00ean Compute Node : Nova Compute /var/log/nova/nova-compute.log Linux Bridge Agent /var/log/neutron/linuxbridge-agent.log Compute nodes libvirt /var/log/libvirt/libvirtd.log Compute nodes Console (boot upmessages) for VM instances: /var/lib/nova/instances/instance-/console.log_ Tr\u00ean Block Storage Node ; - Block Storage nodes cinder-volume /var/log/cinder/cinder-volume.log 2. C\u1ea5u h\u00ecnh Syslog \u00b6 \u0110\u1ec3 c\u1ea5u h\u00ecnh c\u00e1c message log s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn syslog c\u1ea5u h\u00ecnh tr\u00ean t\u1eebng service [DEFAULT] debug = False use_syslog = True syslog_log_facility = LOG_LOCAL0","title":"3. Log"},{"location":"Openstack_Research/Advance/3. Log/#log_trong_ops","text":"","title":"Log trong OPS"},{"location":"Openstack_Research/Advance/3. Log/#1_thu_muc_log_mac_inh","text":"Tr\u00ean Controller Node Compute nova- * /var/log/nova Image Service glance- * /var/log/glance Block Storage cinder- * /var/log/cinder Identity service keystone- * /var/log/keystone Networking neutron- * /var/log/neutron Dashboard horizon /var/log/apache2 ho\u1eb7c /var/log/httpd Orchestration service heat /var/log/heat Telemetry service ceilometer /var/log/ceilometer Tr\u00ean Compute Node : Nova Compute /var/log/nova/nova-compute.log Linux Bridge Agent /var/log/neutron/linuxbridge-agent.log Compute nodes libvirt /var/log/libvirt/libvirtd.log Compute nodes Console (boot upmessages) for VM instances: /var/lib/nova/instances/instance-/console.log_ Tr\u00ean Block Storage Node ; - Block Storage nodes cinder-volume /var/log/cinder/cinder-volume.log","title":"1. Th\u01b0 m\u1ee5c log m\u1eb7c \u0111\u1ecbnh"},{"location":"Openstack_Research/Advance/3. Log/#2_cau_hinh_syslog","text":"\u0110\u1ec3 c\u1ea5u h\u00ecnh c\u00e1c message log s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn syslog c\u1ea5u h\u00ecnh tr\u00ean t\u1eebng service [DEFAULT] debug = False use_syslog = True syslog_log_facility = LOG_LOCAL0","title":"2. C\u1ea5u h\u00ecnh Syslog"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/","text":"noVNC trong OPS \u00b6 \u0110\u1ec3 cung c\u1ea5p cho m\u1ed9t giao di\u1ec7n \u0111i\u1ec1u khi\u1ec3n ho\u1eb7c truy c\u1eadp t\u1eeb xa v\u00e0o m\u00e1y \u1ea3o , trong OPS cung c\u1ea5p h\u1ed7 tr\u1ee3 noVNC ho\u1eb7c SPICE HTML 5. 1. noVNC & nova-console-auth \u00b6 C\u00e1c Client tham gia v\u00e0o noVNC proxy \u0111\u1ec1u s\u1eed d\u1ee5ng m\u1ed9t d\u1ecbch v\u1ee5 \u0111\u1ec3 qu\u1ea3n l\u00fd c\u00e1c token t\u00ean l\u00e0 : nova-consoleauth. \u0110\u1ec3 proxy ho\u1ea1t \u0111\u1ed9ng c\u1ea7n c\u00f3 nova-consoleauth . Nhi\u1ec1u proxy c\u00f3 s\u1eed d\u1ee5ng chung nova-consoleauth \u0111\u1ec3 qu\u1ea3n l\u00fd Workflow B1 . M\u1ed9t user g\u1eedi m\u1ed9t request qua API , v\u00e0 nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t access_url \u0111\u1ec3 truy c\u1eadp VNC . Ex : https://{ip}:port/?token=xyz B2 . User truy c\u1eadp v\u00e0o URL th\u00f4ng qua brower B3 . Brower k\u1ebft n\u1ed1i n\u1ed1i t\u01a1i proxy. B4 . Proxy trao \u0111\u1ed5i v\u1edbi nova-console-auth \u0111\u1ec3 t\u00e1ch token v\u00e0 x\u00e1c th\u1ef1c token cho ng\u01b0\u1eddi d\u00f9ng, v\u00e0 map token t\u1edbi compute host v\u00e0 port c\u1ee7a t\u1eebng instance tr\u00ean VNC Server Tr\u00ean compute host c\u00f3 m\u1ed9t \u0111\u1ecba ch\u1ec9 IP m\u00e0 proxy c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i t\u1edbi , option vncserver_proxyclient_address d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh IP n\u00e0y . VNC proxy s\u1ebd ho\u1ea1t \u0111\u1ed9ng gi\u1ed1ng nh\u01b0 m\u1ed9t bridge gi\u1eefa public network v\u00e0 private network. B5. Proxy thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i t\u1edbi VNC Server v\u00e0 gi\u1eef nguy\u00ean k\u1ebft n\u1ed1i khi h\u1ebft session. LOG info console-auth INFO nova.consoleauth.manager [req-8ca21e6d-875d-4017-9aad-365f888dac16 6ca03d3c55444c10aa22f481f2e13381 9373ec3c823343de87ae613b972aa4d3 - default default] Received Token: 7b08b51a-78f3-4ff5-a84e-6cc668f78a08, {'instance_uuid': u'861da5b8-284d-463f-8b48-fb2050acc366', 'access_url': u'http://192.168.30.130:6080/vnc_auto.html?token=7b08b51a-78f3-4ff5-a84e-6cc668f78a08', 'token': u'7b08b51a-78f3-4ff5-a84e-6cc668f78a08', 'last_activity_at': 1542350179.299853, 'internal_access_path': None, 'console_type': u'novnc', 'host': u'192.168.69.131', 'port': u'5900'} 2. C\u1ea5u h\u00ecnh noVNC proxy ri\u00eang \u00b6 2.1 . C\u00e1c option c\u1ea5u h\u00ecnh trong section VNC \u00b6 Configuration option=Default value Descrtion novncproxy_base_url=http://127.0.0.1:6080/vnc_auto.html \u0110\u1ecba ch\u1ec9 c\u1ee7a noVNC Web Proxy Client vnc_enabled=True b\u1eadt c\u00e1c ch\u1ee9c n\u0103ng li\u00ean quan VNC vnc_keymap=en-us keymap cho VNC server_listen=127.0.0.1 \u0111\u1ecba ch\u1ec9 vncserver instance l\u1eafng nghe request server_proxyclient_address=127.0.0.1 \u0111\u1ecba ch\u1ec9 c\u00e1c proxy client (nova-xvpvncproxy - Web-based Management) c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i 2.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh \u00b6 C\u00e0i \u0111\u1eb7t package tr\u00ean VNC Node yum install centos-release-openstack-queens yum install openstack-nova-novncproxy crudini C\u1ea5u h\u00ecnh file nova cho VNC Node crudini /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:rabbitmq_123@controller C\u1ea5u h\u00ecnh file host cho VNC Node echo \"192.168.30.130 controller\" > /etc/hosts C\u1ea5u h\u00ecnh VNC section cho noVNC Node t\u1ea1i /etc/nova/nova.conf [vnc] enabled = true server_proxyclient_address = 192.168.69.132 C\u1ea5u h\u00ecnh VNC Section cho Compute Node t\u1ea1i /etc/nova/nova.conf [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.131 novncproxy_base_url = http://192.168.30.132:6080/vnc_auto.html 2.3 . Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 \u00b6 Tr\u00ean Compute node systemctl status openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service Tr\u00ean Compute Node systemctl restart openstack-nova-compute systemctl enable openstack-nova-compute Tr\u00ean VNC Node systemctl restart openstack-nova-novncproxy systemctl enable openstack-nova-novncproxy Log tr\u00ean VNC Node LOG tr\u00ean nova-consoleauth","title":"noVNC trong OPS"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#novnc_trong_ops","text":"\u0110\u1ec3 cung c\u1ea5p cho m\u1ed9t giao di\u1ec7n \u0111i\u1ec1u khi\u1ec3n ho\u1eb7c truy c\u1eadp t\u1eeb xa v\u00e0o m\u00e1y \u1ea3o , trong OPS cung c\u1ea5p h\u1ed7 tr\u1ee3 noVNC ho\u1eb7c SPICE HTML 5.","title":"noVNC trong OPS"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#1_novnc_nova-console-auth","text":"C\u00e1c Client tham gia v\u00e0o noVNC proxy \u0111\u1ec1u s\u1eed d\u1ee5ng m\u1ed9t d\u1ecbch v\u1ee5 \u0111\u1ec3 qu\u1ea3n l\u00fd c\u00e1c token t\u00ean l\u00e0 : nova-consoleauth. \u0110\u1ec3 proxy ho\u1ea1t \u0111\u1ed9ng c\u1ea7n c\u00f3 nova-consoleauth . Nhi\u1ec1u proxy c\u00f3 s\u1eed d\u1ee5ng chung nova-consoleauth \u0111\u1ec3 qu\u1ea3n l\u00fd Workflow B1 . M\u1ed9t user g\u1eedi m\u1ed9t request qua API , v\u00e0 nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t access_url \u0111\u1ec3 truy c\u1eadp VNC . Ex : https://{ip}:port/?token=xyz B2 . User truy c\u1eadp v\u00e0o URL th\u00f4ng qua brower B3 . Brower k\u1ebft n\u1ed1i n\u1ed1i t\u01a1i proxy. B4 . Proxy trao \u0111\u1ed5i v\u1edbi nova-console-auth \u0111\u1ec3 t\u00e1ch token v\u00e0 x\u00e1c th\u1ef1c token cho ng\u01b0\u1eddi d\u00f9ng, v\u00e0 map token t\u1edbi compute host v\u00e0 port c\u1ee7a t\u1eebng instance tr\u00ean VNC Server Tr\u00ean compute host c\u00f3 m\u1ed9t \u0111\u1ecba ch\u1ec9 IP m\u00e0 proxy c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i t\u1edbi , option vncserver_proxyclient_address d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh IP n\u00e0y . VNC proxy s\u1ebd ho\u1ea1t \u0111\u1ed9ng gi\u1ed1ng nh\u01b0 m\u1ed9t bridge gi\u1eefa public network v\u00e0 private network. B5. Proxy thi\u1ebft l\u1eadp k\u1ebft n\u1ed1i t\u1edbi VNC Server v\u00e0 gi\u1eef nguy\u00ean k\u1ebft n\u1ed1i khi h\u1ebft session. LOG info console-auth INFO nova.consoleauth.manager [req-8ca21e6d-875d-4017-9aad-365f888dac16 6ca03d3c55444c10aa22f481f2e13381 9373ec3c823343de87ae613b972aa4d3 - default default] Received Token: 7b08b51a-78f3-4ff5-a84e-6cc668f78a08, {'instance_uuid': u'861da5b8-284d-463f-8b48-fb2050acc366', 'access_url': u'http://192.168.30.130:6080/vnc_auto.html?token=7b08b51a-78f3-4ff5-a84e-6cc668f78a08', 'token': u'7b08b51a-78f3-4ff5-a84e-6cc668f78a08', 'last_activity_at': 1542350179.299853, 'internal_access_path': None, 'console_type': u'novnc', 'host': u'192.168.69.131', 'port': u'5900'}","title":"1. noVNC &amp; nova-console-auth"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#2_cau_hinh_novnc_proxy_rieng","text":"","title":"2. C\u1ea5u h\u00ecnh noVNC proxy ri\u00eang"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#21_cac_option_cau_hinh_trong_section_vnc","text":"Configuration option=Default value Descrtion novncproxy_base_url=http://127.0.0.1:6080/vnc_auto.html \u0110\u1ecba ch\u1ec9 c\u1ee7a noVNC Web Proxy Client vnc_enabled=True b\u1eadt c\u00e1c ch\u1ee9c n\u0103ng li\u00ean quan VNC vnc_keymap=en-us keymap cho VNC server_listen=127.0.0.1 \u0111\u1ecba ch\u1ec9 vncserver instance l\u1eafng nghe request server_proxyclient_address=127.0.0.1 \u0111\u1ecba ch\u1ec9 c\u00e1c proxy client (nova-xvpvncproxy - Web-based Management) c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i","title":"2.1 . C\u00e1c option c\u1ea5u h\u00ecnh trong section VNC"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#22_cai_at_cau_hinh","text":"C\u00e0i \u0111\u1eb7t package tr\u00ean VNC Node yum install centos-release-openstack-queens yum install openstack-nova-novncproxy crudini C\u1ea5u h\u00ecnh file nova cho VNC Node crudini /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:rabbitmq_123@controller C\u1ea5u h\u00ecnh file host cho VNC Node echo \"192.168.30.130 controller\" > /etc/hosts C\u1ea5u h\u00ecnh VNC section cho noVNC Node t\u1ea1i /etc/nova/nova.conf [vnc] enabled = true server_proxyclient_address = 192.168.69.132 C\u1ea5u h\u00ecnh VNC Section cho Compute Node t\u1ea1i /etc/nova/nova.conf [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.131 novncproxy_base_url = http://192.168.30.132:6080/vnc_auto.html","title":"2.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh"},{"location":"Openstack_Research/Advance/4. Setup-noVNC/#23_khoi_ong_dich_vu","text":"Tr\u00ean Compute node systemctl status openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service Tr\u00ean Compute Node systemctl restart openstack-nova-compute systemctl enable openstack-nova-compute Tr\u00ean VNC Node systemctl restart openstack-nova-novncproxy systemctl enable openstack-nova-novncproxy Log tr\u00ean VNC Node LOG tr\u00ean nova-consoleauth","title":"2.3 . Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5"},{"location":"Openstack_Research/Advance/5. Nova-Compute-Serice-&-RabbitMQ/","text":"\u00b6 1. Stop Service nova-compute tr\u00ean compute \u00b6 1.2 . T\u1eaft service \u00b6 Tr\u00ean compute node root@compute1 nova]# systemctl stop openstack-nova-compute [root@compute1 novsystemctl status openstack-nova-compute \u25cf openstack-nova-compute.service - OpenStack Nova Compute Server Loaded: loaded (/usr/lib/systemd/system/openstack-nova-compute.service; enabled; vendor preset: disabled) Active: inactive (dead) since Fri 2018-11-16 05:51:20 EST; 5s ago Process: 101172 ExecStart=/usr/bin/nova-compute (code=exited, status=0/SUCCESS) Main PID: 101172 (code=exited, status=0/SUCCESS) Nov 16 05:18:12 compute1 systemd[1]: Starting OpenStack Nova Compute Server... Nov 16 05:18:14 compute1 nova-compute[101172]: /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWa...pported Nov 16 05:18:14 compute1 nova-compute[101172]: exception.NotSupportedWarning Nov 16 05:18:17 compute1 systemd[1]: Started OpenStack Nova Compute Server. Nov 16 05:18:17 compute1 sudo[101228]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Nov 16 05:19:47 compute1 sudo[101294]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Nov 16 05:51:05 compute1 systemd[1]: Stopping OpenStack Nova Compute Server... Nov 16 05:51:20 compute1 systemd[1]: Stopped OpenStack Nova Compute Server. Hint: Some lines were ellipsized, use -l to show in full. Tr\u00ean Compute Node Li\u1ec7t k\u00ea server list [root@controller ~]# openstack server list +--------------------------------------+--------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+--------+-----------------------+--------+--------+ | 57f3deea-b4e9-4cd8-8814-5a0e5962ff4e | centos | ACTIVE | net_ex=192.168.30.141 | centos | centos | | 88f1b003-2afe-43b7-8f51-2b719aca1251 | test | ACTIVE | net_ex=192.168.30.148 | cirros | | +--------------------------------------+--------+--------+-----------------------+--------+--------+ M\u1eb7c d\u00f9 \u0111\u00e3 command stop instance nh\u01b0ng v\u1eabn c\u00f3 th\u1ec3 ssh v\u00e0o instance, instance v\u1eabn \u0111i ra internet b\u00ecnh th\u01b0\u1eddng Ki\u1ec3m tra h\u00e0ng ch\u1edd tr\u00ean RabbitMQ T\u1ea1i # Queue **compute.compute1** ta th\u1ea5y N\u1ed9i dung payload s\u1ebd bao g\u1ed3m method\\\": \\\"stop_instance {\"oslo.message\": \"{\\\"_context_domain\\\": null, \\\"_context_request_id\\\": \\\"req-0ba543f8-8bbc-4f6e-a136-2ff8fbbf5bf9\\\", \\\"_context_global_request_id\\\": null, \\\"_context_quota_class\\\": null, \\\"_context_service_catalog\\\": [{\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:9696\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:9696\\\", \\\"publicURL\\\": \\\"http://controller:9696\\\"}], \\\"type\\\": \\\"network\\\", \\\"name\\\": \\\"neutron\\\"}, {\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:9292\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:9292\\\", \\\"publicURL\\\": \\\"http://controller:9292\\\"}], \\\"type\\\": \\\"image\\\", \\\"name\\\": \\\"glance\\\"}, {\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:8778\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:8778\\\", \\\"publicURL\\\": \\\"http://controller:8778\\\"}], \\\"type\\\": \\\"placement\\\", \\\"name\\\": \\\"placement\\\"}], \\\"_context_auth_token\\\": \\\"gAAAAABb7qIbfChibJt6nwaoirvg0CmC4tWbjCdvSZcZz2sgZ3KldgUalt-Q0WR_U-VGZGFV6AvRp7m0Ulk5LzxZQhtBirYS-oDHGUmsqFdVAjN6XG16zm-xXGihIUreCHDq_iS4UMRL_23_SJyhb15W7DQL-NkOfaR241H87Wi1VXuIXQR6tlg\\\", \\\"_context_resource_uuid\\\": null, \\\"_context_user\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"_context_user_id\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"_context_show_deleted\\\": false, \\\"_context_is_admin\\\": true, \\\"version\\\": \\\"5.0\\\", \\\"_context_project_domain\\\": \\\"default\\\", \\\"_context_timestamp\\\": \\\"2018-11-16T10:55:25.379534\\\", \\\"method\\\": \\\"stop_instance\\\", \\\"_context_project\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_remote_address\\\": \\\"192.168.69.130\\\", \\\"_context_roles\\\": [\\\"admin\\\"], \\\"args\\\": {\\\"instance\\\": {\\\"nova_object.version\\\": \\\"2.3\\\", \\\"nova_object.name\\\": \\\"Instance\\\", \\\"nova_object.data\\\": {\\\"vm_state\\\": \\\"active\\\", \\\"availability_zone\\\": \\\"nova\\\", \\\"terminated_at\\\": null, \\\"ephemeral_gb\\\": 0, \\\"instance_type_id\\\": 4, \\\"updated_at\\\": \\\"2018-11-16T10:44:19Z\\\", \\\"cleaned\\\": false, \\\"vm_mode\\\": null, \\\"deleted_at\\\": null, \\\"reservation_id\\\": \\\"r-s1q61ghb\\\", \\\"id\\\": 13, \\\"disable_terminate\\\": false, \\\"root_device_name\\\": \\\"/dev/vda\\\", \\\"user_id\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"uuid\\\": \\\"57f3deea-b4e9-4cd8-8814-5a0e5962ff4e\\\", \\\"default_swap_device\\\": null, \\\"hostname\\\": \\\"centos\\\", \\\"launched_on\\\": \\\"compute1\\\", \\\"display_description\\\": null, \\\"key_data\\\": null, \\\"kernel_id\\\": \\\"\\\", \\\"power_state\\\": 1, \\\"default_ephemeral_device\\\": null, \\\"progress\\\": 0, \\\"project_id\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"launched_at\\\": \\\"2018-11-16T10:44:19Z\\\", \\\"config_drive\\\": \\\"\\\", \\\"node\\\": \\\"compute1\\\", \\\"ramdisk_id\\\": \\\"\\\", \\\"access_ip_v6\\\": null, \\\"access_ip_v4\\\": null, \\\"deleted\\\": false, \\\"key_name\\\": null, \\\"user_data\\\": \\\"I2Nsb3VkLWNvbmZpZwp1c2VyOiByb290CnBhc3N3b3JkOiBodW5nMTkwMzkhCmNocGFzc3dkOiB7ZXhwaXJlOiBGYWxzZX0Kc3NoX3B3YXV0aDogVHJ1ZQ==\\\", \\\"host\\\": \\\"compute1\\\", \\\"root_gb\\\": 10, \\\"display_name\\\": \\\"centos\\\", \\\"system_metadata\\\": {\\\"image_disk_format\\\": \\\"qcow2\\\", \\\"boot_roles\\\": \\\"admin\\\", \\\"owner_user_name\\\": \\\"admin\\\", \\\"owner_project_name\\\": \\\"admin\\\", \\\"image_container_format\\\": \\\"bare\\\", \\\"image_min_ram\\\": \\\"0\\\", \\\"image_min_disk\\\": \\\"10\\\", \\\"image_base_image_ref\\\": \\\"fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81\\\"}, \\\"task_state\\\": \\\"powering-off\\\", \\\"shutdown_terminate\\\": false, \\\"cell_name\\\": null, \\\"ephemeral_key_uuid\\\": null, \\\"locked\\\": false, \\\"created_at\\\": \\\"2018-11-16T10:44:09Z\\\", \\\"locked_by\\\": null, \\\"launch_index\\\": 0, \\\"memory_mb\\\": 1025, \\\"vcpus\\\": 1, \\\"image_ref\\\": \\\"fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81\\\", \\\"architecture\\\": null, \\\"auto_disk_config\\\": true, \\\"os_type\\\": null, \\\"metadata\\\": {}}, \\\"nova_object.namespace\\\": \\\"nova\\\"}, \\\"clean_shutdown\\\": true}, \\\"_unique_id\\\": \\\"37aa7e9c94f5438f979fa11ac20b0223\\\", \\\"_context_is_admin_project\\\": true, \\\"_context_project_name\\\": \\\"admin\\\", \\\"_context_read_deleted\\\": \\\"no\\\", \\\"_context_user_identity\\\": \\\"6ca03d3c55444c10aa22f481f2e13381 9373ec3c823343de87ae613b972aa4d3 - default default\\\", \\\"_context_tenant\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_instance_lock_checked\\\": false, \\\"_context_project_id\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_read_only\\\": false, \\\"_context_user_domain\\\": \\\"default\\\", \\\"_context_user_name\\\": \\\"admin\\\"}\", \"oslo.version\": \"2.0\"} 1.2 . B\u1eadt Service \u00b6 Tr\u00ean Compute Node [root@compute1 nova]# systemctl start openstack-nova-compute [root@compute1 nova]# systemctl status openstack-nova-compute \u25cf openstack-nova-compute.service - OpenStack Nova Compute Server Loaded: loaded (/usr/lib/systemd/system/openstack-nova-compute.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2018-11-16 06:08:45 EST; 3s ago Main PID: 103095 (nova-compute) Tasks: 23 CGroup: /system.slice/openstack-nova-compute.service \u251c\u2500103095 /usr/bin/python2 /usr/bin/nova-compute \u2514\u2500103152 /usr/bin/python2 /bin/privsep-helper --config-file /usr/share/nova/nova-dist.conf --config-file /etc/nova/nova.conf --pri... Nov 16 06:08:40 compute1 systemd[1]: Starting OpenStack Nova Compute Server... Nov 16 06:08:42 compute1 nova-compute[103095]: /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWa...pported Nov 16 06:08:42 compute1 nova-compute[103095]: exception.NotSupportedWarning Nov 16 06:08:45 compute1 systemd[1]: Started OpenStack Nova Compute Server. Nov 16 06:08:45 compute1 sudo[103137]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Hint: Some lines were ellipsized, use -l to show in full. Tr\u00ean Controller Node ki\u1ec3m tra l\u1ea1i state c\u1ee7a instance [root@controller nova]# openstack server list +--------------------------------------+--------+---------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+---------+-----------------------+--------+--------+ | 57f3deea-b4e9-4cd8-8814-5a0e5962ff4e | centos | SHUTOFF | net_ex=192.168.30.141 | centos | centos | | 88f1b003-2afe-43b7-8f51-2b719aca1251 | test | ACTIVE | net_ex=192.168.30.148 | cirros | | +--------------------------------------+--------+---------+-----------------------+--------+--------+ Ki\u1ec3m tra h\u00e0ng ch\u1edd","title":"5. Nova Compute Serice & RabbitMQ"},{"location":"Openstack_Research/Advance/5. Nova-Compute-Serice-&-RabbitMQ/#1_stop_service_nova-compute_tren_compute","text":"","title":"1. Stop Service nova-compute tr\u00ean compute"},{"location":"Openstack_Research/Advance/5. Nova-Compute-Serice-&-RabbitMQ/#12_tat_service","text":"Tr\u00ean compute node root@compute1 nova]# systemctl stop openstack-nova-compute [root@compute1 novsystemctl status openstack-nova-compute \u25cf openstack-nova-compute.service - OpenStack Nova Compute Server Loaded: loaded (/usr/lib/systemd/system/openstack-nova-compute.service; enabled; vendor preset: disabled) Active: inactive (dead) since Fri 2018-11-16 05:51:20 EST; 5s ago Process: 101172 ExecStart=/usr/bin/nova-compute (code=exited, status=0/SUCCESS) Main PID: 101172 (code=exited, status=0/SUCCESS) Nov 16 05:18:12 compute1 systemd[1]: Starting OpenStack Nova Compute Server... Nov 16 05:18:14 compute1 nova-compute[101172]: /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWa...pported Nov 16 05:18:14 compute1 nova-compute[101172]: exception.NotSupportedWarning Nov 16 05:18:17 compute1 systemd[1]: Started OpenStack Nova Compute Server. Nov 16 05:18:17 compute1 sudo[101228]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Nov 16 05:19:47 compute1 sudo[101294]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Nov 16 05:51:05 compute1 systemd[1]: Stopping OpenStack Nova Compute Server... Nov 16 05:51:20 compute1 systemd[1]: Stopped OpenStack Nova Compute Server. Hint: Some lines were ellipsized, use -l to show in full. Tr\u00ean Compute Node Li\u1ec7t k\u00ea server list [root@controller ~]# openstack server list +--------------------------------------+--------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+--------+-----------------------+--------+--------+ | 57f3deea-b4e9-4cd8-8814-5a0e5962ff4e | centos | ACTIVE | net_ex=192.168.30.141 | centos | centos | | 88f1b003-2afe-43b7-8f51-2b719aca1251 | test | ACTIVE | net_ex=192.168.30.148 | cirros | | +--------------------------------------+--------+--------+-----------------------+--------+--------+ M\u1eb7c d\u00f9 \u0111\u00e3 command stop instance nh\u01b0ng v\u1eabn c\u00f3 th\u1ec3 ssh v\u00e0o instance, instance v\u1eabn \u0111i ra internet b\u00ecnh th\u01b0\u1eddng Ki\u1ec3m tra h\u00e0ng ch\u1edd tr\u00ean RabbitMQ T\u1ea1i # Queue **compute.compute1** ta th\u1ea5y N\u1ed9i dung payload s\u1ebd bao g\u1ed3m method\\\": \\\"stop_instance {\"oslo.message\": \"{\\\"_context_domain\\\": null, \\\"_context_request_id\\\": \\\"req-0ba543f8-8bbc-4f6e-a136-2ff8fbbf5bf9\\\", \\\"_context_global_request_id\\\": null, \\\"_context_quota_class\\\": null, \\\"_context_service_catalog\\\": [{\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:9696\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:9696\\\", \\\"publicURL\\\": \\\"http://controller:9696\\\"}], \\\"type\\\": \\\"network\\\", \\\"name\\\": \\\"neutron\\\"}, {\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:9292\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:9292\\\", \\\"publicURL\\\": \\\"http://controller:9292\\\"}], \\\"type\\\": \\\"image\\\", \\\"name\\\": \\\"glance\\\"}, {\\\"endpoints\\\": [{\\\"adminURL\\\": \\\"http://controller:8778\\\", \\\"region\\\": \\\"RegionOne\\\", \\\"internalURL\\\": \\\"http://controller:8778\\\", \\\"publicURL\\\": \\\"http://controller:8778\\\"}], \\\"type\\\": \\\"placement\\\", \\\"name\\\": \\\"placement\\\"}], \\\"_context_auth_token\\\": \\\"gAAAAABb7qIbfChibJt6nwaoirvg0CmC4tWbjCdvSZcZz2sgZ3KldgUalt-Q0WR_U-VGZGFV6AvRp7m0Ulk5LzxZQhtBirYS-oDHGUmsqFdVAjN6XG16zm-xXGihIUreCHDq_iS4UMRL_23_SJyhb15W7DQL-NkOfaR241H87Wi1VXuIXQR6tlg\\\", \\\"_context_resource_uuid\\\": null, \\\"_context_user\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"_context_user_id\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"_context_show_deleted\\\": false, \\\"_context_is_admin\\\": true, \\\"version\\\": \\\"5.0\\\", \\\"_context_project_domain\\\": \\\"default\\\", \\\"_context_timestamp\\\": \\\"2018-11-16T10:55:25.379534\\\", \\\"method\\\": \\\"stop_instance\\\", \\\"_context_project\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_remote_address\\\": \\\"192.168.69.130\\\", \\\"_context_roles\\\": [\\\"admin\\\"], \\\"args\\\": {\\\"instance\\\": {\\\"nova_object.version\\\": \\\"2.3\\\", \\\"nova_object.name\\\": \\\"Instance\\\", \\\"nova_object.data\\\": {\\\"vm_state\\\": \\\"active\\\", \\\"availability_zone\\\": \\\"nova\\\", \\\"terminated_at\\\": null, \\\"ephemeral_gb\\\": 0, \\\"instance_type_id\\\": 4, \\\"updated_at\\\": \\\"2018-11-16T10:44:19Z\\\", \\\"cleaned\\\": false, \\\"vm_mode\\\": null, \\\"deleted_at\\\": null, \\\"reservation_id\\\": \\\"r-s1q61ghb\\\", \\\"id\\\": 13, \\\"disable_terminate\\\": false, \\\"root_device_name\\\": \\\"/dev/vda\\\", \\\"user_id\\\": \\\"6ca03d3c55444c10aa22f481f2e13381\\\", \\\"uuid\\\": \\\"57f3deea-b4e9-4cd8-8814-5a0e5962ff4e\\\", \\\"default_swap_device\\\": null, \\\"hostname\\\": \\\"centos\\\", \\\"launched_on\\\": \\\"compute1\\\", \\\"display_description\\\": null, \\\"key_data\\\": null, \\\"kernel_id\\\": \\\"\\\", \\\"power_state\\\": 1, \\\"default_ephemeral_device\\\": null, \\\"progress\\\": 0, \\\"project_id\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"launched_at\\\": \\\"2018-11-16T10:44:19Z\\\", \\\"config_drive\\\": \\\"\\\", \\\"node\\\": \\\"compute1\\\", \\\"ramdisk_id\\\": \\\"\\\", \\\"access_ip_v6\\\": null, \\\"access_ip_v4\\\": null, \\\"deleted\\\": false, \\\"key_name\\\": null, \\\"user_data\\\": \\\"I2Nsb3VkLWNvbmZpZwp1c2VyOiByb290CnBhc3N3b3JkOiBodW5nMTkwMzkhCmNocGFzc3dkOiB7ZXhwaXJlOiBGYWxzZX0Kc3NoX3B3YXV0aDogVHJ1ZQ==\\\", \\\"host\\\": \\\"compute1\\\", \\\"root_gb\\\": 10, \\\"display_name\\\": \\\"centos\\\", \\\"system_metadata\\\": {\\\"image_disk_format\\\": \\\"qcow2\\\", \\\"boot_roles\\\": \\\"admin\\\", \\\"owner_user_name\\\": \\\"admin\\\", \\\"owner_project_name\\\": \\\"admin\\\", \\\"image_container_format\\\": \\\"bare\\\", \\\"image_min_ram\\\": \\\"0\\\", \\\"image_min_disk\\\": \\\"10\\\", \\\"image_base_image_ref\\\": \\\"fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81\\\"}, \\\"task_state\\\": \\\"powering-off\\\", \\\"shutdown_terminate\\\": false, \\\"cell_name\\\": null, \\\"ephemeral_key_uuid\\\": null, \\\"locked\\\": false, \\\"created_at\\\": \\\"2018-11-16T10:44:09Z\\\", \\\"locked_by\\\": null, \\\"launch_index\\\": 0, \\\"memory_mb\\\": 1025, \\\"vcpus\\\": 1, \\\"image_ref\\\": \\\"fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81\\\", \\\"architecture\\\": null, \\\"auto_disk_config\\\": true, \\\"os_type\\\": null, \\\"metadata\\\": {}}, \\\"nova_object.namespace\\\": \\\"nova\\\"}, \\\"clean_shutdown\\\": true}, \\\"_unique_id\\\": \\\"37aa7e9c94f5438f979fa11ac20b0223\\\", \\\"_context_is_admin_project\\\": true, \\\"_context_project_name\\\": \\\"admin\\\", \\\"_context_read_deleted\\\": \\\"no\\\", \\\"_context_user_identity\\\": \\\"6ca03d3c55444c10aa22f481f2e13381 9373ec3c823343de87ae613b972aa4d3 - default default\\\", \\\"_context_tenant\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_instance_lock_checked\\\": false, \\\"_context_project_id\\\": \\\"9373ec3c823343de87ae613b972aa4d3\\\", \\\"_context_read_only\\\": false, \\\"_context_user_domain\\\": \\\"default\\\", \\\"_context_user_name\\\": \\\"admin\\\"}\", \"oslo.version\": \"2.0\"}","title":"1.2 . T\u1eaft service"},{"location":"Openstack_Research/Advance/5. Nova-Compute-Serice-&-RabbitMQ/#12_bat_service","text":"Tr\u00ean Compute Node [root@compute1 nova]# systemctl start openstack-nova-compute [root@compute1 nova]# systemctl status openstack-nova-compute \u25cf openstack-nova-compute.service - OpenStack Nova Compute Server Loaded: loaded (/usr/lib/systemd/system/openstack-nova-compute.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2018-11-16 06:08:45 EST; 3s ago Main PID: 103095 (nova-compute) Tasks: 23 CGroup: /system.slice/openstack-nova-compute.service \u251c\u2500103095 /usr/bin/python2 /usr/bin/nova-compute \u2514\u2500103152 /usr/bin/python2 /bin/privsep-helper --config-file /usr/share/nova/nova-dist.conf --config-file /etc/nova/nova.conf --pri... Nov 16 06:08:40 compute1 systemd[1]: Starting OpenStack Nova Compute Server... Nov 16 06:08:42 compute1 nova-compute[103095]: /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWa...pported Nov 16 06:08:42 compute1 nova-compute[103095]: exception.NotSupportedWarning Nov 16 06:08:45 compute1 systemd[1]: Started OpenStack Nova Compute Server. Nov 16 06:08:45 compute1 sudo[103137]: nova : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/nova-rootwrap /etc/nova/rootwrap.con...sep.sock Hint: Some lines were ellipsized, use -l to show in full. Tr\u00ean Controller Node ki\u1ec3m tra l\u1ea1i state c\u1ee7a instance [root@controller nova]# openstack server list +--------------------------------------+--------+---------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+---------+-----------------------+--------+--------+ | 57f3deea-b4e9-4cd8-8814-5a0e5962ff4e | centos | SHUTOFF | net_ex=192.168.30.141 | centos | centos | | 88f1b003-2afe-43b7-8f51-2b719aca1251 | test | ACTIVE | net_ex=192.168.30.148 | cirros | | +--------------------------------------+--------+---------+-----------------------+--------+--------+ Ki\u1ec3m tra h\u00e0ng ch\u1edd","title":"1.2 . B\u1eadt Service"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/","text":"T\u00ecm hi\u1ec3u Nova-Placment v\u00e0 Nova-Conductor \u00b6 1. Placement Service \u00b6 1.1 . Kh\u00e1i ni\u1ec7m Placement \u00b6 T\u1eeb b\u1ea3n realase Newton , NOVA \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u01b0a ra th\u00eam m\u1ed9t API c\u00f3 t\u00ean placment API . Placment r\u00e1ch ti\u1ec7t ra m\u1ed9t REST API v\u00e0 data model s\u1eed d\u1ee5ng cho vi\u1ec7c theo d\u00f5i c\u00e1c t\u00e0i nguy\u00ean \u0111\u00e3 s\u1eed d\u1ee5ng v\u00e0 ch\u01b0a \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng gi\u1eefa c\u00e1c lo\u1ea1i t\u00e0i nguy\u00ean kh\u00e1c nhau . V\u00ed d\u1ee5, m\u1ed9t resource provider c\u00f3 th\u1ec3 l\u00e0 m\u1ed9t compute node, storage pool ho\u1eb7c l\u00e0 m\u1ed9t d\u1ea3i IP . Placement service s\u1ebd theo d\u00f5i t\u00e0i nguy\u00ean d\u01b0 th\u1eeba v\u00e0 t\u00e0i nguy\u00ean \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng tr\u00ean m\u1ed7i resource provider. V\u00ed d\u1ee5 , khi m\u1ed9t instance \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean compute node, s\u1ebd s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean RAM, CPU t\u1eeb compute node resource provider , disk t\u1eeb m\u1ed9t external storage resource provider. ( resource provider ) M\u1ed7i lo\u1ea1i t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c placment theo d\u00f5i d\u01b0\u1edbi h\u1ea1ng c\u00e1c class . M\u1ed7i resource class s\u1ebd \u0111\u01b0\u1ee3c placement service s\u1ebd \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i theo chu\u1ea9n kh\u00e1c nhau : DISK_GB, MEMORY_MB, and VCPU ( resource clasess ) Tr\u00ean m\u1ed7i resource provider c\u0169ng c\u00f3 th\u1ec3 bao g\u1ed3m nhi\u1ec1u t\u1eadp h\u1ee3p c\u00e1c \u0111\u1eb7c \u0111i\u1ec3m m\u00f4 t\u1ea3 t\u1eebng kh\u00eda c\u1ea1nh c\u1ee7a resource provider . V\u00ed d\u1ee5 available disk c\u00f3 th\u1ec3 kh\u00f4ng ch\u1ec9 HDD m\u00e0 c\u00f2n c\u00f3 th\u1ec3 l\u00e0 SSD ( Traits ) 1.2. L\u00fd do ph\u00e1t tri\u1ec3n Placment API \u00b6 Trong m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n Cloud, c\u00f3 r\u1ea5t nhi\u1ec1u t\u00e0i resource \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi ng\u01b0\u1eddi d\u00f9ng. M\u1ed9t s\u1ed1 t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node c\u00f3 th\u1ec3 l\u00e0 RAM, CPU, PCI device ho\u1eb7c local disk. Nh\u1eefng lo\u1ea1i t\u00e0i nguy\u00ean kh\u00e1c , kh\u00f4ng \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node, thay v\u00ec \u0111\u00f3 \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi c\u00e1c external provider resource kh\u00e1c. c\u00f3 th\u1ec3 l\u00e0 shared storage , IP pool . Nh\u01b0ng v\u00ec t\u1eeb c\u00e1c phi\u00ean b\u1ea3n tr\u01b0\u1edbc Newton th\u00ec Nova ch\u1ec9 xem x\u00e9t c\u00e1c resource \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node. Vi\u1ec7c theo d\u00f5i t\u00e0i nguy\u00ean gi\u1ea3 \u0111\u1ecbnh r\u1eb1ng compute node l\u00e0 m\u1ed9t resource provider, sau \u0111\u00f3 s\u1ebd report m\u1ed9t s\u1ed1 t\u00e0i nguy\u00ean nh\u1ea5t \u0111\u1ecbnh . Nova t\u00ednh to\u00e1n t\u00e0i nguy\u00ean \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng v\u00e0 ch\u01b0a s\u1eed d\u1ee5ng tr\u00ean b\u1eb1ng c\u00e1ch c\u1ed9ng c\u00e1c ngu\u1ed3n resoure t\u1eeb c\u00e1c compute trong database . Vi\u1ec7c n\u00e0y s\u1ebd g\u00e2y t\u00ednh to\u00e1n t\u00e0i nguy\u00ean kh\u00f4ng ch\u00ednh x\u00e1c . 1.3. Placement API \u00b6 Li\u1ec7t k\u00ea c\u00e1c Resource Provider [root@controller nova]# curl -s -H \"X-Auth-Token: gAAAAABb8hf0piihsQbrCWLkvbR9PNmcXtnCDFnJeW4i4tjO3SCvR1DqMV5l_39nEkGH5PurtqHMO7FYmZ0p-CJrRzSLBUebuF3f2UDRGtwNw3KU_D57XMeXTk3c8DvWmNAit06LpemksHpAr16ostz6YD-YxBSs4iN2XYH-LWwSqsZia-JUp9Q\" http://controller:8778/resource_providers/f69146d0-e1f2-4f1d-951d-bf9ccd06b2fb/inventories| python -mjson.tool { \"inventories\": { \"DISK_GB\": { \"allocation_ratio\": 1.0, \"max_unit\": 35, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 35 }, \"MEMORY_MB\": { \"allocation_ratio\": 1.5, \"max_unit\": 4095, \"min_unit\": 1, \"reserved\": 512, \"step_size\": 1, \"total\": 4095 }, \"VCPU\": { \"allocation_ratio\": 16.0, \"max_unit\": 2, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 2 } }, \"resource_provider_generation\": 14 } B\u00e1o c\u00e1o c\u00e1c resource \u0111ang d\u01b0 th\u1eeba trong provider compute1 [root@controller nova]# curl -s -H \"X-Auth-Token: gAAAAABb8hf0piihsQbrCWLkvbR9PNmcXtnCDFnJeW4i4tjO3SCvR1DqMV5l_39nEkGH5PurtqHMO7FYmZ0p-CJrRzSLBUebuF3f2UDRGtwNw3KU_D57XMeXTk3c8DvWmNAit06LpemksHpAr16ostz6YD-YxBSs4iN2XYH-LWwSqsZia-JUp9Q\" \\ > http://controller:8778/resource_providers/f69146d0-e1f2-4f1d-951d-bf9ccd06b2fb/inventories| python -mjson.tool { \"inventories\": { \"DISK_GB\": { \"allocation_ratio\": 1.0, \"max_unit\": 35, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 35 }, \"MEMORY_MB\": { \"allocation_ratio\": 1.5, \"max_unit\": 4095, \"min_unit\": 1, \"reserved\": 512, \"step_size\": 1, \"total\": 4095 }, \"VCPU\": { \"allocation_ratio\": 16.0, \"max_unit\": 2, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 2 } }, \"resource_provider_generation\": 14 } 2. Nova-Conductor \u00b6 2.1 . Kh\u00e1i ni\u1ec7m Nova-Conductor \u00b6 Nova-conductor l\u00e0 m\u1ed9t service m\u1edbi trong Nova \u0111\u01b0\u1ee3c xu\u1ea5t hi\u1ec7n l\u1ea7n \u0111\u00e2u trong b\u1ea3n Openstack Grizzly. Nova-conductor l\u00e0 m\u1ed9t RPC Server . Trong nova-conductor s\u1ebd c\u00f3 h\u00e0ng lo\u1ea1t API, nhi\u1ec7m v\u1ee5 ch\u00ednh s\u1ebd l\u00e0 l\u00e0 m\u1ed9t proxy line t\u1edbi database v\u00e0 t\u1edbi c\u00e1c RPC Server kh\u00e1c nh\u01b0 nova-api v\u00e0 nova-network. RPC Client s\u1ebd n\u1eb1m trong nova-compute . V\u00ed d\u1ee5 khi mu\u1ed1n update state c\u1ee7a m\u1ed9t VM tr\u00ean nova-compute , thay th\u00ec k\u1ebft n\u1ed1i tr\u1ef1c ti\u1ebfp \u0111\u1ebfn DB th\u00ec nova-compute s\u1ebd call \u0111\u1ebfn nova-conductor, nova conductor s\u1ebd th\u1ef1c hi\u1ec7n k\u1ebft n\u1ed1i \u0111\u1ebfn DB v\u00e0 update state VM 2.2. C\u00e1c l\u1ee3i \u00edch v\u00e0 h\u1ea1n ch\u1ebf Nova-conductor \u00b6 2.2.1 . B\u1ea3o m\u1eadt \u00b6 L\u1ee3i \u00edch : V\u1ea1ch \u0111\u1ecbnh quy\u1ec1n h\u00e0nh c\u1ee7a m\u1ed9t compute node khi ch\u1ea1y node-compute service .Tr\u01b0\u1edbc b\u1ea3n Grizzly, t\u1ea5t c\u1ea3 c\u00e1c compute-node c\u00f3 nova-compute service s\u1ebd c\u00f3 quy\u1ec1n truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o database, khi m\u1ed9t compute-node b\u1ecb t\u1ea5n c\u00f4ng th\u00ec attacker s\u1ebd c\u00f3 ho\u00e0n to\u00e0n quy\u1ec1n \u0111\u1ec3 x\u00e2m nh\u1eadp v\u00e0o DB . V\u1edbi nova-conductor s\u1ef1 \u1ea3nh h\u01b0\u1edfng c\u1ee7a c\u00e1c node t\u1edbi DB s\u1ebd \u0111\u01b0\u1ee3c ki\u1ec3m so\u00e1t thay v\u00ec \u0111\u00f3 s\u1ebd s\u1eed d\u1ee5ng conductor API \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi DB H\u1ea1n ch\u1ebf : M\u1eb7c d\u00f9 conductor API s\u1ebd h\u1ea1n ch\u1ebf c\u00e1c quy\u1ec1n h\u1ea1n \u0111\u1ebfn database c\u1ee7a nova-compute nh\u01b0ng c\u00e1c service kh\u00e1c v\u1eabn c\u00f3 quy\u1ec1n truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o DB . V\u1edbi m\u1ed9t m\u00f4i tr\u01b0\u1eddng network multi-host, th\u00ec nova-compute, nova-api- metadata, nova-network s\u1ebd \u0111\u1ec1u ch\u1ea1y tr\u00ean c\u00e1c compute node , trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y th\u00ec c\u00e1c service nova-api-metadata and nova-network v\u1eabn tham chi\u1ebfu tr\u1ef1c ti\u1ebfp \u0111\u1ebfn DB 2.2.2 . D\u1ec5 d\u00e0ng n\u00e2ng c\u1ea5p \u00b6 L\u1ee3i \u00edch : Nova-conductor \u0111\u1ee9ng gi\u1eefa nova-compute v\u00e0 database. N\u1ebfu DB schema update th\u00ec s\u1ebd kh\u00f4ng upgrade tr\u00ean nova-compute tr\u00ean c\u00f9ng m\u1ed9t th\u1eddi \u0111i\u1ec3m, thay vif \u0111\u00f3 nova-conductor s\u1ebd s\u1eed d\u1ee5ng nh\u1eefng API t\u01b0\u01a1ng th\u00edch \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi DB . 3. Nova Cell Layout \u00b6 Trong Nova system s\u1ebd bao g\u1ed3m c\u00e1c copoment sau : nova-api : cung c\u1ea5p REST API cho ng\u01b0\u1eddi d\u00f9ng nova-scheduler and placement services : \u0111\u1ea3m nhi\u1ec7m theo d\u00f5i c\u00e1c t\u00e0i nguy\u00ean v\u00e0 x\u00e1c \u0111\u1ecbnh compute host n\u01a1i m\u00e0 instance s\u1ebd ch\u1ea1y API Database : gi\u00fap nova-api, nova-scheduler theo d\u00f5i tr\u1ea1ng th\u00e1i c\u1ee7a c\u00e1c instance nova-conductor : l\u00e0m vi\u1ec7c v\u1edbi DB, gi\u00fap c\u00e1c compute node l\u00e0m vi\u1ec7c v\u1edbi database. nova-compute ; qu\u1ea3n l\u00fd virt drvier v\u00e0 hypervisor host cell database : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi API, conductor, compute service . \u0111\u1ea3m nhi\u1ec7m ch\u1ee9a ph\u1ea7n l\u1edbn th\u00f4ng tin c\u1ee7a c\u00e1c instance cell0 database : gi\u1ed1ng nh\u01b0 cell database nh\u01b0ng ch\u1ec9 ch\u1ee9a th\u00f4ng tin v\u1ec1 c\u00e1c instance b\u1ecb l\u1ed7i trong qu\u00e1 tr\u00ecnh scheduled message queue : cho ph\u00e9p giao ti\u1ebfp gi\u1eefa c\u00e1c compoment th\u00f4ng qua RPC Trong c\u00e1c m\u00f4i tr\u01b0\u1eddng deploy OPS s\u1ebd bao g\u1ed3m \u00edt nh\u1ea5t c\u00e1c compoment tr\u00ean . M\u1ed9i m\u00f4i tr\u01b0\u1eddng deployment nh\u1ecf c\u00f3 th\u1ec3 ch\u1ec9 bao g\u1ed3m m\u1ed9t message queue v\u00e0 m\u1ed9t DB server , API DB v\u00e0 m\u1ed9t cell, cell0 database. M\u1ee5c \u0111\u00edch ch\u00ednh c\u1ee7a cell trong nova l\u00e0 cho ph\u00e9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n l\u1edbn . Ch\u1ec9 s\u1eed d\u1ee5ng m\u1ed9t API cho t\u1ea5t nh\u01b0ng s\u1ebd l\u00e0m vi\u1ec7c \u0111\u01b0\u1ee3c t\u1edbi nhi\u1ec1u cell ( x\u00e1c \u0111\u1ecbnh th\u00f4ng tin c\u1ee7a c\u00e1c instance tr\u00ean c\u00e1c node ) . Khi s\u1eed d\u1ee5ng cell database, c\u00e1c compute host s\u1ebd \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp v\u00e0o nh\u00f3m t\u00ean l\u00e0 cells. Cells \u0111\u01b0\u1ee3c xem nh\u01b0 m\u1ed9t c\u00e1i c\u00e2y. Top-cell level s\u1ebd l\u00e0 host bao g\u1ed3m nova-api service. s\u1ebd kh\u00f4ng bao g\u1ed3m c\u00e1c nova-compute service. \u0110\u1ec3 m\u1edf r\u1ed9ng m\u00f4 h\u00ecnh th\u00ec tr\u00ean c\u00e1c child-level s\u1ebd bao g\u1ed3m c\u00e1c nova- service ngo\u1ea1i tr\u1eeb nova-api. Khi s\u1eed d\u1ee5ng cell database, c\u00e1c compute host s\u1ebd \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp v\u00e0o nh\u00f3m t\u00ean l\u00e0 cells. Cells \u0111\u01b0\u1ee3c xem nh\u01b0 m\u1ed9t c\u00e1i c\u00e2y. Top-cell level s\u1ebd l\u00e0 host bao g\u1ed3m nova-api service. s\u1ebd kh\u00f4ng bao g\u1ed3m c\u00e1c nova-compute service. \u0110\u1ec3 m\u1edf r\u1ed9ng m\u00f4 h\u00ecnh th\u00ec tr\u00ean c\u00e1c child-level s\u1ebd bao g\u1ed3m c\u00e1c nova- service ngo\u1ea1i tr\u1eeb nova-api. nova_api database MariaDB [nova_api]> select * from cell_mappings -> ; +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ | created_at | updated_at | id | uuid | name | transport_url | database_connection | +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ | 2018-10-19 09:07:52 | NULL | 1 | 00000000-0000-0000-0000-000000000000 | cell0 | none:/// | mysql+pymysql://nova:nova_123@controller/nova_cell0 | | 2018-10-19 09:07:57 | NULL | 2 | fceee63a-5c41-4080-8711-ce19bee8765d | cell1 | rabbit://openstack:rabbitmq_123@controller | mysql+pymysql://nova:nova_123@controller/nova | +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ 2 rows in set (0.00 sec) Tr\u00ean c\u00e1c nova service \u0111\u1ec1u s\u1eed d\u1ee5ng m\u1ed9t config file bao g\u1ed3m [DEFAULT]/transport_url v\u00e0 k\u1ebft n\u1ed1i t\u1edbi database [database]/connection v\u00e0 API k\u1ebft n\u1ed1i \u0111\u1ebfn database api [api_database]/connection","title":"6. Placement API & Nova Conductor"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#tim_hieu_nova-placment_va_nova-conductor","text":"","title":"T\u00ecm hi\u1ec3u Nova-Placment v\u00e0 Nova-Conductor"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#1_placement_service","text":"","title":"1. Placement Service"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#11_khai_niem_placement","text":"T\u1eeb b\u1ea3n realase Newton , NOVA \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u01b0a ra th\u00eam m\u1ed9t API c\u00f3 t\u00ean placment API . Placment r\u00e1ch ti\u1ec7t ra m\u1ed9t REST API v\u00e0 data model s\u1eed d\u1ee5ng cho vi\u1ec7c theo d\u00f5i c\u00e1c t\u00e0i nguy\u00ean \u0111\u00e3 s\u1eed d\u1ee5ng v\u00e0 ch\u01b0a \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng gi\u1eefa c\u00e1c lo\u1ea1i t\u00e0i nguy\u00ean kh\u00e1c nhau . V\u00ed d\u1ee5, m\u1ed9t resource provider c\u00f3 th\u1ec3 l\u00e0 m\u1ed9t compute node, storage pool ho\u1eb7c l\u00e0 m\u1ed9t d\u1ea3i IP . Placement service s\u1ebd theo d\u00f5i t\u00e0i nguy\u00ean d\u01b0 th\u1eeba v\u00e0 t\u00e0i nguy\u00ean \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng tr\u00ean m\u1ed7i resource provider. V\u00ed d\u1ee5 , khi m\u1ed9t instance \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean compute node, s\u1ebd s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean RAM, CPU t\u1eeb compute node resource provider , disk t\u1eeb m\u1ed9t external storage resource provider. ( resource provider ) M\u1ed7i lo\u1ea1i t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c placment theo d\u00f5i d\u01b0\u1edbi h\u1ea1ng c\u00e1c class . M\u1ed7i resource class s\u1ebd \u0111\u01b0\u1ee3c placement service s\u1ebd \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i theo chu\u1ea9n kh\u00e1c nhau : DISK_GB, MEMORY_MB, and VCPU ( resource clasess ) Tr\u00ean m\u1ed7i resource provider c\u0169ng c\u00f3 th\u1ec3 bao g\u1ed3m nhi\u1ec1u t\u1eadp h\u1ee3p c\u00e1c \u0111\u1eb7c \u0111i\u1ec3m m\u00f4 t\u1ea3 t\u1eebng kh\u00eda c\u1ea1nh c\u1ee7a resource provider . V\u00ed d\u1ee5 available disk c\u00f3 th\u1ec3 kh\u00f4ng ch\u1ec9 HDD m\u00e0 c\u00f2n c\u00f3 th\u1ec3 l\u00e0 SSD ( Traits )","title":"1.1 . Kh\u00e1i ni\u1ec7m Placement"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#12_ly_do_phat_trien_placment_api","text":"Trong m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n Cloud, c\u00f3 r\u1ea5t nhi\u1ec1u t\u00e0i resource \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi ng\u01b0\u1eddi d\u00f9ng. M\u1ed9t s\u1ed1 t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node c\u00f3 th\u1ec3 l\u00e0 RAM, CPU, PCI device ho\u1eb7c local disk. Nh\u1eefng lo\u1ea1i t\u00e0i nguy\u00ean kh\u00e1c , kh\u00f4ng \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node, thay v\u00ec \u0111\u00f3 \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi c\u00e1c external provider resource kh\u00e1c. c\u00f3 th\u1ec3 l\u00e0 shared storage , IP pool . Nh\u01b0ng v\u00ec t\u1eeb c\u00e1c phi\u00ean b\u1ea3n tr\u01b0\u1edbc Newton th\u00ec Nova ch\u1ec9 xem x\u00e9t c\u00e1c resource \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi compute node. Vi\u1ec7c theo d\u00f5i t\u00e0i nguy\u00ean gi\u1ea3 \u0111\u1ecbnh r\u1eb1ng compute node l\u00e0 m\u1ed9t resource provider, sau \u0111\u00f3 s\u1ebd report m\u1ed9t s\u1ed1 t\u00e0i nguy\u00ean nh\u1ea5t \u0111\u1ecbnh . Nova t\u00ednh to\u00e1n t\u00e0i nguy\u00ean \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng v\u00e0 ch\u01b0a s\u1eed d\u1ee5ng tr\u00ean b\u1eb1ng c\u00e1ch c\u1ed9ng c\u00e1c ngu\u1ed3n resoure t\u1eeb c\u00e1c compute trong database . Vi\u1ec7c n\u00e0y s\u1ebd g\u00e2y t\u00ednh to\u00e1n t\u00e0i nguy\u00ean kh\u00f4ng ch\u00ednh x\u00e1c .","title":"1.2. L\u00fd do ph\u00e1t tri\u1ec3n Placment API"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#13_placement_api","text":"Li\u1ec7t k\u00ea c\u00e1c Resource Provider [root@controller nova]# curl -s -H \"X-Auth-Token: gAAAAABb8hf0piihsQbrCWLkvbR9PNmcXtnCDFnJeW4i4tjO3SCvR1DqMV5l_39nEkGH5PurtqHMO7FYmZ0p-CJrRzSLBUebuF3f2UDRGtwNw3KU_D57XMeXTk3c8DvWmNAit06LpemksHpAr16ostz6YD-YxBSs4iN2XYH-LWwSqsZia-JUp9Q\" http://controller:8778/resource_providers/f69146d0-e1f2-4f1d-951d-bf9ccd06b2fb/inventories| python -mjson.tool { \"inventories\": { \"DISK_GB\": { \"allocation_ratio\": 1.0, \"max_unit\": 35, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 35 }, \"MEMORY_MB\": { \"allocation_ratio\": 1.5, \"max_unit\": 4095, \"min_unit\": 1, \"reserved\": 512, \"step_size\": 1, \"total\": 4095 }, \"VCPU\": { \"allocation_ratio\": 16.0, \"max_unit\": 2, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 2 } }, \"resource_provider_generation\": 14 } B\u00e1o c\u00e1o c\u00e1c resource \u0111ang d\u01b0 th\u1eeba trong provider compute1 [root@controller nova]# curl -s -H \"X-Auth-Token: gAAAAABb8hf0piihsQbrCWLkvbR9PNmcXtnCDFnJeW4i4tjO3SCvR1DqMV5l_39nEkGH5PurtqHMO7FYmZ0p-CJrRzSLBUebuF3f2UDRGtwNw3KU_D57XMeXTk3c8DvWmNAit06LpemksHpAr16ostz6YD-YxBSs4iN2XYH-LWwSqsZia-JUp9Q\" \\ > http://controller:8778/resource_providers/f69146d0-e1f2-4f1d-951d-bf9ccd06b2fb/inventories| python -mjson.tool { \"inventories\": { \"DISK_GB\": { \"allocation_ratio\": 1.0, \"max_unit\": 35, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 35 }, \"MEMORY_MB\": { \"allocation_ratio\": 1.5, \"max_unit\": 4095, \"min_unit\": 1, \"reserved\": 512, \"step_size\": 1, \"total\": 4095 }, \"VCPU\": { \"allocation_ratio\": 16.0, \"max_unit\": 2, \"min_unit\": 1, \"reserved\": 0, \"step_size\": 1, \"total\": 2 } }, \"resource_provider_generation\": 14 }","title":"1.3. Placement API"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#2_nova-conductor","text":"","title":"2. Nova-Conductor"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#21_khai_niem_nova-conductor","text":"Nova-conductor l\u00e0 m\u1ed9t service m\u1edbi trong Nova \u0111\u01b0\u1ee3c xu\u1ea5t hi\u1ec7n l\u1ea7n \u0111\u00e2u trong b\u1ea3n Openstack Grizzly. Nova-conductor l\u00e0 m\u1ed9t RPC Server . Trong nova-conductor s\u1ebd c\u00f3 h\u00e0ng lo\u1ea1t API, nhi\u1ec7m v\u1ee5 ch\u00ednh s\u1ebd l\u00e0 l\u00e0 m\u1ed9t proxy line t\u1edbi database v\u00e0 t\u1edbi c\u00e1c RPC Server kh\u00e1c nh\u01b0 nova-api v\u00e0 nova-network. RPC Client s\u1ebd n\u1eb1m trong nova-compute . V\u00ed d\u1ee5 khi mu\u1ed1n update state c\u1ee7a m\u1ed9t VM tr\u00ean nova-compute , thay th\u00ec k\u1ebft n\u1ed1i tr\u1ef1c ti\u1ebfp \u0111\u1ebfn DB th\u00ec nova-compute s\u1ebd call \u0111\u1ebfn nova-conductor, nova conductor s\u1ebd th\u1ef1c hi\u1ec7n k\u1ebft n\u1ed1i \u0111\u1ebfn DB v\u00e0 update state VM","title":"2.1 . Kh\u00e1i ni\u1ec7m Nova-Conductor"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#22_cac_loi_ich_va_han_che_nova-conductor","text":"","title":"2.2. C\u00e1c l\u1ee3i \u00edch v\u00e0 h\u1ea1n ch\u1ebf Nova-conductor"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#221_bao_mat","text":"L\u1ee3i \u00edch : V\u1ea1ch \u0111\u1ecbnh quy\u1ec1n h\u00e0nh c\u1ee7a m\u1ed9t compute node khi ch\u1ea1y node-compute service .Tr\u01b0\u1edbc b\u1ea3n Grizzly, t\u1ea5t c\u1ea3 c\u00e1c compute-node c\u00f3 nova-compute service s\u1ebd c\u00f3 quy\u1ec1n truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o database, khi m\u1ed9t compute-node b\u1ecb t\u1ea5n c\u00f4ng th\u00ec attacker s\u1ebd c\u00f3 ho\u00e0n to\u00e0n quy\u1ec1n \u0111\u1ec3 x\u00e2m nh\u1eadp v\u00e0o DB . V\u1edbi nova-conductor s\u1ef1 \u1ea3nh h\u01b0\u1edfng c\u1ee7a c\u00e1c node t\u1edbi DB s\u1ebd \u0111\u01b0\u1ee3c ki\u1ec3m so\u00e1t thay v\u00ec \u0111\u00f3 s\u1ebd s\u1eed d\u1ee5ng conductor API \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi DB H\u1ea1n ch\u1ebf : M\u1eb7c d\u00f9 conductor API s\u1ebd h\u1ea1n ch\u1ebf c\u00e1c quy\u1ec1n h\u1ea1n \u0111\u1ebfn database c\u1ee7a nova-compute nh\u01b0ng c\u00e1c service kh\u00e1c v\u1eabn c\u00f3 quy\u1ec1n truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o DB . V\u1edbi m\u1ed9t m\u00f4i tr\u01b0\u1eddng network multi-host, th\u00ec nova-compute, nova-api- metadata, nova-network s\u1ebd \u0111\u1ec1u ch\u1ea1y tr\u00ean c\u00e1c compute node , trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y th\u00ec c\u00e1c service nova-api-metadata and nova-network v\u1eabn tham chi\u1ebfu tr\u1ef1c ti\u1ebfp \u0111\u1ebfn DB","title":"2.2.1 . B\u1ea3o m\u1eadt"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#222_de_dang_nang_cap","text":"L\u1ee3i \u00edch : Nova-conductor \u0111\u1ee9ng gi\u1eefa nova-compute v\u00e0 database. N\u1ebfu DB schema update th\u00ec s\u1ebd kh\u00f4ng upgrade tr\u00ean nova-compute tr\u00ean c\u00f9ng m\u1ed9t th\u1eddi \u0111i\u1ec3m, thay vif \u0111\u00f3 nova-conductor s\u1ebd s\u1eed d\u1ee5ng nh\u1eefng API t\u01b0\u01a1ng th\u00edch \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi DB .","title":"2.2.2 . D\u1ec5 d\u00e0ng n\u00e2ng c\u1ea5p"},{"location":"Openstack_Research/Advance/6. Placement-API-&-Nova-Conductor/#3_nova_cell_layout","text":"Trong Nova system s\u1ebd bao g\u1ed3m c\u00e1c copoment sau : nova-api : cung c\u1ea5p REST API cho ng\u01b0\u1eddi d\u00f9ng nova-scheduler and placement services : \u0111\u1ea3m nhi\u1ec7m theo d\u00f5i c\u00e1c t\u00e0i nguy\u00ean v\u00e0 x\u00e1c \u0111\u1ecbnh compute host n\u01a1i m\u00e0 instance s\u1ebd ch\u1ea1y API Database : gi\u00fap nova-api, nova-scheduler theo d\u00f5i tr\u1ea1ng th\u00e1i c\u1ee7a c\u00e1c instance nova-conductor : l\u00e0m vi\u1ec7c v\u1edbi DB, gi\u00fap c\u00e1c compute node l\u00e0m vi\u1ec7c v\u1edbi database. nova-compute ; qu\u1ea3n l\u00fd virt drvier v\u00e0 hypervisor host cell database : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi API, conductor, compute service . \u0111\u1ea3m nhi\u1ec7m ch\u1ee9a ph\u1ea7n l\u1edbn th\u00f4ng tin c\u1ee7a c\u00e1c instance cell0 database : gi\u1ed1ng nh\u01b0 cell database nh\u01b0ng ch\u1ec9 ch\u1ee9a th\u00f4ng tin v\u1ec1 c\u00e1c instance b\u1ecb l\u1ed7i trong qu\u00e1 tr\u00ecnh scheduled message queue : cho ph\u00e9p giao ti\u1ebfp gi\u1eefa c\u00e1c compoment th\u00f4ng qua RPC Trong c\u00e1c m\u00f4i tr\u01b0\u1eddng deploy OPS s\u1ebd bao g\u1ed3m \u00edt nh\u1ea5t c\u00e1c compoment tr\u00ean . M\u1ed9i m\u00f4i tr\u01b0\u1eddng deployment nh\u1ecf c\u00f3 th\u1ec3 ch\u1ec9 bao g\u1ed3m m\u1ed9t message queue v\u00e0 m\u1ed9t DB server , API DB v\u00e0 m\u1ed9t cell, cell0 database. M\u1ee5c \u0111\u00edch ch\u00ednh c\u1ee7a cell trong nova l\u00e0 cho ph\u00e9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n l\u1edbn . Ch\u1ec9 s\u1eed d\u1ee5ng m\u1ed9t API cho t\u1ea5t nh\u01b0ng s\u1ebd l\u00e0m vi\u1ec7c \u0111\u01b0\u1ee3c t\u1edbi nhi\u1ec1u cell ( x\u00e1c \u0111\u1ecbnh th\u00f4ng tin c\u1ee7a c\u00e1c instance tr\u00ean c\u00e1c node ) . Khi s\u1eed d\u1ee5ng cell database, c\u00e1c compute host s\u1ebd \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp v\u00e0o nh\u00f3m t\u00ean l\u00e0 cells. Cells \u0111\u01b0\u1ee3c xem nh\u01b0 m\u1ed9t c\u00e1i c\u00e2y. Top-cell level s\u1ebd l\u00e0 host bao g\u1ed3m nova-api service. s\u1ebd kh\u00f4ng bao g\u1ed3m c\u00e1c nova-compute service. \u0110\u1ec3 m\u1edf r\u1ed9ng m\u00f4 h\u00ecnh th\u00ec tr\u00ean c\u00e1c child-level s\u1ebd bao g\u1ed3m c\u00e1c nova- service ngo\u1ea1i tr\u1eeb nova-api. Khi s\u1eed d\u1ee5ng cell database, c\u00e1c compute host s\u1ebd \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp v\u00e0o nh\u00f3m t\u00ean l\u00e0 cells. Cells \u0111\u01b0\u1ee3c xem nh\u01b0 m\u1ed9t c\u00e1i c\u00e2y. Top-cell level s\u1ebd l\u00e0 host bao g\u1ed3m nova-api service. s\u1ebd kh\u00f4ng bao g\u1ed3m c\u00e1c nova-compute service. \u0110\u1ec3 m\u1edf r\u1ed9ng m\u00f4 h\u00ecnh th\u00ec tr\u00ean c\u00e1c child-level s\u1ebd bao g\u1ed3m c\u00e1c nova- service ngo\u1ea1i tr\u1eeb nova-api. nova_api database MariaDB [nova_api]> select * from cell_mappings -> ; +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ | created_at | updated_at | id | uuid | name | transport_url | database_connection | +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ | 2018-10-19 09:07:52 | NULL | 1 | 00000000-0000-0000-0000-000000000000 | cell0 | none:/// | mysql+pymysql://nova:nova_123@controller/nova_cell0 | | 2018-10-19 09:07:57 | NULL | 2 | fceee63a-5c41-4080-8711-ce19bee8765d | cell1 | rabbit://openstack:rabbitmq_123@controller | mysql+pymysql://nova:nova_123@controller/nova | +---------------------+------------+----+--------------------------------------+-------+--------------------------------------------+-----------------------------------------------------+ 2 rows in set (0.00 sec) Tr\u00ean c\u00e1c nova service \u0111\u1ec1u s\u1eed d\u1ee5ng m\u1ed9t config file bao g\u1ed3m [DEFAULT]/transport_url v\u00e0 k\u1ebft n\u1ed1i t\u1edbi database [database]/connection v\u00e0 API k\u1ebft n\u1ed1i \u0111\u1ebfn database api [api_database]/connection","title":"3. Nova Cell Layout"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/","text":"Resource Management trong OPS \u00b6 1. CPU Topology \u00b6 Nh\u1edd v\u00e0o NUMA Techonoly v\u00e0 CPU Pinting trong OPS cung c\u1ea5p m\u1ed9t c\u00e1ch ki\u1ec3m so\u00e1t cao c\u00e1ch c\u00e1c instance ch\u1ea1y tr\u00ean c\u00e1c hypervisor CPU v\u00e0 c\u1ea5u tr\u00fac li\u00ean k\u1ebft c\u1ee7a c\u00e1c vCPU tr\u00ean c\u00e1c instance . 1.1. SMP, NUMA, \u00b6 Symmetric multiprocessing (SMP) : l\u00e0 thi\u1ebft k\u1ebf \u0111\u01b0\u1ee3c t\u00ecm nhi\u1ec1u trong c\u00e1c muilti-core system. Trong SMP system, c\u00f3 2 ho\u1eb7c nhi\u1ec1u CPU v\u00e0 nh\u1eefng CPU s\u1ebd k\u1ebft n\u1ed1i v\u1edbi nhau . \u0110i\u1ec1u n\u00e0y cho ph\u00e9p CPU cung c\u1ea5p kh\u1ea3 n\u0103ng truy c\u1eadp nh\u01b0 nhau v\u00e0o t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng ho\u1eb7c input/output NUMA (Non-Uniform Memory Access) : m\u1ed9t ki\u1ec3u c\u1ee7a SMP ,\u0111\u00e2y l\u00e0 m\u1ed9t ki\u1ec3u ki\u1ebfn tr\u00fac b\u1ed9 nh\u1edb m\u00e1y t\u00ednh nh\u1eb1m h\u1ed5 tr\u1ee3 cho h\u1ec7 th\u1ed1ng \u0111a x\u1eed l\u00fd (multi processing) trong \u0111\u00f3 b\u1ed9 nh\u1edb (memory) th\u1ec3 hi\u1ec7n c\u00e1c \u0111\u1eb7c t\u00ednh hi\u1ec7u n\u0103ng ri\u00eang bi\u1ec7t t\u1ea1i nh\u1eefng \u0111i\u1ec3m kh\u00e1c nhau trong kh\u00f4ng gian \u0111\u1ecba ch\u1ec9 c\u1ee7a CPU. 2. CPU customize topology \u00b6 Ch\u1ee9c n\u0103ng n\u00e0y ch\u1ec9 h\u1ed7 tr\u1ee3 cho libvirt/kvm driver Ngo\u00e0i vi\u1ec7c c\u1ea5u h\u00ecnh l\u00ean l\u1ecbch CPU cho c\u00e1c instance , th\u00ec c\u00f3 th\u1ec3 t\u1ef1 c\u1ea5u h\u00ecnh m\u00f4 h\u00ecnh CPU cho c\u00e1c instance. M\u1eb7c \u0111\u1ecbnh khi instance NUMA kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh, c\u1ea5u tr\u00fac li\u00ean k\u1ebft CPU c\u1ee7a c\u00e1c instance l\u00e0 : N socket, v\u1edbi m\u1ed9t core , 1 lu\u1ed3ng => N s\u1ebd l\u00e0 s\u1ed1 vCPU d\u00e0nh cho instance . Khi instance NUMA \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh, s\u1ed1 socket \u0111\u01b0\u1ee3c c\u1ed1 \u0111\u1ecbnh th\u00e0nh s\u1ed1 NUMA host v\u00e0 t\u1ed5ng c\u00e1c CPU c\u1ee7a c\u00e1c instance \u0111\u01b0\u1ee3c chia tr\u00ean c\u00e1c socket n\u00e0y . Kh\u1edfi t\u1ea1o m\u1ed9t flavor m\u1edbi [root@controller nova]# openstack flavor create --disk 10 --project admin --ram 1024 --private large +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | | name | large | | os-flavor-access:is_public | False | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ C\u1ea5u h\u00ecnh CPU topology openstack flavor set large --property hw:cpu_sockets=2 --property hw:cpu_cores=4 --property hw:cpu_threads=2 Trong \u0111\u00f3 : - SOCKET : s\u1ed1 CPU socket cho VM , m\u1eb7c \u0111\u1ecbnh s\u1ed1 n\u00e0y s\u1ebd l\u00e0 s\u1ed1 vCPU theo y\u00eau c\u1ea7u - CORE : s\u1ed1 core tr\u00ean tr\u1eebng socket. M\u1eb7c \u0111\u1ecbnh s\u1ebd l\u00e0 1 - THEADS : s\u1ed1 lu\u1ed3ng tr\u00ean t\u1eebng core. M\u1eb7c \u0111\u1ecbnh s\u1ebd l\u00e0 1 Ki\u1ec3m tra flavor [root@controller nova]# openstack flavor show 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 +----------------------------+----------------------------------------------------------+ | Field | Value | +----------------------------+----------------------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | 9373ec3c823343de87ae613b972aa4d3 | | disk | 10 | | id | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | | name | large | | os-flavor-access:is_public | False | | properties | hw:cpu_cores='4', hw:cpu_sockets='2', hw:cpu_threads='8' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+----------------------------------------------------------+ 3. C\u1ea5u h\u00ecnh t\u1ec9 l\u1ec7 overcommitting \u00b6 3.1 . Kh\u00e1i ni\u1ec7m overcommitting trong KVM \u00b6 Trong KVM h\u1ed7 tr\u1ee3 t\u1ef1 \u0111\u1ed9ng overcommit CPU v\u00e0 Memory . C\u00f3 ngh\u0129a l\u00e0 c\u00e1c RAM v\u00e0 CPU \u1ea3o h\u00f3a c\u00f3 th\u1ec3 ph\u00e2n b\u1ed5 t\u1edbi c\u00e1c m\u00e1y \u1ea3o nhi\u1ec1u h\u01a1n s\u1ed1 t\u00e0i nguy\u00ean c\u00f3 tr\u00ean v\u1eadt l\u00fd . \u0110i\u1ec1u n\u00e0y l\u00e0 ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 v\u00ec h\u1ea7u nh\u01b0 c\u00e1c process s\u1ebd kh\u00f4ng s\u1eed d\u1ee5ng 100% memory \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5. C\u00e1c server d\u01b0\u1edbi n\u1ec1n t\u1ea3ng \u1ea3o h\u00f3a c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean m\u1ed9t host nh\u1ecf t\u00e0i nguy\u00ean h\u01a1n , gi\u00fap ti\u1ebft ki\u1ec7m t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng. OVERCOMMITTING MEMORY : C\u00e1c m\u00e1y \u1ea3o trong KVM kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 cho m\u1ed9t block RAM, thay v\u00ec \u0111\u00f3 m\u1ed7i m\u00e1y \u1ea3o s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t process , khi \u0111\u00f3 Linux Kernel s\u1ebd ph\u00e2n b\u1ed5 memory khi m\u00e0 m\u00e1y \u1ea3o y\u00eau c\u1ea7u. Th\u00eam v\u00e0o \u0111\u00f3 sau khi m\u1ed9t process ho\u00e0n th\u00e0nh c\u00f4ng vi\u1ec7c, ph\u1ea7n RAM c\u1ee7a process s\u1ebd \u0111\u01b0\u1ee3c di chuy\u1ec3n v\u00e0o Swap. C\u00e1c memory \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi c\u00e1ch m\u00e1y \u1ea3o khi kh\u00f4ng \u0111\u01b0owjc s\u1eed d\u1ee5ng nhi\u1ec1u s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o Swap. Overcommitting y\u00eau c\u1ea7u ph\u00e2n b\u1ed5 \u0111\u1ee7 kh\u00f4ng gian swap tr\u00ean physical host \u0111\u1ec3 ch\u1ee9a c\u00e1c process m\u00e1y \u1ea3o KVM v\u00e0 \u0111\u1ee7 \u0111\u1ec3 ch\u1ee9a c\u00e1c process c\u1ee7a c\u00e1c d\u1ecbch v\u1ee5 kh\u00e1c . C\u00f4ng th\u1ee9c ration : (0.5 * RAM) + (overcommit ratio * RAM) = Recommended swap size Overcommiting kh\u00f4ng ho\u00e0n to\u00e0n l\u00e0 gi\u1ea3i ph\u00e1p t\u00f2an di\u1ec7n \u0111\u1ec3i gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 v\u1ec1 memory thay vi \u0111\u00f3 s\u1ebd ph\u00e2n b\u1ed5 \u00edt RAM h\u01a1n tr\u00ean t\u1eebng m\u00e1y \u1ea3o . M\u1ed9t m\u00e1y \u1ea3o s\u1ebd ch\u1ea1y ch\u1eadm h\u01a1n khi n\u00f3 ho\u1ea1t \u0111\u1ed9ng tr\u00ean swap. Th\u00eam v\u00e0o \u0111\u00f3 overcommitting s\u1ebd l\u00e0m cho system h\u1ebft memory. \u0110i\u1ec1u n\u00e0y d\u1eabn \u0111\u1ebfn kernel s\u1ebd t\u1ef1 \u0111\u1ed9ng shutdown m\u1ed9t s\u1ed1 process kh\u00f4ng li\u00ean quan. Overcommitting virtualized CPUs : KVM Hypervisor h\u1ed7 tr\u1ee3 overcommitting CPU \u1ea3o h\u00f3a. CPU \u1ea3o h\u00f3a cho ph\u00e9p t\u1ea3i qu\u00e1 m\u1ee9c so m\u1edbi m\u1eb7c \u0111\u1ecbnh c\u1ee7a c\u00e1c m\u1ea3y \u1ea3o \u0111\u01b0\u1ee3c cho ph\u00e9p. Ch\u00fa \u00fd khi s\u1eed d\u1ee5ng overcommit vCPU, khi load g\u1ea7n 100% th\u00ec s\u1ebd b\u1ecb drop c\u00e1c request ho\u1eb7c kh\u1ea3 n\u0103ng reponse b\u1ecb ch\u1eadm l\u1ea1i C\u00e1c CPU \u1ea3o h\u00f3a (vCPUs) \u0111\u01b0\u1ee3c overcommitted t\u1ed1t nh\u1ea5t khi m\u1ed9t m\u00e1y v\u1eadt l\u00fd m\u00e1y ch\u1ee7 duy nh\u1ea5t c\u00f3 nhi\u1ec1u m\u00e1y \u1ea3o kh\u00e1ch m\u00e0 kh\u00f4ng d\u00f9ng chung m\u1ed9t vCPU. KVM h\u1ed7 tr\u1ee3 \u1edf m\u1ee9c an to\u00e0n c\u00e1c m\u00e1y \u1ea3o load d\u01b0\u1edbi 100% theo t\u1ec9 l\u1ec7 5vCPU ( cho 5 m\u00e1y \u1ea3o ) tr\u00ean m\u1ed9t CPU v\u1eadt l\u00fd. KVM s\u1ebd chuy\u1ec3n ph\u00e2n b\u1ed5 CPU gi\u1eefa c\u00e1c m\u00e1y \u1ea3o \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c c\u00e2n b\u1eb1ng t\u1ea3i Kh\u00f4ng \u0111\u01b0\u1ee3c overcommit c\u00e1c m\u1ea3y \u1ea3o c\u00f3 s\u1ed1 vCPU nhi\u1ec1u h\u01a1n s\u1ed1 core process . V\u00ed d\u1ee5 m\u1ed9t m\u00e1y \u1ea3o v\u1edbi 4 vCPU kh\u00f4ng th\u1ec3 ch\u1ea1y tr\u00ean host 2 core nh\u01b0ng c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean quad core .Kkhuy\u1ebfn ngh\u1ecb : kh\u00f4ng n\u00ean ph\u00e2n b\u1ed5 qu\u00e1 1 vCPU tr\u00ean 1 CPU v\u1eadt l\u00fd 3.2 . Overcommitting trong OPS \u00b6 Trong OPS h\u1ed7 tr\u1ee3 overcommitting tr\u00ean c\u00e1c compute node . Tr\u00ean compute service t\u1ec9 l\u1ec7 overcommit \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 CPU allocation ratio: 16:1 - \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 16 vCPU tr\u00ean 1 CPU v\u1eadt l\u00fd . RAM allocation ratio: 1.5:1 - cho ph\u00e9p ph\u00e2n b\u1ed5 RAM t\u1edbi c\u00e1c instance s\u1ebd nhi\u1ec1u h\u01a1n 1.5 l\u1ea7n so v\u1edbi memory physical C\u1ea5u h\u00ecnh t\u1ec9 l\u1ec7 overcommit tr\u00ean controller node /etc/nova/nova.conf : [DEFAULT] cpu_allocation_ratio = 10.1 Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service \\ openstack-nova-scheduler.service openstack-nova-conductor.service \\ openstack-nova-novncproxy.service","title":"Resource Management trong OPS"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#resource_management_trong_ops","text":"","title":"Resource Management trong OPS"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#1_cpu_topology","text":"Nh\u1edd v\u00e0o NUMA Techonoly v\u00e0 CPU Pinting trong OPS cung c\u1ea5p m\u1ed9t c\u00e1ch ki\u1ec3m so\u00e1t cao c\u00e1ch c\u00e1c instance ch\u1ea1y tr\u00ean c\u00e1c hypervisor CPU v\u00e0 c\u1ea5u tr\u00fac li\u00ean k\u1ebft c\u1ee7a c\u00e1c vCPU tr\u00ean c\u00e1c instance .","title":"1. CPU Topology"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#11_smp_numa","text":"Symmetric multiprocessing (SMP) : l\u00e0 thi\u1ebft k\u1ebf \u0111\u01b0\u1ee3c t\u00ecm nhi\u1ec1u trong c\u00e1c muilti-core system. Trong SMP system, c\u00f3 2 ho\u1eb7c nhi\u1ec1u CPU v\u00e0 nh\u1eefng CPU s\u1ebd k\u1ebft n\u1ed1i v\u1edbi nhau . \u0110i\u1ec1u n\u00e0y cho ph\u00e9p CPU cung c\u1ea5p kh\u1ea3 n\u0103ng truy c\u1eadp nh\u01b0 nhau v\u00e0o t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng ho\u1eb7c input/output NUMA (Non-Uniform Memory Access) : m\u1ed9t ki\u1ec3u c\u1ee7a SMP ,\u0111\u00e2y l\u00e0 m\u1ed9t ki\u1ec3u ki\u1ebfn tr\u00fac b\u1ed9 nh\u1edb m\u00e1y t\u00ednh nh\u1eb1m h\u1ed5 tr\u1ee3 cho h\u1ec7 th\u1ed1ng \u0111a x\u1eed l\u00fd (multi processing) trong \u0111\u00f3 b\u1ed9 nh\u1edb (memory) th\u1ec3 hi\u1ec7n c\u00e1c \u0111\u1eb7c t\u00ednh hi\u1ec7u n\u0103ng ri\u00eang bi\u1ec7t t\u1ea1i nh\u1eefng \u0111i\u1ec3m kh\u00e1c nhau trong kh\u00f4ng gian \u0111\u1ecba ch\u1ec9 c\u1ee7a CPU.","title":"1.1. SMP, NUMA,"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#2_cpu_customize_topology","text":"Ch\u1ee9c n\u0103ng n\u00e0y ch\u1ec9 h\u1ed7 tr\u1ee3 cho libvirt/kvm driver Ngo\u00e0i vi\u1ec7c c\u1ea5u h\u00ecnh l\u00ean l\u1ecbch CPU cho c\u00e1c instance , th\u00ec c\u00f3 th\u1ec3 t\u1ef1 c\u1ea5u h\u00ecnh m\u00f4 h\u00ecnh CPU cho c\u00e1c instance. M\u1eb7c \u0111\u1ecbnh khi instance NUMA kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh, c\u1ea5u tr\u00fac li\u00ean k\u1ebft CPU c\u1ee7a c\u00e1c instance l\u00e0 : N socket, v\u1edbi m\u1ed9t core , 1 lu\u1ed3ng => N s\u1ebd l\u00e0 s\u1ed1 vCPU d\u00e0nh cho instance . Khi instance NUMA \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh, s\u1ed1 socket \u0111\u01b0\u1ee3c c\u1ed1 \u0111\u1ecbnh th\u00e0nh s\u1ed1 NUMA host v\u00e0 t\u1ed5ng c\u00e1c CPU c\u1ee7a c\u00e1c instance \u0111\u01b0\u1ee3c chia tr\u00ean c\u00e1c socket n\u00e0y . Kh\u1edfi t\u1ea1o m\u1ed9t flavor m\u1edbi [root@controller nova]# openstack flavor create --disk 10 --project admin --ram 1024 --private large +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | | name | large | | os-flavor-access:is_public | False | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ C\u1ea5u h\u00ecnh CPU topology openstack flavor set large --property hw:cpu_sockets=2 --property hw:cpu_cores=4 --property hw:cpu_threads=2 Trong \u0111\u00f3 : - SOCKET : s\u1ed1 CPU socket cho VM , m\u1eb7c \u0111\u1ecbnh s\u1ed1 n\u00e0y s\u1ebd l\u00e0 s\u1ed1 vCPU theo y\u00eau c\u1ea7u - CORE : s\u1ed1 core tr\u00ean tr\u1eebng socket. M\u1eb7c \u0111\u1ecbnh s\u1ebd l\u00e0 1 - THEADS : s\u1ed1 lu\u1ed3ng tr\u00ean t\u1eebng core. M\u1eb7c \u0111\u1ecbnh s\u1ebd l\u00e0 1 Ki\u1ec3m tra flavor [root@controller nova]# openstack flavor show 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 +----------------------------+----------------------------------------------------------+ | Field | Value | +----------------------------+----------------------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | 9373ec3c823343de87ae613b972aa4d3 | | disk | 10 | | id | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | | name | large | | os-flavor-access:is_public | False | | properties | hw:cpu_cores='4', hw:cpu_sockets='2', hw:cpu_threads='8' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+----------------------------------------------------------+","title":"2. CPU customize topology"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#3_cau_hinh_ti_le_overcommitting","text":"","title":"3. C\u1ea5u h\u00ecnh t\u1ec9 l\u1ec7 overcommitting"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#31_khai_niem_overcommitting_trong_kvm","text":"Trong KVM h\u1ed7 tr\u1ee3 t\u1ef1 \u0111\u1ed9ng overcommit CPU v\u00e0 Memory . C\u00f3 ngh\u0129a l\u00e0 c\u00e1c RAM v\u00e0 CPU \u1ea3o h\u00f3a c\u00f3 th\u1ec3 ph\u00e2n b\u1ed5 t\u1edbi c\u00e1c m\u00e1y \u1ea3o nhi\u1ec1u h\u01a1n s\u1ed1 t\u00e0i nguy\u00ean c\u00f3 tr\u00ean v\u1eadt l\u00fd . \u0110i\u1ec1u n\u00e0y l\u00e0 ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 v\u00ec h\u1ea7u nh\u01b0 c\u00e1c process s\u1ebd kh\u00f4ng s\u1eed d\u1ee5ng 100% memory \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5. C\u00e1c server d\u01b0\u1edbi n\u1ec1n t\u1ea3ng \u1ea3o h\u00f3a c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean m\u1ed9t host nh\u1ecf t\u00e0i nguy\u00ean h\u01a1n , gi\u00fap ti\u1ebft ki\u1ec7m t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng. OVERCOMMITTING MEMORY : C\u00e1c m\u00e1y \u1ea3o trong KVM kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 cho m\u1ed9t block RAM, thay v\u00ec \u0111\u00f3 m\u1ed7i m\u00e1y \u1ea3o s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t process , khi \u0111\u00f3 Linux Kernel s\u1ebd ph\u00e2n b\u1ed5 memory khi m\u00e0 m\u00e1y \u1ea3o y\u00eau c\u1ea7u. Th\u00eam v\u00e0o \u0111\u00f3 sau khi m\u1ed9t process ho\u00e0n th\u00e0nh c\u00f4ng vi\u1ec7c, ph\u1ea7n RAM c\u1ee7a process s\u1ebd \u0111\u01b0\u1ee3c di chuy\u1ec3n v\u00e0o Swap. C\u00e1c memory \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi c\u00e1ch m\u00e1y \u1ea3o khi kh\u00f4ng \u0111\u01b0owjc s\u1eed d\u1ee5ng nhi\u1ec1u s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o Swap. Overcommitting y\u00eau c\u1ea7u ph\u00e2n b\u1ed5 \u0111\u1ee7 kh\u00f4ng gian swap tr\u00ean physical host \u0111\u1ec3 ch\u1ee9a c\u00e1c process m\u00e1y \u1ea3o KVM v\u00e0 \u0111\u1ee7 \u0111\u1ec3 ch\u1ee9a c\u00e1c process c\u1ee7a c\u00e1c d\u1ecbch v\u1ee5 kh\u00e1c . C\u00f4ng th\u1ee9c ration : (0.5 * RAM) + (overcommit ratio * RAM) = Recommended swap size Overcommiting kh\u00f4ng ho\u00e0n to\u00e0n l\u00e0 gi\u1ea3i ph\u00e1p t\u00f2an di\u1ec7n \u0111\u1ec3i gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 v\u1ec1 memory thay vi \u0111\u00f3 s\u1ebd ph\u00e2n b\u1ed5 \u00edt RAM h\u01a1n tr\u00ean t\u1eebng m\u00e1y \u1ea3o . M\u1ed9t m\u00e1y \u1ea3o s\u1ebd ch\u1ea1y ch\u1eadm h\u01a1n khi n\u00f3 ho\u1ea1t \u0111\u1ed9ng tr\u00ean swap. Th\u00eam v\u00e0o \u0111\u00f3 overcommitting s\u1ebd l\u00e0m cho system h\u1ebft memory. \u0110i\u1ec1u n\u00e0y d\u1eabn \u0111\u1ebfn kernel s\u1ebd t\u1ef1 \u0111\u1ed9ng shutdown m\u1ed9t s\u1ed1 process kh\u00f4ng li\u00ean quan. Overcommitting virtualized CPUs : KVM Hypervisor h\u1ed7 tr\u1ee3 overcommitting CPU \u1ea3o h\u00f3a. CPU \u1ea3o h\u00f3a cho ph\u00e9p t\u1ea3i qu\u00e1 m\u1ee9c so m\u1edbi m\u1eb7c \u0111\u1ecbnh c\u1ee7a c\u00e1c m\u1ea3y \u1ea3o \u0111\u01b0\u1ee3c cho ph\u00e9p. Ch\u00fa \u00fd khi s\u1eed d\u1ee5ng overcommit vCPU, khi load g\u1ea7n 100% th\u00ec s\u1ebd b\u1ecb drop c\u00e1c request ho\u1eb7c kh\u1ea3 n\u0103ng reponse b\u1ecb ch\u1eadm l\u1ea1i C\u00e1c CPU \u1ea3o h\u00f3a (vCPUs) \u0111\u01b0\u1ee3c overcommitted t\u1ed1t nh\u1ea5t khi m\u1ed9t m\u00e1y v\u1eadt l\u00fd m\u00e1y ch\u1ee7 duy nh\u1ea5t c\u00f3 nhi\u1ec1u m\u00e1y \u1ea3o kh\u00e1ch m\u00e0 kh\u00f4ng d\u00f9ng chung m\u1ed9t vCPU. KVM h\u1ed7 tr\u1ee3 \u1edf m\u1ee9c an to\u00e0n c\u00e1c m\u00e1y \u1ea3o load d\u01b0\u1edbi 100% theo t\u1ec9 l\u1ec7 5vCPU ( cho 5 m\u00e1y \u1ea3o ) tr\u00ean m\u1ed9t CPU v\u1eadt l\u00fd. KVM s\u1ebd chuy\u1ec3n ph\u00e2n b\u1ed5 CPU gi\u1eefa c\u00e1c m\u00e1y \u1ea3o \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c c\u00e2n b\u1eb1ng t\u1ea3i Kh\u00f4ng \u0111\u01b0\u1ee3c overcommit c\u00e1c m\u1ea3y \u1ea3o c\u00f3 s\u1ed1 vCPU nhi\u1ec1u h\u01a1n s\u1ed1 core process . V\u00ed d\u1ee5 m\u1ed9t m\u00e1y \u1ea3o v\u1edbi 4 vCPU kh\u00f4ng th\u1ec3 ch\u1ea1y tr\u00ean host 2 core nh\u01b0ng c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean quad core .Kkhuy\u1ebfn ngh\u1ecb : kh\u00f4ng n\u00ean ph\u00e2n b\u1ed5 qu\u00e1 1 vCPU tr\u00ean 1 CPU v\u1eadt l\u00fd","title":"3.1 . Kh\u00e1i ni\u1ec7m overcommitting trong KVM"},{"location":"Openstack_Research/Advance/7.1.  Resource-Management-OPS/#32_overcommitting_trong_ops","text":"Trong OPS h\u1ed7 tr\u1ee3 overcommitting tr\u00ean c\u00e1c compute node . Tr\u00ean compute service t\u1ec9 l\u1ec7 overcommit \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 CPU allocation ratio: 16:1 - \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 16 vCPU tr\u00ean 1 CPU v\u1eadt l\u00fd . RAM allocation ratio: 1.5:1 - cho ph\u00e9p ph\u00e2n b\u1ed5 RAM t\u1edbi c\u00e1c instance s\u1ebd nhi\u1ec1u h\u01a1n 1.5 l\u1ea7n so v\u1edbi memory physical C\u1ea5u h\u00ecnh t\u1ec9 l\u1ec7 overcommit tr\u00ean controller node /etc/nova/nova.conf : [DEFAULT] cpu_allocation_ratio = 10.1 Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service \\ openstack-nova-scheduler.service openstack-nova-conductor.service \\ openstack-nova-novncproxy.service","title":"3.2 . Overcommitting trong OPS"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/","text":"1. Nova-scheduler \u00b6 Nova s\u1eed d\u1ee5ng nova-scheduler service \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh compute noe th\u1ef1c hi\u1ec7n m\u1ed9t request , v\u00ed d\u1ee5 nova-scheduler service x\u00e1c \u0111\u1ecbnh host \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o 1. Filter scheduler \u00b6 Filter scheduler \u0111\u01b0\u1ee3c scheduler s\u1eed d\u1ee5ng m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 l\u1eadp k\u1ebf ho\u1ea1ch kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o . Trong filter schduler h\u1ed7 tr\u1ee3 filtering v\u00e0 weighting \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh m\u1ed9t compute \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o. Khi nh\u1eadn filter scheduler nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t request s\u1ebd d\u00f9ng Filtering nh\u1eefng host ph\u00f9 h\u1ee3p \u0111\u1ec3 launch m\u00e1y \u1ea3o, nh\u1eefng host kh\u00f4ng ph\u00f9 h\u1ee3p s\u1ebd b\u1ecb lo\u1ea1i. Host \u0111\u01b0\u1ee3c ch\u1ea5p nh\u1eadp \u0111\u1ee7 y\u00eau c\u1ea7u filtering s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n kh\u00e1c \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh host cho y\u00eau c\u1ea7u s\u1eed d\u1ee5ng weighting 1.1. Filtering \u00b6 C\u1ea5u h\u00ecnh Filtering trong nova.conf [scheduler] driver = filter_scheduler [filter_scheduler] available_filters = nova.scheduler.filters.all_filters enabled_filters = RetryFilter, AvailabilityZoneFilter, ComputeFilter, ComputeCapabilitiesFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter Danh s\u00e1ch c\u00e1c filter \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong filtering AllHostsFilter : Kh\u00f4ng filter, \u0111\u01b0\u1ee3c t\u1ea1o m\u00e1y \u1ea3o tr\u00ean b\u1ea5t c\u1ee9 host n\u00e0o available. ImagePropertiesFilter : filter host d\u1ef1a v\u00e0o properties \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a tr\u00ean instance\u2019s image. N\u00f3 s\u1ebd ch\u1ecdn c\u00e1c host c\u00f3 th\u1ec3 h\u1ed7 tr\u1ee3 c\u00e1c th\u00f4ng s\u1ed1 c\u1ee5 th\u1ec3 tr\u00ean image \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi instance. ImagePropertiesFilter d\u1ef1a v\u00e0o ki\u1ebfn tr\u00fac, hypervisor type v\u00e0 virtual machine mode \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong instance. V\u00ed d\u1ee5, m\u00e1y \u1ea3o y\u00eau c\u1ea7u host h\u1ed7 tr\u1ee3 ki\u1ebfn tr\u00fac ARM th\u00ec ImagePropertiesFilter s\u1ebd ch\u1ec9 ch\u1ecdn nh\u1eefng host \u0111\u00e1p \u1ee9ng y\u00eau c\u1ea7u n\u00e0y. AvailabilityZoneFilter : filter b\u1eb1ng availability zone. C\u00e1c host ph\u00f9 h\u1ee3p v\u1edbi availability zone \u0111\u01b0\u1ee3c ghi tr\u00ean instance properties s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. N\u00f3 s\u1ebd xem availability zone c\u1ee7a compute node v\u00e0 availability zone t\u1eeb ph\u1ea7n request. ComputeCapabilitiesFilter : Ki\u1ec3m tra xem host compute service c\u00f3 \u0111\u1ee7 kh\u1ea3 n\u0103ng \u0111\u00e1p \u1ee9ng c\u00e1c y\u00eau c\u1ea7u ngo\u00e0i l\u1ec1 (extra_specs) v\u1edbi instance type kh\u00f4ng. N\u00f3 s\u1ebd ch\u1ecdn c\u00e1c host c\u00f3 th\u1ec3 t\u1ea1o \u0111\u01b0\u1ee3c instance type c\u1ee5 th\u1ec3. extra_specs ch\u1ee9a key/value pairs v\u00ed d\u1ee5 nh\u01b0 free_ram_mb (compared with a number, values like \">= 4096\") ComputeFilter : Ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c hosts \u0111ang \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t. CoreFilter : filter d\u1ef1a v\u00e0o m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng CPU core. N\u00f3 s\u1ebd ch\u1ecdn host c\u00f3 \u0111\u1ee7 s\u1ed1 l\u01b0\u1ee3ng CPU core. AggregateCoreFilter : filter b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng CPU core v\u1edbi gi\u00e1 tr\u1ecb cpu_allocation_ratio . IsolatedHostsFilter : filter d\u1ef1a v\u00e0o image_isolated, host_isolated v\u00e0 restrict_isolated_hosts_to_isolated_images flags. JsonFilter : Cho ph\u00e9p s\u1eed d\u1ee5ng JSON-based grammar \u0111\u1ec3 l\u1ef1a ch\u1ecdn host. RamFilter : filter b\u1eb1ng RAM, c\u00e1c hosts c\u00f3 \u0111\u1ee7 dung l\u01b0\u1ee3ng RAM s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. AggregateRamFilter : filter b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng RAM v\u1edbi gi\u00e1 tr\u1ecb ram_allocation_ratio . ram_allocation_ratio \u1edf \u0111\u00e2y l\u00e0 t\u1ec9 l\u1ec7 RAM \u1ea3o v\u1edbi RAM v\u1eadt l\u00fd (m\u1eb7c \u0111\u1ecbnh l\u00e0 1.5) DiskFilter : filter b\u1eb1ng dung l\u01b0\u1ee3ng disk. c\u00e1c hosts c\u00f3 \u0111\u1ee7 dung l\u01b0\u1ee3ng disk s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. AggregateDiskFilter : filter b\u1eb1ng dung l\u01b0\u1ee3ng disk v\u1edbi gi\u00e1 tr\u1ecb disk_allocation_ratio . NumInstancesFilter : filter d\u1ef1a v\u00e0o s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o \u0111ang ch\u1ea1y tr\u00ean node compute \u0111\u00f3. node n\u00e0o c\u00f3 qu\u00e1 nhi\u1ec1u m\u00e1y \u1ea3o \u0111ang ch\u1ea1y s\u1ebd b\u1ecb lo\u1ea1i. N\u1ebfu ch\u1ec9 s\u1ed1 max_instances_per_host \u0111\u01b0\u01a1c thi\u1ebft l\u1eadp. Nh\u1eefng node c\u00f3 s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o \u0111\u1ea1t ng\u01b0\u1ee1ng max_instances_per_host s\u1ebd b\u1ecb ignored. AggregateNumInstancesFilter : filter d\u1ef1a theo ch\u1ec9 s\u1ed1 max_instances_per_host . IoOpsFilter : filter d\u1ef1a theo s\u1ed1 l\u01b0\u1ee3ng I/O operations. AggregateIoOpsFilter: filter d\u1ef1a theo ch\u1ec9 s\u1ed1 max_io_ops_per_host . SimpleCIDRAffinityFilter : Cho ph\u00e9p c\u00e1c instance tr\u00ean c\u00e1c node kh\u00e1c nhau c\u00f3 c\u00f9ng IP block. DifferentHostFilter : Cho ph\u00e9p c\u00e1c instances \u0111\u1eb7t tr\u00ean c\u00e1c node kh\u00e1c nhau. SameHostFilter : \u0110\u1eb7t instance tr\u00ean c\u00f9ng 1 node. RetryFilter : ch\u1ec9 ch\u1ecdn c\u00e1c host ch\u01b0a t\u1eebng \u0111\u01b0\u1ee3c schedule. Xem th\u00eam t\u1ea1i \u0111\u00e2y AggregateInstanceExtraSpecsFilter : x\u00e1c \u0111\u1ecbnh host aggragate ph\u00f9 h\u1ee3p cho m\u00e1y \u1ea3o . 1.2. Weighting \u00b6 Sau khi qu\u00e1 tr\u00ecnh filtering , scheduler s\u1ebd x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c c\u00e1c host \u0111\u1ee7 y\u00eau c\u1ea7u \u0111\u1ec3 \u0111\u1eb7t m\u00e1y \u1ea3o . Weighting s\u1ebd th\u1ef1c hi\u1ec7n t\u00ecm host th\u00edch h\u1ee3p nh\u1ea5t tr\u00ean c\u00e1c host sau qu\u00e1 tr\u00ecnh filtering. C\u1ea5u h\u00ecnh host weigher trong nova.conf : [DEFAULT] scheduler_weight_classes = class Trong \u0111\u00f3 c\u00e1c g\u1ed3m c\u00e1c class : - nova.scheduler.weights.ram : RAM tr\u00ean host c\u00f2n d\u01b0 th\u1eeba - nova.scheduler.weights.metrics : ch\u1ec9 \u0111\u1ecbnh c\u00e1c metric tr\u00ean host - ova.scheduler.weights.all_weighers : s\u1eed d\u1ee5ng t\u1ea5t c\u1ea3 c\u00e1c metric tr\u00ean host C\u1ea5u h\u00ecnh c\u00e1c option metric Section Option Description [DEFAULT] ram_weight_multiplier [DEFAULT] scheduler_host_subset_size [DEFAULT] scheduler_weight_classes [DEFAULT] io_ops_weight_multiplier [DEFAULT] soft_affinity_weight_multiplier [DEFAULT] soft_anti_affinity_weight_multiplier [filter_scheduler] build_failure_weight_multiplier [metrics] weight_multiplier [metrics] weight_setting [metrics] required [metrics] weight_of_unavailable 2. T\u00ecm hi\u1ec3u kh\u00e1i ni\u1ec7m Host aggregate v\u00e0 Availability zones \u00b6 2.1 : Host aggregate \u00b6 Ph\u01b0\u01a1ng th\u1ee9c t\u1ea1o t\u1ea1o ra m\u1ed9t nh\u00f3m logic \u0111\u1ec3 ph\u00e2n v\u00f9ng c\u00e1c server . Host aggregate trong OPS t\u1eadp h\u1ee3p c\u00e1c Compute Node \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh v\u00e0 li\u00ean k\u1ebft v\u1edbi metadata. M\u1ed9t host c\u00f3 th\u1ec3 n\u1eb1m trong nhi\u1ec1u h\u01a1n m\u1ed9t host aggregate. Ch\u1ec9 c\u00f3 ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb m\u1edbi c\u00f3 quy\u1ec1n t\u1ea1o v\u00e0 th\u1ea5y \u0111\u01b0\u1ee3c c\u00e1c host aggregates C\u00e1c metadata trong c\u00e1c host aggregate th\u01b0\u1eddng \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 cung c\u1ea5p th\u00f4ng tin cho qu\u00e1 tr\u00ecnh nova-scheduler \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c \u0111\u01b0\u1ee3c host \u0111\u1eb7t c\u00e1c m\u1ea3y \u1ea3o . Metadata quy \u0111\u1ecbnh trong m\u1ed9t host aggretate s\u1ebd ch\u1ec9 \u0111\u1ecbnh host ch\u1ea1y c\u00e1c instance m\u00e0 c\u00f3 falvor c\u00f9ng metadata Ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb s\u1eed d\u1ee5ng host aggregate \u0111\u1ec3 x\u1eed l\u00fd c\u00e2n b\u1eb1ng t\u1ea3i, d\u1ef1 ph\u00f2ng, resource pool ,nh\u00f3m c\u00e1c server c\u00f9ng thu\u1ed9c t\u00ednh. C\u00e1c host aggregate s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c public ra cho c\u00e1c end-user m\u00e0 thay \u0111\u00f3 s\u1ebd \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c flavor. V\u00ed d\u1ee5 v\u1ec1 Host aggregate : c\u00f3 th\u1ec3 t\u1ea1o m\u1ed9t t\u00e2p h\u1ee3p c\u00e1c compute node t\u00f9y v\u00e0o v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd : \"DC FPT HCM\", ho\u1eb7c c\u00e1c host tr\u00ean rack 1 s\u1eed d\u1ee5ng disk SSD RACK 1 SSD 2.2. Availability zones \u00b6 L\u00e0 ch\u1ebf \u0111\u1ed9 d\u00e0nh cho c\u00e1c end-user c\u1ee7a Host aggregate , tr\u00ecnh b\u00e0y c\u00e1c host aggetes d\u01b0\u1edbi d\u1ea1ng c\u00e1c availability zone. C\u00e1c end-user kh\u00f4ng th\u1ec3 xem \u0111\u01b0\u1ee3c host aggrete t\u1ea1o n\u00ean zone , kh\u00f4ng th\u1ec3 xem \u0111\u01b0\u1ee3c metadata m\u00e0 ch\u1ec9 xem \u0111\u01b0\u1ee3c c\u00e1c zone name. Availability zone l\u00e0 m\u1ed9t medata c\u1ee5 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o m\u1ed9t host aggregate. Vi\u1ec7c th\u00eam m\u1ed9t medata v\u00e0o m\u1ed9t host aggregate l\u00e0m c\u00e1c t\u1eadp h\u1ee3p n\u00e0y \u0111\u01b0\u1ee3c nh\u00ecn th\u1ea5y t\u1eeb c\u00e1c end-user , do \u0111\u00f3 c\u00f3 th\u1ec3 nh\u1edd nova-sheduler l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t host aggregate c\u1ee5 th\u1ec3. Avalibalitiy zone cho ph\u00e9p c\u00e1c c\u00e1c end-user ch\u1ecdn m\u1ed9t host aggregate \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o . V\u00ed d\u1ee5 s\u1eed d\u1ee5ng availability zone , ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean DC FPT \u1edf HCM C\u00e1c rule gi\u1eefa aggregates v\u00e0 availability zone M\u1ed9t host c\u00f3 th\u1ec3 c\u00f3 th\u1ec3 nhi\u1ec1u host aggregate, nh\u01b0ng ch\u1ec9 c\u00f3 th\u1ec3 m\u1ed9t avaibility zone M\u1eb7c \u0111\u1ecbnh, m\u1ed9t host s\u1ebd c\u00f3 m\u1ed9t availability zone m\u1eb7c \u0111\u1ecbnh n\u1ebfu kh\u00f4ng c\u00f3 host aggregate. 2.3 . C\u1ea5u h\u00ecnh Host Aggregate Scheduling \u00b6 Trong file c\u1ea5u h\u00ecnh /etc/nova/nova.conf tr\u00ean node ch\u1ea1y nova-scheduler service [filter_scheduler] enabled_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter Kh\u1edfi t\u1ea1o m\u1ed9t host aggregate DC_HCM [root@controller ~]# openstack aggregate create ssd-rack1 --zone rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.225058 | | deleted | False | | deleted_at | None | | id | 4 | | name | ssd-rack1 | | updated_at | None | +-------------------+----------------------------+ G\u1eafn metadata SSD=True v\u00e0o aggregate [root@controller ~]# openstack aggregate set --property ssd=true --zone rack1 ssd-rack1 [root@controller ~]# openstack aggregate show ssd-rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | nova | | created_at | 2018-11-21T08:03:02.000000 | | deleted | False | | deleted_at | None | | hosts | [] | | id | 1 | | name | fast-io | | properties | ssd='true' | | updated_at | None | +-------------------+----------------------------+ Th\u00eam host v\u00e0o host aggregate fast-io [root@controller ~]# openstack aggregate add host ssd-rack1 compute1 +-------------------+---------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.000000 | | deleted | False | | deleted_at | None | | hosts | [u'compute1'] | | id | 4 | | metadata | {u'ssd': u'true', u'availability_zone': u'rack1'} | | name | ssd-rack1 | | updated_at | None | +-------------------+---------------------------------------------------+ [root@controller ~]# openstack aggregate show ssd-rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.000000 | | deleted | False | | deleted_at | None | | hosts | [u'compute1'] | | id | 4 | | name | ssd-rack1 | | properties | ssd='true' | | updated_at | None | +-------------------+----------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t flavor [root@controller nova]# openstack flavor create --ram 1024 --disk 10 --vcpus 2 ssd.small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 408d8c23-dcb6-4bd0-b86b-9be7eb239ed8 | | name | ssd.small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 2 | +----------------------------+--------------------------------------+ Ch\u1ec9 \u0111\u1ecbnh host aggregate medata [root@controller nova]# openstack flavor set --property aggregate_instance_extra_specs:ssd=true ssd.small +----------------------------+-------------------------------------------+ | Field | Value | +----------------------------+-------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | None | | disk | 10 | | id | 408d8c23-dcb6-4bd0-b86b-9be7eb239ed8 | | name | ssd.small | | os-flavor-access:is_public | True | | properties | aggregate_instance_extra_specs:ssd='true' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 2 | +----------------------------+-------------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean node compute1 tr\u00ean zone rack1 root@controller ~]# openstack server create --image cirros --flavor large \\ > --availability-zone rack1:compute1 \\ > --network net_ex cirros_compute1 +-------------------------------------+-----------------------------------------------+ | Field | Value | +-------------------------------------+-----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | rack1 | | OS-EXT-SRV-ATTR:host | None | | OS-EXT-SRV-ATTR:hypervisor_hostname | None | | OS-EXT-SRV-ATTR:instance_name | | | OS-EXT-STS:power_state | NOSTATE | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | fYofnK758TkK | | config_drive | | | created | 2018-11-21T09:21:26Z | | flavor | large (0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15) | | hostId | | | id | 8c6c067c-5a90-4d80-830d-2752e5a1673d | | image | cirros (8bc5ff78-118b-435a-9611-e6a99d9f6b1c) | | key_name | None | | name | cirros_compute1 | | progress | 0 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | properties | | | security_groups | name='default' | | status | BUILD | | updated | 2018-11-21T09:21:26Z | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | | volumes_attached | | +-------------------------------------+-----------------------------------------------+ 3. T\u00ecm hi\u1ec3u th\u00eam \u00b6 https://docs.openstack.org/nova/queens/admin/configuration/schedulers.html https://slack-files.com/TC7HVUK9S-FE8QTT1RS-7015680558","title":"1. Nova-scheduler"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#1_nova-scheduler","text":"Nova s\u1eed d\u1ee5ng nova-scheduler service \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh compute noe th\u1ef1c hi\u1ec7n m\u1ed9t request , v\u00ed d\u1ee5 nova-scheduler service x\u00e1c \u0111\u1ecbnh host \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o","title":"1. Nova-scheduler"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#1_filter_scheduler","text":"Filter scheduler \u0111\u01b0\u1ee3c scheduler s\u1eed d\u1ee5ng m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 l\u1eadp k\u1ebf ho\u1ea1ch kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o . Trong filter schduler h\u1ed7 tr\u1ee3 filtering v\u00e0 weighting \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh m\u1ed9t compute \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o. Khi nh\u1eadn filter scheduler nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t request s\u1ebd d\u00f9ng Filtering nh\u1eefng host ph\u00f9 h\u1ee3p \u0111\u1ec3 launch m\u00e1y \u1ea3o, nh\u1eefng host kh\u00f4ng ph\u00f9 h\u1ee3p s\u1ebd b\u1ecb lo\u1ea1i. Host \u0111\u01b0\u1ee3c ch\u1ea5p nh\u1eadp \u0111\u1ee7 y\u00eau c\u1ea7u filtering s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n kh\u00e1c \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh host cho y\u00eau c\u1ea7u s\u1eed d\u1ee5ng weighting","title":"1. Filter scheduler"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#11_filtering","text":"C\u1ea5u h\u00ecnh Filtering trong nova.conf [scheduler] driver = filter_scheduler [filter_scheduler] available_filters = nova.scheduler.filters.all_filters enabled_filters = RetryFilter, AvailabilityZoneFilter, ComputeFilter, ComputeCapabilitiesFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter Danh s\u00e1ch c\u00e1c filter \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong filtering AllHostsFilter : Kh\u00f4ng filter, \u0111\u01b0\u1ee3c t\u1ea1o m\u00e1y \u1ea3o tr\u00ean b\u1ea5t c\u1ee9 host n\u00e0o available. ImagePropertiesFilter : filter host d\u1ef1a v\u00e0o properties \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a tr\u00ean instance\u2019s image. N\u00f3 s\u1ebd ch\u1ecdn c\u00e1c host c\u00f3 th\u1ec3 h\u1ed7 tr\u1ee3 c\u00e1c th\u00f4ng s\u1ed1 c\u1ee5 th\u1ec3 tr\u00ean image \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi instance. ImagePropertiesFilter d\u1ef1a v\u00e0o ki\u1ebfn tr\u00fac, hypervisor type v\u00e0 virtual machine mode \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong instance. V\u00ed d\u1ee5, m\u00e1y \u1ea3o y\u00eau c\u1ea7u host h\u1ed7 tr\u1ee3 ki\u1ebfn tr\u00fac ARM th\u00ec ImagePropertiesFilter s\u1ebd ch\u1ec9 ch\u1ecdn nh\u1eefng host \u0111\u00e1p \u1ee9ng y\u00eau c\u1ea7u n\u00e0y. AvailabilityZoneFilter : filter b\u1eb1ng availability zone. C\u00e1c host ph\u00f9 h\u1ee3p v\u1edbi availability zone \u0111\u01b0\u1ee3c ghi tr\u00ean instance properties s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. N\u00f3 s\u1ebd xem availability zone c\u1ee7a compute node v\u00e0 availability zone t\u1eeb ph\u1ea7n request. ComputeCapabilitiesFilter : Ki\u1ec3m tra xem host compute service c\u00f3 \u0111\u1ee7 kh\u1ea3 n\u0103ng \u0111\u00e1p \u1ee9ng c\u00e1c y\u00eau c\u1ea7u ngo\u00e0i l\u1ec1 (extra_specs) v\u1edbi instance type kh\u00f4ng. N\u00f3 s\u1ebd ch\u1ecdn c\u00e1c host c\u00f3 th\u1ec3 t\u1ea1o \u0111\u01b0\u1ee3c instance type c\u1ee5 th\u1ec3. extra_specs ch\u1ee9a key/value pairs v\u00ed d\u1ee5 nh\u01b0 free_ram_mb (compared with a number, values like \">= 4096\") ComputeFilter : Ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c hosts \u0111ang \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t. CoreFilter : filter d\u1ef1a v\u00e0o m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng CPU core. N\u00f3 s\u1ebd ch\u1ecdn host c\u00f3 \u0111\u1ee7 s\u1ed1 l\u01b0\u1ee3ng CPU core. AggregateCoreFilter : filter b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng CPU core v\u1edbi gi\u00e1 tr\u1ecb cpu_allocation_ratio . IsolatedHostsFilter : filter d\u1ef1a v\u00e0o image_isolated, host_isolated v\u00e0 restrict_isolated_hosts_to_isolated_images flags. JsonFilter : Cho ph\u00e9p s\u1eed d\u1ee5ng JSON-based grammar \u0111\u1ec3 l\u1ef1a ch\u1ecdn host. RamFilter : filter b\u1eb1ng RAM, c\u00e1c hosts c\u00f3 \u0111\u1ee7 dung l\u01b0\u1ee3ng RAM s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. AggregateRamFilter : filter b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng RAM v\u1edbi gi\u00e1 tr\u1ecb ram_allocation_ratio . ram_allocation_ratio \u1edf \u0111\u00e2y l\u00e0 t\u1ec9 l\u1ec7 RAM \u1ea3o v\u1edbi RAM v\u1eadt l\u00fd (m\u1eb7c \u0111\u1ecbnh l\u00e0 1.5) DiskFilter : filter b\u1eb1ng dung l\u01b0\u1ee3ng disk. c\u00e1c hosts c\u00f3 \u0111\u1ee7 dung l\u01b0\u1ee3ng disk s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn. AggregateDiskFilter : filter b\u1eb1ng dung l\u01b0\u1ee3ng disk v\u1edbi gi\u00e1 tr\u1ecb disk_allocation_ratio . NumInstancesFilter : filter d\u1ef1a v\u00e0o s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o \u0111ang ch\u1ea1y tr\u00ean node compute \u0111\u00f3. node n\u00e0o c\u00f3 qu\u00e1 nhi\u1ec1u m\u00e1y \u1ea3o \u0111ang ch\u1ea1y s\u1ebd b\u1ecb lo\u1ea1i. N\u1ebfu ch\u1ec9 s\u1ed1 max_instances_per_host \u0111\u01b0\u01a1c thi\u1ebft l\u1eadp. Nh\u1eefng node c\u00f3 s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o \u0111\u1ea1t ng\u01b0\u1ee1ng max_instances_per_host s\u1ebd b\u1ecb ignored. AggregateNumInstancesFilter : filter d\u1ef1a theo ch\u1ec9 s\u1ed1 max_instances_per_host . IoOpsFilter : filter d\u1ef1a theo s\u1ed1 l\u01b0\u1ee3ng I/O operations. AggregateIoOpsFilter: filter d\u1ef1a theo ch\u1ec9 s\u1ed1 max_io_ops_per_host . SimpleCIDRAffinityFilter : Cho ph\u00e9p c\u00e1c instance tr\u00ean c\u00e1c node kh\u00e1c nhau c\u00f3 c\u00f9ng IP block. DifferentHostFilter : Cho ph\u00e9p c\u00e1c instances \u0111\u1eb7t tr\u00ean c\u00e1c node kh\u00e1c nhau. SameHostFilter : \u0110\u1eb7t instance tr\u00ean c\u00f9ng 1 node. RetryFilter : ch\u1ec9 ch\u1ecdn c\u00e1c host ch\u01b0a t\u1eebng \u0111\u01b0\u1ee3c schedule. Xem th\u00eam t\u1ea1i \u0111\u00e2y AggregateInstanceExtraSpecsFilter : x\u00e1c \u0111\u1ecbnh host aggragate ph\u00f9 h\u1ee3p cho m\u00e1y \u1ea3o .","title":"1.1. Filtering"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#12_weighting","text":"Sau khi qu\u00e1 tr\u00ecnh filtering , scheduler s\u1ebd x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c c\u00e1c host \u0111\u1ee7 y\u00eau c\u1ea7u \u0111\u1ec3 \u0111\u1eb7t m\u00e1y \u1ea3o . Weighting s\u1ebd th\u1ef1c hi\u1ec7n t\u00ecm host th\u00edch h\u1ee3p nh\u1ea5t tr\u00ean c\u00e1c host sau qu\u00e1 tr\u00ecnh filtering. C\u1ea5u h\u00ecnh host weigher trong nova.conf : [DEFAULT] scheduler_weight_classes = class Trong \u0111\u00f3 c\u00e1c g\u1ed3m c\u00e1c class : - nova.scheduler.weights.ram : RAM tr\u00ean host c\u00f2n d\u01b0 th\u1eeba - nova.scheduler.weights.metrics : ch\u1ec9 \u0111\u1ecbnh c\u00e1c metric tr\u00ean host - ova.scheduler.weights.all_weighers : s\u1eed d\u1ee5ng t\u1ea5t c\u1ea3 c\u00e1c metric tr\u00ean host C\u1ea5u h\u00ecnh c\u00e1c option metric Section Option Description [DEFAULT] ram_weight_multiplier [DEFAULT] scheduler_host_subset_size [DEFAULT] scheduler_weight_classes [DEFAULT] io_ops_weight_multiplier [DEFAULT] soft_affinity_weight_multiplier [DEFAULT] soft_anti_affinity_weight_multiplier [filter_scheduler] build_failure_weight_multiplier [metrics] weight_multiplier [metrics] weight_setting [metrics] required [metrics] weight_of_unavailable","title":"1.2. Weighting"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#2_tim_hieu_khai_niem_host_aggregate_va_availability_zones","text":"","title":"2. T\u00ecm hi\u1ec3u kh\u00e1i ni\u1ec7m Host aggregate v\u00e0  Availability zones"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#21_host_aggregate","text":"Ph\u01b0\u01a1ng th\u1ee9c t\u1ea1o t\u1ea1o ra m\u1ed9t nh\u00f3m logic \u0111\u1ec3 ph\u00e2n v\u00f9ng c\u00e1c server . Host aggregate trong OPS t\u1eadp h\u1ee3p c\u00e1c Compute Node \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh v\u00e0 li\u00ean k\u1ebft v\u1edbi metadata. M\u1ed9t host c\u00f3 th\u1ec3 n\u1eb1m trong nhi\u1ec1u h\u01a1n m\u1ed9t host aggregate. Ch\u1ec9 c\u00f3 ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb m\u1edbi c\u00f3 quy\u1ec1n t\u1ea1o v\u00e0 th\u1ea5y \u0111\u01b0\u1ee3c c\u00e1c host aggregates C\u00e1c metadata trong c\u00e1c host aggregate th\u01b0\u1eddng \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 cung c\u1ea5p th\u00f4ng tin cho qu\u00e1 tr\u00ecnh nova-scheduler \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c \u0111\u01b0\u1ee3c host \u0111\u1eb7t c\u00e1c m\u1ea3y \u1ea3o . Metadata quy \u0111\u1ecbnh trong m\u1ed9t host aggretate s\u1ebd ch\u1ec9 \u0111\u1ecbnh host ch\u1ea1y c\u00e1c instance m\u00e0 c\u00f3 falvor c\u00f9ng metadata Ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb s\u1eed d\u1ee5ng host aggregate \u0111\u1ec3 x\u1eed l\u00fd c\u00e2n b\u1eb1ng t\u1ea3i, d\u1ef1 ph\u00f2ng, resource pool ,nh\u00f3m c\u00e1c server c\u00f9ng thu\u1ed9c t\u00ednh. C\u00e1c host aggregate s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c public ra cho c\u00e1c end-user m\u00e0 thay \u0111\u00f3 s\u1ebd \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c flavor. V\u00ed d\u1ee5 v\u1ec1 Host aggregate : c\u00f3 th\u1ec3 t\u1ea1o m\u1ed9t t\u00e2p h\u1ee3p c\u00e1c compute node t\u00f9y v\u00e0o v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd : \"DC FPT HCM\", ho\u1eb7c c\u00e1c host tr\u00ean rack 1 s\u1eed d\u1ee5ng disk SSD RACK 1 SSD","title":"2.1 : Host aggregate"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#22_availability_zones","text":"L\u00e0 ch\u1ebf \u0111\u1ed9 d\u00e0nh cho c\u00e1c end-user c\u1ee7a Host aggregate , tr\u00ecnh b\u00e0y c\u00e1c host aggetes d\u01b0\u1edbi d\u1ea1ng c\u00e1c availability zone. C\u00e1c end-user kh\u00f4ng th\u1ec3 xem \u0111\u01b0\u1ee3c host aggrete t\u1ea1o n\u00ean zone , kh\u00f4ng th\u1ec3 xem \u0111\u01b0\u1ee3c metadata m\u00e0 ch\u1ec9 xem \u0111\u01b0\u1ee3c c\u00e1c zone name. Availability zone l\u00e0 m\u1ed9t medata c\u1ee5 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o m\u1ed9t host aggregate. Vi\u1ec7c th\u00eam m\u1ed9t medata v\u00e0o m\u1ed9t host aggregate l\u00e0m c\u00e1c t\u1eadp h\u1ee3p n\u00e0y \u0111\u01b0\u1ee3c nh\u00ecn th\u1ea5y t\u1eeb c\u00e1c end-user , do \u0111\u00f3 c\u00f3 th\u1ec3 nh\u1edd nova-sheduler l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t host aggregate c\u1ee5 th\u1ec3. Avalibalitiy zone cho ph\u00e9p c\u00e1c c\u00e1c end-user ch\u1ecdn m\u1ed9t host aggregate \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o . V\u00ed d\u1ee5 s\u1eed d\u1ee5ng availability zone , ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean DC FPT \u1edf HCM C\u00e1c rule gi\u1eefa aggregates v\u00e0 availability zone M\u1ed9t host c\u00f3 th\u1ec3 c\u00f3 th\u1ec3 nhi\u1ec1u host aggregate, nh\u01b0ng ch\u1ec9 c\u00f3 th\u1ec3 m\u1ed9t avaibility zone M\u1eb7c \u0111\u1ecbnh, m\u1ed9t host s\u1ebd c\u00f3 m\u1ed9t availability zone m\u1eb7c \u0111\u1ecbnh n\u1ebfu kh\u00f4ng c\u00f3 host aggregate.","title":"2.2. Availability zones"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#23_cau_hinh_host_aggregate_scheduling","text":"Trong file c\u1ea5u h\u00ecnh /etc/nova/nova.conf tr\u00ean node ch\u1ea1y nova-scheduler service [filter_scheduler] enabled_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter Kh\u1edfi t\u1ea1o m\u1ed9t host aggregate DC_HCM [root@controller ~]# openstack aggregate create ssd-rack1 --zone rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.225058 | | deleted | False | | deleted_at | None | | id | 4 | | name | ssd-rack1 | | updated_at | None | +-------------------+----------------------------+ G\u1eafn metadata SSD=True v\u00e0o aggregate [root@controller ~]# openstack aggregate set --property ssd=true --zone rack1 ssd-rack1 [root@controller ~]# openstack aggregate show ssd-rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | nova | | created_at | 2018-11-21T08:03:02.000000 | | deleted | False | | deleted_at | None | | hosts | [] | | id | 1 | | name | fast-io | | properties | ssd='true' | | updated_at | None | +-------------------+----------------------------+ Th\u00eam host v\u00e0o host aggregate fast-io [root@controller ~]# openstack aggregate add host ssd-rack1 compute1 +-------------------+---------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.000000 | | deleted | False | | deleted_at | None | | hosts | [u'compute1'] | | id | 4 | | metadata | {u'ssd': u'true', u'availability_zone': u'rack1'} | | name | ssd-rack1 | | updated_at | None | +-------------------+---------------------------------------------------+ [root@controller ~]# openstack aggregate show ssd-rack1 +-------------------+----------------------------+ | Field | Value | +-------------------+----------------------------+ | availability_zone | rack1 | | created_at | 2018-11-21T09:02:07.000000 | | deleted | False | | deleted_at | None | | hosts | [u'compute1'] | | id | 4 | | name | ssd-rack1 | | properties | ssd='true' | | updated_at | None | +-------------------+----------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t flavor [root@controller nova]# openstack flavor create --ram 1024 --disk 10 --vcpus 2 ssd.small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 408d8c23-dcb6-4bd0-b86b-9be7eb239ed8 | | name | ssd.small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 2 | +----------------------------+--------------------------------------+ Ch\u1ec9 \u0111\u1ecbnh host aggregate medata [root@controller nova]# openstack flavor set --property aggregate_instance_extra_specs:ssd=true ssd.small +----------------------------+-------------------------------------------+ | Field | Value | +----------------------------+-------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | None | | disk | 10 | | id | 408d8c23-dcb6-4bd0-b86b-9be7eb239ed8 | | name | ssd.small | | os-flavor-access:is_public | True | | properties | aggregate_instance_extra_specs:ssd='true' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 2 | +----------------------------+-------------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean node compute1 tr\u00ean zone rack1 root@controller ~]# openstack server create --image cirros --flavor large \\ > --availability-zone rack1:compute1 \\ > --network net_ex cirros_compute1 +-------------------------------------+-----------------------------------------------+ | Field | Value | +-------------------------------------+-----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | rack1 | | OS-EXT-SRV-ATTR:host | None | | OS-EXT-SRV-ATTR:hypervisor_hostname | None | | OS-EXT-SRV-ATTR:instance_name | | | OS-EXT-STS:power_state | NOSTATE | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | fYofnK758TkK | | config_drive | | | created | 2018-11-21T09:21:26Z | | flavor | large (0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15) | | hostId | | | id | 8c6c067c-5a90-4d80-830d-2752e5a1673d | | image | cirros (8bc5ff78-118b-435a-9611-e6a99d9f6b1c) | | key_name | None | | name | cirros_compute1 | | progress | 0 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | properties | | | security_groups | name='default' | | status | BUILD | | updated | 2018-11-21T09:21:26Z | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | | volumes_attached | | +-------------------------------------+-----------------------------------------------+","title":"2.3 . C\u1ea5u h\u00ecnh Host Aggregate Scheduling"},{"location":"Openstack_Research/Advance/7.2 . Nova-Scheduler-&-Host-Aggreaggregate/#3_tim_hieu_them","text":"https://docs.openstack.org/nova/queens/admin/configuration/schedulers.html https://slack-files.com/TC7HVUK9S-FE8QTT1RS-7015680558","title":"3. T\u00ecm hi\u1ec3u th\u00eam"},{"location":"Openstack_Research/Advance/7.3. Lab-Filter-Scheduler/","text":"Sheduler Filter \u00b6 1. Host Aggregate Filter \u00b6 Host Aggregate cho SSD Rack openstack aggregate create ssd-rack1 --zone rack1 openstack aggregate set --property ssd=true ssd-rack1 openstack aggregate add host ssd-rack1 compute1 Host Aggregate cho HDD Rack openstack aggregate create hdd-rack2 --zone rack2 openstack aggregate set --property hdd=true hdd-rack2 openstack aggregate add host hdd-rack2 compute2 C\u1ea5u h\u00ecnh filtering Host Aggregate /etc/nova/nova.conf [scheduler] driver = filter_scheduler [filter_scheduler] available_filters = nova.scheduler.filters.all_filters scheduler_default_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter Kh\u1edfi t\u1ea1o flavor SSD openstack flavor create --ram 1024 --disk 10 --vcpus 1 ssd.small openstack flavor set --property aggregate_instance_extra_specs:ssd=true ssd.small Kh\u1edfi t\u1ea1o flavort HDD openstack flavor create --ram 1024 --disk 10 --vcpus 1 hdd.small openstack flavor set --property aggregate_instance_extra_specs:hdd=true hdd.small Kh\u1edfi ta\u1ecd m\u00e1y \u1ea3o b\u1eb1ng flavor ssd.small v\u00e0 hdd.small openstack server create --image cirros --flavor ssd.small cirros-ssd openstack server create --image cirros --flavor hdd.small cirros-hdd S\u1ebd th\u1ea5y 2 instance \u0111ang ch\u1ea1y tr\u00ean 2 zone kh\u00e1c nhau [root@controller nova]# nova show cirros-hdd | grep OS-EXT-AZ | awk '{print$2\":\"$4}' OS-EXT-AZ:availability_zone:rack2 [root@controller nova]# nova show cirros-ssd | grep OS-EXT-AZ | awk '{print$2\":\"$4}' OS-EXT-AZ:availability_zone:rack1 2. ComputeCapabilitiesFilter Filter \u00b6 T\u1ea1o m\u1ed9t flavor m\u1edbi root@controller ~]# openstack flavor create --disk 10 --ram 1024 --public linux_small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 2d41c5f8-9ddf-46b6-bef1-ecaab8b1d4e3 | | name | linux_small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ C\u1ea5u h\u00ecnh extra_specs cho flavor openstack flavor set linux_small --property free_ram_mb=\">= 1024\" openstack flavor set linux_small --property vcpus_total=\">= 1\" [root@controller ~]# openstack flavor show linux_small +----------------------------+-------------------------------------------+ | Field | Value | +----------------------------+-------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | None | | disk | 10 | | id | 2d41c5f8-9ddf-46b6-bef1-ecaab8b1d4e3 | | name | linux_small | | os-flavor-access:is_public | True | | properties | free_ram_mb='>= 1024', vcpus_total='>= 1' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+-------------------------------------------+ Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o t\u1eeb flavort linux_small openstack server create --image centos --flavor linux_small centos_filter 4. T\u00ecm hi\u1ec3u th\u00eam \u00b6 [1] : https://docs.openstack.org/nova/pike/user/filter-scheduler.html","title":"7.3. Lab Filter Scheduler"},{"location":"Openstack_Research/Advance/7.3. Lab-Filter-Scheduler/#sheduler_filter","text":"","title":"Sheduler Filter"},{"location":"Openstack_Research/Advance/7.3. Lab-Filter-Scheduler/#1_host_aggregate_filter","text":"Host Aggregate cho SSD Rack openstack aggregate create ssd-rack1 --zone rack1 openstack aggregate set --property ssd=true ssd-rack1 openstack aggregate add host ssd-rack1 compute1 Host Aggregate cho HDD Rack openstack aggregate create hdd-rack2 --zone rack2 openstack aggregate set --property hdd=true hdd-rack2 openstack aggregate add host hdd-rack2 compute2 C\u1ea5u h\u00ecnh filtering Host Aggregate /etc/nova/nova.conf [scheduler] driver = filter_scheduler [filter_scheduler] available_filters = nova.scheduler.filters.all_filters scheduler_default_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter Kh\u1edfi t\u1ea1o flavor SSD openstack flavor create --ram 1024 --disk 10 --vcpus 1 ssd.small openstack flavor set --property aggregate_instance_extra_specs:ssd=true ssd.small Kh\u1edfi t\u1ea1o flavort HDD openstack flavor create --ram 1024 --disk 10 --vcpus 1 hdd.small openstack flavor set --property aggregate_instance_extra_specs:hdd=true hdd.small Kh\u1edfi ta\u1ecd m\u00e1y \u1ea3o b\u1eb1ng flavor ssd.small v\u00e0 hdd.small openstack server create --image cirros --flavor ssd.small cirros-ssd openstack server create --image cirros --flavor hdd.small cirros-hdd S\u1ebd th\u1ea5y 2 instance \u0111ang ch\u1ea1y tr\u00ean 2 zone kh\u00e1c nhau [root@controller nova]# nova show cirros-hdd | grep OS-EXT-AZ | awk '{print$2\":\"$4}' OS-EXT-AZ:availability_zone:rack2 [root@controller nova]# nova show cirros-ssd | grep OS-EXT-AZ | awk '{print$2\":\"$4}' OS-EXT-AZ:availability_zone:rack1","title":"1. Host Aggregate Filter"},{"location":"Openstack_Research/Advance/7.3. Lab-Filter-Scheduler/#2_computecapabilitiesfilter_filter","text":"T\u1ea1o m\u1ed9t flavor m\u1edbi root@controller ~]# openstack flavor create --disk 10 --ram 1024 --public linux_small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | 2d41c5f8-9ddf-46b6-bef1-ecaab8b1d4e3 | | name | linux_small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ C\u1ea5u h\u00ecnh extra_specs cho flavor openstack flavor set linux_small --property free_ram_mb=\">= 1024\" openstack flavor set linux_small --property vcpus_total=\">= 1\" [root@controller ~]# openstack flavor show linux_small +----------------------------+-------------------------------------------+ | Field | Value | +----------------------------+-------------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | access_project_ids | None | | disk | 10 | | id | 2d41c5f8-9ddf-46b6-bef1-ecaab8b1d4e3 | | name | linux_small | | os-flavor-access:is_public | True | | properties | free_ram_mb='>= 1024', vcpus_total='>= 1' | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+-------------------------------------------+ Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o t\u1eeb flavort linux_small openstack server create --image centos --flavor linux_small centos_filter","title":"2. ComputeCapabilitiesFilter Filter"},{"location":"Openstack_Research/Advance/7.3. Lab-Filter-Scheduler/#4_tim_hieu_them","text":"[1] : https://docs.openstack.org/nova/pike/user/filter-scheduler.html","title":"4. T\u00ecm hi\u1ec3u th\u00eam"},{"location":"Openstack_Research/Advance/8. Resize-instance/","text":"1. Resize instance tr\u00ean 1 Host \u00b6 1.1. Note \u00b6 \u0110\u1ed1i v\u1edbi KVM : n\u1ebfu ch\u1ecdn m\u1ed9t flavor c\u00f3 disk nh\u1ecf h\u01a1n th\u00ec KVM s\u1ebd b\u1ecf qua qu\u00e1 tr\u00ecnh resize disk n\u1ebfu kh\u00f4ng ho\u00e0n th\u00e0nh .C\u00e1c t\u00e0i nguy\u00ean kh\u00e1c \u0111\u01b0\u1ee3c thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc cho ph\u00f9 h\u1ee3p. Resize instance ch\u1ec9 h\u1ed7 tr\u1ee3 local storage. 1.2. C\u1ea5u h\u00ecnh resize instance \u00b6 C\u1ea5u h\u00ecnh file nova.conf tr\u00ean controller [DEFAULT] allow_resize_to_same_host = True Li\u1ec7t k\u00ea danh s\u00e1ch instance [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | ACTIVE | net_ex=192.168.30.141 | cirros | small | +--------------------------------------+---------+--------+-----------------------+--------+--------+ Li\u1ec7t k\u00ea danh s\u00e1ch flavor +--------------------------------------+-----------+------+------+-----------+-------+-----------+ | ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public | +--------------------------------------+-----------+------+------+-----------+-------+-----------+ | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | large | 1024 | 10 | 0 | 1 | False | | 165e8c44-207c-4549-9bb5-12031e7a2090 | small | 1024 | 2 | 0 | 1 | True | | 39d8a5cf-7585-4e03-88ff-ea3deeff1380 | test_disk | 512 | 15 | 0 | 1 | True | | 7ef65cbe-4a70-442e-b4e2-d7b62995c208 | server | 2048 | 12 | 0 | 1 | True | +--------------------------------------+-----------+------+------+-----------+-------+-----------+ Resize instance t\u1eeb flavor small sang large [root@controller ~]# openstack server resize --confirm --flavor large cirrors [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | RESIZE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+ [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | RESIZE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+ Khi s\u1eed d\u1ee5ng nova-resize th\u00ec m\u00e1y \u1ea3o n\u1ebfu power \u0111ang \u1edf tr\u1ea1ng th\u00e1i power on s\u1ebd chuy\u1ec3n sang power off tr\u01b0\u1edbc khi th\u1ef1c hi\u1ec7n resize. Confirm resize instance [root@controller ~]# openstack server resize --confirm cirrors [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | ACTIVE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+","title":"8. Resize instance"},{"location":"Openstack_Research/Advance/8. Resize-instance/#1_resize_instance_tren_1_host","text":"","title":"1. Resize instance tr\u00ean 1 Host"},{"location":"Openstack_Research/Advance/8. Resize-instance/#11_note","text":"\u0110\u1ed1i v\u1edbi KVM : n\u1ebfu ch\u1ecdn m\u1ed9t flavor c\u00f3 disk nh\u1ecf h\u01a1n th\u00ec KVM s\u1ebd b\u1ecf qua qu\u00e1 tr\u00ecnh resize disk n\u1ebfu kh\u00f4ng ho\u00e0n th\u00e0nh .C\u00e1c t\u00e0i nguy\u00ean kh\u00e1c \u0111\u01b0\u1ee3c thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc cho ph\u00f9 h\u1ee3p. Resize instance ch\u1ec9 h\u1ed7 tr\u1ee3 local storage.","title":"1.1. Note"},{"location":"Openstack_Research/Advance/8. Resize-instance/#12_cau_hinh_resize_instance","text":"C\u1ea5u h\u00ecnh file nova.conf tr\u00ean controller [DEFAULT] allow_resize_to_same_host = True Li\u1ec7t k\u00ea danh s\u00e1ch instance [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | ACTIVE | net_ex=192.168.30.141 | cirros | small | +--------------------------------------+---------+--------+-----------------------+--------+--------+ Li\u1ec7t k\u00ea danh s\u00e1ch flavor +--------------------------------------+-----------+------+------+-----------+-------+-----------+ | ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public | +--------------------------------------+-----------+------+------+-----------+-------+-----------+ | 0ba339ae-9ac2-4dc1-abca-2e9fa9ac1e15 | large | 1024 | 10 | 0 | 1 | False | | 165e8c44-207c-4549-9bb5-12031e7a2090 | small | 1024 | 2 | 0 | 1 | True | | 39d8a5cf-7585-4e03-88ff-ea3deeff1380 | test_disk | 512 | 15 | 0 | 1 | True | | 7ef65cbe-4a70-442e-b4e2-d7b62995c208 | server | 2048 | 12 | 0 | 1 | True | +--------------------------------------+-----------+------+------+-----------+-------+-----------+ Resize instance t\u1eeb flavor small sang large [root@controller ~]# openstack server resize --confirm --flavor large cirrors [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | RESIZE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+ [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | RESIZE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+ Khi s\u1eed d\u1ee5ng nova-resize th\u00ec m\u00e1y \u1ea3o n\u1ebfu power \u0111ang \u1edf tr\u1ea1ng th\u00e1i power on s\u1ebd chuy\u1ec3n sang power off tr\u01b0\u1edbc khi th\u1ef1c hi\u1ec7n resize. Confirm resize instance [root@controller ~]# openstack server resize --confirm cirrors [root@controller ~]# openstack server list +--------------------------------------+---------+--------+-----------------------+--------+--------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+---------+--------+-----------------------+--------+--------+ | bacf0a20-ab47-4bc4-aa19-c0b77b8b3614 | cirrors | ACTIVE | net_ex=192.168.30.141 | cirros | large | +--------------------------------------+---------+--------+-----------------------+--------+--------+","title":"1.2. C\u1ea5u h\u00ecnh resize  instance"},{"location":"Openstack_Research/Advance/9. Rescue-instance/","text":"1. Nova-rescue \u00b6 OPS cung c\u1ea5p ch\u1ee9c n\u0103ng \u0111\u1ec3 rescue c\u00e1c instnace trong c\u00e1c tr\u01b0\u1eddng h\u1ee3p h\u1ecfng h\u00f3c, m\u1ea5t m\u00e1t filesystem, m\u1ea5t SSH key, c\u1ea5u h\u00ecnh network b\u1ecb sai ho\u1eb7c d\u00f9ng \u0111\u1ec3 kh\u00f4i d\u1ee5c m\u1eadt kh\u1ea9u 1. C\u1ea5u h\u00ecnh image cho qu\u00e1 tr\u00ecnh recuse \u00b6 Trong qu\u00e1 tr\u00ecnh boot th\u00ec instance disk v\u00e0 recuse disk c\u00f3 th\u1ec3 tr\u00f9ng UUID , v\u00ec th\u1ebf trong 1 m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p th\u00ec instance \u0111\u00e3 v\u00e0o mode rescue nh\u01b0ng v\u1eabn boot t\u1eeb local disk Li\u1ec7t k\u00ea danh s\u00e1ch image [root@controller ~]# openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81 | centos | active | | 8bc5ff78-118b-435a-9611-e6a99d9f6b1c | cirros | active | +--------------------------------------+--------+--------+ Li\u1ec7t k\u00ea danh s\u00e1ch instance [root@controller ~]# nova list +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | a67030b1-31b0-4ca9-8911-5cca45f8b779 | centos | ACTIVE | - | Running | net_ex=192.168.30.143 | | 0ad7db51-aad6-4058-b87d-45f69a836319 | centos2 | ACTIVE | - | Running | net_ex=192.168.30.144 | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ Rescue instance centos2 [root@controller ~]# nova rescue --image centos centos2 +-----------+--------------+ | Property | Value | +-----------+--------------+ | adminPass | 3f654N7iy7ss | +-----------+--------------+ [root@controller ~]# nova list +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | a67030b1-31b0-4ca9-8911-5cca45f8b779 | centos | ACTIVE | - | Running | net_ex=192.168.30.143 | | 0ad7db51-aad6-4058-b87d-45f69a836319 | centos2 | RESCUE | - | Running | net_ex=192.168.30.144 | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ Sau \u0111\u00f3 SSH v\u00e0o instance ( qu\u00e1 tr\u00ecnh c\u00f3 th\u1ec3 timeout 30s ) [root@controller ~]# ssh root@192.168.30.144 root@192.168.30.144's password: Last login: Mon Nov 26 01:43:18 2018 from 192.168.30.130 [root@centos2 ~]# Mount","title":"1. Nova-rescue"},{"location":"Openstack_Research/Advance/9. Rescue-instance/#1_nova-rescue","text":"OPS cung c\u1ea5p ch\u1ee9c n\u0103ng \u0111\u1ec3 rescue c\u00e1c instnace trong c\u00e1c tr\u01b0\u1eddng h\u1ee3p h\u1ecfng h\u00f3c, m\u1ea5t m\u00e1t filesystem, m\u1ea5t SSH key, c\u1ea5u h\u00ecnh network b\u1ecb sai ho\u1eb7c d\u00f9ng \u0111\u1ec3 kh\u00f4i d\u1ee5c m\u1eadt kh\u1ea9u","title":"1. Nova-rescue"},{"location":"Openstack_Research/Advance/9. Rescue-instance/#1_cau_hinh_image_cho_qua_trinh_recuse","text":"Trong qu\u00e1 tr\u00ecnh boot th\u00ec instance disk v\u00e0 recuse disk c\u00f3 th\u1ec3 tr\u00f9ng UUID , v\u00ec th\u1ebf trong 1 m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p th\u00ec instance \u0111\u00e3 v\u00e0o mode rescue nh\u01b0ng v\u1eabn boot t\u1eeb local disk Li\u1ec7t k\u00ea danh s\u00e1ch image [root@controller ~]# openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81 | centos | active | | 8bc5ff78-118b-435a-9611-e6a99d9f6b1c | cirros | active | +--------------------------------------+--------+--------+ Li\u1ec7t k\u00ea danh s\u00e1ch instance [root@controller ~]# nova list +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | a67030b1-31b0-4ca9-8911-5cca45f8b779 | centos | ACTIVE | - | Running | net_ex=192.168.30.143 | | 0ad7db51-aad6-4058-b87d-45f69a836319 | centos2 | ACTIVE | - | Running | net_ex=192.168.30.144 | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ Rescue instance centos2 [root@controller ~]# nova rescue --image centos centos2 +-----------+--------------+ | Property | Value | +-----------+--------------+ | adminPass | 3f654N7iy7ss | +-----------+--------------+ [root@controller ~]# nova list +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ | a67030b1-31b0-4ca9-8911-5cca45f8b779 | centos | ACTIVE | - | Running | net_ex=192.168.30.143 | | 0ad7db51-aad6-4058-b87d-45f69a836319 | centos2 | RESCUE | - | Running | net_ex=192.168.30.144 | +--------------------------------------+---------+--------+------------+-------------+-----------------------+ Sau \u0111\u00f3 SSH v\u00e0o instance ( qu\u00e1 tr\u00ecnh c\u00f3 th\u1ec3 timeout 30s ) [root@controller ~]# ssh root@192.168.30.144 root@192.168.30.144's password: Last login: Mon Nov 26 01:43:18 2018 from 192.168.30.130 [root@centos2 ~]# Mount","title":"1. C\u1ea5u h\u00ecnh image cho qu\u00e1 tr\u00ecnh recuse"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/","text":"Barbican trong Openstack \u00b6 1. Barbian \u00b6 Barbican - OpenStack Key Manager service l\u00e0 m\u1ed9t REST API \u0111\u1ec3 l\u01b0u tr\u1eef , ph\u00e2n ph\u1ed1i v\u00e0 qu\u1ea3n l\u00fd c\u00e1c v\u1ea5n \u0111\u1ec1 li\u00ean quan \u0111\u1ebfn b\u1ea3o m\u1eadt nh\u01b0 l\u00e0 m\u1eadt kh\u1ea9u, encrypt key, v\u00e0 X.509 Certificates. C\u0169ng nh\u01b0 c\u00e1c lo\u1ea1i key Symmetric Keys, Asymmetric Keys, Certificates and raw binary data 2. C\u00e1c thu\u1eadt ng\u1eef m\u1edf \u0111\u1ea7u \u00b6 Key Manager Service l\u00e0 d\u1ecbch v\u1ee5 l\u01b0u tr\u1eef c\u00e1c n\u1ed9i dung nh\u1eady c\u1ea3m m\u1eb7c \u0111\u1ecbnh cho OpenStack. 2.1 : Access Control \u00b6 Role Based Access Control ( RBAC ) \u00b6 Gi\u1ed1ng nh\u01b0 c\u00e1c service kh\u00e1c, Key Manager h\u1ed7 tr\u1ee3 b\u1ea3o v\u1ec7 API c\u1ee7a n\u00f3 b\u1edfi c\u00e1c rule \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong policy file . Key manager service l\u01b0u tr\u1eef c\u00e1c policy d\u01b0\u1edbi d\u1ea1ng JSON format t\u1ea1i /etc/barbican/policy.json C\u00e1c Policy m\u1eb7c \u0111\u1ecbnh \u00b6 Policy trong Openstack r\u1ea5t linh ho\u1ea1t v\u00e0 cho ph\u00e9p t\u00f9y ch\u1ecdn c\u00e1c policy cho ph\u00f9 h\u1ee3p v\u1edbi m\u1ed7i m\u00f4i tr\u01b0\u1eddng cloud. . Trong m\u1eb7c \u0111\u1ecbnh \u1edf policy.json, Key Manager x\u00e2y d\u1ef1ng c\u00e1c policy s\u1eb5n \u0111\u1ec3 ph\u00f9 h\u1ee3p nh\u1ea5t c\u00f3 th\u1ec3 v\u1edbi t\u1ea5t c\u1ea3 m\u00f4i tr\u01b0\u1eddng cloud key:manager:service-admin : Cloud administrator c\u00f3 quy\u1ec1n qu\u1ea3n l\u00fd Keymanager,. Ng\u01b0\u1eddi d\u00f9ng n\u00e0y c\u00f3 th\u1ec3 qu\u1ea3n l\u00fd c\u00e1c API , project v\u00e0 quota admin : Project administrator , ng\u01b0\u1eddi d\u00f9ng n\u00e0y c\u00f3 \u0111\u1ea7y \u0111\u1ee7 quy\u1ec1n \u0111\u1ec3 tham chi\u1ebfu t\u1edbi c\u00e1c t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c s\u1eed h\u1eefu b\u1edfi t\u00e0i nguy\u00ean . \u0110\u1ecdc access v\u1edbi admin scope creator : ng\u01b0\u1eddi d\u00f9ng v\u1edbi quy\u1ec1n n\u00e0y \u0111\u01b0\u1ee3c cho ph\u00e9p kh\u1edfi t\u1ea1o m\u1ed9t t\u00e0i nguy\u00ean v\u1edbi v\u00e0 ch\u1ec9 c\u00f3 th\u1ec3 x\u00f3a \u0111\u01b0\u1ee3c t\u00e0i nguy\u00ean ng\u01b0\u1eddi \u0111\u00f3 t\u1ea1o ra. User kh\u00f4ng th\u1ec3 x\u00f3a \u0111\u01b0\u1ee3c t\u00e0i nguy\u00ean c\u1ee7a user kh\u00e1c trong c\u00f9ng m\u1ed9t project. . Ng\u01b0\u1eddi d\u00f9ng \u0111\u1ea7y \u0111\u1ee7 quy\u1ec1n \u0111\u1ec3 tham chi\u1ebfu t\u1edbi c\u00e1c t\u00e0i nguy\u00ean trong project. ( * ) observer : ng\u01b0\u1eddi d\u00f9ng v\u1edbi quy\u1ec1n n\u00e0y \u0111\u01b0\u1ee3c truy c\u1eadp c\u00e1c t\u00e0i nguy\u00ean c\u00f3 s\u1eb5n nh\u01b0ng kh\u00f4ng \u0111\u01b0\u1ee3c upload t\u00e0i nguy\u00ean m\u1edbi v\u00e0 x\u00f3a c\u00e1c t\u00e0i nguy\u00ean c\u0169 audit : ng\u01b0\u1eddi d\u00f9ng n\u00e0y ch\u1ec9 c\u00f3 quy\u1ec1n tham chi\u1ebfu v\u00e0o metadata. Kh\u00f4ng c\u00f3 quy\u1ec1n decrypt c\u00e1c kh\u00f3a b\u1ea3o m\u1eadt 2.2 Barbican Service Management Utility \u00b6 Barbican-manager : l\u00e0 m\u1ed9t c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 qu\u1ea3n l\u00fd database trong barbican . v\u00e0 Hardware Secure Module ( HSM ) plugin device. C\u00e1c tr\u01b0\u1eddng h\u1ee3p s\u1eed d\u1ee5ng bao g\u1ed3m migrate seceret database ho\u1eb7c t\u1ea1o Kh\u00f3a m\u00e3 h\u00f3a kh\u00f3a ch\u00ednh (MKEK) trong HSM. Barbian bao g\u1ed3m barbican-api service cung c\u1ea5p m\u1ed9t giao di\u1ec7n API \u0111\u1ec3 h\u1ed7 tr\u1ee3 qu\u1ea3n l\u00fd v\u00e0 ph\u00e2n ph\u1ed1i c\u00e1c kh\u00f3a b\u1ea3o m\u1eadt Tham kh\u1ea3o th\u00eam c\u00e1c command t\u1ea1i \u0111\u00e2y 2.3 Database Cleaning \u00b6 C\u00e1c danh m\u1ee5c trong Barican DB c\u00f3 th\u1ec3 l\u1edbn theo l\u1eddi gian v\u00ec v\u1eady c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng clean command \u0111\u1ec3 x\u00f3a c\u00e1c database ho\u1eb7c crontab \u0111\u1ec3 x\u00f3a theo \u0111\u1ecbnh k\u1ef3 : C\u00e1c command \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng : barbican-manage db clean : m\u1eb7c \u0111\u1ecbnh keymanager s\u1ebd x\u00f3a d\u1eef li\u1ec7u 90 ng\u00e0y g\u1ea7n nh\u1ea5t `barbican-manage db clean --clean-unassociated-projects` ( `-p` ) `barbican-manage db clean --clean-unassociated-projects` ( `-p` ) : x\u00f3a c\u00e1c project hi\u1ec7n kh\u00f4ng c\u00f3 t\u00e0i nguy\u00ean n\u00e0o \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o barbican-manage db clean --soft-delete-expired-secrets ( -e ) : x\u00f3a c\u00e1c key \u0111\u00e3 h\u1ebft h\u1ea1n S\u1eed d\u1ee5ng Crontab : echo \"\"00 03 01 * * barbican-manage db clean -m 30\" | crontab - S\u1eed d\u1ee5ng x\u00f3a d\u1eef li\u1ec7u trong 30 ng\u00e0y g\u1ea7n nh\u1ea5t l\u00fac 3h s\u00e1ng m\u1ed7i th\u00e1ng 3. C\u00e0i \u0111\u1eb7t Barbican \u00b6 3.1. C\u1ea5u h\u00ecnh v\u00e0 c\u00e0i \u0111\u1eb7t ban \u0111\u1ea7u \u00b6 Kh\u1edfi t\u1ea1o DB mysql -u root -p123@123Aa <<EOF CREATE DATABASE barbican; GRANT ALL PRIVILEGES ON barbican.* TO 'barbican'@'localhost' \\ IDENTIFIED BY 'barbican_123'; GRANT ALL PRIVILEGES ON barbican.* TO 'barbican'@'%' \\ IDENTIFIED BY 'barbican_123'; EOF Kh\u1edfi t\u1ea1o barbican user ,g\u1eafn quy\u1ec1n v\u00e0 service openstack user create --domain default --password barbican_123 barbican openstack role add --project service --user barbican admin openstack role create creator openstack role add --project service --user barbican creator openstack service create --name barbican --description \"Key Manager\" key-manager Kh\u1edfi t\u1ea1o c\u00e1c Endpoint openstack endpoint create --region RegionOne \\ key-manager public http://controller:9311 openstack endpoint create --region RegionOne \\ key-manager internal http://controller:9311 openstack endpoint create --region RegionOne \\ key-manager admin http://controller:9311 C\u00e0i \u0111\u1eb7t package yum install -y openstack-barbican-api wget https://pypi.python.org/packages/5e/5d/4e4364bb8b2a3e8d6c41ec21095aae3ac3396a6fa6983ea7f5551e929661/pyasn1-0.4.2-py2.4.egg#md5=84cf09817d8eb3b8955c5c558abd7ba7 easy_install pyasn1-0.4.2-py2.4.egg ## do goi pyasn1 version 1.0 dang bi loi nen cai dat phien ban khac Backup v\u00e0 kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh m\u1edbi cp -p /etc/barbican/barbican.conf /etc/barbican/barbican.conf.bak cat <<EOF > /etc/barbican/barbican.conf [DEFAULT] sql_connection = mysql+pymysql://barbican:barbican_123@controller/barbican transport_url = rabbit://openstack:rabbitmq_123@controller debug = True log_file = /var/log/barbican/api.log bind_host = 0.0.0.0 bind_port = 9311 host_href = http://192.168.30.130:9311 log_file = /var/log/barbican/api.log [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = barbican password = barbican_123 EOF \u0110\u1ed3ng b\u1ed9 Database su -s /bin/sh -c \"barbican-manage db upgrade\" barbican Kh\u1edfi t\u1ea1o WSGIApplication cho Barbican ( API Interface ) cat <<EOF > /etc/httpd/conf.d/wsgi-barbican.conf <VirtualHost [::1]:9311> ServerName controller ## Logging ErrorLog \"/var/log/httpd/barbican_wsgi_main_error_ssl.log\" LogLevel debug ServerSignature Off CustomLog \"/var/log/httpd/barbican_wsgi_main_access_ssl.log\" combined WSGIApplicationGroup %{GLOBAL} WSGIDaemonProcess barbican-api display-name=barbican-api group=barbican processes=2 threads=8 user=barbican WSGIProcessGroup barbican-api WSGIScriptAlias / \"/usr/lib/python2.7/site-packages/barbican/api/app.wsgi\" WSGIPassAuthorization On </VirtualHost> EOF C\u1ea5u h\u00ecnh Firewall firewall-cmd --add-port=9311/tcp --permanent firewall-cmd --reload Kh\u1edfi \u0111\u1ed9ng l\u1ea1i service systemctl start openstack-barbican-api systemctl enable httpd openstack-barbican-api systemctl restart httpd 3.2 . C\u1ea5u h\u00ecnh Backend \u00b6 M\u1eb7c \u0111\u1ecbnh Barbican s\u1ebd l\u01b0u c\u00e1c secert tr\u00ean t\u1eadp tin. C\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c backend kh\u00e1c , tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y C\u00e1c lo\u1ea1i plugin n\u00e0y l\u01b0u tr\u1eef an to\u00e0n d\u01b0\u1edbi d\u1ea1ng \u0111\u01b0\u1ee3c m\u00e3 h\u00f3a trong c\u01a1 s\u1edf d\u1eef li\u1ec7u c\u1ee7a Barbican. Plugin \u0111\u01b0\u1ee3c g\u1ecdi \u0111\u1ec3 m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3. C\u1ea5u h\u00ecnh Simple Crypto Plugin \u00b6 cat <<EOF >> /etc/barbican/barbican.conf [secretstore] namespace = barbican.secretstore.plugin enabled_secretstore_plugins = store_crypto [crypto] enabled_crypto_plugins = simple_crypto [simple_crypto_plugin] # the kek should be a 32-byte value which is base64 encoded kek = 'YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=' EOF Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart openstack-barbican-api Note : \u00b6 Ngo\u00e0i c\u1ea5u h\u00ecnh secert storage ta c\u00f2n c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh : Using Keystone Middleware with Barbican Using Audit Middleware with Barbican Tham kh\u1ea3o th\u00eam : https://docs.openstack.org/barbican/queens/configuration/index.html 4. T\u00e0i li\u1ec7u tham kh\u1ea3o \u00b6 https://docs.openstack.org/barbican/queens/configuration/index.html END .","title":"1. Intro Setup"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#barbican_trong_openstack","text":"","title":"Barbican trong Openstack"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#1_barbian","text":"Barbican - OpenStack Key Manager service l\u00e0 m\u1ed9t REST API \u0111\u1ec3 l\u01b0u tr\u1eef , ph\u00e2n ph\u1ed1i v\u00e0 qu\u1ea3n l\u00fd c\u00e1c v\u1ea5n \u0111\u1ec1 li\u00ean quan \u0111\u1ebfn b\u1ea3o m\u1eadt nh\u01b0 l\u00e0 m\u1eadt kh\u1ea9u, encrypt key, v\u00e0 X.509 Certificates. C\u0169ng nh\u01b0 c\u00e1c lo\u1ea1i key Symmetric Keys, Asymmetric Keys, Certificates and raw binary data","title":"1. Barbian"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#2_cac_thuat_ngu_mo_au","text":"Key Manager Service l\u00e0 d\u1ecbch v\u1ee5 l\u01b0u tr\u1eef c\u00e1c n\u1ed9i dung nh\u1eady c\u1ea3m m\u1eb7c \u0111\u1ecbnh cho OpenStack.","title":"2. C\u00e1c thu\u1eadt ng\u1eef m\u1edf \u0111\u1ea7u"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#21_access_control","text":"","title":"2.1 : Access Control"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#role_based_access_control_rbac","text":"Gi\u1ed1ng nh\u01b0 c\u00e1c service kh\u00e1c, Key Manager h\u1ed7 tr\u1ee3 b\u1ea3o v\u1ec7 API c\u1ee7a n\u00f3 b\u1edfi c\u00e1c rule \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong policy file . Key manager service l\u01b0u tr\u1eef c\u00e1c policy d\u01b0\u1edbi d\u1ea1ng JSON format t\u1ea1i /etc/barbican/policy.json","title":"Role Based Access Control ( RBAC )"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#cac_policy_mac_inh","text":"Policy trong Openstack r\u1ea5t linh ho\u1ea1t v\u00e0 cho ph\u00e9p t\u00f9y ch\u1ecdn c\u00e1c policy cho ph\u00f9 h\u1ee3p v\u1edbi m\u1ed7i m\u00f4i tr\u01b0\u1eddng cloud. . Trong m\u1eb7c \u0111\u1ecbnh \u1edf policy.json, Key Manager x\u00e2y d\u1ef1ng c\u00e1c policy s\u1eb5n \u0111\u1ec3 ph\u00f9 h\u1ee3p nh\u1ea5t c\u00f3 th\u1ec3 v\u1edbi t\u1ea5t c\u1ea3 m\u00f4i tr\u01b0\u1eddng cloud key:manager:service-admin : Cloud administrator c\u00f3 quy\u1ec1n qu\u1ea3n l\u00fd Keymanager,. Ng\u01b0\u1eddi d\u00f9ng n\u00e0y c\u00f3 th\u1ec3 qu\u1ea3n l\u00fd c\u00e1c API , project v\u00e0 quota admin : Project administrator , ng\u01b0\u1eddi d\u00f9ng n\u00e0y c\u00f3 \u0111\u1ea7y \u0111\u1ee7 quy\u1ec1n \u0111\u1ec3 tham chi\u1ebfu t\u1edbi c\u00e1c t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c s\u1eed h\u1eefu b\u1edfi t\u00e0i nguy\u00ean . \u0110\u1ecdc access v\u1edbi admin scope creator : ng\u01b0\u1eddi d\u00f9ng v\u1edbi quy\u1ec1n n\u00e0y \u0111\u01b0\u1ee3c cho ph\u00e9p kh\u1edfi t\u1ea1o m\u1ed9t t\u00e0i nguy\u00ean v\u1edbi v\u00e0 ch\u1ec9 c\u00f3 th\u1ec3 x\u00f3a \u0111\u01b0\u1ee3c t\u00e0i nguy\u00ean ng\u01b0\u1eddi \u0111\u00f3 t\u1ea1o ra. User kh\u00f4ng th\u1ec3 x\u00f3a \u0111\u01b0\u1ee3c t\u00e0i nguy\u00ean c\u1ee7a user kh\u00e1c trong c\u00f9ng m\u1ed9t project. . Ng\u01b0\u1eddi d\u00f9ng \u0111\u1ea7y \u0111\u1ee7 quy\u1ec1n \u0111\u1ec3 tham chi\u1ebfu t\u1edbi c\u00e1c t\u00e0i nguy\u00ean trong project. ( * ) observer : ng\u01b0\u1eddi d\u00f9ng v\u1edbi quy\u1ec1n n\u00e0y \u0111\u01b0\u1ee3c truy c\u1eadp c\u00e1c t\u00e0i nguy\u00ean c\u00f3 s\u1eb5n nh\u01b0ng kh\u00f4ng \u0111\u01b0\u1ee3c upload t\u00e0i nguy\u00ean m\u1edbi v\u00e0 x\u00f3a c\u00e1c t\u00e0i nguy\u00ean c\u0169 audit : ng\u01b0\u1eddi d\u00f9ng n\u00e0y ch\u1ec9 c\u00f3 quy\u1ec1n tham chi\u1ebfu v\u00e0o metadata. Kh\u00f4ng c\u00f3 quy\u1ec1n decrypt c\u00e1c kh\u00f3a b\u1ea3o m\u1eadt","title":"C\u00e1c Policy m\u1eb7c \u0111\u1ecbnh"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#22_barbican_service_management_utility","text":"Barbican-manager : l\u00e0 m\u1ed9t c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 qu\u1ea3n l\u00fd database trong barbican . v\u00e0 Hardware Secure Module ( HSM ) plugin device. C\u00e1c tr\u01b0\u1eddng h\u1ee3p s\u1eed d\u1ee5ng bao g\u1ed3m migrate seceret database ho\u1eb7c t\u1ea1o Kh\u00f3a m\u00e3 h\u00f3a kh\u00f3a ch\u00ednh (MKEK) trong HSM. Barbian bao g\u1ed3m barbican-api service cung c\u1ea5p m\u1ed9t giao di\u1ec7n API \u0111\u1ec3 h\u1ed7 tr\u1ee3 qu\u1ea3n l\u00fd v\u00e0 ph\u00e2n ph\u1ed1i c\u00e1c kh\u00f3a b\u1ea3o m\u1eadt Tham kh\u1ea3o th\u00eam c\u00e1c command t\u1ea1i \u0111\u00e2y","title":"2.2 Barbican Service Management Utility"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#23_database_cleaning","text":"C\u00e1c danh m\u1ee5c trong Barican DB c\u00f3 th\u1ec3 l\u1edbn theo l\u1eddi gian v\u00ec v\u1eady c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng clean command \u0111\u1ec3 x\u00f3a c\u00e1c database ho\u1eb7c crontab \u0111\u1ec3 x\u00f3a theo \u0111\u1ecbnh k\u1ef3 : C\u00e1c command \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng : barbican-manage db clean : m\u1eb7c \u0111\u1ecbnh keymanager s\u1ebd x\u00f3a d\u1eef li\u1ec7u 90 ng\u00e0y g\u1ea7n nh\u1ea5t `barbican-manage db clean --clean-unassociated-projects` ( `-p` ) `barbican-manage db clean --clean-unassociated-projects` ( `-p` ) : x\u00f3a c\u00e1c project hi\u1ec7n kh\u00f4ng c\u00f3 t\u00e0i nguy\u00ean n\u00e0o \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o barbican-manage db clean --soft-delete-expired-secrets ( -e ) : x\u00f3a c\u00e1c key \u0111\u00e3 h\u1ebft h\u1ea1n S\u1eed d\u1ee5ng Crontab : echo \"\"00 03 01 * * barbican-manage db clean -m 30\" | crontab - S\u1eed d\u1ee5ng x\u00f3a d\u1eef li\u1ec7u trong 30 ng\u00e0y g\u1ea7n nh\u1ea5t l\u00fac 3h s\u00e1ng m\u1ed7i th\u00e1ng","title":"2.3 Database Cleaning"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#3_cai_at_barbican","text":"","title":"3. C\u00e0i \u0111\u1eb7t Barbican"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#31_cau_hinh_va_cai_at_ban_au","text":"Kh\u1edfi t\u1ea1o DB mysql -u root -p123@123Aa <<EOF CREATE DATABASE barbican; GRANT ALL PRIVILEGES ON barbican.* TO 'barbican'@'localhost' \\ IDENTIFIED BY 'barbican_123'; GRANT ALL PRIVILEGES ON barbican.* TO 'barbican'@'%' \\ IDENTIFIED BY 'barbican_123'; EOF Kh\u1edfi t\u1ea1o barbican user ,g\u1eafn quy\u1ec1n v\u00e0 service openstack user create --domain default --password barbican_123 barbican openstack role add --project service --user barbican admin openstack role create creator openstack role add --project service --user barbican creator openstack service create --name barbican --description \"Key Manager\" key-manager Kh\u1edfi t\u1ea1o c\u00e1c Endpoint openstack endpoint create --region RegionOne \\ key-manager public http://controller:9311 openstack endpoint create --region RegionOne \\ key-manager internal http://controller:9311 openstack endpoint create --region RegionOne \\ key-manager admin http://controller:9311 C\u00e0i \u0111\u1eb7t package yum install -y openstack-barbican-api wget https://pypi.python.org/packages/5e/5d/4e4364bb8b2a3e8d6c41ec21095aae3ac3396a6fa6983ea7f5551e929661/pyasn1-0.4.2-py2.4.egg#md5=84cf09817d8eb3b8955c5c558abd7ba7 easy_install pyasn1-0.4.2-py2.4.egg ## do goi pyasn1 version 1.0 dang bi loi nen cai dat phien ban khac Backup v\u00e0 kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh m\u1edbi cp -p /etc/barbican/barbican.conf /etc/barbican/barbican.conf.bak cat <<EOF > /etc/barbican/barbican.conf [DEFAULT] sql_connection = mysql+pymysql://barbican:barbican_123@controller/barbican transport_url = rabbit://openstack:rabbitmq_123@controller debug = True log_file = /var/log/barbican/api.log bind_host = 0.0.0.0 bind_port = 9311 host_href = http://192.168.30.130:9311 log_file = /var/log/barbican/api.log [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = barbican password = barbican_123 EOF \u0110\u1ed3ng b\u1ed9 Database su -s /bin/sh -c \"barbican-manage db upgrade\" barbican Kh\u1edfi t\u1ea1o WSGIApplication cho Barbican ( API Interface ) cat <<EOF > /etc/httpd/conf.d/wsgi-barbican.conf <VirtualHost [::1]:9311> ServerName controller ## Logging ErrorLog \"/var/log/httpd/barbican_wsgi_main_error_ssl.log\" LogLevel debug ServerSignature Off CustomLog \"/var/log/httpd/barbican_wsgi_main_access_ssl.log\" combined WSGIApplicationGroup %{GLOBAL} WSGIDaemonProcess barbican-api display-name=barbican-api group=barbican processes=2 threads=8 user=barbican WSGIProcessGroup barbican-api WSGIScriptAlias / \"/usr/lib/python2.7/site-packages/barbican/api/app.wsgi\" WSGIPassAuthorization On </VirtualHost> EOF C\u1ea5u h\u00ecnh Firewall firewall-cmd --add-port=9311/tcp --permanent firewall-cmd --reload Kh\u1edfi \u0111\u1ed9ng l\u1ea1i service systemctl start openstack-barbican-api systemctl enable httpd openstack-barbican-api systemctl restart httpd","title":"3.1. C\u1ea5u h\u00ecnh v\u00e0 c\u00e0i \u0111\u1eb7t ban \u0111\u1ea7u"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#32_cau_hinh_backend","text":"M\u1eb7c \u0111\u1ecbnh Barbican s\u1ebd l\u01b0u c\u00e1c secert tr\u00ean t\u1eadp tin. C\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c backend kh\u00e1c , tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y C\u00e1c lo\u1ea1i plugin n\u00e0y l\u01b0u tr\u1eef an to\u00e0n d\u01b0\u1edbi d\u1ea1ng \u0111\u01b0\u1ee3c m\u00e3 h\u00f3a trong c\u01a1 s\u1edf d\u1eef li\u1ec7u c\u1ee7a Barbican. Plugin \u0111\u01b0\u1ee3c g\u1ecdi \u0111\u1ec3 m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3. C\u1ea5u h\u00ecnh Simple Crypto Plugin \u00b6 cat <<EOF >> /etc/barbican/barbican.conf [secretstore] namespace = barbican.secretstore.plugin enabled_secretstore_plugins = store_crypto [crypto] enabled_crypto_plugins = simple_crypto [simple_crypto_plugin] # the kek should be a 32-byte value which is base64 encoded kek = 'YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=' EOF Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart openstack-barbican-api","title":"3.2 . C\u1ea5u h\u00ecnh Backend"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#note","text":"Ngo\u00e0i c\u1ea5u h\u00ecnh secert storage ta c\u00f2n c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh : Using Keystone Middleware with Barbican Using Audit Middleware with Barbican Tham kh\u1ea3o th\u00eam : https://docs.openstack.org/barbican/queens/configuration/index.html","title":"Note :"},{"location":"Openstack_Research/Barbican/1. Intro-Setup/#4_tai_lieu_tham_khao","text":"https://docs.openstack.org/barbican/queens/configuration/index.html END .","title":"4. T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"Openstack_Research/Barbican/2. Command/","text":"Use Barbican \u00b6 1. Python-OpenstackClient \u00b6 Kh\u1edfi t\u1ea1o 1 key m\u1edbi [root@controller ~]# openstack secret store --name secret01 --payload secretkey +---------------+-----------------------------------------------------------------------+ | Field | Value | +---------------+-----------------------------------------------------------------------+ | Secret href | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | | Name | secret01 | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+-----------------------------------------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch secret [root@controller ~]# openstack secret list +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | secret01 | 2019-01-07T04:31:34+00:00 | ACTIVE | {u'default': u'text/plain'} | aes | 256 | opaque | cbc | None | +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ L\u1ea5y metadata t\u1eeb key [root@controller ~]# openstack secret get http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 +---------------+-----------------------------------------------------------------------+ | Field | Value | +---------------+-----------------------------------------------------------------------+ | Secret href | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | | Name | secret01 | | Created | 2019-01-07T04:31:34+00:00 | | Status | ACTIVE | | Content types | {u'default': u'text/plain'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+-----------------------------------------------------------------------+ X\u00f3a m\u1ed9t key openstack secret delete http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 2. Seceret API \u00b6 Secret resouce l\u00e0 tr\u00e1i tim trong barbican service . N\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng truy c\u1eadp v\u00e0o c\u00e1c secret /key \u0111\u01b0\u1ee3c l\u01b0u trong system M\u1ed9t secret l\u00e0 m\u1ed9t th\u1ef1c th\u1ec3 \u0111\u01b0\u1ee3c l\u01b0u trong barbican. M\u1ed9t secret c\u00f3 th\u1ec3 l\u00e0 m\u1ecdi th\u1ee9 nh\u01b0ng trong \u0111a s\u1ed1 tr\u01b0\u1eddng h\u1ee3p l\u00e0 m\u1ed9t key Private Key Certificate Password SSH Keys - Kh\u1edfi t\u1ea1o secret \u0111\u01a1n gi\u1ea3n \u00b6 S\u1eed d\u1ee5ng CURL g\u1eedi request post lab@compute:~$ curl -X POST -H \"content-type:application/json\" -H \"X-Auth-Token: $token\" -d '{\"payload\": \"bWVkaXRlY2gyMDE5Cg==\", \"payload_content_type\": \"text/plain\"}' http://192.168.30.130:9311/v1/secrets {\"secret_ref\": \"http://192.168.30.130:9311/v1/secrets/2c7509c3-5644-440b-b960-8002bd124a1b\"} - Kh\u1edfi t\u1ea1o Secret sau \u0111\u00f3 upload data \u00b6 S\u1eed d\u1ee5ng CURL \u0111\u1ec3 kh\u1edfi t\u1ea1o secret lab@compute:~$ curl -X POST -H \"content-type:application/json\" -H \"X-Auth-Token: $token\" -d '{}' http://192.168.30.130:9311/v1/secrets {\"secret_ref\": \"http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491\"} Update secret lab@compute:~$ curl -X PUT -H \"content-type:text/plain\" -H \"X-Auth-Token: $token\" \\ > -d 'meditech2019' \\ > http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 Ki\u1ec3m th\u1eed secret v\u1eeba update nguyenhungsync@compute:~$ curl -X GET -H \"Accept: text/plain\" -H \"X-Auth-Token: $token\" \\ > http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 meditech2019 X\u00f3a secret curl -X DELETE -H \"X-Auth-Token: $TOKEN\" \\ http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 Tham kh\u1ea3o th\u00eam c\u00e1c secret type , payload content type https://developer.openstack.org/api-guide/key-manager/secrets.html","title":"2. Command"},{"location":"Openstack_Research/Barbican/2. Command/#use_barbican","text":"","title":"Use Barbican"},{"location":"Openstack_Research/Barbican/2. Command/#1_python-openstackclient","text":"Kh\u1edfi t\u1ea1o 1 key m\u1edbi [root@controller ~]# openstack secret store --name secret01 --payload secretkey +---------------+-----------------------------------------------------------------------+ | Field | Value | +---------------+-----------------------------------------------------------------------+ | Secret href | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | | Name | secret01 | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+-----------------------------------------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch secret [root@controller ~]# openstack secret list +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | secret01 | 2019-01-07T04:31:34+00:00 | ACTIVE | {u'default': u'text/plain'} | aes | 256 | opaque | cbc | None | +-----------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------+-----------+------------+-------------+------+------------+ L\u1ea5y metadata t\u1eeb key [root@controller ~]# openstack secret get http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 +---------------+-----------------------------------------------------------------------+ | Field | Value | +---------------+-----------------------------------------------------------------------+ | Secret href | http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188 | | Name | secret01 | | Created | 2019-01-07T04:31:34+00:00 | | Status | ACTIVE | | Content types | {u'default': u'text/plain'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+-----------------------------------------------------------------------+ X\u00f3a m\u1ed9t key openstack secret delete http://localhost:9311/v1/secrets/e6c254c9-31b3-4520-9ba1-e85804b8c188","title":"1. Python-OpenstackClient"},{"location":"Openstack_Research/Barbican/2. Command/#2_seceret_api","text":"Secret resouce l\u00e0 tr\u00e1i tim trong barbican service . N\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng truy c\u1eadp v\u00e0o c\u00e1c secret /key \u0111\u01b0\u1ee3c l\u01b0u trong system M\u1ed9t secret l\u00e0 m\u1ed9t th\u1ef1c th\u1ec3 \u0111\u01b0\u1ee3c l\u01b0u trong barbican. M\u1ed9t secret c\u00f3 th\u1ec3 l\u00e0 m\u1ecdi th\u1ee9 nh\u01b0ng trong \u0111a s\u1ed1 tr\u01b0\u1eddng h\u1ee3p l\u00e0 m\u1ed9t key Private Key Certificate Password SSH Keys","title":"2. Seceret API"},{"location":"Openstack_Research/Barbican/2. Command/#-_khoi_tao_secret_on_gian","text":"S\u1eed d\u1ee5ng CURL g\u1eedi request post lab@compute:~$ curl -X POST -H \"content-type:application/json\" -H \"X-Auth-Token: $token\" -d '{\"payload\": \"bWVkaXRlY2gyMDE5Cg==\", \"payload_content_type\": \"text/plain\"}' http://192.168.30.130:9311/v1/secrets {\"secret_ref\": \"http://192.168.30.130:9311/v1/secrets/2c7509c3-5644-440b-b960-8002bd124a1b\"}","title":"- Kh\u1edfi t\u1ea1o secret  \u0111\u01a1n gi\u1ea3n"},{"location":"Openstack_Research/Barbican/2. Command/#-_khoi_tao_secret_sau_o_upload_data","text":"S\u1eed d\u1ee5ng CURL \u0111\u1ec3 kh\u1edfi t\u1ea1o secret lab@compute:~$ curl -X POST -H \"content-type:application/json\" -H \"X-Auth-Token: $token\" -d '{}' http://192.168.30.130:9311/v1/secrets {\"secret_ref\": \"http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491\"} Update secret lab@compute:~$ curl -X PUT -H \"content-type:text/plain\" -H \"X-Auth-Token: $token\" \\ > -d 'meditech2019' \\ > http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 Ki\u1ec3m th\u1eed secret v\u1eeba update nguyenhungsync@compute:~$ curl -X GET -H \"Accept: text/plain\" -H \"X-Auth-Token: $token\" \\ > http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 meditech2019 X\u00f3a secret curl -X DELETE -H \"X-Auth-Token: $TOKEN\" \\ http://192.168.30.130:9311/v1/secrets/632c6d91-212a-4aa0-bcce-eddec64d5491 Tham kh\u1ea3o th\u00eam c\u00e1c secret type , payload content type https://developer.openstack.org/api-guide/key-manager/secrets.html","title":"- Kh\u1edfi t\u1ea1o Secret sau \u0111\u00f3 upload data"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/","text":"OpenStack Block Storage - Cinder \u00b6 1. T\u1ed5ng quan v\u1ec1 Cinder \u00b6 1.1. Kh\u00e1i ni\u1ec7m Cinder \u00b6 Cinder l\u00e0 code-name cho Openstack Block Storage. N\u00f3 \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u1edbi kh\u1ea3 n\u0103ng l\u01b0u tr\u1eef d\u1eef li\u1ec7u m\u00e0 ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng b\u1ecfi Project Compute (NOVA). N\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng th\u00f4ng qua c\u00e1c reference implementation (LVM) ho\u1eb7c c\u00e1c plugin driver d\u00e0nh cho l\u01b0u tr\u1eef. C\u00f3 th\u1ec3 hi\u1ec3u ng\u1eafn g\u1ecdn v\u1ec1 Cinder nh\u01b0 sau : Cinder l\u00e0 \u1ea3o h\u00f3a vi\u1ec7c qu\u1ea3n l\u00fd c\u00e1c thi\u1ebft b\u1ecb Block Storage v\u00e0 cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng m\u1ed9t API \u0111\u00e1p \u1ee9ng \u0111\u01b0\u1ee3c nh\u01b0 c\u1ea7u t\u1ef1 ph\u1ee5c v\u1ee5 c\u0169ng nh\u01b0 y\u00eau c\u1ea7u ti\u00eau th\u1ee5 c\u00e1c t\u00e0i nguy\u00ean \u0111\u00f3 m\u00e0 kh\u00f4ng c\u1ea7n c\u00f3 qu\u00e1 nhi\u1ec1u ki\u1ebfn th\u1ee9c v\u1ec1 l\u01b0u tr\u1eef. 1.2. C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh \u00b6 Cung c\u1ea5p v\u00e0 qu\u1ea3n l\u00fd c\u00e1c t\u00e0i nguy\u00ean l\u01b0u tr\u1eef d\u1ea1ng persistent block storage (volume) cho c\u00e1c m\u00e1y \u1ea3o C\u00e1c volume n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u00e1ch t\u1eeb m\u00e1y \u1ea3o n\u00e0y v\u00e0 g\u00e1n l\u1ea1i v\u00e0o m\u1ed9t m\u00e1y \u1ea3o kh\u00e1c, m\u00e0 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c gi\u1eef nguy\u00ean kh\u00f4ng b\u1ecb thay \u0111\u1ed5i. Hi\u1ec7n t\u1ea1i, m\u1ed9t volume ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u00e1n (attached) v\u00e0 m\u1ed9t m\u00e1y \u1ea3o t\u1ea1i m\u1ed9t th\u1eddi \u0111i\u1ec3m C\u00e1c volume t\u1ed3n t\u1ea1i \u0111\u1ed9c l\u1eadp v\u1edbi c\u00e1c m\u00e1y \u1ea3o (t\u1ee9c l\u00e0 khi m\u00e1y \u1ea3o b\u1ecb x\u00f3a th\u00ec volume kh\u00f4ng b\u1ecb x\u00f3a). Ph\u00e2n chia t\u00e0i nguy\u00ean l\u01b0u tr\u1eef th\u00e0nh c\u00e1c kh\u1ed1i g\u1ecdi l\u00e0 Cinder volume. Cung c\u1ea5p c\u00e1c API nh\u01b0 l\u00e0 t\u1ea1o, x\u00f3a, backup, restore, t\u1ea1o snapshot, clone volume v\u00e0 nhi\u1ec1u h\u01a1n n\u1eefa. Nh\u1eefng API n\u00e0y th\u1ef1c hi\u1ec7n b\u1edfi c\u00e1c backend l\u01b0u tr\u1eef m\u00e0 \u0111\u01b0\u1ee3c cinder h\u1ed7 tr\u1ee3. C\u00e1c ki\u1ebfn tr\u00fac plugin drive cho ph\u00e9p nhi\u1ec1u l\u1ef1a ch\u1ecdn l\u00e0m backend storage. 1.3. L\u1ee3i \u00edch ch\u00ednh \u00b6 Cinder cung c\u1ea5p block storage d\u01b0\u1edbi d\u1ea1ng block as a service Component based architecture : th\u1ef1c hi\u1ec7n m\u1ed9t h\u00e0nh \u0111\u1ed9ng m\u1edbi d\u1ec5 d\u00e0ng Highly available : t\u1ec9 l\u1ec7 % c\u00f4ng vi\u1ec7c \u0111\u01b0\u1ee3c chia nh\u1ecf Fault-Tolerant : c\u00e1c ti\u1ebfn tr\u00ecnh \u0111\u01b0\u1ee3c t\u00e1ch ri\u00eang bi\u1ec7t Recoverable : d\u1ec5 d\u00e0ng ph\u00e1n \u0111o\u00e1n, s\u1eeda l\u1ed7i Open Standards : c\u1ed9ng \u0111\u1ed3ng API m\u1edf 2. Ki\u1ebfn tr\u00fac trong Cinder \u00b6 openstack-cinder-volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi volume cho c\u00e1c m\u00e1y \u1ea3o theo y\u00eau c\u1ea7u . Khi c\u00f3 m\u1ed9t request t\u1eeb sheduler , volume service s\u1ebd t\u1ea1o, ch\u1ec9nh s\u1eeda, x\u00f3a c\u00e1c volume theo y\u00eau c\u1ea7u. M\u1ed9t s\u1ed1 c\u00e1c driver s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi storage provider openstack-cinder-api : tr\u1ea3 l\u1eddi v\u00e0 x\u1eed l\u00fd theo y\u00eau c\u1ea7u, g\u1eedi c\u00e1c tin nh\u1eafn v\u00e0o h\u00e0ng ch\u1edd . Khi c\u00f3 m\u1ed9t request g\u1eedi \u0111\u1ebfn, c\u00e1c API nh\u1edd indentify service \u0111\u1ec3 x\u00e1c th\u1ef1c , sau \u0111\u00f3 g\u1eedi th\u00f4ng \u0111i\u1ec7p \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c block storage. openstack-cinder-backup : cung c\u1ea5p kh\u1ea3 n\u0103ng backup c\u00e1c Storage Voluem sang m\u1ed9t repo kh\u00e1c openstack-cinder-sheduler : g\u1eedi c\u00e1c task v\u00e0o h\u00e0ng ch\u1edd , v\u00e0 x\u00e1c \u0111\u1ecbnh volume server. Sheduler s\u1ebd nh\u1eadn c\u00e1c b\u1ea3n tin t\u1eeb h\u00e0ng ch\u1edd sau \u0111\u00f3 x\u00e1c \u0111\u1ecbnh block storage host s\u1ebd l\u00e0m vi\u1ec7c . Database : l\u01b0u th\u1ea1ng tr\u00e1i c\u00e1c volume RabbitMQ server : cung c\u1ea5p h\u00e0ng ch\u1edd tin nh\u1eafn AMQP, RabbitMQ l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c c\u00e1c Openstack Copoment kh\u00e1c : h\u00e0ng ch\u1edd, ph\u00e2n ph\u1ed1i,, qu\u1ea3n l\u00fd, b\u1ea3o m\u1eadt li\u00ean k\u1ebft2x 3. C\u00e1c th\u00e0nh ph\u1ea7n trong Cinder \u00b6 Back-end storage device : y\u00eau c\u1ea7u m\u1ed9t s\u1ed1 back-end storage service. M\u1eb7c \u0111\u1ecbnh Cinder t\u00edch h\u1ee3p v\u00e0 s\u1eed d\u1ee5ng v\u1edbi LVM, tr\u00ean m\u1ed9t logical volume group c\u00f3 t\u00ean cinder volume . Ngo\u00e0i vi\u1ec7c s\u1eed d\u1ee5ng LVM, tra c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng nhi\u1ec1u drvier kh\u00e1c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi Cinder nh\u01b0 Raid ho\u1eb7c c\u00e1c driver l\u01b0u tr\u1eef kh\u00e1c. Nh\u1eefng back-end driver n\u00e0y c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh block size khi s\u1eed d\u1ee5ng KVM-QEMU l\u00e0m hypersvisor Users and Tenants (Projects) : d\u1ecbch v\u1ee5 Block Storage c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi nhi\u1ec1u kh\u00e1ch h\u00e0ng ho\u1eb7c kh\u00e1ch h\u00e0ng \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y kh\u00e1c nhau (nh\u1eefng tenant tr\u00ean m\u1ed9t h\u1ec7 th\u1ed1ng shared system), s\u1eed d\u1ee5ng g\u00e1n quy\u1ec1n truy c\u1eadp theo role. C\u00e1c role \u0111i\u1ec3u khi\u1ec3n c\u00e1c h\u00e0nh \u0111\u1ed9ng m\u00e0 ng\u01b0\u1eddi d\u00f9ng \u0111\u01b0\u1ee3c ph\u00e9p th\u1ef1c hi\u1ec7n. Trong c\u1ea5u h\u00ecnh m\u1eb7c \u0111\u1ecbnh, h\u1ea7u h\u1ebft c\u00e1c h\u00e0nh \u0111\u1ed9ng kh\u00f4ng y\u00eau c\u1ea7u role c\u1ee5 th\u1ec3, nh\u01b0ng \u0111i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh b\u1edfi qu\u1ea3n tr\u1ecb vi\u00ean h\u1ec7 th\u1ed1ng trong t\u1ec7p policy.json th\u00edch h\u1ee3p \u0111\u1ec3 duy tr\u00ec c\u00e1c quy t\u1eafc. Quy\u1ec1n truy c\u1eadp v\u00e0o m\u1ed9t volume c\u1ee5 th\u1ec3 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi tenant (project), nh\u01b0ng t\u00ean ng\u01b0\u1eddi d\u00f9ng v\u00e0 m\u1eadt kh\u1ea9u \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh cho m\u1ed7i ng\u01b0\u1eddi d\u00f9ng. C\u00e1c c\u1eb7p kh\u00f3a key-pairs cho ph\u00e9p truy c\u1eadp v\u00e0o m\u1ed9t volume \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t cho m\u1ed7i ng\u01b0\u1eddi d\u00f9ng, nh\u01b0ng h\u1ea1n ng\u1ea1ch quotas \u0111\u1ec3 ki\u1ec3m so\u00e1t t\u00e0i nguy\u00ean s\u1eed d\u1ee5ng tr\u00ean c\u00e1c thi\u1ebft b\u1ecb ph\u1ea7n c\u1ee9ng c\u00f3 s\u1eb5n l\u00e0 cho m\u1ed7i tenant. Volume, Snapshots v\u00e0 Backups : Volume : g\u1eafn c\u00e1c blcok storage \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 v\u00e0o c\u00e1c instance, ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t storage th\u1ee9 2 cho c\u00e1c instance ho\u1eb7c nh\u01b0 root filesystem storage \u0111\u1ec3 l\u00e0m boot disk cho instance. C\u00e1c volume l\u00e0 c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef d\u01b0\u1edbi d\u1ea1ng Read/Write \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c compute node s\u1eed d\u1ee5ng iSCSI. Snapshot : m\u1ed9t b\u1ea3n read-only d\u1eef tr\u1eef d\u1eef li\u1ec7u c\u1ee7a volume t\u1ea1o m\u1ed9t th\u1eddi \u0111i\u1ec3m n\u00e0o \u0111\u00f3 . Snapshot c\u00f3 th\u1ec3 kh\u1edfi t\u1ea1o cho m\u1ed9t volume \u0111ang \u1edf tr\u1ea1ng th\u00e1i active n\u1ebfu s\u1eed d\u1ee5ng --force True Backup : b\u1ea3n copy c\u1ee7a m\u1ed9t volume l\u01b0u tr\u1eef tr\u00ean Object Storage ( Swift ) 4. Tham kh\u1ea3o th\u00eam \u00b6 [1] : https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Cinder/docs/Tong_quan_Cinder.md [2] : https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/6/html/Component_Overview/section-blockStorage.html [3] : https://docs.openstack.org/cinder/latest/configuration/block-storage/block-storage-overview.html","title":"OpenStack Block Storage - Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#openstack_block_storage_-_cinder","text":"","title":"OpenStack Block Storage - Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#1_tong_quan_ve_cinder","text":"","title":"1. T\u1ed5ng quan v\u1ec1 Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#11_khai_niem_cinder","text":"Cinder l\u00e0 code-name cho Openstack Block Storage. N\u00f3 \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u1edbi kh\u1ea3 n\u0103ng l\u01b0u tr\u1eef d\u1eef li\u1ec7u m\u00e0 ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng b\u1ecfi Project Compute (NOVA). N\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng th\u00f4ng qua c\u00e1c reference implementation (LVM) ho\u1eb7c c\u00e1c plugin driver d\u00e0nh cho l\u01b0u tr\u1eef. C\u00f3 th\u1ec3 hi\u1ec3u ng\u1eafn g\u1ecdn v\u1ec1 Cinder nh\u01b0 sau : Cinder l\u00e0 \u1ea3o h\u00f3a vi\u1ec7c qu\u1ea3n l\u00fd c\u00e1c thi\u1ebft b\u1ecb Block Storage v\u00e0 cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng m\u1ed9t API \u0111\u00e1p \u1ee9ng \u0111\u01b0\u1ee3c nh\u01b0 c\u1ea7u t\u1ef1 ph\u1ee5c v\u1ee5 c\u0169ng nh\u01b0 y\u00eau c\u1ea7u ti\u00eau th\u1ee5 c\u00e1c t\u00e0i nguy\u00ean \u0111\u00f3 m\u00e0 kh\u00f4ng c\u1ea7n c\u00f3 qu\u00e1 nhi\u1ec1u ki\u1ebfn th\u1ee9c v\u1ec1 l\u01b0u tr\u1eef.","title":"1.1. Kh\u00e1i ni\u1ec7m Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#12_cac_chuc_nang_chinh","text":"Cung c\u1ea5p v\u00e0 qu\u1ea3n l\u00fd c\u00e1c t\u00e0i nguy\u00ean l\u01b0u tr\u1eef d\u1ea1ng persistent block storage (volume) cho c\u00e1c m\u00e1y \u1ea3o C\u00e1c volume n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u00e1ch t\u1eeb m\u00e1y \u1ea3o n\u00e0y v\u00e0 g\u00e1n l\u1ea1i v\u00e0o m\u1ed9t m\u00e1y \u1ea3o kh\u00e1c, m\u00e0 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c gi\u1eef nguy\u00ean kh\u00f4ng b\u1ecb thay \u0111\u1ed5i. Hi\u1ec7n t\u1ea1i, m\u1ed9t volume ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u00e1n (attached) v\u00e0 m\u1ed9t m\u00e1y \u1ea3o t\u1ea1i m\u1ed9t th\u1eddi \u0111i\u1ec3m C\u00e1c volume t\u1ed3n t\u1ea1i \u0111\u1ed9c l\u1eadp v\u1edbi c\u00e1c m\u00e1y \u1ea3o (t\u1ee9c l\u00e0 khi m\u00e1y \u1ea3o b\u1ecb x\u00f3a th\u00ec volume kh\u00f4ng b\u1ecb x\u00f3a). Ph\u00e2n chia t\u00e0i nguy\u00ean l\u01b0u tr\u1eef th\u00e0nh c\u00e1c kh\u1ed1i g\u1ecdi l\u00e0 Cinder volume. Cung c\u1ea5p c\u00e1c API nh\u01b0 l\u00e0 t\u1ea1o, x\u00f3a, backup, restore, t\u1ea1o snapshot, clone volume v\u00e0 nhi\u1ec1u h\u01a1n n\u1eefa. Nh\u1eefng API n\u00e0y th\u1ef1c hi\u1ec7n b\u1edfi c\u00e1c backend l\u01b0u tr\u1eef m\u00e0 \u0111\u01b0\u1ee3c cinder h\u1ed7 tr\u1ee3. C\u00e1c ki\u1ebfn tr\u00fac plugin drive cho ph\u00e9p nhi\u1ec1u l\u1ef1a ch\u1ecdn l\u00e0m backend storage.","title":"1.2. C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#13_loi_ich_chinh","text":"Cinder cung c\u1ea5p block storage d\u01b0\u1edbi d\u1ea1ng block as a service Component based architecture : th\u1ef1c hi\u1ec7n m\u1ed9t h\u00e0nh \u0111\u1ed9ng m\u1edbi d\u1ec5 d\u00e0ng Highly available : t\u1ec9 l\u1ec7 % c\u00f4ng vi\u1ec7c \u0111\u01b0\u1ee3c chia nh\u1ecf Fault-Tolerant : c\u00e1c ti\u1ebfn tr\u00ecnh \u0111\u01b0\u1ee3c t\u00e1ch ri\u00eang bi\u1ec7t Recoverable : d\u1ec5 d\u00e0ng ph\u00e1n \u0111o\u00e1n, s\u1eeda l\u1ed7i Open Standards : c\u1ed9ng \u0111\u1ed3ng API m\u1edf","title":"1.3. L\u1ee3i \u00edch ch\u00ednh"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#2_kien_truc_trong_cinder","text":"openstack-cinder-volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi volume cho c\u00e1c m\u00e1y \u1ea3o theo y\u00eau c\u1ea7u . Khi c\u00f3 m\u1ed9t request t\u1eeb sheduler , volume service s\u1ebd t\u1ea1o, ch\u1ec9nh s\u1eeda, x\u00f3a c\u00e1c volume theo y\u00eau c\u1ea7u. M\u1ed9t s\u1ed1 c\u00e1c driver s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi storage provider openstack-cinder-api : tr\u1ea3 l\u1eddi v\u00e0 x\u1eed l\u00fd theo y\u00eau c\u1ea7u, g\u1eedi c\u00e1c tin nh\u1eafn v\u00e0o h\u00e0ng ch\u1edd . Khi c\u00f3 m\u1ed9t request g\u1eedi \u0111\u1ebfn, c\u00e1c API nh\u1edd indentify service \u0111\u1ec3 x\u00e1c th\u1ef1c , sau \u0111\u00f3 g\u1eedi th\u00f4ng \u0111i\u1ec7p \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c block storage. openstack-cinder-backup : cung c\u1ea5p kh\u1ea3 n\u0103ng backup c\u00e1c Storage Voluem sang m\u1ed9t repo kh\u00e1c openstack-cinder-sheduler : g\u1eedi c\u00e1c task v\u00e0o h\u00e0ng ch\u1edd , v\u00e0 x\u00e1c \u0111\u1ecbnh volume server. Sheduler s\u1ebd nh\u1eadn c\u00e1c b\u1ea3n tin t\u1eeb h\u00e0ng ch\u1edd sau \u0111\u00f3 x\u00e1c \u0111\u1ecbnh block storage host s\u1ebd l\u00e0m vi\u1ec7c . Database : l\u01b0u th\u1ea1ng tr\u00e1i c\u00e1c volume RabbitMQ server : cung c\u1ea5p h\u00e0ng ch\u1edd tin nh\u1eafn AMQP, RabbitMQ l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c c\u00e1c Openstack Copoment kh\u00e1c : h\u00e0ng ch\u1edd, ph\u00e2n ph\u1ed1i,, qu\u1ea3n l\u00fd, b\u1ea3o m\u1eadt li\u00ean k\u1ebft2x","title":"2. Ki\u1ebfn tr\u00fac trong Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#3_cac_thanh_phan_trong_cinder","text":"Back-end storage device : y\u00eau c\u1ea7u m\u1ed9t s\u1ed1 back-end storage service. M\u1eb7c \u0111\u1ecbnh Cinder t\u00edch h\u1ee3p v\u00e0 s\u1eed d\u1ee5ng v\u1edbi LVM, tr\u00ean m\u1ed9t logical volume group c\u00f3 t\u00ean cinder volume . Ngo\u00e0i vi\u1ec7c s\u1eed d\u1ee5ng LVM, tra c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng nhi\u1ec1u drvier kh\u00e1c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi Cinder nh\u01b0 Raid ho\u1eb7c c\u00e1c driver l\u01b0u tr\u1eef kh\u00e1c. Nh\u1eefng back-end driver n\u00e0y c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh block size khi s\u1eed d\u1ee5ng KVM-QEMU l\u00e0m hypersvisor Users and Tenants (Projects) : d\u1ecbch v\u1ee5 Block Storage c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi nhi\u1ec1u kh\u00e1ch h\u00e0ng ho\u1eb7c kh\u00e1ch h\u00e0ng \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y kh\u00e1c nhau (nh\u1eefng tenant tr\u00ean m\u1ed9t h\u1ec7 th\u1ed1ng shared system), s\u1eed d\u1ee5ng g\u00e1n quy\u1ec1n truy c\u1eadp theo role. C\u00e1c role \u0111i\u1ec3u khi\u1ec3n c\u00e1c h\u00e0nh \u0111\u1ed9ng m\u00e0 ng\u01b0\u1eddi d\u00f9ng \u0111\u01b0\u1ee3c ph\u00e9p th\u1ef1c hi\u1ec7n. Trong c\u1ea5u h\u00ecnh m\u1eb7c \u0111\u1ecbnh, h\u1ea7u h\u1ebft c\u00e1c h\u00e0nh \u0111\u1ed9ng kh\u00f4ng y\u00eau c\u1ea7u role c\u1ee5 th\u1ec3, nh\u01b0ng \u0111i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh b\u1edfi qu\u1ea3n tr\u1ecb vi\u00ean h\u1ec7 th\u1ed1ng trong t\u1ec7p policy.json th\u00edch h\u1ee3p \u0111\u1ec3 duy tr\u00ec c\u00e1c quy t\u1eafc. Quy\u1ec1n truy c\u1eadp v\u00e0o m\u1ed9t volume c\u1ee5 th\u1ec3 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi tenant (project), nh\u01b0ng t\u00ean ng\u01b0\u1eddi d\u00f9ng v\u00e0 m\u1eadt kh\u1ea9u \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh cho m\u1ed7i ng\u01b0\u1eddi d\u00f9ng. C\u00e1c c\u1eb7p kh\u00f3a key-pairs cho ph\u00e9p truy c\u1eadp v\u00e0o m\u1ed9t volume \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t cho m\u1ed7i ng\u01b0\u1eddi d\u00f9ng, nh\u01b0ng h\u1ea1n ng\u1ea1ch quotas \u0111\u1ec3 ki\u1ec3m so\u00e1t t\u00e0i nguy\u00ean s\u1eed d\u1ee5ng tr\u00ean c\u00e1c thi\u1ebft b\u1ecb ph\u1ea7n c\u1ee9ng c\u00f3 s\u1eb5n l\u00e0 cho m\u1ed7i tenant. Volume, Snapshots v\u00e0 Backups : Volume : g\u1eafn c\u00e1c blcok storage \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 v\u00e0o c\u00e1c instance, ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t storage th\u1ee9 2 cho c\u00e1c instance ho\u1eb7c nh\u01b0 root filesystem storage \u0111\u1ec3 l\u00e0m boot disk cho instance. C\u00e1c volume l\u00e0 c\u00e1c thi\u1ebft b\u1ecb l\u01b0u tr\u1eef d\u01b0\u1edbi d\u1ea1ng Read/Write \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c compute node s\u1eed d\u1ee5ng iSCSI. Snapshot : m\u1ed9t b\u1ea3n read-only d\u1eef tr\u1eef d\u1eef li\u1ec7u c\u1ee7a volume t\u1ea1o m\u1ed9t th\u1eddi \u0111i\u1ec3m n\u00e0o \u0111\u00f3 . Snapshot c\u00f3 th\u1ec3 kh\u1edfi t\u1ea1o cho m\u1ed9t volume \u0111ang \u1edf tr\u1ea1ng th\u00e1i active n\u1ebfu s\u1eed d\u1ee5ng --force True Backup : b\u1ea3n copy c\u1ee7a m\u1ed9t volume l\u01b0u tr\u1eef tr\u00ean Object Storage ( Swift )","title":"3. C\u00e1c th\u00e0nh ph\u1ea7n trong Cinder"},{"location":"Openstack_Research/Cinder/1. Introduction-cinder/#4_tham_khao_them","text":"[1] : https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Cinder/docs/Tong_quan_Cinder.md [2] : https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/6/html/Component_Overview/section-blockStorage.html [3] : https://docs.openstack.org/cinder/latest/configuration/block-storage/block-storage-overview.html","title":"4. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/","text":"M\u1ed1i quan h\u1ec7 gi\u1eefa instance v\u00e0 disk \u00b6 1. Boot Source \u00b6 Trong Openstack c\u00f3 nhi\u1ec1u c\u00e1c \u0111\u1ec3 kh\u1edfi t\u1ea1o \u1ed5 \u0111\u0129a cho m\u00e1y \u1ea3o Image : Kh\u1edfi ch\u1ea1y instance s\u1eed d\u1ee5ng image ch\u1ea1y tr\u00ean ephemeral disk ho\u1eb7c volume disk Instance Shapshoot : kh\u1edfi ch\u1ea1y instance t\u1eeb m\u1ed9t b\u1ea3n snapshot tr\u00ean m\u1ed9t ephermeral disk ho\u1eb7c volume disk Volume : Kh\u1edfi ch\u1ea1y instance t\u1eeb m\u1ed9t bootable volume \u0111\u00e3 t\u1ed3n t\u1ea1i Volume Snapshot : Kh\u1edfi t\u1ea1o m\u1ed9t volume m\u1edbi t\u1eeb volume snapshot v\u00e0 ch\u1ea1y instance m\u1edbi s\u1eed d\u1ee5ng bootable volume m\u1edbi 2. Ephemeral boot disk \u00b6 Ephemeral disk l\u00e0 m\u1ed9t disk \u1ea3o cho m\u1ee5c \u0111\u00edch duy nh\u1ea5t l\u00e0 \u0111\u1ec3 boot m\u00e1y \u1ea3o v\u00e0 \u0111\u01b0\u1ee3c coi l\u00e0 disk t\u1ea1m th\u1eddi Ephemeral disk \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong tr\u01b0\u1eddng h\u1ee3p kh\u00f4ng quan t\u00e2m trong tr\u01b0\u1eddng h\u1ee3p x\u00f3a m\u00e1y \u1ea3o v\u00e0 m\u1ea5t quan t\u00e2m d\u1eef li\u1ec7u b\u00ean trong . C\u00f3 th\u1ec3 mount m\u1ed9t volume n\u00e0o \u0111\u00f3 v\u00e0o m\u1ed9t instance \u0111ang boot t\u1eeb enphemeral disk v\u00e0 \u0111\u1ed5 d\u1eef li\u1ec7u v\u00e0o trong volume \u0111\u00f3 \u0110\u1eb7c t\u00ednh c\u1ee7a ephemeral disk : C\u00f3 th\u1ec3 snapshot : c\u00f3 th\u1ec3 nh\u00e2n \u0111\u00f4i b\u1ea3n instance ho\u1eb7c s\u1eed d\u1ee5ng snapshot Kh\u00f4ng s\u1eed d\u1ee5ng h\u1ebft volume quota : N\u1ebfu b\u1ea1n c\u00f3 nhi\u1ec1u instance quota, b\u1ea1n c\u00f3 th\u1ec3 boot ch\u00fang t\u1eeb ephemeral disk ngay c\u1ea3 khi kh\u00f4ng c\u00f3 nhi\u1ec1u volume quota \u1ed4 \u0111\u0129a b\u1ecb x\u00f3a khi m\u00e1y \u1ea3o x\u00f3a 3. Volume boot disk \u00b6 Voume l\u00e0 d\u1ea1ng l\u01b0u tr\u1eef b\u1ec1n v\u1eefng h\u01a1n ephemeral disk v\u00e0 c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 boot nh\u01b0 l\u00e0 m\u1ed9t block device, c\u0169ng c\u00f3 th\u1ec3 mount \u0111\u01b0\u1ee3c. Volume boot disk h\u1eefu d\u1ee5ng khi b\u1ea1n c\u1ea7n dupicate m\u1ed9t vm ho\u1eb7c backup ch\u00fang b\u1eb1ng c\u00e1ch snapshot, ho\u1eb7c n\u1ebfu b\u1ea1n mu\u1ed1n d\u00f9ng ph\u01b0\u01a1ng ph\u00e1p l\u01b0u tr\u1eef \u0111\u00e1ng tin c\u1eady h\u01a1n l\u00e0 ephemeral disk. N\u1ebfu d\u00f9ng d\u1ea1ng n\u00e0y, c\u1ea7n c\u00f3 \u0111\u1ee7 quota cho c\u00e1c vm c\u1ea7n boot. M\u1ed9t s\u1ed1 \u0111\u1eb7c t\u00ednh : - C\u00f3 th\u1ec3 snapshot - Kh\u00f4ng b\u1ecb x\u00f3a khi x\u00f3a m\u00e1y \u1ea3o : B\u1ea1n c\u00f3 th\u1ec3 x\u00f3a m\u00e1y \u1ea3o nh\u01b0ng d\u1eef li\u1ec7u v\u1eabn c\u00f2n trong volume - S\u1eed d\u1ee5ng h\u1ebft volume quota : volume quota s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng h\u1ebft khi d\u00f9ng t\u00f9y ch\u1ecdn n\u00e0y. 4. M\u1ed9t s\u1ed1 storage backend \u00b6 5. Cinder Processes Concept Diagram \u00b6 G\u1ed3m c\u00f3 4 process li\u00ean h\u1ec7 v\u1edbi nhau trong Cinder service cinder-api : WSGI application nh\u1eadn c\u00e1c Request t\u1eeb client v\u00e0 router \u0111\u1ebfn c\u00e1c cinder process kh\u00e1c s\u1eed d\u1ee5ng AMQP cinder-sheduler : x\u00e1c \u0111\u1ecbnh backend \u0111\u00edch d\u00f9ng \u0111\u1ec3 kh\u1edfi t\u1ea1o volume ho\u1eb7c c\u00e1c t\u00e1c v\u1ee5 khac cinder-volume : ch\u1ea5p nh\u1eadn c\u00e1c request t\u1eeb c\u00e1c cinder process v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c Cinder Driver . Qu\u00e1 tr\u00ecnh n\u00e0y ho\u1ea1t \u0111\u1ed9ng \u0111a lu\u1ed3ng v\u00e0 th\u01b0\u1eddng ch\u1ec9 c\u00f3 m\u1ed9t lu\u1ed3ng cho m\u1ed7i Cinder Backend cinder-backup : l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c backend backup ( SWIFT ) , x\u1eed l\u00fd c\u00e1c request khi client y\u00eau c\u1ea7u kh\u1edfi t\u1ea1o backup ho\u1eb7c qu\u1ea3n l\u00fd c\u00e1c volume 6. Qu\u00e1 tr\u00ecnh Cinder kh\u1edfi t\u1ea1o Volume \u00b6 B1 : Client x\u1eed l\u00fd request t\u1ea1o m\u00e1y t\u1eeb Rest API B2 : cinder-api ki\u1ec3m tra c\u00e1c request h\u1ee3p l\u1ec7, sau \u0111\u00f3 g\u1ee7i c\u00e1c b\u1ea3n tin \u0111\u1ebfn h\u00e0ng ch\u1edd AMQP B3 : Cinder-sheduler : th\u1ef1c hi\u1ec7n \u0111\u01b0a c\u00e1c message ra kh\u1edfi h\u00e0ng ch\u1edd v\u00e0 li\u1ec7t k\u00ea c\u00e1c th\u00f4ng tin tr\u00ean request \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c backend s\u1eed d\u1ee5ng B4 : Cinder-volume : \u0111\u1ecdc c\u00e1c message t\u1eeb cinder-sheduler g\u1eedi v\u1ec1 h\u00e0ng ch\u1edd, v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi backend driver \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u B5 : Cinder driver t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c storage backend \u0111\u1ec3 kh\u1edfi t\u1ea1o volume B6 : Cinder-volume t\u1eadp h\u1ee3p volume metadata v\u00e0 g\u1eedi l\u00ean AMQP queue B8: Cinder-api \u0111\u1ecdc message tr\u1ea3 l\u1eddi t\u1eeb queue v\u00e0 tr\u1ea3 l\u1eddi client. B9: Cinder client nh\u1eadn c\u00e1c request th\u00f4ng tin c\u1ee7a volume 7 . Qu\u00e1 tr\u00ecnh Cinder Attach Volume \u00b6 B11.Client y\u00eau c\u1ea7u attach volume th\u00f4ng Nova Rest API ( client s\u1eed d\u1ee5ng python-cinderclient ho\u1eb7c th\u00f4ng qua dashboard) B2.nova-api x\u00e1c th\u1ef1c y\u00eau c\u1ea7u xem c\u00f3 h\u1ee3p l\u1ec7 hay kh\u00f4ng? , th\u00f4ng tin user. M\u1ed9t khi \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, g\u1ecdi Cinder API \u0111\u1ec3 l\u1ea5y th\u00f4ng tin v\u1ec1 volume c\u1ee5 th\u1ec3. B3.cinder-api x\u00e1c th\u1ef1c y\u00eau c\u1ea7u xem c\u00f3 h\u1ee3p l\u1ec7 hay kh\u00f4ng?, th\u00f4ng tin user. M\u1ed9t khi \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, post message \u0111\u1ebfn volume manager th\u00f4ng qua AMQP. B4.cinder-volume \u0111\u1ecdc message t\u1eeb queue, g\u1ecdi Cinder driver t\u01b0\u01a1ng \u1ee9ng \u0111\u1ebfn volume \u0111\u1ec3 attached. B5.Cinder driver chu\u1ea9n b\u1ecb Cinder volume cho vi\u1ec7c attachment ( c\u00e1c b\u01b0\u1edbc c\u1ee5 th\u1ec3 ph\u1ee5 thu\u1ed9c v\u00e0o giao th\u1ee9c storage \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng) B6.cinder-volume post th\u00f4ng tin tr\u1ea3 l\u1eddi \u0111\u1ebfn cinder-api th\u00f4ng qua AMQP queue. B7.cinder-api \u0111\u1ecdc message tr\u1ea3 l\u1eddi t\u1eeb cinder-volume t\u1eeb queue, truy\u1ec1n th\u00f4ng tin k\u1ebft n\u1ed1i trong RESTful reponse \u0111\u1ebfn Nova caller. B8.Nova t\u1ea1o k\u1ebft n\u1ed1i \u0111\u1ebfn storage v\u1edbi th\u00f4ng tin tr\u1ea3 l\u1ea1i t\u1eeb Cinder. B9.Nova truy\u1ec1n volume device/file \u0111\u1ebfn hypervisor, sau \u0111\u00f3 attach volume device/file \u0111\u1ebfn guest VM nh\u01b0 m\u1ed9t thi\u1ebft b\u1ecb block th\u1ef1c t\u1ebf ho\u1eb7c (ph\u1ee5 thu\u1ed9c v\u00e0o giao th\u1ee9c storage). 8 . Tham kh\u1ea3o th\u00eam \u00b6 https://help.dreamhost.com/hc/en-us/articles/217701757-What-s-the-difference-between-ephemeral-and-volume-boot-disks- https://github.com/thaonguyenvan/meditech-thuctap/blob/master/ThaoNV/Tim%20hieu%20OpenStack/docs/cinder/cinder-workflow.md http://netapp.github.io/openstack-deploy-ops-guide/icehouse/content/section_cinder-processes.html https://docs.openstack.org/project-deploy-guide/openstack-ansible/draft/overview-storage-arch.html https://docs.openstack.org/arch-design/design-storage/design-storage-concepts.html","title":"2. Cinder Disk Work Flow"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#moi_quan_he_giua_instance_va_disk","text":"","title":"M\u1ed1i quan h\u1ec7 gi\u1eefa instance v\u00e0 disk"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#1_boot_source","text":"Trong Openstack c\u00f3 nhi\u1ec1u c\u00e1c \u0111\u1ec3 kh\u1edfi t\u1ea1o \u1ed5 \u0111\u0129a cho m\u00e1y \u1ea3o Image : Kh\u1edfi ch\u1ea1y instance s\u1eed d\u1ee5ng image ch\u1ea1y tr\u00ean ephemeral disk ho\u1eb7c volume disk Instance Shapshoot : kh\u1edfi ch\u1ea1y instance t\u1eeb m\u1ed9t b\u1ea3n snapshot tr\u00ean m\u1ed9t ephermeral disk ho\u1eb7c volume disk Volume : Kh\u1edfi ch\u1ea1y instance t\u1eeb m\u1ed9t bootable volume \u0111\u00e3 t\u1ed3n t\u1ea1i Volume Snapshot : Kh\u1edfi t\u1ea1o m\u1ed9t volume m\u1edbi t\u1eeb volume snapshot v\u00e0 ch\u1ea1y instance m\u1edbi s\u1eed d\u1ee5ng bootable volume m\u1edbi","title":"1. Boot Source"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#2_ephemeral_boot_disk","text":"Ephemeral disk l\u00e0 m\u1ed9t disk \u1ea3o cho m\u1ee5c \u0111\u00edch duy nh\u1ea5t l\u00e0 \u0111\u1ec3 boot m\u00e1y \u1ea3o v\u00e0 \u0111\u01b0\u1ee3c coi l\u00e0 disk t\u1ea1m th\u1eddi Ephemeral disk \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong tr\u01b0\u1eddng h\u1ee3p kh\u00f4ng quan t\u00e2m trong tr\u01b0\u1eddng h\u1ee3p x\u00f3a m\u00e1y \u1ea3o v\u00e0 m\u1ea5t quan t\u00e2m d\u1eef li\u1ec7u b\u00ean trong . C\u00f3 th\u1ec3 mount m\u1ed9t volume n\u00e0o \u0111\u00f3 v\u00e0o m\u1ed9t instance \u0111ang boot t\u1eeb enphemeral disk v\u00e0 \u0111\u1ed5 d\u1eef li\u1ec7u v\u00e0o trong volume \u0111\u00f3 \u0110\u1eb7c t\u00ednh c\u1ee7a ephemeral disk : C\u00f3 th\u1ec3 snapshot : c\u00f3 th\u1ec3 nh\u00e2n \u0111\u00f4i b\u1ea3n instance ho\u1eb7c s\u1eed d\u1ee5ng snapshot Kh\u00f4ng s\u1eed d\u1ee5ng h\u1ebft volume quota : N\u1ebfu b\u1ea1n c\u00f3 nhi\u1ec1u instance quota, b\u1ea1n c\u00f3 th\u1ec3 boot ch\u00fang t\u1eeb ephemeral disk ngay c\u1ea3 khi kh\u00f4ng c\u00f3 nhi\u1ec1u volume quota \u1ed4 \u0111\u0129a b\u1ecb x\u00f3a khi m\u00e1y \u1ea3o x\u00f3a","title":"2. Ephemeral boot disk"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#3_volume_boot_disk","text":"Voume l\u00e0 d\u1ea1ng l\u01b0u tr\u1eef b\u1ec1n v\u1eefng h\u01a1n ephemeral disk v\u00e0 c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 boot nh\u01b0 l\u00e0 m\u1ed9t block device, c\u0169ng c\u00f3 th\u1ec3 mount \u0111\u01b0\u1ee3c. Volume boot disk h\u1eefu d\u1ee5ng khi b\u1ea1n c\u1ea7n dupicate m\u1ed9t vm ho\u1eb7c backup ch\u00fang b\u1eb1ng c\u00e1ch snapshot, ho\u1eb7c n\u1ebfu b\u1ea1n mu\u1ed1n d\u00f9ng ph\u01b0\u01a1ng ph\u00e1p l\u01b0u tr\u1eef \u0111\u00e1ng tin c\u1eady h\u01a1n l\u00e0 ephemeral disk. N\u1ebfu d\u00f9ng d\u1ea1ng n\u00e0y, c\u1ea7n c\u00f3 \u0111\u1ee7 quota cho c\u00e1c vm c\u1ea7n boot. M\u1ed9t s\u1ed1 \u0111\u1eb7c t\u00ednh : - C\u00f3 th\u1ec3 snapshot - Kh\u00f4ng b\u1ecb x\u00f3a khi x\u00f3a m\u00e1y \u1ea3o : B\u1ea1n c\u00f3 th\u1ec3 x\u00f3a m\u00e1y \u1ea3o nh\u01b0ng d\u1eef li\u1ec7u v\u1eabn c\u00f2n trong volume - S\u1eed d\u1ee5ng h\u1ebft volume quota : volume quota s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng h\u1ebft khi d\u00f9ng t\u00f9y ch\u1ecdn n\u00e0y.","title":"3. Volume boot disk"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#4_mot_so_storage_backend","text":"","title":"4. M\u1ed9t s\u1ed1 storage backend"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#5_cinder_processes_concept_diagram","text":"G\u1ed3m c\u00f3 4 process li\u00ean h\u1ec7 v\u1edbi nhau trong Cinder service cinder-api : WSGI application nh\u1eadn c\u00e1c Request t\u1eeb client v\u00e0 router \u0111\u1ebfn c\u00e1c cinder process kh\u00e1c s\u1eed d\u1ee5ng AMQP cinder-sheduler : x\u00e1c \u0111\u1ecbnh backend \u0111\u00edch d\u00f9ng \u0111\u1ec3 kh\u1edfi t\u1ea1o volume ho\u1eb7c c\u00e1c t\u00e1c v\u1ee5 khac cinder-volume : ch\u1ea5p nh\u1eadn c\u00e1c request t\u1eeb c\u00e1c cinder process v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c Cinder Driver . Qu\u00e1 tr\u00ecnh n\u00e0y ho\u1ea1t \u0111\u1ed9ng \u0111a lu\u1ed3ng v\u00e0 th\u01b0\u1eddng ch\u1ec9 c\u00f3 m\u1ed9t lu\u1ed3ng cho m\u1ed7i Cinder Backend cinder-backup : l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c backend backup ( SWIFT ) , x\u1eed l\u00fd c\u00e1c request khi client y\u00eau c\u1ea7u kh\u1edfi t\u1ea1o backup ho\u1eb7c qu\u1ea3n l\u00fd c\u00e1c volume","title":"5. Cinder Processes Concept Diagram"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#6_qua_trinh_cinder_khoi_tao_volume","text":"B1 : Client x\u1eed l\u00fd request t\u1ea1o m\u00e1y t\u1eeb Rest API B2 : cinder-api ki\u1ec3m tra c\u00e1c request h\u1ee3p l\u1ec7, sau \u0111\u00f3 g\u1ee7i c\u00e1c b\u1ea3n tin \u0111\u1ebfn h\u00e0ng ch\u1edd AMQP B3 : Cinder-sheduler : th\u1ef1c hi\u1ec7n \u0111\u01b0a c\u00e1c message ra kh\u1edfi h\u00e0ng ch\u1edd v\u00e0 li\u1ec7t k\u00ea c\u00e1c th\u00f4ng tin tr\u00ean request \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c backend s\u1eed d\u1ee5ng B4 : Cinder-volume : \u0111\u1ecdc c\u00e1c message t\u1eeb cinder-sheduler g\u1eedi v\u1ec1 h\u00e0ng ch\u1edd, v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi backend driver \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u B5 : Cinder driver t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c storage backend \u0111\u1ec3 kh\u1edfi t\u1ea1o volume B6 : Cinder-volume t\u1eadp h\u1ee3p volume metadata v\u00e0 g\u1eedi l\u00ean AMQP queue B8: Cinder-api \u0111\u1ecdc message tr\u1ea3 l\u1eddi t\u1eeb queue v\u00e0 tr\u1ea3 l\u1eddi client. B9: Cinder client nh\u1eadn c\u00e1c request th\u00f4ng tin c\u1ee7a volume","title":"6. Qu\u00e1 tr\u00ecnh Cinder kh\u1edfi t\u1ea1o Volume"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#7_qua_trinh_cinder_attach_volume","text":"B11.Client y\u00eau c\u1ea7u attach volume th\u00f4ng Nova Rest API ( client s\u1eed d\u1ee5ng python-cinderclient ho\u1eb7c th\u00f4ng qua dashboard) B2.nova-api x\u00e1c th\u1ef1c y\u00eau c\u1ea7u xem c\u00f3 h\u1ee3p l\u1ec7 hay kh\u00f4ng? , th\u00f4ng tin user. M\u1ed9t khi \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, g\u1ecdi Cinder API \u0111\u1ec3 l\u1ea5y th\u00f4ng tin v\u1ec1 volume c\u1ee5 th\u1ec3. B3.cinder-api x\u00e1c th\u1ef1c y\u00eau c\u1ea7u xem c\u00f3 h\u1ee3p l\u1ec7 hay kh\u00f4ng?, th\u00f4ng tin user. M\u1ed9t khi \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, post message \u0111\u1ebfn volume manager th\u00f4ng qua AMQP. B4.cinder-volume \u0111\u1ecdc message t\u1eeb queue, g\u1ecdi Cinder driver t\u01b0\u01a1ng \u1ee9ng \u0111\u1ebfn volume \u0111\u1ec3 attached. B5.Cinder driver chu\u1ea9n b\u1ecb Cinder volume cho vi\u1ec7c attachment ( c\u00e1c b\u01b0\u1edbc c\u1ee5 th\u1ec3 ph\u1ee5 thu\u1ed9c v\u00e0o giao th\u1ee9c storage \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng) B6.cinder-volume post th\u00f4ng tin tr\u1ea3 l\u1eddi \u0111\u1ebfn cinder-api th\u00f4ng qua AMQP queue. B7.cinder-api \u0111\u1ecdc message tr\u1ea3 l\u1eddi t\u1eeb cinder-volume t\u1eeb queue, truy\u1ec1n th\u00f4ng tin k\u1ebft n\u1ed1i trong RESTful reponse \u0111\u1ebfn Nova caller. B8.Nova t\u1ea1o k\u1ebft n\u1ed1i \u0111\u1ebfn storage v\u1edbi th\u00f4ng tin tr\u1ea3 l\u1ea1i t\u1eeb Cinder. B9.Nova truy\u1ec1n volume device/file \u0111\u1ebfn hypervisor, sau \u0111\u00f3 attach volume device/file \u0111\u1ebfn guest VM nh\u01b0 m\u1ed9t thi\u1ebft b\u1ecb block th\u1ef1c t\u1ebf ho\u1eb7c (ph\u1ee5 thu\u1ed9c v\u00e0o giao th\u1ee9c storage).","title":"7 . Qu\u00e1 tr\u00ecnh Cinder Attach Volume"},{"location":"Openstack_Research/Cinder/2. Cinder-Disk-Work-Flow/#8_tham_khao_them","text":"https://help.dreamhost.com/hc/en-us/articles/217701757-What-s-the-difference-between-ephemeral-and-volume-boot-disks- https://github.com/thaonguyenvan/meditech-thuctap/blob/master/ThaoNV/Tim%20hieu%20OpenStack/docs/cinder/cinder-workflow.md http://netapp.github.io/openstack-deploy-ops-guide/icehouse/content/section_cinder-processes.html https://docs.openstack.org/project-deploy-guide/openstack-ansible/draft/overview-storage-arch.html https://docs.openstack.org/arch-design/design-storage/design-storage-concepts.html","title":"8 . Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Cinder/3. Install-Cinder-LVM/","text":"C\u00e0i \u0111\u1eb7t Cinder v\u1edbi backend LVM \u00b6 1. Tr\u00ean Controller \u00b6 Bi\u1ebfn m\u00f4i tr\u01b0\u1eddng echo \"export OS_VOLUME_API_VERSION=2\" >> ~/admin-openrc source ~/admin-openrc Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE cinder; GRANT ALL PRIVILEGES on cinder.* to 'cinder'@'localhost' identified by \"cinder_123\"; GRANT ALL PRIVILEGES on cinder.* to 'cinder'@'%' identified by \"cinder_123\"; EOF Kh\u1edfi t\u1ea1o User Service Cinder v\u00e0 Endpoint openstack user create --domain default --password=cinder_123 cinder openstack role add --project service --user cinder admin openstack service create --name cinderv2 --description \"OpenStack Block Storage\" volumev2 openstack service create --name cinderv3 --description \"OpenStack Block Storage\" volumev3 openstack endpoint create --region RegionOne volumev2 public http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev2 internal http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev2 admin http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%\\(project_id\\)s C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Cinder yum install openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF > /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.130 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF su -s /bin/sh -c \"cinder-manage db sync\" cinder cat <<EOF >> /etc/nova/nova.conf [cinder] os_region_name = RegionOne EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=3306/tcp --permanent firewall-cmd --add-port=8776/tcp --permanent firewall-cmd --reload 2. Tr\u00ean Storage Node - LVM Backend \u00b6 C\u1ea5u h\u00ecnh m\u00f4i tr\u01b0\u1eddng cat <<EOF >> /etc/hosts 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute EOF C\u1ea5u h\u00ecnh NTP yum install -y chronyc sed -i -e \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service C\u00e0i \u0111\u1eb7t LVM yum install -y lvm2 device-mapper-persistent-data systemctl enable lvm2-lvmetad.service systemctl start lvm2-lvmetad.service Kh\u1edfi t\u1ea1o LVM echo '2048,,8e;' | sfdisk /dev/sdb pvcreate /dev/sdb1 vgcreate cinder-volumes /dev/sdb1 C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Cinder yum install -y centos-release-openstack-queens yum install -y openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF> /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.133 enabled_backends = lvm glance_api_servers = http://controller:9292 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=iscsi-target --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh LVM Filter Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-cinder-volume.service target.service systemctl start openstack-cinder-volume.service target.service","title":"3. Install Cinder LVM"},{"location":"Openstack_Research/Cinder/3. Install-Cinder-LVM/#cai_at_cinder_voi_backend_lvm","text":"","title":"C\u00e0i \u0111\u1eb7t Cinder v\u1edbi backend LVM"},{"location":"Openstack_Research/Cinder/3. Install-Cinder-LVM/#1_tren_controller","text":"Bi\u1ebfn m\u00f4i tr\u01b0\u1eddng echo \"export OS_VOLUME_API_VERSION=2\" >> ~/admin-openrc source ~/admin-openrc Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE cinder; GRANT ALL PRIVILEGES on cinder.* to 'cinder'@'localhost' identified by \"cinder_123\"; GRANT ALL PRIVILEGES on cinder.* to 'cinder'@'%' identified by \"cinder_123\"; EOF Kh\u1edfi t\u1ea1o User Service Cinder v\u00e0 Endpoint openstack user create --domain default --password=cinder_123 cinder openstack role add --project service --user cinder admin openstack service create --name cinderv2 --description \"OpenStack Block Storage\" volumev2 openstack service create --name cinderv3 --description \"OpenStack Block Storage\" volumev3 openstack endpoint create --region RegionOne volumev2 public http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev2 internal http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev2 admin http://controller:8776/v2/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%\\(project_id\\)s openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%\\(project_id\\)s C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Cinder yum install openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF > /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.130 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF su -s /bin/sh -c \"cinder-manage db sync\" cinder cat <<EOF >> /etc/nova/nova.conf [cinder] os_region_name = RegionOne EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=3306/tcp --permanent firewall-cmd --add-port=8776/tcp --permanent firewall-cmd --reload","title":"1. Tr\u00ean Controller"},{"location":"Openstack_Research/Cinder/3. Install-Cinder-LVM/#2_tren_storage_node_-_lvm_backend","text":"C\u1ea5u h\u00ecnh m\u00f4i tr\u01b0\u1eddng cat <<EOF >> /etc/hosts 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute EOF C\u1ea5u h\u00ecnh NTP yum install -y chronyc sed -i -e \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service C\u00e0i \u0111\u1eb7t LVM yum install -y lvm2 device-mapper-persistent-data systemctl enable lvm2-lvmetad.service systemctl start lvm2-lvmetad.service Kh\u1edfi t\u1ea1o LVM echo '2048,,8e;' | sfdisk /dev/sdb pvcreate /dev/sdb1 vgcreate cinder-volumes /dev/sdb1 C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Cinder yum install -y centos-release-openstack-queens yum install -y openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF> /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.133 enabled_backends = lvm glance_api_servers = http://controller:9292 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=iscsi-target --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh LVM Filter Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-cinder-volume.service target.service systemctl start openstack-cinder-volume.service target.service","title":"2. Tr\u00ean Storage Node - LVM Backend"},{"location":"Openstack_Research/Cinder/4. Basic-Command/","text":"L\u00e0m vi\u1ec7c v\u1edbi Cinder \u00b6 1. T\u1ea1o, x\u00f3a, li\u1ec7t k\u00ea, show volume \u00b6 T\u1ea1o m\u1ed9t volume no-source ```bash [root@controller ~]# openstack volume create --size 10 testcreate +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2018-12-19T08:01:38.000000 | | description | None | | encrypted | False | | id | 37179e4e-7f0b-40a4-9c35-0ccf5cfdec6e | | migration_status | None | | multiattach | False | | name | testcreate | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | - T\u1ea1o volume t\u1eeb image ```bash [root@controller ~]# openstack image list +--------------------------------------+------------+--------+ | ID | Name | Status | +--------------------------------------+------------+--------+ | fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81 | centos | active | | 8bc5ff78-118b-435a-9611-e6a99d9f6b1c | cirros | active | | 9a3cf56e-8730-49f4-a74f-3b76503c2c03 | not-edit | active | | 6a443ca4-a96f-4dbb-a898-38922292ab06 | test-cloud | active | | 50bb3b13-7474-4559-9dce-03b4cb574234 | ubuntu-16 | active | +--------------------------------------+------------+--------+ [root@controller ~]# openstack volume create --size 10 --image centos testimage +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2018-12-19T08:03:09.000000 | | description | None | | encrypted | False | | id | ea0467c7-3844-4d51-8ce7-71afff383c3c | | migration_status | None | | multiattach | False | | name | testimage | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | +---------------------+--------------------------------------+ T\u1ea1o m\u1ed9t volume t\u1eeb volume kh\u00e1c [root@controller ~]# openstack volume create --size 20 --source testimage dup_testimage +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | true | | consistencygroup_id | None | | created_at | 2018-12-19T08:06:59.000000 | | description | None | | encrypted | False | | id | 1f502752-3764-4604-8b9d-fcc595dc9cfa | | migration_status | None | | multiattach | False | | name | dup_testimage | | properties | | | replication_status | None | | size | 20 | | snapshot_id | None | | source_volid | ea0467c7-3844-4d51-8ce7-71afff383c3c | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | ``` - X\u00f3a volume ```bash openstack volume delete <t\u00ean ho\u1eb7c ID volume> Li\u1ec7t k\u00ea c\u00e1c volume openstack volume list show volume bash openstack volume show <t\u00ean ho\u1eb7c ID volume> 2. Snapshot volume \u00b6 T\u1ea1o snapshot [root@controller ~]# openstack volume snapshot create --volume dup_testimage snap_test +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | created_at | 2018-12-19T08:26:31.246334 | | description | None | | id | 039383eb-a7c2-4b6d-9121-eb6fdea0b19d | | name | snap_test | | properties | | | size | 20 | | status | creating | | updated_at | None | | volume_id | 1f502752-3764-4604-8b9d-fcc595dc9cfa | +-------------+--------------------------------------+ List ra danh s\u00e1ch c\u00e1c snapshot c\u1ee7a volume openstack volume snapshot list X\u00f3a snapshot openstack volume snapshot delete <t\u00ean snapshot> ``` ## 3. Attach v\u00e0 detach volume cho m\u00e1y \u1ea3o - Attach volume ```sh openstack server add volume < VM> <t\u00ean volume> --device </dev/...> Detach volume sh openstack server remove volume <VM> <t\u00ean volume>","title":"4. Basic Command"},{"location":"Openstack_Research/Cinder/4. Basic-Command/#lam_viec_voi_cinder","text":"","title":"L\u00e0m vi\u1ec7c v\u1edbi Cinder"},{"location":"Openstack_Research/Cinder/4. Basic-Command/#1_tao_xoa_liet_ke_show_volume","text":"T\u1ea1o m\u1ed9t volume no-source ```bash [root@controller ~]# openstack volume create --size 10 testcreate +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2018-12-19T08:01:38.000000 | | description | None | | encrypted | False | | id | 37179e4e-7f0b-40a4-9c35-0ccf5cfdec6e | | migration_status | None | | multiattach | False | | name | testcreate | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | - T\u1ea1o volume t\u1eeb image ```bash [root@controller ~]# openstack image list +--------------------------------------+------------+--------+ | ID | Name | Status | +--------------------------------------+------------+--------+ | fc5c8ce8-9dac-4f8e-ae4a-5212dc145b81 | centos | active | | 8bc5ff78-118b-435a-9611-e6a99d9f6b1c | cirros | active | | 9a3cf56e-8730-49f4-a74f-3b76503c2c03 | not-edit | active | | 6a443ca4-a96f-4dbb-a898-38922292ab06 | test-cloud | active | | 50bb3b13-7474-4559-9dce-03b4cb574234 | ubuntu-16 | active | +--------------------------------------+------------+--------+ [root@controller ~]# openstack volume create --size 10 --image centos testimage +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2018-12-19T08:03:09.000000 | | description | None | | encrypted | False | | id | ea0467c7-3844-4d51-8ce7-71afff383c3c | | migration_status | None | | multiattach | False | | name | testimage | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | +---------------------+--------------------------------------+ T\u1ea1o m\u1ed9t volume t\u1eeb volume kh\u00e1c [root@controller ~]# openstack volume create --size 20 --source testimage dup_testimage +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | true | | consistencygroup_id | None | | created_at | 2018-12-19T08:06:59.000000 | | description | None | | encrypted | False | | id | 1f502752-3764-4604-8b9d-fcc595dc9cfa | | migration_status | None | | multiattach | False | | name | dup_testimage | | properties | | | replication_status | None | | size | 20 | | snapshot_id | None | | source_volid | ea0467c7-3844-4d51-8ce7-71afff383c3c | | status | creating | | type | None | | updated_at | None | | user_id | 6ca03d3c55444c10aa22f481f2e13381 | ``` - X\u00f3a volume ```bash openstack volume delete <t\u00ean ho\u1eb7c ID volume> Li\u1ec7t k\u00ea c\u00e1c volume openstack volume list show volume bash openstack volume show <t\u00ean ho\u1eb7c ID volume>","title":"1. T\u1ea1o, x\u00f3a, li\u1ec7t k\u00ea, show volume"},{"location":"Openstack_Research/Cinder/4. Basic-Command/#2_snapshot_volume","text":"T\u1ea1o snapshot [root@controller ~]# openstack volume snapshot create --volume dup_testimage snap_test +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | created_at | 2018-12-19T08:26:31.246334 | | description | None | | id | 039383eb-a7c2-4b6d-9121-eb6fdea0b19d | | name | snap_test | | properties | | | size | 20 | | status | creating | | updated_at | None | | volume_id | 1f502752-3764-4604-8b9d-fcc595dc9cfa | +-------------+--------------------------------------+ List ra danh s\u00e1ch c\u00e1c snapshot c\u1ee7a volume openstack volume snapshot list X\u00f3a snapshot openstack volume snapshot delete <t\u00ean snapshot> ``` ## 3. Attach v\u00e0 detach volume cho m\u00e1y \u1ea3o - Attach volume ```sh openstack server add volume < VM> <t\u00ean volume> --device </dev/...> Detach volume sh openstack server remove volume <VM> <t\u00ean volume>","title":"2. Snapshot volume"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/","text":"C\u1ea5u h\u00ecnh Multi Backend - LVM & NFS \u00b6 1. Introduction \u00b6 Khi c\u1ea5u h\u00ecnh Multi-storage backend , m\u1ed7i backend storage kh\u1edfi t\u1ea1o s\u1ebd c\u00f3 m\u1ed9t service cinder-volume ri\u00eang - Trong multi-storage backend , m\u1ed7i backend s\u1ebd c\u00f3 m\u1ed9t t\u00ean ri\u00eang ( volume_backend_name ) . Nhi\u1ec1u backend c\u00f3 th\u1ec3 c\u00f3 c\u00f9ng m\u1ed9t t\u00ean . D\u1ef1a v\u00e0o backend name \u0111\u1ec3 scheduler c\u00f3 th\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c backend m\u00e0 volume s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o . T\u00ean c\u1ee7a backend s\u1ebd l\u00e0 th\u00f4ng tin k\u1ef9 thu\u1eadt \u0111\u1eb7c tr\u01b0ng ( extra-specification ) c\u1ee7a m\u1ed9t volume type ( volume_backend_name=LVM ) . Khi m\u1ed9t volume kh\u1edfi t\u1ea1o , cinder-sheduler s\u1ebd ch\u1ecdn backend d\u1ef1a v\u00e0o th\u00f4ng s\u1ed1 n\u00e0y tr\u00ean volume type b\u1edfi ng\u01b0\u1eddi d\u00f9ng. \u0110\u1ec3 kh\u1edfi t\u1ea1o \u0111\u01b0\u1ee3c m\u00f4i tr\u01b0\u1eddng back-end s\u1ebd s\u1eed d\u1ee5ng option enabled_backends . M\u1ed7i backend s\u1ebd l\u00e0 m\u1ed9t group trong t\u1eadp tin c\u1ea5u h\u00ecnh cinder v\u00e0 kh\u00f4ng li\u00ean quan \u0111\u1ebfn volume_backend_name 2. C\u1ea5u h\u00ecnh tr\u00ean NFS Node \u00b6 C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh NFS yum install -y install nfs-utils mkdir /var/lib/nfs-share echo \"/var/lib/nfs-share 192.168.69.0/24(rw,no_root_squash)\" > /etc/exports systemctl restart rpcbind nfs-server systemctl enable rpcbind nfs-server C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-service=nfs --permanent firewall-cmd --reload 3. C\u1ea5u h\u00ecnh Storage Node \u00b6 C\u1ea5u h\u00ecnh LVM \u1edf b\u00e0i tr\u01b0\u1edbc : https://github.com/nguyenhungsync/Report-Intern-Meditech/blob/master/Openstack/Cinder/3.%20Install-Cinder-LVM.md C\u1ea5u h\u00ecnh m\u00f4i tr\u01b0\u1eddng cat <<EOF >> /etc/hosts 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute 192.168.69.133 cinder EOF - C\u1ea5u h\u00ecnh NTP ```bash yum update -y yum install -y chronyc sed -i -e \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Cinder yum install -y centos-release-openstack-queens python-openstackclient openstack-selinux yum install -y openstack-cinder targetcli python-keystone yum install -y centos-release-openstack-queens python-openstackclient openstack-selinux yum install -y openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF> /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.134 enabled_backends = lvm,nfs glance_api_servers = http://controller:9292 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = lvmdriver-1 [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = \\$state_path/mnt_nfs volume_backend_name = nfsdriver-1 nfs_snapshot_support = True [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh NFS Client yum -y install nfs-utils systemctl enable rpcbind systemctl start rpcbind cat <<EOF > /etc/cinder/nfs_shares 192.168.69.134:/var/lib/nfs-share EOF chmod 640 /etc/cinder/nfs_shares chgrp cinder /etc/cinder/nfs_shares systemctl restart openstack-cinder-volume chown -R cinder. /var/lib/cinder/mnt_nfs/ Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-cinder-volume.service target.service systemctl start openstack-cinder-volume.service target.service 4. Tr\u00ean Controller \u00b6 Kh\u1edfi t\u1ea1o type Volume openstack volume type create lvm openstack volume type set lvm --property volume_backend_name=lvmdriver-1 openstack volume type create nfs openstack volume type set nfs --property volume_backend_name=nfsdriver-1 Ki\u1ec3m tra c\u00e1c Volume type openstack volume type list --long Kh\u1edfi t\u1ea1o NFS DISK openstack volume create --type nfs-node2 --size 10 disk_nfs Ki\u1ec3m tra Log Note \u0111\u1ed1i v\u1edbi c\u00e1c Network Node \u0111ang s\u1eed d\u1ee5ng Selinux c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t rule m\u1edbi \u00b6 setsebool -P virt_use_nfs on","title":"5. Install Multi Backend"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#cau_hinh_multi_backend_-_lvm_nfs","text":"","title":"C\u1ea5u h\u00ecnh Multi Backend - LVM &amp; NFS"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#1_introduction","text":"Khi c\u1ea5u h\u00ecnh Multi-storage backend , m\u1ed7i backend storage kh\u1edfi t\u1ea1o s\u1ebd c\u00f3 m\u1ed9t service cinder-volume ri\u00eang - Trong multi-storage backend , m\u1ed7i backend s\u1ebd c\u00f3 m\u1ed9t t\u00ean ri\u00eang ( volume_backend_name ) . Nhi\u1ec1u backend c\u00f3 th\u1ec3 c\u00f3 c\u00f9ng m\u1ed9t t\u00ean . D\u1ef1a v\u00e0o backend name \u0111\u1ec3 scheduler c\u00f3 th\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c backend m\u00e0 volume s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o . T\u00ean c\u1ee7a backend s\u1ebd l\u00e0 th\u00f4ng tin k\u1ef9 thu\u1eadt \u0111\u1eb7c tr\u01b0ng ( extra-specification ) c\u1ee7a m\u1ed9t volume type ( volume_backend_name=LVM ) . Khi m\u1ed9t volume kh\u1edfi t\u1ea1o , cinder-sheduler s\u1ebd ch\u1ecdn backend d\u1ef1a v\u00e0o th\u00f4ng s\u1ed1 n\u00e0y tr\u00ean volume type b\u1edfi ng\u01b0\u1eddi d\u00f9ng. \u0110\u1ec3 kh\u1edfi t\u1ea1o \u0111\u01b0\u1ee3c m\u00f4i tr\u01b0\u1eddng back-end s\u1ebd s\u1eed d\u1ee5ng option enabled_backends . M\u1ed7i backend s\u1ebd l\u00e0 m\u1ed9t group trong t\u1eadp tin c\u1ea5u h\u00ecnh cinder v\u00e0 kh\u00f4ng li\u00ean quan \u0111\u1ebfn volume_backend_name","title":"1. Introduction"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#2_cau_hinh_tren_nfs_node","text":"C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh NFS yum install -y install nfs-utils mkdir /var/lib/nfs-share echo \"/var/lib/nfs-share 192.168.69.0/24(rw,no_root_squash)\" > /etc/exports systemctl restart rpcbind nfs-server systemctl enable rpcbind nfs-server C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-service=nfs --permanent firewall-cmd --reload","title":"2. C\u1ea5u h\u00ecnh tr\u00ean NFS Node"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#3_cau_hinh_storage_node","text":"C\u1ea5u h\u00ecnh LVM \u1edf b\u00e0i tr\u01b0\u1edbc : https://github.com/nguyenhungsync/Report-Intern-Meditech/blob/master/Openstack/Cinder/3.%20Install-Cinder-LVM.md C\u1ea5u h\u00ecnh m\u00f4i tr\u01b0\u1eddng cat <<EOF >> /etc/hosts 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute 192.168.69.133 cinder EOF - C\u1ea5u h\u00ecnh NTP ```bash yum update -y yum install -y chronyc sed -i -e \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Cinder yum install -y centos-release-openstack-queens python-openstackclient openstack-selinux yum install -y openstack-cinder targetcli python-keystone yum install -y centos-release-openstack-queens python-openstackclient openstack-selinux yum install -y openstack-cinder targetcli python-keystone cp -p /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak cat <<EOF> /etc/cinder/cinder.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone my_ip = 192.168.69.134 enabled_backends = lvm,nfs glance_api_servers = http://controller:9292 [database] connection = mysql+pymysql://cinder:cinder_123@controller/cinder [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = cinder_123 [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = lvmdriver-1 [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = \\$state_path/mnt_nfs volume_backend_name = nfsdriver-1 nfs_snapshot_support = True [oslo_concurrency] lock_path = /var/lib/cinder/tmp EOF C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh NFS Client yum -y install nfs-utils systemctl enable rpcbind systemctl start rpcbind cat <<EOF > /etc/cinder/nfs_shares 192.168.69.134:/var/lib/nfs-share EOF chmod 640 /etc/cinder/nfs_shares chgrp cinder /etc/cinder/nfs_shares systemctl restart openstack-cinder-volume chown -R cinder. /var/lib/cinder/mnt_nfs/ Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-cinder-volume.service target.service systemctl start openstack-cinder-volume.service target.service","title":"3. C\u1ea5u h\u00ecnh Storage Node"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#4_tren_controller","text":"Kh\u1edfi t\u1ea1o type Volume openstack volume type create lvm openstack volume type set lvm --property volume_backend_name=lvmdriver-1 openstack volume type create nfs openstack volume type set nfs --property volume_backend_name=nfsdriver-1 Ki\u1ec3m tra c\u00e1c Volume type openstack volume type list --long Kh\u1edfi t\u1ea1o NFS DISK openstack volume create --type nfs-node2 --size 10 disk_nfs Ki\u1ec3m tra Log","title":"4. Tr\u00ean Controller"},{"location":"Openstack_Research/Cinder/5. Install-Multi-Backend/#note_oi_voi_cac_network_node_ang_su_dung_selinux_can_khoi_tao_mot_rule_moi","text":"setsebool -P virt_use_nfs on","title":"Note \u0111\u1ed1i v\u1edbi c\u00e1c Network Node \u0111ang s\u1eed d\u1ee5ng Selinux c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t rule m\u1edbi"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/","text":"C\u1ea5u h\u00ecnh Multi Backend Scheduler Filter \u00b6 1. Introduction \u00b6 Openstack Block Storage cho ph\u00e9p l\u1ef1a ch\u1ecdn back-end storage d\u1ef1a v\u00e0o c\u00e1c c\u00e0i \u0111\u1eb7t b\u1ed5 sung d\u1ef1a v\u00e0o DriverFilter v\u00e0 GoodnessWeigher trong qu\u00e1 tringh schduler . Nh\u1edd v\u00e0o filter v\u00e0 weigher \u0111\u1ec3 ch\u1eafc ch\u1eafn scheduler l\u1ef1a ch\u1ecdn backend t\u1ed1t nh\u1ea5t tr\u00ean m\u1ed7i request \u0111\u01b0a v\u00e0o API 1.2 : Cinder Scheduler Filters \u00b6 AvailabilityZoneFilter : Filter b\u1eb1ng availability zone CapabilitiesFilter : Filter theo t\u00e0i nguy\u00ean (m\u00e1y \u1ea3o v\u00e0 volume) CapacityFilter : Filter d\u1ef1a v\u00e0o c\u00f4ng su\u1ea5t s\u1eed d\u1ee5ng c\u1ee7a volume backend DifferentBackendFilter : L\u00ean k\u1ebf ho\u1ea1ch \u0111\u1eb7t c\u00e1c volume \u1edf c\u00e1c backend kh\u00e1c nhau khi c\u00f3 1 danh s\u00e1ch c\u00e1c volume DriverFilter : D\u1ef1a v\u00e0o \u2018filter function\u2019 v\u00e0 metrics. InstanceLocalityFilter : l\u00ean k\u1ebf ho\u1ea1ch cho c\u00e1c volume tr\u00ean c\u00f9ng 1 host. \u0110\u1ec3 c\u00f3 th\u1ec3 d\u00f9ng filter n\u00e0y th\u00ec Extended Server Attributes c\u1ea7n \u0111\u01b0\u1ee3c b\u1eadt b\u1edfi nova v\u00e0 user s\u1eed d\u1ee5ng ph\u1ea3i \u0111\u01b0\u1ee3c khai b\u00e1o x\u00e1c th\u1ef1c tr\u00ean c\u1ea3 nova v\u00e0 cinder. JsonFilter : D\u1ef1a v\u00e0o JSON-based grammar \u0111\u1ec3 ch\u1ecdn l\u1ef1a backends RetryFilter : Filter nh\u1eefng node ch\u01b0a t\u1eebng \u0111\u01b0\u1ee3c schedule SameBackendFilter : L\u00ean k\u1ebf ho\u1ea1ch \u0111\u1eb7t c\u00e1c volume c\u00f3 c\u00f9ng backend nh\u01b0 nh\u1eefng volume kh\u00e1c. 1.3 Cinder Scheduler Weights \u00b6 AllocatedCapacityWeigher : Allocated Capacity Weigher s\u1ebd t\u00ednh tr\u1ecdng s\u1ed1 c\u1ee7a host b\u1eb1ng c\u00f4ng su\u1ea5t \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5. N\u00f3 s\u1ebd \u0111\u1eb7t volume v\u00e0o host \u0111\u01b0\u1ee3c khai b\u00e1o chi\u1ebfm \u00edt t\u00e0i nguy\u00ean nh\u1ea5t. CapacityWeigher : Tr\u1ea1ng th\u00e1i c\u00f4ng su\u1ea5t th\u1ef1c t\u1ebf ch\u01b0a \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. ChanceWeigher : T\u00ednh tr\u1ecdng s\u1ed1 random, d\u00f9ng \u0111\u1ec3 t\u1ea1o c\u00e1c volume khi c\u00e1c host g\u1ea7n gi\u1ed1ng nhau GoodnessWeigher : G\u00e1n tr\u1ecdng s\u1ed1 d\u1ef1a v\u00e0o goodness function. 2. C\u1ea5u h\u00ecnh tr\u00ean Cinder Node \u00b6 \u0110\u1ec3 c\u1ea5u h\u00ecnh Block Storage scheduler multi back end c\u1ea7n s\u1eed d\u1ee5ng option filter_scheduler . Trong filter scheduler : Cinder Scheduler Filters : m\u1eb7c \u0111\u1ecbnh c\u00e1c filter AvailabilityZoneFilter , CapacityFilter and CapabilitiesFilter \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng Cinder Scheduler Weights : m\u1eb7c \u0111\u1ecbnh option CapacityWeigher \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng 2.1 . B\u1eadt DriverFilter v\u00e0 GoodnessWeigher \u00b6 \u0110\u1ec3 enable driver filter s\u1eed d\u1ee5ng option scheduler_default_filters = DriverFilter , \u0111\u1ec3 s\u1eed d\u1ee5ng GoodnessWeigher s\u1eed d\u1ee5ng option scheduler_default_weighers = GoodnessWeigher . [DEFAULT] .... scheduler_driver = cinder.scheduler.filter_scheduler.FilterScheduler scheduler_default_filters = DriverFilter 2.2 . \u0110\u1ecbnh ngh\u0129a Filter function v\u00e0 Goodness function \u00b6 C\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ecbnh ngh\u0129a c\u00e1c filter v\u00e0 weigher . C\u00e1c thu\u1ed9c t\u00ednh t\u1ef1 \u0111\u1ecbnh ngh\u0129a n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi k\u00e8m v\u1ec1 request , sau \u0111\u00f3 s\u1ebd l\u00e0m vi\u1ec7c v\u1edbi scheduler Filter function s\u1ebd x\u00e1c \u0111\u1ecbnh c\u00e1c x\u00e1c \u0111\u1ecbnh back-end ph\u00f9 h\u1ee3p v\u1edbi c\u00e1c y\u00eau c\u1ea7u \u0111\u1ec3 \u0111\u1ea9y v\u00e0o qu\u00e1 tr\u00ecnh scheduler. Goodness function s\u1ebd \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng c\u1ee7a c\u00e1c host thu\u1ed9c back-end t\u1eeb qu\u00e1 tr\u00ecnh filter r\u1ed3i \u0111\u1ea9y v\u00e0o scheduler (0 to 100, 0 lowest, 100 highest). C\u00e1c ph\u00e9p to\u00e1n h\u1ed7 tr\u1ee3 trong qu\u00e1 tr\u00ecnh filtering C\u1ea5u h\u00ecnh filter_function cho LVM v\u00e0 NFS [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm filter_function = \"volume.size > 5 or volume.size = 5\" volume_backend_name = lvmdriver-1 [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = $state_path/mnt_nfs volume_backend_name = nfsdriver-1 filter_function = \"volume.size < 5\" Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 tr\u00ean Storage Node systemctl restart openstack-cinder-api.service systemctl restart lvm2-lvmetad.service systemctl start openstack-cinder-scheduler.service systemctl enable openstack-cinder-api.service systemctl enable openstack-cinder-scheduler.service 3. C\u1ea5u h\u00ecnh tr\u00ean Controller \u00b6 Ki\u1ec3m tra volume service [root@controller ~]# openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2018-12-21T07:04:31.000000 | | cinder-volume | cinder1@lvm | nova | enabled | up | 2018-12-21T07:04:33.000000 | | cinder-volume | cinder1@nfs | nova | enabled | up | 2018-12-21T07:04:35.000000 | | cinder-scheduler | cinder1 | nova | enabled | up | 2018-12-21T07:04:32.000000 | +------------------+-------------+------+---------+-------+----------------------------+ Kh\u1edfi t\u1ea1o \u1ed5 c\u1ee9ng tr\u00ean 5GB 2018-12-21 02:02:02.184 16688 DEBUG cinder.scheduler.host_manager [req-c02f5866-241a-47a6-823f- 06bd1fc91d1d - - - - -] Received volume service update from cinder1@nfs: {u'filter_function': u'volume.size >= 5', u'QoS_support': False, u'thick_provisioning_support': False, u'provisioned_capacity_gb': 10.0, u'allocated_capacity_gb': 10, u'volume_backend_name': u'nfs', u'thin_provisioning_support': True, u'free_capacity_gb': 33.87841796875, u'driver_version': u'1.4.0', u'total_capacity_gb': 36.974365234375, u'sparse_copy_volume': True, u'reserved_percentage': 0, u'goodness_function': None, u'max_over_subscription_ratio': 20.0, u'vendor_name': u'Open Source', u'storage_protocol': u'nfs'} update_service_capabilities /usr/lib/python2.7/site- packages/cinder/scheduler/host_manager.py:547 Kh\u1edfi t\u1ea1o \u1ed5 c\u1ee9ng d\u01b0\u1edbi 5GB 2018-12-21 02:03:25.229 16688 DEBUG cinder.scheduler.host_manager [req-4090a060-36a3-43ef-bdc3- fca6248f89db - - - - -] Received volume service update from cinder1@lvm: {u'filter_function': u'volume.size < 5', u'goodness_function': None, u'shared_targets': False, u'volume_backend_name': u'lvm', u'driver_version': u'3.0.0', u'sparse_copy_volume': True, u'pools': [{u'pool_name': u'lvm', u'filter_function': u'volume.size < 5', u'goodness_function': None, u'multiattach': True, u'total_volumes': 1, u'provisioned_capacity_gb': 0.0, u'allocated_capacity_gb': 0, u'thin_provisioning_support': True, u'free_capacity_gb': 26.6, u'location_info': u'LVMVolumeDriver:cinder1:cinder- volumes:thin:0', u'total_capacity_gb': 26.6, u'thick_provisioning_support': False, u'reserved_percentage': 0, u'QoS_support': False, u'max_over_subscription_ratio': u'20.0', u'backend_state': u'up'}], u'vendor_name': u'Open Source', u'storage_protocol': u'iSCSI'} update_service_capabilities /usr/lib/python2.7/site- packages/cinder/scheduler/host_manager.py:547","title":"6. Filtering Multi Backend"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#cau_hinh_multi_backend_scheduler_filter","text":"","title":"C\u1ea5u h\u00ecnh Multi Backend Scheduler Filter"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#1_introduction","text":"Openstack Block Storage cho ph\u00e9p l\u1ef1a ch\u1ecdn back-end storage d\u1ef1a v\u00e0o c\u00e1c c\u00e0i \u0111\u1eb7t b\u1ed5 sung d\u1ef1a v\u00e0o DriverFilter v\u00e0 GoodnessWeigher trong qu\u00e1 tringh schduler . Nh\u1edd v\u00e0o filter v\u00e0 weigher \u0111\u1ec3 ch\u1eafc ch\u1eafn scheduler l\u1ef1a ch\u1ecdn backend t\u1ed1t nh\u1ea5t tr\u00ean m\u1ed7i request \u0111\u01b0a v\u00e0o API","title":"1. Introduction"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#12_cinder_scheduler_filters","text":"AvailabilityZoneFilter : Filter b\u1eb1ng availability zone CapabilitiesFilter : Filter theo t\u00e0i nguy\u00ean (m\u00e1y \u1ea3o v\u00e0 volume) CapacityFilter : Filter d\u1ef1a v\u00e0o c\u00f4ng su\u1ea5t s\u1eed d\u1ee5ng c\u1ee7a volume backend DifferentBackendFilter : L\u00ean k\u1ebf ho\u1ea1ch \u0111\u1eb7t c\u00e1c volume \u1edf c\u00e1c backend kh\u00e1c nhau khi c\u00f3 1 danh s\u00e1ch c\u00e1c volume DriverFilter : D\u1ef1a v\u00e0o \u2018filter function\u2019 v\u00e0 metrics. InstanceLocalityFilter : l\u00ean k\u1ebf ho\u1ea1ch cho c\u00e1c volume tr\u00ean c\u00f9ng 1 host. \u0110\u1ec3 c\u00f3 th\u1ec3 d\u00f9ng filter n\u00e0y th\u00ec Extended Server Attributes c\u1ea7n \u0111\u01b0\u1ee3c b\u1eadt b\u1edfi nova v\u00e0 user s\u1eed d\u1ee5ng ph\u1ea3i \u0111\u01b0\u1ee3c khai b\u00e1o x\u00e1c th\u1ef1c tr\u00ean c\u1ea3 nova v\u00e0 cinder. JsonFilter : D\u1ef1a v\u00e0o JSON-based grammar \u0111\u1ec3 ch\u1ecdn l\u1ef1a backends RetryFilter : Filter nh\u1eefng node ch\u01b0a t\u1eebng \u0111\u01b0\u1ee3c schedule SameBackendFilter : L\u00ean k\u1ebf ho\u1ea1ch \u0111\u1eb7t c\u00e1c volume c\u00f3 c\u00f9ng backend nh\u01b0 nh\u1eefng volume kh\u00e1c.","title":"1.2 : Cinder Scheduler Filters"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#13_cinder_scheduler_weights","text":"AllocatedCapacityWeigher : Allocated Capacity Weigher s\u1ebd t\u00ednh tr\u1ecdng s\u1ed1 c\u1ee7a host b\u1eb1ng c\u00f4ng su\u1ea5t \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5. N\u00f3 s\u1ebd \u0111\u1eb7t volume v\u00e0o host \u0111\u01b0\u1ee3c khai b\u00e1o chi\u1ebfm \u00edt t\u00e0i nguy\u00ean nh\u1ea5t. CapacityWeigher : Tr\u1ea1ng th\u00e1i c\u00f4ng su\u1ea5t th\u1ef1c t\u1ebf ch\u01b0a \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. ChanceWeigher : T\u00ednh tr\u1ecdng s\u1ed1 random, d\u00f9ng \u0111\u1ec3 t\u1ea1o c\u00e1c volume khi c\u00e1c host g\u1ea7n gi\u1ed1ng nhau GoodnessWeigher : G\u00e1n tr\u1ecdng s\u1ed1 d\u1ef1a v\u00e0o goodness function.","title":"1.3 Cinder Scheduler Weights"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#2_cau_hinh_tren_cinder_node","text":"\u0110\u1ec3 c\u1ea5u h\u00ecnh Block Storage scheduler multi back end c\u1ea7n s\u1eed d\u1ee5ng option filter_scheduler . Trong filter scheduler : Cinder Scheduler Filters : m\u1eb7c \u0111\u1ecbnh c\u00e1c filter AvailabilityZoneFilter , CapacityFilter and CapabilitiesFilter \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng Cinder Scheduler Weights : m\u1eb7c \u0111\u1ecbnh option CapacityWeigher \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Cinder Node"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#21_bat_driverfilter_va_goodnessweigher","text":"\u0110\u1ec3 enable driver filter s\u1eed d\u1ee5ng option scheduler_default_filters = DriverFilter , \u0111\u1ec3 s\u1eed d\u1ee5ng GoodnessWeigher s\u1eed d\u1ee5ng option scheduler_default_weighers = GoodnessWeigher . [DEFAULT] .... scheduler_driver = cinder.scheduler.filter_scheduler.FilterScheduler scheduler_default_filters = DriverFilter","title":"2.1 . B\u1eadt DriverFilter  v\u00e0 GoodnessWeigher"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#22_inh_nghia_filter_function_va_goodness_function","text":"C\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ecbnh ngh\u0129a c\u00e1c filter v\u00e0 weigher . C\u00e1c thu\u1ed9c t\u00ednh t\u1ef1 \u0111\u1ecbnh ngh\u0129a n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi k\u00e8m v\u1ec1 request , sau \u0111\u00f3 s\u1ebd l\u00e0m vi\u1ec7c v\u1edbi scheduler Filter function s\u1ebd x\u00e1c \u0111\u1ecbnh c\u00e1c x\u00e1c \u0111\u1ecbnh back-end ph\u00f9 h\u1ee3p v\u1edbi c\u00e1c y\u00eau c\u1ea7u \u0111\u1ec3 \u0111\u1ea9y v\u00e0o qu\u00e1 tr\u00ecnh scheduler. Goodness function s\u1ebd \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng c\u1ee7a c\u00e1c host thu\u1ed9c back-end t\u1eeb qu\u00e1 tr\u00ecnh filter r\u1ed3i \u0111\u1ea9y v\u00e0o scheduler (0 to 100, 0 lowest, 100 highest). C\u00e1c ph\u00e9p to\u00e1n h\u1ed7 tr\u1ee3 trong qu\u00e1 tr\u00ecnh filtering C\u1ea5u h\u00ecnh filter_function cho LVM v\u00e0 NFS [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm filter_function = \"volume.size > 5 or volume.size = 5\" volume_backend_name = lvmdriver-1 [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = $state_path/mnt_nfs volume_backend_name = nfsdriver-1 filter_function = \"volume.size < 5\" Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 tr\u00ean Storage Node systemctl restart openstack-cinder-api.service systemctl restart lvm2-lvmetad.service systemctl start openstack-cinder-scheduler.service systemctl enable openstack-cinder-api.service systemctl enable openstack-cinder-scheduler.service","title":"2.2 . \u0110\u1ecbnh ngh\u0129a Filter function  v\u00e0 Goodness function"},{"location":"Openstack_Research/Cinder/6. Filtering-Multi-Backend/#3_cau_hinh_tren_controller","text":"Ki\u1ec3m tra volume service [root@controller ~]# openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2018-12-21T07:04:31.000000 | | cinder-volume | cinder1@lvm | nova | enabled | up | 2018-12-21T07:04:33.000000 | | cinder-volume | cinder1@nfs | nova | enabled | up | 2018-12-21T07:04:35.000000 | | cinder-scheduler | cinder1 | nova | enabled | up | 2018-12-21T07:04:32.000000 | +------------------+-------------+------+---------+-------+----------------------------+ Kh\u1edfi t\u1ea1o \u1ed5 c\u1ee9ng tr\u00ean 5GB 2018-12-21 02:02:02.184 16688 DEBUG cinder.scheduler.host_manager [req-c02f5866-241a-47a6-823f- 06bd1fc91d1d - - - - -] Received volume service update from cinder1@nfs: {u'filter_function': u'volume.size >= 5', u'QoS_support': False, u'thick_provisioning_support': False, u'provisioned_capacity_gb': 10.0, u'allocated_capacity_gb': 10, u'volume_backend_name': u'nfs', u'thin_provisioning_support': True, u'free_capacity_gb': 33.87841796875, u'driver_version': u'1.4.0', u'total_capacity_gb': 36.974365234375, u'sparse_copy_volume': True, u'reserved_percentage': 0, u'goodness_function': None, u'max_over_subscription_ratio': 20.0, u'vendor_name': u'Open Source', u'storage_protocol': u'nfs'} update_service_capabilities /usr/lib/python2.7/site- packages/cinder/scheduler/host_manager.py:547 Kh\u1edfi t\u1ea1o \u1ed5 c\u1ee9ng d\u01b0\u1edbi 5GB 2018-12-21 02:03:25.229 16688 DEBUG cinder.scheduler.host_manager [req-4090a060-36a3-43ef-bdc3- fca6248f89db - - - - -] Received volume service update from cinder1@lvm: {u'filter_function': u'volume.size < 5', u'goodness_function': None, u'shared_targets': False, u'volume_backend_name': u'lvm', u'driver_version': u'3.0.0', u'sparse_copy_volume': True, u'pools': [{u'pool_name': u'lvm', u'filter_function': u'volume.size < 5', u'goodness_function': None, u'multiattach': True, u'total_volumes': 1, u'provisioned_capacity_gb': 0.0, u'allocated_capacity_gb': 0, u'thin_provisioning_support': True, u'free_capacity_gb': 26.6, u'location_info': u'LVMVolumeDriver:cinder1:cinder- volumes:thin:0', u'total_capacity_gb': 26.6, u'thick_provisioning_support': False, u'reserved_percentage': 0, u'QoS_support': False, u'max_over_subscription_ratio': u'20.0', u'backend_state': u'up'}], u'vendor_name': u'Open Source', u'storage_protocol': u'iSCSI'} update_service_capabilities /usr/lib/python2.7/site- packages/cinder/scheduler/host_manager.py:547","title":"3. C\u1ea5u h\u00ecnh tr\u00ean Controller"},{"location":"Openstack_Research/Cinder/7. Cinder-More/","text":"C\u1ea5u h\u00ecnh b\u1ed5 sung trong Cinder \u00b6 1. T\u0103ng s\u1ed1 l\u01b0\u1ee3ng ti\u1ebfn tr\u00ecnh cho API Service \u00b6 M\u1eb7c \u0111\u1ecbnh , Block Storage API service s\u1ebd ch\u1ec9 chi\u1ebfm m\u1ed9t process . \u0110i\u1ec1u n\u00e0y ki\u1ebfn gi\u1edbi h\u1ea1n c\u00e1c API request trong m\u1ed9t th\u1eddi \u0111i\u1ec3m. Trong m\u00f4i tr\u01b0\u1eddng production , c\u00f3 th\u1ec3 \u0111i\u1ec1u ch\u1ec9nh l\u01b0u l\u01b0\u1ee3ng \u0111i qua Block Storage API nh\u1edd vi\u1ec7c t\u0103ng process c\u1ee7a \u0110\u1ec3 c\u1ea5u h\u00ecnh ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u00f9y ch\u1ecdn [DEFAULT] osapi_volume_workers CORES Trong \u0111\u00f3 : Cores l\u00e0 s\u1ed1 core / lu\u1ed3ng CPU v\u1eadt l\u00fd 2. Instance Volume \u00b6 M\u1eb7c \u0111\u1ecbnh trong Cinder s\u1ebd t\u00edch h\u1ee3p ISCSI \u0111\u1ec3 s\u1eed d\u1ee5ng LVM ( Logical Volume Manager ) Openstack Block Storage service kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p shared storage gi\u1ed1ng nh\u01b0 Network Attached Storage (NAS) c\u00f3 th\u1ec3 g\u1eafn nhi\u1ec1u volume v\u00e0o m\u1ed9t server. Trong Block Service ch\u1ec9 c\u00f3 th\u1ec3 g\u1eafn m\u1ed9t volume v\u00e0o m\u1ed9t instance tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m Khi s\u1eed d\u1ee5ng ISCSI , c\u00e1c storage node s\u1ebd kh\u1edfi t\u1ea1o m\u1ed9t ISCSI session v\u00e0 attack m\u1ed9t storage m\u1edbi c\u00f3 \u0111\u1ecbnh d\u1ea1ng ( /dev/sdX ) Khi s\u1eed d\u1ee5ng NFS , c\u00e1c storage s\u1ebd mount c\u00e1c NFS , m\u1ed7i instance s\u1ebd l\u00e0 m\u1ed9t volume , th\u01b0\u1eddng s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /var/lib/cinder/mnt - t\u00f9y c\u1ea5u h\u00ecnh Livirt s\u1ebd s\u1eed d\u1ee5ng storage n\u00e0y cho c\u00e1c c\u00e1c instance. C\u00e1c instance khi kh\u1edfi t\u1ea1o t\u1eeb volume s\u1ebd c\u00f3 \u0111\u1ecbnh d\u1ea1ng ( /dev/vdX ) 3. Get capabilities \u00b6 Khi c\u1ea5u h\u00ecnh volume type v\u00e0 extra spec c\u1ee7a m\u1ed9t storage back-end th\u00ec c\u1ea7n xem c\u00e1c kh\u1ea3 n\u0103ng c\u1ee7a backend , x\u00e1c \u0111\u1ecbnh back-end c\u00f3 \u0111\u1ee7 y\u00eau c\u1ea7u \u0111\u1ec1 ra L\u1ea5y danh s\u00e1ch service [root@controller ~]# openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2018-12-21T08:37:36.000000 | | cinder-volume | cinder1@lvm | nova | enabled | up | 2018-12-21T08:37:34.000000 | | cinder-volume | cinder1@nfs | nova | enabled | up | 2018-12-21T08:37:37.000000 | | cinder-scheduler | cinder1 | nova | enabled | up | 2018-12-21T08:37:33.000000 | +------------------+-------------+------+---------+-------+----------------------------+ Xem kh\u1ea3 n\u0103ng h\u1ed7 tr\u1ee3 c\u1ee5 th\u1ec3 tr\u00ean t\u1eebng cinder-volume host [root@controller ~]# cinder get-capabilities cinder1@nfs +---------------------+----------------------------------------+ | Volume stats | Value | +---------------------+----------------------------------------+ | description | None | | display_name | None | | driver_version | 1.4.0 | | namespace | OS::Storage::Capabilities::cinder1@nfs | | pool_name | None | | replication_targets | [] | | storage_protocol | nfs | | vendor_name | Open Source | | visibility | None | | volume_backend_name | nfsdriver-1 | +---------------------+----------------------------------------+ +---------------------+---------------------------------------+ | Backend properties | Value | +---------------------+---------------------------------------+ | compression | description : Enables compression. | | | title : Compression | | | type : boolean | | qos | description : Enables QoS. | | | title : QoS | | | type : boolean | | replication_enabled | description : Enables replication. | | | title : Replication | | | type : boolean | | thin_provisioning | description : Sets thin provisioning. | | | title : Thin Provisioning | | | type : boolean | +---------------------+---------------------------------------+ 4. Volume Group \u00b6 Ch\u1ee9c n\u0103ng n\u00e0y h\u1ed7 tr\u1ee3 t\u1ea1o m\u1ed9t group type ho\u1eb7c m\u1ed9t group spec , kh\u1edfi t\u1ea1o m\u1ed9t group c\u00e1c volume ho\u1eb7c snapshot. Group type gi\u1ed1ng nh\u01b0 volume type . M\u1ed7i group type c\u00f3 th\u1ec3 g\u1eafn c\u00e1c extra spec gi\u1ed1ng nh\u01b0 volume type . 5. Image-Volume cache \u00b6 Ch\u1ee9c n\u0103ng n\u00e0y cho ph\u00e9p c\u1ea3i thi\u1ec7n hi\u1ec7u n\u0103ng khi t\u1ea1o volume t\u1eeb image. L\u1ea7n \u0111\u1ea7u khi m\u1ed9t volume \u0111\u01b0\u1ee3c t\u1ea1o t\u1eeb image , th\u00ec m\u1ed9t cached image-volume \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o \u0111\u01b0\u1ee3c s\u1edf h\u1eefu b\u1edfi Block Storage internal project. Sau \u0111\u00f3 khi m\u1ed9t y\u00eau c\u1ea7u t\u1ea1o m\u1ed9t volume t\u1eeb image c\u0169 th\u00ec image s\u1ebd \u0111\u01b0\u1ee3c clone t\u1eeb cacher thay v\u00ec ph\u1ea3i download image t\u1eeb glance v\u1ec1 \u0110\u1ec3 s\u1eed d\u1ee5ng ch\u1ee9c n\u0103ng n\u00e0y . Block Storage service ph\u1ea3i c\u00f3 quy\u1ec1n truy c\u1eadp v\u00e0o Internal tenant. C\u1ea5u h\u00ecnh trong /etc/cinder/cinder.conf . User v\u00e0 project s\u1eed d\u1ee5ng cho q\u00faa tr\u00ecnh image-volume cache s\u1ebd kh\u00f4ng c\u1ea7n \u0111\u1eb7c quy\u1ec1n. cinder_internal_tenant_project_id = 9373ec3c823343de87ae613b972aa4d3 cinder_internal_tenant_user_id = 6ca03d3c55444c10aa22f481f2e13381 image_volume_cache_enabled = True","title":"7. Cinder More"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#cau_hinh_bo_sung_trong_cinder","text":"","title":"C\u1ea5u h\u00ecnh b\u1ed5 sung trong Cinder"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#1_tang_so_luong_tien_trinh_cho_api_service","text":"M\u1eb7c \u0111\u1ecbnh , Block Storage API service s\u1ebd ch\u1ec9 chi\u1ebfm m\u1ed9t process . \u0110i\u1ec1u n\u00e0y ki\u1ebfn gi\u1edbi h\u1ea1n c\u00e1c API request trong m\u1ed9t th\u1eddi \u0111i\u1ec3m. Trong m\u00f4i tr\u01b0\u1eddng production , c\u00f3 th\u1ec3 \u0111i\u1ec1u ch\u1ec9nh l\u01b0u l\u01b0\u1ee3ng \u0111i qua Block Storage API nh\u1edd vi\u1ec7c t\u0103ng process c\u1ee7a \u0110\u1ec3 c\u1ea5u h\u00ecnh ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u00f9y ch\u1ecdn [DEFAULT] osapi_volume_workers CORES Trong \u0111\u00f3 : Cores l\u00e0 s\u1ed1 core / lu\u1ed3ng CPU v\u1eadt l\u00fd","title":"1. T\u0103ng s\u1ed1 l\u01b0\u1ee3ng ti\u1ebfn tr\u00ecnh cho API Service"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#2_instance_volume","text":"M\u1eb7c \u0111\u1ecbnh trong Cinder s\u1ebd t\u00edch h\u1ee3p ISCSI \u0111\u1ec3 s\u1eed d\u1ee5ng LVM ( Logical Volume Manager ) Openstack Block Storage service kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p shared storage gi\u1ed1ng nh\u01b0 Network Attached Storage (NAS) c\u00f3 th\u1ec3 g\u1eafn nhi\u1ec1u volume v\u00e0o m\u1ed9t server. Trong Block Service ch\u1ec9 c\u00f3 th\u1ec3 g\u1eafn m\u1ed9t volume v\u00e0o m\u1ed9t instance tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m Khi s\u1eed d\u1ee5ng ISCSI , c\u00e1c storage node s\u1ebd kh\u1edfi t\u1ea1o m\u1ed9t ISCSI session v\u00e0 attack m\u1ed9t storage m\u1edbi c\u00f3 \u0111\u1ecbnh d\u1ea1ng ( /dev/sdX ) Khi s\u1eed d\u1ee5ng NFS , c\u00e1c storage s\u1ebd mount c\u00e1c NFS , m\u1ed7i instance s\u1ebd l\u00e0 m\u1ed9t volume , th\u01b0\u1eddng s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /var/lib/cinder/mnt - t\u00f9y c\u1ea5u h\u00ecnh Livirt s\u1ebd s\u1eed d\u1ee5ng storage n\u00e0y cho c\u00e1c c\u00e1c instance. C\u00e1c instance khi kh\u1edfi t\u1ea1o t\u1eeb volume s\u1ebd c\u00f3 \u0111\u1ecbnh d\u1ea1ng ( /dev/vdX )","title":"2.  Instance Volume"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#3_get_capabilities","text":"Khi c\u1ea5u h\u00ecnh volume type v\u00e0 extra spec c\u1ee7a m\u1ed9t storage back-end th\u00ec c\u1ea7n xem c\u00e1c kh\u1ea3 n\u0103ng c\u1ee7a backend , x\u00e1c \u0111\u1ecbnh back-end c\u00f3 \u0111\u1ee7 y\u00eau c\u1ea7u \u0111\u1ec1 ra L\u1ea5y danh s\u00e1ch service [root@controller ~]# openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2018-12-21T08:37:36.000000 | | cinder-volume | cinder1@lvm | nova | enabled | up | 2018-12-21T08:37:34.000000 | | cinder-volume | cinder1@nfs | nova | enabled | up | 2018-12-21T08:37:37.000000 | | cinder-scheduler | cinder1 | nova | enabled | up | 2018-12-21T08:37:33.000000 | +------------------+-------------+------+---------+-------+----------------------------+ Xem kh\u1ea3 n\u0103ng h\u1ed7 tr\u1ee3 c\u1ee5 th\u1ec3 tr\u00ean t\u1eebng cinder-volume host [root@controller ~]# cinder get-capabilities cinder1@nfs +---------------------+----------------------------------------+ | Volume stats | Value | +---------------------+----------------------------------------+ | description | None | | display_name | None | | driver_version | 1.4.0 | | namespace | OS::Storage::Capabilities::cinder1@nfs | | pool_name | None | | replication_targets | [] | | storage_protocol | nfs | | vendor_name | Open Source | | visibility | None | | volume_backend_name | nfsdriver-1 | +---------------------+----------------------------------------+ +---------------------+---------------------------------------+ | Backend properties | Value | +---------------------+---------------------------------------+ | compression | description : Enables compression. | | | title : Compression | | | type : boolean | | qos | description : Enables QoS. | | | title : QoS | | | type : boolean | | replication_enabled | description : Enables replication. | | | title : Replication | | | type : boolean | | thin_provisioning | description : Sets thin provisioning. | | | title : Thin Provisioning | | | type : boolean | +---------------------+---------------------------------------+","title":"3. Get capabilities"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#4_volume_group","text":"Ch\u1ee9c n\u0103ng n\u00e0y h\u1ed7 tr\u1ee3 t\u1ea1o m\u1ed9t group type ho\u1eb7c m\u1ed9t group spec , kh\u1edfi t\u1ea1o m\u1ed9t group c\u00e1c volume ho\u1eb7c snapshot. Group type gi\u1ed1ng nh\u01b0 volume type . M\u1ed7i group type c\u00f3 th\u1ec3 g\u1eafn c\u00e1c extra spec gi\u1ed1ng nh\u01b0 volume type .","title":"4. Volume Group"},{"location":"Openstack_Research/Cinder/7. Cinder-More/#5_image-volume_cache","text":"Ch\u1ee9c n\u0103ng n\u00e0y cho ph\u00e9p c\u1ea3i thi\u1ec7n hi\u1ec7u n\u0103ng khi t\u1ea1o volume t\u1eeb image. L\u1ea7n \u0111\u1ea7u khi m\u1ed9t volume \u0111\u01b0\u1ee3c t\u1ea1o t\u1eeb image , th\u00ec m\u1ed9t cached image-volume \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o \u0111\u01b0\u1ee3c s\u1edf h\u1eefu b\u1edfi Block Storage internal project. Sau \u0111\u00f3 khi m\u1ed9t y\u00eau c\u1ea7u t\u1ea1o m\u1ed9t volume t\u1eeb image c\u0169 th\u00ec image s\u1ebd \u0111\u01b0\u1ee3c clone t\u1eeb cacher thay v\u00ec ph\u1ea3i download image t\u1eeb glance v\u1ec1 \u0110\u1ec3 s\u1eed d\u1ee5ng ch\u1ee9c n\u0103ng n\u00e0y . Block Storage service ph\u1ea3i c\u00f3 quy\u1ec1n truy c\u1eadp v\u00e0o Internal tenant. C\u1ea5u h\u00ecnh trong /etc/cinder/cinder.conf . User v\u00e0 project s\u1eed d\u1ee5ng cho q\u00faa tr\u00ecnh image-volume cache s\u1ebd kh\u00f4ng c\u1ea7n \u0111\u1eb7c quy\u1ec1n. cinder_internal_tenant_project_id = 9373ec3c823343de87ae613b972aa4d3 cinder_internal_tenant_user_id = 6ca03d3c55444c10aa22f481f2e13381 image_volume_cache_enabled = True","title":"5. Image-Volume cache"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/","text":"OPENSTACK IMAGE - GLANCE \u00b6 1: Kh\u00e1i ni\u1ec7m \u00b6 Glance l\u00e0 Image services c\u1ee7a Openstack . D\u1ecbch v\u1ee5 n\u00e0y cung c\u1ea5p c\u00e1c virtual image cho c\u00e1c m\u00e1y \u1ea3o \u0111\u1ec3 bootable v\u00e0 \u0111\u1ec3 qu\u1ea3n l\u00fd volume snapshot. C\u00e1c volume snapshot c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ec3 backup ho\u1eb7c l\u00e0m template cho m\u00e1y \u1ea3o m\u1edbi. Glance \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 c\u00f3 th\u1ec3 l\u00e0 d\u1ecbch v\u1ee5 ho\u1ea1t \u0111\u1ed9ng \u0111\u1ed9c l\u1eadp cho s\u1ef1 c\u1ea7n thi\u1ebft c\u00e1c t\u1ed5 ch\u1ee9c l\u1edbn l\u01b0u tr\u1eef v\u00e0 qu\u1ea3n l\u00fd c\u00e1c disk image \u1ea3o. Glance cung c\u1ea5p RESTful API cho ph\u00e9p truy c\u1eadp VM image metadata. 2 : C\u00e1c th\u00e0nh ph\u1ea7n trong Glance \u00b6 Glance bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n sau : - openstack-glance-api : X\u1eed l\u00fd y\u00eau c\u1ea7u v\u00e0 iamge . S\u1eed d\u1ee5ng registry \u0111\u1ec3 l\u1ea5y th\u00f4ng tin image - openstack-glance-registry : qu\u1ea3n l\u00fd , l\u01b0u tr\u1eef, x\u1eed l\u00fd c\u00e1c metadata m\u1ed7i image - database : l\u01b0u tr\u0169 c\u00e1c metadata c\u1ee7a c\u00e1c images - mabbitmq-server : cung c\u1ea5p h\u00e0ng ch\u1edd AMQP. RabbitMQ (c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi c\u00e1c d\u1ecbch v\u1ee5 kh\u00e1c), l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c openstack service kh\u00e1c bao g\u1ed3m x\u1ebfp h\u00e0ng, ph\u00e2n ph\u1ed1i, b\u1ea3o m\u1eadt, qu\u1ea3n l\u00fd, ph\u00e2n c\u1ee5m v\u00e0 li\u00ean k\u1ebft. 3. Glance Architecture \u00b6 Glance c\u00f3 ki\u1ebfn tr\u00fac client-server v\u00e0 cung c\u1ea5p REST API th\u00f4ng qua \u0111\u00f3 y\u00eau c\u1ea7u t\u1edbi server \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n. Y\u00eau c\u1ea7u t\u1eeb client \u0111\u01b0\u1ee3c ti\u1ebfp nh\u1eadn th\u00f4ng qua REST API v\u00e0 \u0111\u1ee3i s\u1ef1 x\u00e1c th\u1ef1c c\u1ee7a Keystone. Keystone Domain controller qu\u1ea3n l\u00fd t\u1ea5t c\u1ea3 c\u00e1c t\u00e1c v\u1ee5 v\u1eadn h\u00e0nh b\u00ean trong. C\u00e1c t\u00e1c v\u1ee5 n\u00e0y chia th\u00e0nh c\u00e1c l\u1edbp, m\u1ed7i l\u1edbp tri\u1ec3n khai nhi\u1ec7m v\u1ee5 v\u1ee5 ri\u00eang c\u1ee7a ch\u00fang. Glance store driver l\u00e0 l\u1edbp giao ti\u1ebfp gi\u1eefa glane v\u00e0 c\u00e1c h\u1ec7 th\u1ed1ng backend b\u00ean ngo\u00e0i ho\u1eb7c h\u1ec7 th\u1ed1ng t\u1ec7p tin c\u1ee5c b\u1ed9, cung c\u1ea5p giao di\u1ec7n chung \u0111\u1ec3 truy c\u1eadp. Glance s\u1eed d\u1ee5ng SQL Database l\u00e0m \u0111i\u1ec3m truy c\u1eadp cho c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c trong h\u1ec7 th\u1ed1ng. Glance ti\u1ebfp nh\u1eadn c\u00e1c API request y\u00eau c\u1ea7u images t\u1eeb ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i ho\u1eb7c c\u00e1c nova component v\u00e0 costheer l\u01b0u tr\u1eef c\u00e1c file images trong h\u1ec7 th\u1ed1ng object storage Swift ho\u1eb7c c\u00e1c storage repos kh\u00e1c. Glance h\u1ed7 tr\u1ee3 c\u00e1c h\u1ec7 th\u1ed1ng backend l\u01b0u tr\u1eef sau: File system : Glance l\u01b0u tr\u1eef images c\u1ee7a c\u00e1c m\u00e1y \u1ea3o trong h\u1ec7 th\u1ed1ng t\u1ec7p tin th\u00f4ng th\u01b0\u1eddng theo m\u1eb7c \u0111\u1ecbnh, h\u1ed7 tr\u1ee3 \u0111\u1ecdc ghi c\u00e1c image files d\u1ec5 d\u00e0ng v\u00e0o h\u1ec7 th\u1ed1ng t\u1ec7p tin Object Storage : L\u00e0 h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef do OpenStack Swift cung c\u1ea5p - d\u1ecbch v\u1ee5 l\u01b0u tr\u1eef c\u00f3 t\u00ednh s\u1eb5n s\u00e0ng cao , l\u01b0u tr\u1eef c\u00e1c image d\u01b0\u1edbi d\u1ea1ng c\u00e1c object. BlockStorage H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef c\u00f3 t\u00ednh s\u1eb5n s\u00e0ng cao do OpenStack Cinder cung c\u1ea5p, l\u01b0u tr\u1eef c\u00e1c image d\u01b0\u1edbi d\u1ea1ng kh\u1ed1i VMWare Amazon S3 HTTP : Glance c\u00f3 th\u1ec3 \u0111\u1ecdc c\u00e1c images c\u1ee7a c\u00e1c m\u00e1y \u1ea3o s\u1eb5n s\u00e0ng tr\u00ean Internet th\u00f4ng qua HTTP. H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef n\u00e0y ch\u1ec9 cho ph\u00e9p \u0111\u1ecdc. RADOS Block Device(RBD) : L\u01b0u tr\u1eef c\u00e1c images trong c\u1ee5m l\u01b0u tr\u1eef Ceph s\u1eed d\u1ee5ng giao di\u1ec7n RBD c\u1ee7a Ceph Sheepdog : H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef ph\u00e2n t\u00e1n d\u00e0nh cho QEMU/KVM GridFS : L\u01b0u tr\u1eef c\u00e1c image s\u1eed d\u1ee5ng MongoDB 4. \u0110\u1ecbnh d\u1ea1ng h\u1ed7 tr\u1ee3 \u00b6 Khi upload m\u1ed9t image l\u00ean Glance, ta c\u1ea7n x\u00e1c \u0111\u1ecbnh \u0111\u1ecbnh d\u1ea1ng c\u1ee7a image m\u00e1y \u1ea3o VM. Glance h\u1ed7 tr\u1ee3 nhi\u1ec1u lo\u1ea1i \u0111\u1ecbnh d\u1ea1ng \u0111\u0129a (iamge format) v\u00e0 \u0111\u1ecbnh d\u1ea1ng container (Container format). Disk Format bao g\u1ed3m : - aki :An Amazon kernel image. ami :An Amazon machine image. ari : An Amazon ramdisk image. iso : An archive format for the data contents of an optical disc, such as CD-ROM. qcow2 : Supported by the QEMU emulator that can expand dynamically and supports Copy on Write. raw : An unstructured disk image format; if you have a file without an extension it is possibly a raw format. vdi : Supported by VirtualBox virtual machine monitor and the QEMU emulator. vhd : The VHD disk format, a common disk format used by virtual machine monitors from VMware, Xen, Microsoft, VirtualBox, and others. vhdx : The VHDX disk format, an enhanced version of the VHD format, which supports larger disk sizes among other features. vmdk : Vmware Container format bao g\u1ed3m : aki : An Amazon kernel image. ami :An Amazon machine image. ari : An Amazon ramdisk image. bare: The image does not have a container or metadata envelope. docker: A docker container format. ova :An OVF package in a tarfile. ovf : The OVF container format. 5. Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a image trong Glance \u00b6 Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a Glance cho bi\u1ebft tr\u1ea1ng th\u00e1i c\u1ee7a image trong qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean. Khi t\u1ea1o m\u1ed9t image, b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean l\u00e0 queing, image \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o h\u00e0ng \u0111\u1ee3i trong m\u1ed9t kho\u1ea3ng th\u1eddi gian ng\u1eafn, \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 v\u00e0 s\u1eb5n s\u00e0ng \u0111\u1ec3 t\u1ea3i l\u00ean. Sau khi queuing, image chuy\u1ec3n sang tr\u1ea1ng th\u00e1i saving ngh\u0129a l\u00e0 qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean ch\u01b0a ho\u00e0n th\u00e0nh. M\u1ed9t khi image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean ho\u00e0n to\u00e0n, tr\u1ea1ng th\u00e1i image chuy\u1ec3n sang Active. Khi qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean th\u1ea5t b\u1ea1i n\u00f3 s\u1ebd chuy\u1ec3n sang tr\u1ea1ng th\u00e1i b\u1ecb h\u1ee7y ho\u1eb7c b\u1ecb x\u00f3a. Ta c\u00f3 th\u1ec3 deactive v\u00e0 reactive c\u00e1c image \u0111\u00e3 upload th\u00e0nh c\u00f4ng b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng command. Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a flow \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 theo h\u00ecnh sau: C\u00e1c tr\u1ea1ng th\u00e1i c\u1ee7a image: queued \u0110\u1ecbnh danh c\u1ee7a image \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 trong Glance registry. Kh\u00f4ng c\u00f3 d\u1eef li\u1ec7u n\u00e0o c\u1ee7a image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean Glance v\u00e0 k\u00edch th\u01b0\u1edbc c\u1ee7a image kh\u00f4ng \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp r\u00f5 r\u00e0ng s\u1ebd \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp v\u1ec1 zero khi kh\u1edfi t\u1ea1o. saving Tr\u1ea1ng th\u00e1i n\u00e0y bi\u1ec3u th\u1ecb r\u1eb1ng d\u1eef li\u1ec7u th\u00f4 c\u1ee7a image \u0111ang upload l\u00ean Glance. Khi image \u0111\u01b0\u1ee3c \u0111\u0103ng k\u00fd v\u1edbi l\u1eddi g\u1ecdi POST /images v\u00e0 c\u00f3 m\u1ed9t header \u0111\u1ea1i di\u1ec7n x-image-meta-location, image \u0111\u00f3 s\u1ebd kh\u00f4ng bao gi\u1edd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0 tr\u1ea1ng th\u00e1i \"saving\" (b\u1edfi v\u00ec d\u1eef li\u1ec7u c\u1ee7a image \u0111\u00e3 c\u00f3 s\u1eb5n \u1edf m\u1ed9t n\u01a1i n\u00e0o \u0111\u00f3) active Bi\u1ec3u th\u1ecb r\u1eb1ng m\u1ed9t image \u0111\u00e3 s\u1eb5n s\u00e0ng trong Glance. Tr\u1ea1ng th\u00e1i n\u00e0y \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp khi d\u1eef li\u1ec7u c\u1ee7a image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean ho\u00e0n to\u00e0n. deactivated Tr\u1ea1ng th\u00e1i bi\u1ec3u th\u1ecb vi\u1ec7c kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p truy c\u1eadp v\u00e0o d\u1eef li\u1ec7u c\u1ee7a image v\u1edbi t\u00e0i kho\u1ea3n kh\u00f4ng ph\u1ea3i admin. Khi image \u1edf tr\u1ea1ng th\u00e1i n\u00e0y, ta kh\u00f4ng th\u1ec3 t\u1ea3i xu\u1ed1ng c\u0169ng nh\u01b0 export hay clone image. killed Tr\u1ea1ng th\u00e1i bi\u1ec3u th\u1ecb r\u1eb1ng c\u00f3 v\u1ea5n \u0111\u1ec1 x\u1ea3y ra trong qu\u00e1 tr\u00ecnh t\u1ea3i d\u1eef li\u1ec7u c\u1ee7a image l\u00ean v\u00e0 image \u0111\u00f3 kh\u00f4ng th\u1ec3 \u0111\u1ecdc \u0111\u01b0\u1ee3c deleted Tr\u1ea1ng th\u00e1i n\u00e0y bi\u1ec3u th\u1ecb vi\u1ec7c Glance v\u1eabn gi\u1eef th\u00f4ng tin v\u1ec1 image nh\u01b0ng n\u00f3 kh\u00f4ng c\u00f2n s\u1eb5n s\u00e0ng \u0111\u1ec3 s\u1eed d\u1ee5ng n\u1eefa. Image \u1edf tr\u1ea1ng th\u00e1i n\u00e0y s\u1ebd t\u1ef1 \u0111\u1ed9ng b\u1ecb g\u1ee1 b\u1ecf v\u00e0o ng\u00e0y h\u00f4m sau. pending_delete : T\u01b0\u01a1ng t\u1ef1 nh\u01b0 tr\u1ea1ng th\u00e1i deleted, tuy nhi\u00ean Glance ch\u01b0a g\u1ee1 b\u1ecf d\u1eef li\u1ec7u c\u1ee7a image ngay. M\u1ed9t image khi \u0111\u00e3 r\u01a1i v\u00e0o tr\u1ea1ng th\u00e1i n\u00e0y s\u1ebd kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng kh\u00f4i ph\u1ee5c. 6. Tham kh\u1ea3o \u00b6 https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Glance/docs/1.Tim_hieu_Glance_trong_Openstack.md# https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/6/html-single/Component_Overview/index.html#section-image https://docs.openstack.org/image-guide/image-formats.html","title":"OPENSTACK IMAGE - GLANCE"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#openstack_image_-_glance","text":"","title":"OPENSTACK IMAGE - GLANCE"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#1_khai_niem","text":"Glance l\u00e0 Image services c\u1ee7a Openstack . D\u1ecbch v\u1ee5 n\u00e0y cung c\u1ea5p c\u00e1c virtual image cho c\u00e1c m\u00e1y \u1ea3o \u0111\u1ec3 bootable v\u00e0 \u0111\u1ec3 qu\u1ea3n l\u00fd volume snapshot. C\u00e1c volume snapshot c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ec3 backup ho\u1eb7c l\u00e0m template cho m\u00e1y \u1ea3o m\u1edbi. Glance \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 c\u00f3 th\u1ec3 l\u00e0 d\u1ecbch v\u1ee5 ho\u1ea1t \u0111\u1ed9ng \u0111\u1ed9c l\u1eadp cho s\u1ef1 c\u1ea7n thi\u1ebft c\u00e1c t\u1ed5 ch\u1ee9c l\u1edbn l\u01b0u tr\u1eef v\u00e0 qu\u1ea3n l\u00fd c\u00e1c disk image \u1ea3o. Glance cung c\u1ea5p RESTful API cho ph\u00e9p truy c\u1eadp VM image metadata.","title":"1: Kh\u00e1i ni\u1ec7m"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#2_cac_thanh_phan_trong_glance","text":"Glance bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n sau : - openstack-glance-api : X\u1eed l\u00fd y\u00eau c\u1ea7u v\u00e0 iamge . S\u1eed d\u1ee5ng registry \u0111\u1ec3 l\u1ea5y th\u00f4ng tin image - openstack-glance-registry : qu\u1ea3n l\u00fd , l\u01b0u tr\u1eef, x\u1eed l\u00fd c\u00e1c metadata m\u1ed7i image - database : l\u01b0u tr\u0169 c\u00e1c metadata c\u1ee7a c\u00e1c images - mabbitmq-server : cung c\u1ea5p h\u00e0ng ch\u1edd AMQP. RabbitMQ (c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi c\u00e1c d\u1ecbch v\u1ee5 kh\u00e1c), l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c openstack service kh\u00e1c bao g\u1ed3m x\u1ebfp h\u00e0ng, ph\u00e2n ph\u1ed1i, b\u1ea3o m\u1eadt, qu\u1ea3n l\u00fd, ph\u00e2n c\u1ee5m v\u00e0 li\u00ean k\u1ebft.","title":"2 : C\u00e1c th\u00e0nh ph\u1ea7n trong Glance"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#3_glance_architecture","text":"Glance c\u00f3 ki\u1ebfn tr\u00fac client-server v\u00e0 cung c\u1ea5p REST API th\u00f4ng qua \u0111\u00f3 y\u00eau c\u1ea7u t\u1edbi server \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n. Y\u00eau c\u1ea7u t\u1eeb client \u0111\u01b0\u1ee3c ti\u1ebfp nh\u1eadn th\u00f4ng qua REST API v\u00e0 \u0111\u1ee3i s\u1ef1 x\u00e1c th\u1ef1c c\u1ee7a Keystone. Keystone Domain controller qu\u1ea3n l\u00fd t\u1ea5t c\u1ea3 c\u00e1c t\u00e1c v\u1ee5 v\u1eadn h\u00e0nh b\u00ean trong. C\u00e1c t\u00e1c v\u1ee5 n\u00e0y chia th\u00e0nh c\u00e1c l\u1edbp, m\u1ed7i l\u1edbp tri\u1ec3n khai nhi\u1ec7m v\u1ee5 v\u1ee5 ri\u00eang c\u1ee7a ch\u00fang. Glance store driver l\u00e0 l\u1edbp giao ti\u1ebfp gi\u1eefa glane v\u00e0 c\u00e1c h\u1ec7 th\u1ed1ng backend b\u00ean ngo\u00e0i ho\u1eb7c h\u1ec7 th\u1ed1ng t\u1ec7p tin c\u1ee5c b\u1ed9, cung c\u1ea5p giao di\u1ec7n chung \u0111\u1ec3 truy c\u1eadp. Glance s\u1eed d\u1ee5ng SQL Database l\u00e0m \u0111i\u1ec3m truy c\u1eadp cho c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c trong h\u1ec7 th\u1ed1ng. Glance ti\u1ebfp nh\u1eadn c\u00e1c API request y\u00eau c\u1ea7u images t\u1eeb ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i ho\u1eb7c c\u00e1c nova component v\u00e0 costheer l\u01b0u tr\u1eef c\u00e1c file images trong h\u1ec7 th\u1ed1ng object storage Swift ho\u1eb7c c\u00e1c storage repos kh\u00e1c. Glance h\u1ed7 tr\u1ee3 c\u00e1c h\u1ec7 th\u1ed1ng backend l\u01b0u tr\u1eef sau: File system : Glance l\u01b0u tr\u1eef images c\u1ee7a c\u00e1c m\u00e1y \u1ea3o trong h\u1ec7 th\u1ed1ng t\u1ec7p tin th\u00f4ng th\u01b0\u1eddng theo m\u1eb7c \u0111\u1ecbnh, h\u1ed7 tr\u1ee3 \u0111\u1ecdc ghi c\u00e1c image files d\u1ec5 d\u00e0ng v\u00e0o h\u1ec7 th\u1ed1ng t\u1ec7p tin Object Storage : L\u00e0 h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef do OpenStack Swift cung c\u1ea5p - d\u1ecbch v\u1ee5 l\u01b0u tr\u1eef c\u00f3 t\u00ednh s\u1eb5n s\u00e0ng cao , l\u01b0u tr\u1eef c\u00e1c image d\u01b0\u1edbi d\u1ea1ng c\u00e1c object. BlockStorage H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef c\u00f3 t\u00ednh s\u1eb5n s\u00e0ng cao do OpenStack Cinder cung c\u1ea5p, l\u01b0u tr\u1eef c\u00e1c image d\u01b0\u1edbi d\u1ea1ng kh\u1ed1i VMWare Amazon S3 HTTP : Glance c\u00f3 th\u1ec3 \u0111\u1ecdc c\u00e1c images c\u1ee7a c\u00e1c m\u00e1y \u1ea3o s\u1eb5n s\u00e0ng tr\u00ean Internet th\u00f4ng qua HTTP. H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef n\u00e0y ch\u1ec9 cho ph\u00e9p \u0111\u1ecdc. RADOS Block Device(RBD) : L\u01b0u tr\u1eef c\u00e1c images trong c\u1ee5m l\u01b0u tr\u1eef Ceph s\u1eed d\u1ee5ng giao di\u1ec7n RBD c\u1ee7a Ceph Sheepdog : H\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef ph\u00e2n t\u00e1n d\u00e0nh cho QEMU/KVM GridFS : L\u01b0u tr\u1eef c\u00e1c image s\u1eed d\u1ee5ng MongoDB","title":"3. Glance Architecture"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#4_inh_dang_ho_tro","text":"Khi upload m\u1ed9t image l\u00ean Glance, ta c\u1ea7n x\u00e1c \u0111\u1ecbnh \u0111\u1ecbnh d\u1ea1ng c\u1ee7a image m\u00e1y \u1ea3o VM. Glance h\u1ed7 tr\u1ee3 nhi\u1ec1u lo\u1ea1i \u0111\u1ecbnh d\u1ea1ng \u0111\u0129a (iamge format) v\u00e0 \u0111\u1ecbnh d\u1ea1ng container (Container format). Disk Format bao g\u1ed3m : - aki :An Amazon kernel image. ami :An Amazon machine image. ari : An Amazon ramdisk image. iso : An archive format for the data contents of an optical disc, such as CD-ROM. qcow2 : Supported by the QEMU emulator that can expand dynamically and supports Copy on Write. raw : An unstructured disk image format; if you have a file without an extension it is possibly a raw format. vdi : Supported by VirtualBox virtual machine monitor and the QEMU emulator. vhd : The VHD disk format, a common disk format used by virtual machine monitors from VMware, Xen, Microsoft, VirtualBox, and others. vhdx : The VHDX disk format, an enhanced version of the VHD format, which supports larger disk sizes among other features. vmdk : Vmware Container format bao g\u1ed3m : aki : An Amazon kernel image. ami :An Amazon machine image. ari : An Amazon ramdisk image. bare: The image does not have a container or metadata envelope. docker: A docker container format. ova :An OVF package in a tarfile. ovf : The OVF container format.","title":"4. \u0110\u1ecbnh d\u1ea1ng h\u1ed7 tr\u1ee3"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#5_luong_trang_thai_cua_image_trong_glance","text":"Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a Glance cho bi\u1ebft tr\u1ea1ng th\u00e1i c\u1ee7a image trong qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean. Khi t\u1ea1o m\u1ed9t image, b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean l\u00e0 queing, image \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o h\u00e0ng \u0111\u1ee3i trong m\u1ed9t kho\u1ea3ng th\u1eddi gian ng\u1eafn, \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 v\u00e0 s\u1eb5n s\u00e0ng \u0111\u1ec3 t\u1ea3i l\u00ean. Sau khi queuing, image chuy\u1ec3n sang tr\u1ea1ng th\u00e1i saving ngh\u0129a l\u00e0 qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean ch\u01b0a ho\u00e0n th\u00e0nh. M\u1ed9t khi image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean ho\u00e0n to\u00e0n, tr\u1ea1ng th\u00e1i image chuy\u1ec3n sang Active. Khi qu\u00e1 tr\u00ecnh t\u1ea3i l\u00ean th\u1ea5t b\u1ea1i n\u00f3 s\u1ebd chuy\u1ec3n sang tr\u1ea1ng th\u00e1i b\u1ecb h\u1ee7y ho\u1eb7c b\u1ecb x\u00f3a. Ta c\u00f3 th\u1ec3 deactive v\u00e0 reactive c\u00e1c image \u0111\u00e3 upload th\u00e0nh c\u00f4ng b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng command. Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a flow \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 theo h\u00ecnh sau: C\u00e1c tr\u1ea1ng th\u00e1i c\u1ee7a image: queued \u0110\u1ecbnh danh c\u1ee7a image \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 trong Glance registry. Kh\u00f4ng c\u00f3 d\u1eef li\u1ec7u n\u00e0o c\u1ee7a image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean Glance v\u00e0 k\u00edch th\u01b0\u1edbc c\u1ee7a image kh\u00f4ng \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp r\u00f5 r\u00e0ng s\u1ebd \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp v\u1ec1 zero khi kh\u1edfi t\u1ea1o. saving Tr\u1ea1ng th\u00e1i n\u00e0y bi\u1ec3u th\u1ecb r\u1eb1ng d\u1eef li\u1ec7u th\u00f4 c\u1ee7a image \u0111ang upload l\u00ean Glance. Khi image \u0111\u01b0\u1ee3c \u0111\u0103ng k\u00fd v\u1edbi l\u1eddi g\u1ecdi POST /images v\u00e0 c\u00f3 m\u1ed9t header \u0111\u1ea1i di\u1ec7n x-image-meta-location, image \u0111\u00f3 s\u1ebd kh\u00f4ng bao gi\u1edd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0 tr\u1ea1ng th\u00e1i \"saving\" (b\u1edfi v\u00ec d\u1eef li\u1ec7u c\u1ee7a image \u0111\u00e3 c\u00f3 s\u1eb5n \u1edf m\u1ed9t n\u01a1i n\u00e0o \u0111\u00f3) active Bi\u1ec3u th\u1ecb r\u1eb1ng m\u1ed9t image \u0111\u00e3 s\u1eb5n s\u00e0ng trong Glance. Tr\u1ea1ng th\u00e1i n\u00e0y \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp khi d\u1eef li\u1ec7u c\u1ee7a image \u0111\u01b0\u1ee3c t\u1ea3i l\u00ean ho\u00e0n to\u00e0n. deactivated Tr\u1ea1ng th\u00e1i bi\u1ec3u th\u1ecb vi\u1ec7c kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p truy c\u1eadp v\u00e0o d\u1eef li\u1ec7u c\u1ee7a image v\u1edbi t\u00e0i kho\u1ea3n kh\u00f4ng ph\u1ea3i admin. Khi image \u1edf tr\u1ea1ng th\u00e1i n\u00e0y, ta kh\u00f4ng th\u1ec3 t\u1ea3i xu\u1ed1ng c\u0169ng nh\u01b0 export hay clone image. killed Tr\u1ea1ng th\u00e1i bi\u1ec3u th\u1ecb r\u1eb1ng c\u00f3 v\u1ea5n \u0111\u1ec1 x\u1ea3y ra trong qu\u00e1 tr\u00ecnh t\u1ea3i d\u1eef li\u1ec7u c\u1ee7a image l\u00ean v\u00e0 image \u0111\u00f3 kh\u00f4ng th\u1ec3 \u0111\u1ecdc \u0111\u01b0\u1ee3c deleted Tr\u1ea1ng th\u00e1i n\u00e0y bi\u1ec3u th\u1ecb vi\u1ec7c Glance v\u1eabn gi\u1eef th\u00f4ng tin v\u1ec1 image nh\u01b0ng n\u00f3 kh\u00f4ng c\u00f2n s\u1eb5n s\u00e0ng \u0111\u1ec3 s\u1eed d\u1ee5ng n\u1eefa. Image \u1edf tr\u1ea1ng th\u00e1i n\u00e0y s\u1ebd t\u1ef1 \u0111\u1ed9ng b\u1ecb g\u1ee1 b\u1ecf v\u00e0o ng\u00e0y h\u00f4m sau. pending_delete : T\u01b0\u01a1ng t\u1ef1 nh\u01b0 tr\u1ea1ng th\u00e1i deleted, tuy nhi\u00ean Glance ch\u01b0a g\u1ee1 b\u1ecf d\u1eef li\u1ec7u c\u1ee7a image ngay. M\u1ed9t image khi \u0111\u00e3 r\u01a1i v\u00e0o tr\u1ea1ng th\u00e1i n\u00e0y s\u1ebd kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng kh\u00f4i ph\u1ee5c.","title":"5. Lu\u1ed3ng tr\u1ea1ng th\u00e1i c\u1ee7a image trong Glance"},{"location":"Openstack_Research/Glance/1. Introduction-Glance/#6_tham_khao","text":"https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Glance/docs/1.Tim_hieu_Glance_trong_Openstack.md# https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/6/html-single/Component_Overview/index.html#section-image https://docs.openstack.org/image-guide/image-formats.html","title":"6. Tham kh\u1ea3o"},{"location":"Openstack_Research/Glance/2. Install Glance/","text":"C\u00e0i \u0111\u1eb7t Glance - Openstack IMAGE \u00b6 2. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Memcached \u00b6 2.1. Gi\u1edbi thi\u1ec7u Memcached \u00b6 Memcached l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef b\u1ea3n sao c\u00e1c \u0111\u1ed1i t\u01b0\u1ee3ng (objects) v\u00e0 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c truy c\u1eadp nhi\u1ec1u l\u1ea7n \u0111\u1ec3 t\u0103ng t\u1ed1c \u0111\u1ed9c truy xu\u1ea5t. M\u1ee5c \u0111\u00edch ch\u00ednh c\u1ee7a n\u00f3 l\u00e0 \u0111\u1ec3 t\u0103ng t\u1ed1c \u0111\u1ed9 \u1ee9ng d\u1ee5ng web b\u1eb1ng c\u00e1ch truy v\u1ea5n c\u01a1 s\u1edf d\u1eef li\u1ec7u b\u1ed9 nh\u1edb \u0111\u1ec7m, n\u1ed9i dung, ho\u1eb7c k\u1ebft qu\u1ea3 t\u00ednh to\u00e1n kh\u00e1c. Trong Openstack Indentity Service , memcached \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 cache token, th\u01b0\u1eddng \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t tr\u00ean Controller Node 2.2. C\u00e0i \u0111\u1eb7t Memcached \u00b6 C\u00e0i \u0111\u1eb7t package yum install memcached python-memcached Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable memcached.service systemctl start memcached.service 3. C\u00e0i \u0111\u1eb7t , c\u1ea5u h\u00ecnh Glance \u00b6 3.1. C\u1ea5u h\u00ecnh DB, User, Service \u00b6 Kh\u1edfi t\u1ea1o database [root@localhost ~]# mysql -u root --password=123@123Aa -e \"create database glance\" [root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'localhost' IDENTIFIED BY 'glance_123' \" [root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'%' IDENTIFIED BY 'glance_123'\" Kh\u1edfi t\u1ea1o ng\u01b0\u1eddi d\u00f9ng , glance service entity v\u00e0 g\u1eafn quy\u1ec1n [root@localhost ~]# openstack user create --domain default glance --password glance_123 +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 8bb5b9ee5e7e46f5a669cc5a11d468dc | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ [root@localhost ~]# openstack service create --name glance --des \"Openstack Image -- Glance\" image +-------------+----------------------------------+ | Field | Value |[root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'%' IDENTIFIED BY 'glance_123@123Aa'\" +-------------+----------------------------------+ | description | Openstack Image -- Glance | | enabled | True | | id | 4de24c47507d482c9274a9f9a23c986c | | name | glance | | type | image | +-------------+----------------------------------+ [root@localhost ~]# openstack role add --project service --user glance admin Kh\u1edfi t\u1ea1o API endpoint : public , internal, admin [root@localhost ~]# openstack endpoint create --region RegionOne image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 9579f05b41f84e2a8d3309a81adee83e | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@localhost ~]# openstack endpoint create --region RegionOne image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 6de4f423b9894deebd364c8d049df393 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@localhost ~]# openstack endpoint create --region RegionOne image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 39fa1756a5a84c6782f13f7cbdc80b0c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ 3.2. C\u00e0i \u0111\u1eb7t , c\u1ea5u h\u00ecnh Glance \u00b6 C\u00e0i \u0111\u1eb7t package yum install openstack-glance C\u1ea5u h\u00ecnh Glance API trong file /etc/glance/glance-api.conf crudini --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:glance_123@controller/glance set1=(auth_uri auth_url memcached_servers auth_type project_domain_name user_domain_name project_name username password ) set2=(http://controller:5000 http://controller:5000 controller:11211 password Default Default service glance glance_123) id_set2=0 for i in \"${set1[@]}\" do echo $i ${set2[id_set2]} crudini --set /etc/glance/glance-api.conf keystone_authtoken $i ${set2[id_set2]} let id_set2+=1 done crudini --set /etc/glance/glance-api.conf paste_deploy flavor keystone crudini --set /etc/glance/glance-api.conf glance_store stores file,http crudini --set /etc/glance/glance-api.conf glance_store default_store file crudini --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/ C\u1ea5u h\u00ecnh Glance Registry trong /etc/glance/glance-registry.conf crudini --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:glance_123@controller/glance set1=(auth_uri auth_url memcached_servers auth_type project_domain_name user_domain_name project_name username password ) set2=(http://controller:5000 http://controller:5000 controller:11211 password Default Default service glance glance_123@) id_set2=0 for i in \"${set1[@]}\" do echo $i ${set2[id_set2]} crudini --set /etc/glance/glance-registry.conf keystone_authtoken $i ${set2[id_set2]} let id_set2+=1 done crudini --set /etc/glance/glance-registry.conf paste_deploy flavor keystone \u0110\u1ed3ng b\u1ed9 h\u00f3a d\u1eef li\u1ec7u \u0111\u1ebfn DB su -s /bin/sh -c \"glance-manage db_sync\" glance Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-glance-api.service \\ openstack-glance-registry.service systemctl start openstack-glance-api.service \\ openstack-glance-registry.service C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-port={11211/tcp,9191/tcp,9292/tcp} --permanent firewall-cmd --reload","title":"C\u00e0i \u0111\u1eb7t Glance - Openstack IMAGE"},{"location":"Openstack_Research/Glance/2. Install Glance/#cai_at_glance_-_openstack_image","text":"","title":"C\u00e0i \u0111\u1eb7t Glance - Openstack IMAGE"},{"location":"Openstack_Research/Glance/2. Install Glance/#2_cai_at_cau_hinh_memcached","text":"","title":"2. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Memcached"},{"location":"Openstack_Research/Glance/2. Install Glance/#21_gioi_thieu_memcached","text":"Memcached l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef b\u1ea3n sao c\u00e1c \u0111\u1ed1i t\u01b0\u1ee3ng (objects) v\u00e0 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c truy c\u1eadp nhi\u1ec1u l\u1ea7n \u0111\u1ec3 t\u0103ng t\u1ed1c \u0111\u1ed9c truy xu\u1ea5t. M\u1ee5c \u0111\u00edch ch\u00ednh c\u1ee7a n\u00f3 l\u00e0 \u0111\u1ec3 t\u0103ng t\u1ed1c \u0111\u1ed9 \u1ee9ng d\u1ee5ng web b\u1eb1ng c\u00e1ch truy v\u1ea5n c\u01a1 s\u1edf d\u1eef li\u1ec7u b\u1ed9 nh\u1edb \u0111\u1ec7m, n\u1ed9i dung, ho\u1eb7c k\u1ebft qu\u1ea3 t\u00ednh to\u00e1n kh\u00e1c. Trong Openstack Indentity Service , memcached \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 cache token, th\u01b0\u1eddng \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t tr\u00ean Controller Node","title":"2.1. Gi\u1edbi thi\u1ec7u Memcached"},{"location":"Openstack_Research/Glance/2. Install Glance/#22_cai_at_memcached","text":"C\u00e0i \u0111\u1eb7t package yum install memcached python-memcached Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable memcached.service systemctl start memcached.service","title":"2.2. C\u00e0i \u0111\u1eb7t Memcached"},{"location":"Openstack_Research/Glance/2. Install Glance/#3_cai_at_cau_hinh_glance","text":"","title":"3. C\u00e0i \u0111\u1eb7t , c\u1ea5u h\u00ecnh Glance"},{"location":"Openstack_Research/Glance/2. Install Glance/#31_cau_hinh_db_user_service","text":"Kh\u1edfi t\u1ea1o database [root@localhost ~]# mysql -u root --password=123@123Aa -e \"create database glance\" [root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'localhost' IDENTIFIED BY 'glance_123' \" [root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'%' IDENTIFIED BY 'glance_123'\" Kh\u1edfi t\u1ea1o ng\u01b0\u1eddi d\u00f9ng , glance service entity v\u00e0 g\u1eafn quy\u1ec1n [root@localhost ~]# openstack user create --domain default glance --password glance_123 +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 8bb5b9ee5e7e46f5a669cc5a11d468dc | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ [root@localhost ~]# openstack service create --name glance --des \"Openstack Image -- Glance\" image +-------------+----------------------------------+ | Field | Value |[root@localhost ~]# mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES on glance.* to 'glance'@'%' IDENTIFIED BY 'glance_123@123Aa'\" +-------------+----------------------------------+ | description | Openstack Image -- Glance | | enabled | True | | id | 4de24c47507d482c9274a9f9a23c986c | | name | glance | | type | image | +-------------+----------------------------------+ [root@localhost ~]# openstack role add --project service --user glance admin Kh\u1edfi t\u1ea1o API endpoint : public , internal, admin [root@localhost ~]# openstack endpoint create --region RegionOne image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 9579f05b41f84e2a8d3309a81adee83e | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@localhost ~]# openstack endpoint create --region RegionOne image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 6de4f423b9894deebd364c8d049df393 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@localhost ~]# openstack endpoint create --region RegionOne image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 39fa1756a5a84c6782f13f7cbdc80b0c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 4de24c47507d482c9274a9f9a23c986c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+","title":"3.1. C\u1ea5u h\u00ecnh DB, User, Service"},{"location":"Openstack_Research/Glance/2. Install Glance/#32_cai_at_cau_hinh_glance","text":"C\u00e0i \u0111\u1eb7t package yum install openstack-glance C\u1ea5u h\u00ecnh Glance API trong file /etc/glance/glance-api.conf crudini --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:glance_123@controller/glance set1=(auth_uri auth_url memcached_servers auth_type project_domain_name user_domain_name project_name username password ) set2=(http://controller:5000 http://controller:5000 controller:11211 password Default Default service glance glance_123) id_set2=0 for i in \"${set1[@]}\" do echo $i ${set2[id_set2]} crudini --set /etc/glance/glance-api.conf keystone_authtoken $i ${set2[id_set2]} let id_set2+=1 done crudini --set /etc/glance/glance-api.conf paste_deploy flavor keystone crudini --set /etc/glance/glance-api.conf glance_store stores file,http crudini --set /etc/glance/glance-api.conf glance_store default_store file crudini --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/ C\u1ea5u h\u00ecnh Glance Registry trong /etc/glance/glance-registry.conf crudini --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:glance_123@controller/glance set1=(auth_uri auth_url memcached_servers auth_type project_domain_name user_domain_name project_name username password ) set2=(http://controller:5000 http://controller:5000 controller:11211 password Default Default service glance glance_123@) id_set2=0 for i in \"${set1[@]}\" do echo $i ${set2[id_set2]} crudini --set /etc/glance/glance-registry.conf keystone_authtoken $i ${set2[id_set2]} let id_set2+=1 done crudini --set /etc/glance/glance-registry.conf paste_deploy flavor keystone \u0110\u1ed3ng b\u1ed9 h\u00f3a d\u1eef li\u1ec7u \u0111\u1ebfn DB su -s /bin/sh -c \"glance-manage db_sync\" glance Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-glance-api.service \\ openstack-glance-registry.service systemctl start openstack-glance-api.service \\ openstack-glance-registry.service C\u1ea5u h\u00ecnh Firewalld firewall-cmd --add-port={11211/tcp,9191/tcp,9292/tcp} --permanent firewall-cmd --reload","title":"3.2. C\u00e0i \u0111\u1eb7t , c\u1ea5u h\u00ecnh Glance"},{"location":"Openstack_Research/Glance/3. Openstack-Glance-&-CURL/","text":"L\u00e0m vi\u1ec7c v\u1edbi Glance \u00b6 1. Thao t\u00e1c v\u1edbi Glance qua Openstack Client \u00b6 T\u1ea1o m\u1ed9t image m\u1edbi [root@localhost ~]# source ~/admin-openrc [root@localhost ~]# yum install wget -y [root@localhost ~]# wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img [root@localhost ~]# openstack image create \"cirros\" \\ > --file cirros-0.4.0-x86_64-disk.img \\ > --disk-format qcow2 --container-format bare \\ > --public +------------------+------------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------------+ | checksum | 443b7623e27ecf03dc9e01ee93f67afe | | container_format | bare | | created_at | 2018-11-05T04:11:06Z | | disk_format | qcow2 | | file | /v2/images/aa614334-8c0c-4e98-b692-85a42dbcb4fb/file | | id | aa614334-8c0c-4e98-b692-85a42dbcb4fb | | min_disk | 0 | | min_ram | 0 | | name | cirros | | owner | baedd3b48fbc4134ac1eba01798addea | | protected | False | | schema | /v2/schemas/image | | size | 12716032 | | status | active | | tags | | | updated_at | 2018-11-05T04:11:07Z | | virtual_size | None | | visibility | public | +------------------+------------------------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch image [root@localhost ~]# openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | aa614334-8c0c-4e98-b692-85a42dbcb4fb | cirros | active | +--------------------------------------+--------+--------+ Th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t image [root@localhost fernet-keys]# openstack image show cirror +------------------+------------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------------+ | checksum | ec508c1e3a5399ca60ae6e6d0feefc45 | | container_format | bare | | created_at | 2018-11-05T06:47:38Z | | disk_format | qcow2 | | file | /v2/images/8a37019d-3d85-416c-b903-615f437a6773/file | | id | 8a37019d-3d85-416c-b903-615f437a6773 | | min_disk | 0 | | min_ram | 0 | | name | cirror | | owner | baedd3b48fbc4134ac1eba01798addea | | protected | False | | schema | /v2/schemas/image | | size | 6472401 | | status | active | | tags | | | updated_at | 2018-11-05T06:48:06Z | | virtual_size | None | | visibility | shared | +------------------+------------------------------------------------------+ X\u00f3a m\u1ed9t image [root@localhost ~]# openstack image delete cirros [root@localhost ~]# openstack image list 2. L\u00e0m vi\u1ec7c v\u1edbi Glance qua CURL \u00b6 Kh\u1edfi t\u1ea1o token curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } }}}}' \\ http://localhost:5000/v3/auth/tokens | jq Kh\u1edfi t\u1ea1o m\u1ed9t image curl -s -H \"X-Auth-Token: $TOKEN\" \\ -d '{ \"container_format\": \"bare\", \"disk_format\": \"qcow2\", \"name\": \"cirror\" }' \\ http://controller:9292/v2/images | jq .id Sau khi kh\u1edfi t\u1ea1o image ch\u01b0a c\u00f3 data, upload data cho image curl -i -X PUT -H \"X-Auth-Token: $TOKEN\" \\ -H \"X-Image-Meta-Store: {store_identifier}\" \\ -H \"Content-Type: application/octet-stream\" \\ -d @/etc/glance/cirros-0.4.0-x86_64-disk.img \\ http://controller:9292/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file Li\u1ec7t k\u00ea danh s\u00e1ch image [root@localhost fernet-keys]# curl -s -H \"X-Auth-Token: $TOKEN\" http://controller:9292/v2/images | jq { \"images\": [ { \"status\": \"active\", \"name\": \"cirror\", \"tags\": [], \"container_format\": \"bare\", \"created_at\": \"2018-11-05T06:47:38Z\", \"size\": 6472401, \"disk_format\": \"qcow2\", \"updated_at\": \"2018-11-05T06:48:06Z\", \"visibility\": \"shared\", \"self\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773\", \"min_disk\": 0, \"protected\": false, \"id\": \"8a37019d-3d85-416c-b903-615f437a6773\", \"file\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file\", \"checksum\": \"ec508c1e3a5399ca60ae6e6d0feefc45\", \"owner\": \"baedd3b48fbc4134ac1eba01798addea\", \"virtual_size\": null, \"min_ram\": 0, \"schema\": \"/v2/schemas/image\" } ],image \"schema\": \"/v2/schemas/images\", \"first\": \"/v2/images\" } Th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t image [root@localhost fernet-keys]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:9292/v2/images/8a37019d-3d85-416c-b903-615f437a6773 | jq { \"status\": \"active\", \"name\": \"cirror\", \"tags\": [], \"container_format\": \"bare\", \"created_at\": \"2018-11-05T06:47:38Z\", \"size\": 6472401, \"disk_format\": \"qcow2\", \"updated_at\": \"2018-11-05T06:48:06Z\", \"visibility\": \"shared\", \"self\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773\", \"min_disk\": 0, \"protected\": false, \"id\": \"8a37019d-3d85-416c-b903-615f437a6773\", \"file\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file\", \"checksum\": \"ec508c1e3a5399ca60ae6e6d0feefc45\", \"owner\": \"baedd3b48fbc4134ac1eba01798addea\", \"virtual_size\": null, \"min_ram\": 0, \"schema\": \"/v2/schemas/image\" }","title":"L\u00e0m vi\u1ec7c v\u1edbi Glance"},{"location":"Openstack_Research/Glance/3. Openstack-Glance-&-CURL/#lam_viec_voi_glance","text":"","title":"L\u00e0m vi\u1ec7c v\u1edbi Glance"},{"location":"Openstack_Research/Glance/3. Openstack-Glance-&-CURL/#1_thao_tac_voi_glance_qua_openstack_client","text":"T\u1ea1o m\u1ed9t image m\u1edbi [root@localhost ~]# source ~/admin-openrc [root@localhost ~]# yum install wget -y [root@localhost ~]# wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img [root@localhost ~]# openstack image create \"cirros\" \\ > --file cirros-0.4.0-x86_64-disk.img \\ > --disk-format qcow2 --container-format bare \\ > --public +------------------+------------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------------+ | checksum | 443b7623e27ecf03dc9e01ee93f67afe | | container_format | bare | | created_at | 2018-11-05T04:11:06Z | | disk_format | qcow2 | | file | /v2/images/aa614334-8c0c-4e98-b692-85a42dbcb4fb/file | | id | aa614334-8c0c-4e98-b692-85a42dbcb4fb | | min_disk | 0 | | min_ram | 0 | | name | cirros | | owner | baedd3b48fbc4134ac1eba01798addea | | protected | False | | schema | /v2/schemas/image | | size | 12716032 | | status | active | | tags | | | updated_at | 2018-11-05T04:11:07Z | | virtual_size | None | | visibility | public | +------------------+------------------------------------------------------+ Li\u1ec7t k\u00ea danh s\u00e1ch image [root@localhost ~]# openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | aa614334-8c0c-4e98-b692-85a42dbcb4fb | cirros | active | +--------------------------------------+--------+--------+ Th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t image [root@localhost fernet-keys]# openstack image show cirror +------------------+------------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------------+ | checksum | ec508c1e3a5399ca60ae6e6d0feefc45 | | container_format | bare | | created_at | 2018-11-05T06:47:38Z | | disk_format | qcow2 | | file | /v2/images/8a37019d-3d85-416c-b903-615f437a6773/file | | id | 8a37019d-3d85-416c-b903-615f437a6773 | | min_disk | 0 | | min_ram | 0 | | name | cirror | | owner | baedd3b48fbc4134ac1eba01798addea | | protected | False | | schema | /v2/schemas/image | | size | 6472401 | | status | active | | tags | | | updated_at | 2018-11-05T06:48:06Z | | virtual_size | None | | visibility | shared | +------------------+------------------------------------------------------+ X\u00f3a m\u1ed9t image [root@localhost ~]# openstack image delete cirros [root@localhost ~]# openstack image list","title":"1. Thao t\u00e1c v\u1edbi Glance qua Openstack Client"},{"location":"Openstack_Research/Glance/3. Openstack-Glance-&-CURL/#2_lam_viec_voi_glance_qua_curl","text":"Kh\u1edfi t\u1ea1o token curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } }}}}' \\ http://localhost:5000/v3/auth/tokens | jq Kh\u1edfi t\u1ea1o m\u1ed9t image curl -s -H \"X-Auth-Token: $TOKEN\" \\ -d '{ \"container_format\": \"bare\", \"disk_format\": \"qcow2\", \"name\": \"cirror\" }' \\ http://controller:9292/v2/images | jq .id Sau khi kh\u1edfi t\u1ea1o image ch\u01b0a c\u00f3 data, upload data cho image curl -i -X PUT -H \"X-Auth-Token: $TOKEN\" \\ -H \"X-Image-Meta-Store: {store_identifier}\" \\ -H \"Content-Type: application/octet-stream\" \\ -d @/etc/glance/cirros-0.4.0-x86_64-disk.img \\ http://controller:9292/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file Li\u1ec7t k\u00ea danh s\u00e1ch image [root@localhost fernet-keys]# curl -s -H \"X-Auth-Token: $TOKEN\" http://controller:9292/v2/images | jq { \"images\": [ { \"status\": \"active\", \"name\": \"cirror\", \"tags\": [], \"container_format\": \"bare\", \"created_at\": \"2018-11-05T06:47:38Z\", \"size\": 6472401, \"disk_format\": \"qcow2\", \"updated_at\": \"2018-11-05T06:48:06Z\", \"visibility\": \"shared\", \"self\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773\", \"min_disk\": 0, \"protected\": false, \"id\": \"8a37019d-3d85-416c-b903-615f437a6773\", \"file\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file\", \"checksum\": \"ec508c1e3a5399ca60ae6e6d0feefc45\", \"owner\": \"baedd3b48fbc4134ac1eba01798addea\", \"virtual_size\": null, \"min_ram\": 0, \"schema\": \"/v2/schemas/image\" } ],image \"schema\": \"/v2/schemas/images\", \"first\": \"/v2/images\" } Th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t image [root@localhost fernet-keys]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:9292/v2/images/8a37019d-3d85-416c-b903-615f437a6773 | jq { \"status\": \"active\", \"name\": \"cirror\", \"tags\": [], \"container_format\": \"bare\", \"created_at\": \"2018-11-05T06:47:38Z\", \"size\": 6472401, \"disk_format\": \"qcow2\", \"updated_at\": \"2018-11-05T06:48:06Z\", \"visibility\": \"shared\", \"self\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773\", \"min_disk\": 0, \"protected\": false, \"id\": \"8a37019d-3d85-416c-b903-615f437a6773\", \"file\": \"/v2/images/8a37019d-3d85-416c-b903-615f437a6773/file\", \"checksum\": \"ec508c1e3a5399ca60ae6e6d0feefc45\", \"owner\": \"baedd3b48fbc4134ac1eba01798addea\", \"virtual_size\": null, \"min_ram\": 0, \"schema\": \"/v2/schemas/image\" }","title":"2. L\u00e0m vi\u1ec7c v\u1edbi Glance qua CURL"},{"location":"Openstack_Research/Glance/4. Config/","text":"T\u00ecm hi\u1ec3u c\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n trong Glance \u00b6 1. C\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n \u00b6 Trong Glance c\u00f3 r\u1ea5t nhi\u1ec1u t\u1eadp tin c\u1ea5u h\u00ecnh cho API Server, Registry server v\u00e0 h\u00e0ng lo\u1ea1t backend \u0111\u1ec3 l\u01b0u tr\u1eef c\u00e1c glance image Khi kh\u1edfi \u0111\u1ed9ng Glance Server , th\u00ec c\u00e1c file c\u1ea5u h\u00ecnh c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c load t\u1eeb c\u00e1c \u0111\u01b0\u1eddng d\u1eabn sau : ~/.glance ~/ /etc/glance /etc \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00f9y ch\u1ecdn \u0111\u01b0\u1ee3c folder c\u00f3 th\u1ec3 load \u0111\u01b0\u1ee3c c\u00e1c file *.conf l\u00e0m c\u00e1c section c\u1ea5u h\u00ecnh c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng glance-api --config-dir=/etc/glance/glance-api.d 2. C\u00e1c file c\u1ea5u h\u00ecnh \u00b6 Trong Glance g\u1ed3m c\u00e1c file c\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n sau : glance-api.conf : File c\u1ea5u h\u00ecnh cho c\u00e1c API c\u1ee7a image service. glance-registry.conf : File c\u1ea5u h\u00ecnh cho glance image registry - n\u01a1i l\u01b0u tr\u1eef metadata v\u1ec1 c\u00e1c images. glance-api-paste.ini : C\u1ea5u h\u00ecnh cho c\u00e1c API middleware pipeline c\u1ee7a Image service glance-manage.conf : L\u00e0 t\u1ec7p c\u1ea5u h\u00ecnh ghi ch\u00e9p t\u00f9y ch\u1ec9nh. C\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance- manage.conf s\u1ebd ghi \u0111\u00e8 l\u00ean c\u00e1c section c\u00f9ng t\u00ean thi\u1ebft l\u1eadp trong c\u00e1c t\u1ec7p glance-registry.conf v\u00e0 glance-api.conf. T\u01b0\u01a1ng t\u1ef1 nh\u01b0 v\u1eady, c\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance-api.conf s\u1ebd ghi \u0111\u00e8 l\u00ean c\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance-registry.conf glance-registry-paste.ini : T\u1ec7p c\u1ea5u h\u00ecnh middle pipeline cho c\u00e1c registry c\u1ee7a Image service. glance-scrubber.conf : Ti\u1ec7n \u00edch s\u1eed d\u1ee5ng \u0111\u1ec3 d\u1ecdn s\u1ea1ch c\u00e1c images \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i \"deleted\" . Nhi\u1ec1u glance-scrubber c\u00f3 th\u1ec3 ch\u1ea1y trong tri\u1ec3n khai, tuy nhi\u00ean ch\u1ec9 c\u00f3 m\u1ed9t scrubber \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp \u0111\u1ec3 \"d\u1ecdn d\u1eb9p\" c\u1ea5u h\u00ecnh trong file \"scrubber.conf\" . Clean-up scrubber n\u00e0y k\u1ebft h\u1ee3p v\u1edbi c\u00e1c scrubber kh\u00e1c b\u1eb1ng c\u00e1ch duy tr\u00ec m\u1ed9t h\u00e0ng \u0111\u1ee3i ch\u00ednh c\u1ee7a c\u00e1c images c\u1ea7n \u0111\u01b0\u1ee3c lo\u1ea1i b\u1ecf. T\u1ec7p glance-scrubber.conf c\u0169ng \u0111\u1eb7c t\u1ea3 c\u1ea5u h\u00ecnh c\u00e1c gi\u00e1 tr\u1ecb quan tr\u1ecdng nh\u01b0 kho\u1ea3ng th\u1eddi gian gi\u1eefa c\u00e1c l\u1ea7n ch\u1ea1y, th\u1eddi gian ch\u1edd c\u1ee7a c\u00e1c images tr\u01b0\u1edbc khi b\u1ecb x\u00f3a. Glance-scrubber c\u00f3 th\u1ec3 ch\u1ea1y theo \u0111\u1ecbnh k\u1ef3 ho\u1eb7c c\u00f3 th\u1ec3 ch\u1ea1y nh\u01b0 m\u1ed9t daemon trong kho\u1ea3ng th\u1eddi gian d\u00e0i. policy.json : File t\u00f9y ch\u1ecdn \u0111\u01b0\u1ee3c th\u00eam v\u00e0o \u0111\u1ec3 \u0111i\u1ec1u khi\u1ec3n truy c\u1eadp \u00e1p d\u1ee5ng v\u1edbi image service. Trong file n\u00e0y ta c\u00f3 th\u1ec3 \u0111\u1ecbnh ngh\u0129a c\u00e1c roles v\u00e0 policies. \u0110\u00f3 l\u00e0 t\u00ednh n\u0103ng b\u1ea3o m\u1eadt trong OpenStack Glance. 3. C\u1ea5u h\u00ecnh LOG \u00b6 M\u1eb7c \u0111\u1ecbnh trong GLANCE s\u1ebd c\u00f3 2 file l\u01b0u l\u1ea1i LOG cho d\u1ecbch v\u1ee5 API Server v\u00e0 Registry Server glance-api.log : ghi c\u00e1c log, warning \u0111\u1ebfn truy c\u1eadp v\u00e0 c\u1ea5u h\u00ecnh cho API Server glance-registry.log : ghi c\u00e1c log, warning \u0111\u1ebfn truy c\u1eadp v\u00e0 c\u1ea5u h\u00ecnh cho Registry Server \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00f9y ch\u1ecdn file LOG cho t\u1eebng service c\u00f3 th\u1ec3 file c\u1ea5u h\u00ecnh m\u00e0 \u0111\u1ebfn section Default , m\u00e0 t\u00f9y ch\u1ec9nh t\u1eadp tin ch\u1ee9a LOG #log_file = <None> 4. C\u1ea5u h\u00ecnh Storage Backend \u00b6 M\u1eb7c \u0111\u1ecbnh Glance s\u1ebd ti\u1ebfn h\u00e0nh c\u00e1c image t\u1ea1i filesystem /var/lib/images \u0110\u1ec3 ch\u1ec9nh s\u1eeda \u0111\u01b0\u1ee3c backend cho GLANCE c\u00f3 th\u1ec3 ch\u1ec9nh s\u1eeda default_store trong file glance-api.conf Hi\u1ec7n Glance \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c backend sau \u0111\u1ec3 l\u01b0u tr\u1eef disk iamge : file, http, swift , rbd, sheepdog, cinder, vmware 5. C\u1ea5u h\u00ecnh User image quota \u00b6 C\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh gi\u1edbi h\u1ea1n t\u1ea1i section DEFAULT trong file c\u1ea5u h\u00ecnh glance-api.conf #user_storage_quota = 0 Gi\u00e1 tr\u1ecb n\u00e0y x\u00e1c \u0111\u1ecbnh l\u01b0\u1ee3ng data nhi\u1ec1u nh\u1ea5t m\u00e0 user c\u00f3 th\u1ec3 l\u01b0u tr\u1eef trong h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef. (\u0111\u01a1n v\u1ecb l\u00e0 B, KB, MB, GB ho\u1eb7c TB t\u01b0\u01a1ng \u1ee9ng cho Byte, Kilobyte, megabyte, Gigabyte v\u00e0 terabyte; n\u1ebfu kh\u00f4ng c\u00f3 \u0111\u01a1n v\u1ecb th\u00ec m\u1eb7c \u0111\u1ecbnh l\u00e0 byte). 5. C\u1ea5u h\u00ecnh Image Cache \u00b6 Glance Local Cache s\u1ebd t\u1ea1o ra c\u00e1c b\u1ea3n copy c\u1ee7a m\u1ed9t image, cho ph\u00e9p m\u1ed7i API Endpoint s\u1ebd truy c\u1eadp v\u00e0o m\u1ed9t b\u1ea3n copy c\u1ee7a Image tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m. 5.1. Qu\u1ea3n l\u00fd glance image cache \u00b6 \u0110\u1ec3 k\u00edch ho\u1ea1t hay t\u1eaft glance cache, ti\u1ebfn h\u00e0nh c\u1ea5u h\u00ecnh trong file /etc/glance/glance-api.conf \u0110\u1ec3 k\u00edch ho\u1ea1t cached \u0111i t\u01a1i section paste_deploy : [paste_deploy] flavor = keystone+cachemanagement T\u1eaft glance cache: [paste_deploy] flavor = keystone 6. C\u1ea5u h\u00ecnh image format \u00b6 Ch\u1ec9nh s\u1eeda trong section [image_format] trong file glance-api.conf C\u1ea5u h\u00ecnh c\u00e1c gi\u00e1 tr\u1ecb c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c li\u1ec7t k\u00ea, ph\u00e2n t\u00e1ch b\u1edfi d\u1ea5u \u201c,\u201d #container_formats = ami,ari,aki,bare,ovf,ova,docker - Li\u1ec7t k\u00ea c\u00e1c container_format \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3. #disk_formats = ami,ari,aki,vhd,vhdx,vmdk,raw,qcow2,vdi,iso,ploop","title":"T\u00ecm hi\u1ec3u c\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n trong Glance"},{"location":"Openstack_Research/Glance/4. Config/#tim_hieu_cau_hinh_co_ban_trong_glance","text":"","title":"T\u00ecm hi\u1ec3u c\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n trong Glance"},{"location":"Openstack_Research/Glance/4. Config/#1_cau_hinh_co_ban","text":"Trong Glance c\u00f3 r\u1ea5t nhi\u1ec1u t\u1eadp tin c\u1ea5u h\u00ecnh cho API Server, Registry server v\u00e0 h\u00e0ng lo\u1ea1t backend \u0111\u1ec3 l\u01b0u tr\u1eef c\u00e1c glance image Khi kh\u1edfi \u0111\u1ed9ng Glance Server , th\u00ec c\u00e1c file c\u1ea5u h\u00ecnh c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c load t\u1eeb c\u00e1c \u0111\u01b0\u1eddng d\u1eabn sau : ~/.glance ~/ /etc/glance /etc \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00f9y ch\u1ecdn \u0111\u01b0\u1ee3c folder c\u00f3 th\u1ec3 load \u0111\u01b0\u1ee3c c\u00e1c file *.conf l\u00e0m c\u00e1c section c\u1ea5u h\u00ecnh c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng glance-api --config-dir=/etc/glance/glance-api.d","title":"1. C\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n"},{"location":"Openstack_Research/Glance/4. Config/#2_cac_file_cau_hinh","text":"Trong Glance g\u1ed3m c\u00e1c file c\u1ea5u h\u00ecnh c\u01a1 b\u1ea3n sau : glance-api.conf : File c\u1ea5u h\u00ecnh cho c\u00e1c API c\u1ee7a image service. glance-registry.conf : File c\u1ea5u h\u00ecnh cho glance image registry - n\u01a1i l\u01b0u tr\u1eef metadata v\u1ec1 c\u00e1c images. glance-api-paste.ini : C\u1ea5u h\u00ecnh cho c\u00e1c API middleware pipeline c\u1ee7a Image service glance-manage.conf : L\u00e0 t\u1ec7p c\u1ea5u h\u00ecnh ghi ch\u00e9p t\u00f9y ch\u1ec9nh. C\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance- manage.conf s\u1ebd ghi \u0111\u00e8 l\u00ean c\u00e1c section c\u00f9ng t\u00ean thi\u1ebft l\u1eadp trong c\u00e1c t\u1ec7p glance-registry.conf v\u00e0 glance-api.conf. T\u01b0\u01a1ng t\u1ef1 nh\u01b0 v\u1eady, c\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance-api.conf s\u1ebd ghi \u0111\u00e8 l\u00ean c\u00e1c t\u00f9y ch\u1ecdn thi\u1ebft l\u1eadp trong t\u1ec7p glance-registry.conf glance-registry-paste.ini : T\u1ec7p c\u1ea5u h\u00ecnh middle pipeline cho c\u00e1c registry c\u1ee7a Image service. glance-scrubber.conf : Ti\u1ec7n \u00edch s\u1eed d\u1ee5ng \u0111\u1ec3 d\u1ecdn s\u1ea1ch c\u00e1c images \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i \"deleted\" . Nhi\u1ec1u glance-scrubber c\u00f3 th\u1ec3 ch\u1ea1y trong tri\u1ec3n khai, tuy nhi\u00ean ch\u1ec9 c\u00f3 m\u1ed9t scrubber \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp \u0111\u1ec3 \"d\u1ecdn d\u1eb9p\" c\u1ea5u h\u00ecnh trong file \"scrubber.conf\" . Clean-up scrubber n\u00e0y k\u1ebft h\u1ee3p v\u1edbi c\u00e1c scrubber kh\u00e1c b\u1eb1ng c\u00e1ch duy tr\u00ec m\u1ed9t h\u00e0ng \u0111\u1ee3i ch\u00ednh c\u1ee7a c\u00e1c images c\u1ea7n \u0111\u01b0\u1ee3c lo\u1ea1i b\u1ecf. T\u1ec7p glance-scrubber.conf c\u0169ng \u0111\u1eb7c t\u1ea3 c\u1ea5u h\u00ecnh c\u00e1c gi\u00e1 tr\u1ecb quan tr\u1ecdng nh\u01b0 kho\u1ea3ng th\u1eddi gian gi\u1eefa c\u00e1c l\u1ea7n ch\u1ea1y, th\u1eddi gian ch\u1edd c\u1ee7a c\u00e1c images tr\u01b0\u1edbc khi b\u1ecb x\u00f3a. Glance-scrubber c\u00f3 th\u1ec3 ch\u1ea1y theo \u0111\u1ecbnh k\u1ef3 ho\u1eb7c c\u00f3 th\u1ec3 ch\u1ea1y nh\u01b0 m\u1ed9t daemon trong kho\u1ea3ng th\u1eddi gian d\u00e0i. policy.json : File t\u00f9y ch\u1ecdn \u0111\u01b0\u1ee3c th\u00eam v\u00e0o \u0111\u1ec3 \u0111i\u1ec1u khi\u1ec3n truy c\u1eadp \u00e1p d\u1ee5ng v\u1edbi image service. Trong file n\u00e0y ta c\u00f3 th\u1ec3 \u0111\u1ecbnh ngh\u0129a c\u00e1c roles v\u00e0 policies. \u0110\u00f3 l\u00e0 t\u00ednh n\u0103ng b\u1ea3o m\u1eadt trong OpenStack Glance.","title":"2. C\u00e1c file c\u1ea5u h\u00ecnh"},{"location":"Openstack_Research/Glance/4. Config/#3_cau_hinh_log","text":"M\u1eb7c \u0111\u1ecbnh trong GLANCE s\u1ebd c\u00f3 2 file l\u01b0u l\u1ea1i LOG cho d\u1ecbch v\u1ee5 API Server v\u00e0 Registry Server glance-api.log : ghi c\u00e1c log, warning \u0111\u1ebfn truy c\u1eadp v\u00e0 c\u1ea5u h\u00ecnh cho API Server glance-registry.log : ghi c\u00e1c log, warning \u0111\u1ebfn truy c\u1eadp v\u00e0 c\u1ea5u h\u00ecnh cho Registry Server \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00f9y ch\u1ecdn file LOG cho t\u1eebng service c\u00f3 th\u1ec3 file c\u1ea5u h\u00ecnh m\u00e0 \u0111\u1ebfn section Default , m\u00e0 t\u00f9y ch\u1ec9nh t\u1eadp tin ch\u1ee9a LOG #log_file = <None>","title":"3. C\u1ea5u h\u00ecnh LOG"},{"location":"Openstack_Research/Glance/4. Config/#4_cau_hinh_storage_backend","text":"M\u1eb7c \u0111\u1ecbnh Glance s\u1ebd ti\u1ebfn h\u00e0nh c\u00e1c image t\u1ea1i filesystem /var/lib/images \u0110\u1ec3 ch\u1ec9nh s\u1eeda \u0111\u01b0\u1ee3c backend cho GLANCE c\u00f3 th\u1ec3 ch\u1ec9nh s\u1eeda default_store trong file glance-api.conf Hi\u1ec7n Glance \u0111ang h\u1ed7 tr\u1ee3 c\u00e1c backend sau \u0111\u1ec3 l\u01b0u tr\u1eef disk iamge : file, http, swift , rbd, sheepdog, cinder, vmware","title":"4. C\u1ea5u h\u00ecnh Storage Backend"},{"location":"Openstack_Research/Glance/4. Config/#5_cau_hinh_user_image_quota","text":"C\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh gi\u1edbi h\u1ea1n t\u1ea1i section DEFAULT trong file c\u1ea5u h\u00ecnh glance-api.conf #user_storage_quota = 0 Gi\u00e1 tr\u1ecb n\u00e0y x\u00e1c \u0111\u1ecbnh l\u01b0\u1ee3ng data nhi\u1ec1u nh\u1ea5t m\u00e0 user c\u00f3 th\u1ec3 l\u01b0u tr\u1eef trong h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef. (\u0111\u01a1n v\u1ecb l\u00e0 B, KB, MB, GB ho\u1eb7c TB t\u01b0\u01a1ng \u1ee9ng cho Byte, Kilobyte, megabyte, Gigabyte v\u00e0 terabyte; n\u1ebfu kh\u00f4ng c\u00f3 \u0111\u01a1n v\u1ecb th\u00ec m\u1eb7c \u0111\u1ecbnh l\u00e0 byte).","title":"5. C\u1ea5u h\u00ecnh User image quota"},{"location":"Openstack_Research/Glance/4. Config/#5_cau_hinh_image_cache","text":"Glance Local Cache s\u1ebd t\u1ea1o ra c\u00e1c b\u1ea3n copy c\u1ee7a m\u1ed9t image, cho ph\u00e9p m\u1ed7i API Endpoint s\u1ebd truy c\u1eadp v\u00e0o m\u1ed9t b\u1ea3n copy c\u1ee7a Image tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m.","title":"5. C\u1ea5u h\u00ecnh Image Cache"},{"location":"Openstack_Research/Glance/4. Config/#51_quan_ly_glance_image_cache","text":"\u0110\u1ec3 k\u00edch ho\u1ea1t hay t\u1eaft glance cache, ti\u1ebfn h\u00e0nh c\u1ea5u h\u00ecnh trong file /etc/glance/glance-api.conf \u0110\u1ec3 k\u00edch ho\u1ea1t cached \u0111i t\u01a1i section paste_deploy : [paste_deploy] flavor = keystone+cachemanagement T\u1eaft glance cache: [paste_deploy] flavor = keystone","title":"5.1. Qu\u1ea3n l\u00fd glance image cache"},{"location":"Openstack_Research/Glance/4. Config/#6_cau_hinh_image_format","text":"Ch\u1ec9nh s\u1eeda trong section [image_format] trong file glance-api.conf C\u1ea5u h\u00ecnh c\u00e1c gi\u00e1 tr\u1ecb c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c li\u1ec7t k\u00ea, ph\u00e2n t\u00e1ch b\u1edfi d\u1ea5u \u201c,\u201d #container_formats = ami,ari,aki,bare,ovf,ova,docker - Li\u1ec7t k\u00ea c\u00e1c container_format \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3. #disk_formats = ami,ari,aki,vhd,vhdx,vmdk,raw,qcow2,vdi,iso,ploop","title":"6. C\u1ea5u h\u00ecnh image format"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/","text":"Glance Advance \u00b6 1 . Instance and Image \u00b6 Khi m\u1ed9t m\u00e1y \u1ea3o kh\u1edfi \u0111\u1ed9ng, Image service s\u1ebd g\u1eedi disk image \u0111\u1ebfn compute node Th\u00f4ng th\u01b0\u1eddng , Compute service s\u1ebd g\u1eedi image indentifier t\u1edbi shuleder service v\u00e0 g\u1eedi request \u0111\u1ebfn Glance th\u00f4ng qua Glance API. - T\u00f9y v\u00e0o Glance Backend , Compute Node s\u1ebd k\u1ebft n\u1ed1i \u0111\u1ebfn Image Service v\u00e0 truy\u1ec1n nh\u1eadn Image N\u1ebfu s\u1eed d\u1ee5ng Object Storage Node l\u00e0m glance backend , v\u00e0 c\u00f3 k\u1ebft n\u1ed1i gi\u1eefa Object storage node v\u00e0 compute node. Tr\u00ean storage node c\u1ea5u h\u00ecnh my_block_storage_ip \u0111\u1ec3 cho ph\u00e9p compute node v\u00e0 storage node k\u1ebft n\u1ed1i v\u1edbi nhau M\u1ed9t s\u1ed1 backend h\u1ed7 tr\u1ee3 c\u00e1c ph\u01b0\u01a1ng th\u1ee9c tr\u1ef1c ti\u1ebfp , n\u01a1i n\u00e0o c\u00f3 request image service s\u1ebd tr\u1ea3 v\u1ec1 m\u1ed9t URL tr\u1ef1c ti\u1ebfp \u0111\u1ebfn back-end storage . C\u00e1c compoute node n\u1ebfu s\u1eed d\u1ee5ng glance cache c\u00f3 ngh\u0129a l\u00e0 n\u1ebfu image \u0111\u00e3 \u0111\u01b0\u1ee3c download 1 l\u1ea7n s\u1ebd kh\u00f4ng download trong l\u1ea7n ti\u1ebfp theo 2. Glance image cache \u00b6 Vi\u1ec7c k\u00edch ho\u1ea1t Glance cache th\u01b0\u1eddng \u0111\u01b0\u1ee3c khuy\u00ean khi s\u1eed d\u1ee5ng h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef m\u1eb7c \u0111\u1ecbnh l\u00e0 file, tuy nhi\u00ean n\u1ebfu s\u1eed d\u1ee5ng Ceph RBD backend s\u1ebd c\u00f3 m\u1ed9t s\u1ed1 kh\u00e1c bi\u1ec7t. K\u00edch ho\u1ea1t glance cache d\u1eabn t\u1edbi vi\u1ec7c t\u1ea1o ra cached c\u1ee7a image \u0111\u00f3 trong th\u01b0 m\u1ee5c /var/lib/glance/image-cache m\u1ed7i l\u1ea7n boot m\u00e1y \u1ea3o l\u00ean. Gi\u1ea3 s\u1eed ta c\u00f3 m\u1ed9t m\u00e1y \u1ea3o v\u1edbi k\u00edch th\u01b0\u1edbc VM image l\u00e0 c\u1ee1 50GB, n\u1ebfu nh\u01b0 m\u1ed7i l\u1ea7n boot m\u00e0 l\u1ea1i t\u1ea1o cached nh\u01b0 v\u00e2y, h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef s\u1ebd s\u1edbm b\u1ecb c\u1ea1n ki\u1ec7t, tr\u1eeb khi ta mount th\u01b0 m\u1ee5c /var v\u00e0o m\u1ed9t \u1ed5 l\u01b0u tr\u1eef l\u1edbn. Glance API server c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh \u0111\u1ec3 c\u00f3 th\u01b0 m\u1ee5c l\u01b0u tr\u1eef image cache local. M\u1ed9t th\u01b0c m\u1ee5c local image cache l\u01b0u tr\u1eef m\u1ed9t b\u1ea3n copy c\u1ee7a c\u00e1c image, v\u1ec1 c\u01a1 b\u1ea3n \u0111i\u1ec1u n\u00e0y cho ph\u00e9p nhi\u1ec1u API server ph\u1ee5c v\u1ee5 c\u00f9ng c\u00e1c file image gi\u1ed1ng nhau, \u0111\u1ec3 m\u1edf r\u1ed9ng kh\u1ea3 n\u0103ng ph\u1ee5c v\u1ee5 c\u1ee7a Glance. Local image cache l\u00e0 trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng. Ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c Glance API \u0111ang chuy\u1ec3n c\u00e1c file image t\u1eeb local cache hay t\u1eeb h\u1ec7 th\u1ed1ng backend l\u01b0u tr\u1eef th\u1ef1c s\u1ef1. Th\u1ef1c hi\u1ec7n c\u1ea5u h\u00ecnh glance-api h\u1ed7 tr\u1ee3 local image cache v\u00e0 s\u1eed d\u1ee5ng local image cache t\u1ea1i \u0111\u00e2y. 3. Glance Image Signing and Verification \u00b6 3.1. \u0110\u1eb7t v\u1ea5n \u0111\u1ec1 v\u1ec1 b\u1ea3o m\u1eadt v\u00e0 to\u00e0n v\u1eb9n Image \u00b6 Tr\u01b0\u1edbc b\u1ea3n ph\u00e1t h\u00e0nh Liberty, kh\u00f4ng h\u1ec1 c\u00f3 ph\u01b0\u01a1ng th\u1ee9c n\u00e0o cho c\u00e1c user \u0111\u1ec3 x\u00e1c nh\u1eadn r\u1eb1ng image h\u1ecd t\u1ea3i l\u00ean c\u00f3 b\u1ecb thay \u0111\u1ed5i hay kh\u00f4ng. M\u1ed9t image b\u1ecb thay \u0111\u1ed5i c\u00f3 th\u1ec3 x\u1ea3y ra trong qu\u00e1 tr\u00ecnh upload t\u1eeb user l\u00ean Glance ho\u1eb7c Glance chuy\u1ec3n image t\u1edbi Nova, ho\u1eb7c c\u0169ng c\u00f3 th\u1ec3 do ch\u00ednh Glance t\u1ef1 m\u00ecnh thay \u0111\u1ed5i m\u00e0 kh\u00f4ng c\u00f3 t\u00e1c \u0111\u1ed9ng t\u1eeb ph\u00eda ng\u01b0\u1eddi d\u00f9ng. M\u1ed9t image b\u1ecb thay \u0111\u1ed5i c\u00f3 th\u1ec3 ch\u1ee9a m\u00e3 \u0111\u1ed9c. B\u1edfi v\u1eady vi\u1ec7c cung c\u1ea5p c\u01a1 ch\u1ebf ch\u1eef k\u00fd s\u1ed1 cho image v\u00e0 x\u00e1c nh\u1eadn ch\u1eef k\u00fd s\u1ed1 cho ph\u00e9p user x\u00e1c nh\u1eadn xem image c\u00f3 b\u1ecb thay \u0111\u1ed5i kh\u00f4ng tr\u01b0\u1edbc khi boot image t\u1ea1o m\u00e1y \u1ea3o. T\u00ednh n\u0103ng n\u00e0y h\u1ed7 tr\u1ee3 m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p nh\u01b0 sau: M\u1ed9t image \u0111\u01b0\u1ee3c k\u00ed b\u1edfi end user, s\u1eed d\u1ee5ng private key (hi\u1ec3u l\u00e0 m\u00e3 h\u00f3a b\u1edfi private key). Sau \u0111\u00f3, user upload image l\u00ean Glance, c\u00f9ng v\u1edbi ch\u1eef k\u00ed v\u01b0a t\u1ea1o v\u00e0 public key certificate c\u1ee7a user. Glance s\u1eed d\u1ee5ng th\u00f4ng tin n\u00e0y \u0111\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd, v\u00e0 th\u00f4ng b\u00e1o t\u1edbi user n\u1ebfu ch\u1eef k\u00fd c\u00f3 b\u1ecb kh\u00f4ng x\u00e1c th\u1ef1c. M\u1ed9t image \u0111\u01b0\u1ee3c t\u1ea1o trong Nova, v\u00e0 Nova k\u00fd l\u00ean image t\u1ea1i request c\u1ee7a end user. Khi image \u0111\u01b0\u1ee3c upload l\u00ean Glance, ch\u1eef k\u00fd v\u00e0 public key certificate c\u0169ng \u0111\u01b0\u1ee3c cung c\u1ea5p. Glance x\u00e1c nh\u1eadn ch\u1eef k\u00fd tr\u01b0\u1edbc khi l\u01b0u tr\u1eef image, v\u00e0 th\u00f4ng b\u00e1o v\u1edbi Nova n\u1ebfu s\u1ef1 x\u00e1c th\u1ef1c x\u1ea3y ra l\u1ed7i. M\u1ed9t image \u0111\u00e3 \u0111\u01b0\u1ee3c k\u00fd \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u b\u1edfi Nova, v\u00e0 Glance cung c\u1ea5p ch\u1eef k\u00fd va public key certificate t\u1edbi Nova c\u00f9ng image \u0111\u1ec3 Nova c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd tr\u01b0\u1edbc khi booting image. 3.2. Qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd image trong Glance \u00b6 Nh\u1eefng phi\u00ean b\u1ea3n tri\u1ec3n khai \u0111\u1ea7u ti\u00ean trong Liberty, thay \u0111\u1ed5i n\u00e0y s\u1eed d\u1ee5ng t\u00ednh n\u0103ng c\u1ee7a Glance \u0111\u1ec3 l\u01b0u tr\u1eef metadate c\u00e2n thi\u1ebft cho vi\u1ec7c k\u00fd v\u00e0 x\u00e1c nh\u1eadn image. Nh\u1eefng th\u00f4ng tin n\u00e0y bao g\u1ed3m: 1 public key certificate, v\u00e0 ch\u1eef k\u00fd. Nh\u1eefng t\u00ednh n\u0103ng n\u00e0y \u0111\u01b0\u1ee3c cung c\u1ea5p khi image \u0111\u01b0\u1ee3c t\u1ea1o v\u00e0 c\u00f3 th\u1ec3 truy c\u1eadp \u0111\u01b0\u1ee3c khi image \u0111\u01b0\u1ee3c upload. L\u01b0u \u00fd r\u1eb1ng t\u00ednh n\u0103ng n\u00e0y ch\u1ec9 h\u1ed7 tr\u1ee3 upload image v\u1edbi Glance APIv2 (v\u00e0 kh\u00f4ng h\u1ed7 tr\u1ee3 Glance APIv1); v\u00e0 nhi\u1ec1u \u0111\u1ecbnh d\u1ea1ng c\u1ee7a key v\u00e0 ch\u1eef k\u00fd \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3, \u0111\u1ecbnh d\u1ea1ng ch\u1eef k\u00fd c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef nh\u01b0 l\u00e0 m\u1ed9t thu\u1ed9c t\u00ednh c\u1ee7a image. Certificate tham chi\u1ebfu \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 truy c\u1eadp t\u1edbi certificate t\u1eeb m\u1ed9t key manager, n\u1edbi m\u00e0 c\u00e1c certificate \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef. Certificate n\u00e0y \u0111\u01b0\u1ee3c th\u00eam v\u00e0o trong key manager b\u1edfi end user tr\u01b0\u1edbc khi upload image. L\u01b0u \u00fd l\u00e0 ch\u1eef k\u00ed \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n offline. Sau \u0111\u00e2y l\u00e0 lu\u1ed3ng th\u1ef1c hi\u1ec7n k\u00fd v\u00e0 x\u00e1c nh\u1eadn image trong c\u00e1c tr\u01b0\u1eddng h\u1ee3p \u0111\u1ec1 c\u1eadp \u1edf tr\u00ean (B\u01b0\u1edbc 1 t\u1edbi B\u01b0\u1edbc 10 l\u00e0 tr\u01b0\u1eddng h\u1ee3p user upload image l\u00ean Glance, t\u1eeb B\u01b0\u1edbc 11 l\u00e0 tr\u01b0\u1eddng h\u1ee3p Nova request image t\u1eeb Glance \u0111\u1ec3 boot m\u00e1y \u1ea3o): B\u01b0\u1edbc 1 : User t\u1ea1o image \u0111\u1ec3 upload l\u00ean Glance. B\u01b0\u1edbc 2 : User t\u1ea1o c\u1eb7p key theo thu\u1eadt to\u00e1n m\u00e3 h\u00f3a kh\u00f3a c\u00f4ng khai (kh\u00f3a b\u1ea5t \u0111\u1ed1i x\u1ee9ng). B\u01b0\u1edbc 3 : User s\u1eed d\u1ee5ng c\u00e1c th\u00f4ng tin c\u1ee7a m\u00ecnh \u0111\u1ec3 t\u1ea1o certificate x\u00e1c minh b\u1ea3n th\u00e2n. B\u01b0\u1edbc 4 : K\u00fd l\u00ean image s\u1eed d\u1ee5ng Private Key (m\u00e3 h\u00f3a image) . Ch\u00fa \u00fd b\u01b0\u1edbc n\u00e0y c\u00f3 s\u1ef1 kh\u00e1c bi\u1ec7t gi\u1eefa Liberty v\u00e0 c\u00e1c b\u1ea3n t\u1eeb Mitaka v\u1ec1 sau: Liberty : Tr\u01b0\u1edbc khi k\u00fd l\u00ean image, d\u1eef li\u1ec7u c\u1ee7a image s\u1ebd \u0111\u01b0\u1ee3c b\u0103m s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n MD5. D\u1eef li\u1ec7u c\u1ee7a image s\u1ebd \u0111\u01b0\u1ee3c chia th\u00e0nh t\u1eebng ph\u1ea7n nh\u1ecf r\u1ed3i b\u0103m. Cu\u1ed1i c\u00f9ng ta s\u1ebd thu l\u1ea1i \u0111\u01b0\u1ee3c m\u1ed9t m\u00e3 b\u0103m checksum_hash c\u1ee7a d\u1eef li\u1ec7u image. Ti\u1ebfp \u0111\u00f3 m\u00e3 n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng v\u00e0o thu\u1eadt to\u00e1n b\u0103m th\u1ee9 hai l\u00e0 SHA-256. Mitaka v\u00e0 c\u00e1c phi\u00ean b\u1ea3n v\u1ec1 sau : Kh\u00f4ng s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n MD5 \u0111\u1ec3 b\u0103m d\u1eef li\u1ec7u c\u1ee7a image. Tuy nhi\u00ean d\u1eef li\u1ec7u c\u1ee7a image s\u1ebd b\u1ecb b\u0103m m\u1ed9t l\u1ea7n s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n SHA-256. Ti\u1ebfp \u0111\u00f3 s\u1eed d\u1ee5ng Private Key \u0111\u00e3 t\u1ea1o \u1edf b\u01b0\u1edbc 2 \u0111\u1ec3 k\u00fd l\u00ean image \u0111\u00e3 b\u1ecb b\u0103m. B\u01b0\u1edbc 5 : G\u1eedi Public Key certificate l\u00ean Key Manager \u0111\u1ec3 l\u01b0u tr\u1eef s\u1eed d\u1ee5ng giao di\u1ec7n Castellan (g\u1eedi th\u00f4ng tin certificate v\u00e0 public key), \u0111\u1ed3ng th\u1eddi thu l\u1ea1i gi\u00e1 tr\u1ecb signature_certificate_uuid s\u1eed d\u1ee5ng cho qu\u00e1 tr\u00ecnh upload image v\u00e0 c\u00e1c \u0111\u1ed1i t\u01b0\u1ee3ng kh\u00e1c thu th\u1eadp Public Key certificate s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e1c th\u1ef1c sau n\u00e0y. B\u01b0\u1edbc 6 : Upload Image l\u00ean Glance k\u00e8m theo c\u00e1c thu\u1ed9c t\u00ednh li\u00ean quan t\u1edbi ch\u1eef k\u00fd s\u1ed1 (c\u00e1c Signature metadata). C\u00e1c thu\u1ed9c t\u00ednh n\u00e0y bao g\u1ed3m: signature : ch\u00ednh l\u00e0 ch\u1eef k\u00fd s\u1ed1 ta thu \u0111\u01b0\u1ee3c. T\u00f9y thu\u1ed9c phi\u00ean b\u1ea3n Liberty hay t\u1eeb phi\u00ean b\u1ea3n Mitaka m\u00e0 ch\u1eef k\u00fd s\u1ed1 n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o ra kh\u00e1c nhau(theo gi\u1ea3i th\u00edch \u1edf b\u01b0\u1edbc 4). V\u1edbi Liberty: signature = RSA-PSS(SHA-256(MD5(IMAGE-CONTENT))) . V\u1edbi c\u00e1c phi\u00ean b\u1ea3n t\u1eeb Mitaka tr\u1edf \u0111i: signature = RSA-PSS(SHA-256(IMAGE-CONTENT)) signature_key_type : l\u00e0 lo\u1ea1i key \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1ea1o ch\u1eef k\u00fd s\u1ed1. V\u00ed d\u1ee5: RSA-PSS signature_hash_method : l\u00e0 ph\u01b0\u01a1ng th\u1ee9c b\u0103m \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1ea1o ch\u1eef k\u1ef9. V\u00ed d\u1ee5: SHA-256 signature_certificate_uuid : ch\u00ednh l\u00e0 cert_uuid thu \u0111\u01b0\u1ee3c \u1edf b\u01b0\u1edbc 5 khi ti\u1ebfn h\u00e0nh l\u01b0u tr\u1eef certificate. mask_gen_algorithm : gi\u00e1 tr\u1ecb n\u00e0y ch\u1ec9 ra thu\u1eadt to\u00e1n t\u1ea1o m\u1eb7t n\u1ea1 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh t\u1ea1o ra ch\u1eef k\u00fd s\u1ed1. V\u00ed d\u1ee5: MGF1. Gi\u00e1 tr\u1ecb n\u00e0y ch\u1ec9 s\u1eed d\u1ee5ng cho m\u00f4 h\u00ecnh RSA-PSS. pss_salt_length : \u0111\u1ecbnh ngh\u0129a sal length s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh t\u1ea1o ch\u1eef k\u00fd v\u00e0 ch\u1ec9 \u00e1p d\u1ee5ng cho m\u00f4 h\u00ecnh RSA-PSS. Gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh l\u00e0 PSS.MAX_LENGTH . B\u01b0\u1edbc 7 : Glance g\u1eedi request \u201cPublic key certificate\u201d t\u1eeb Key-manager \u0111\u1ec3 x\u00e1c nh\u1eadn l\u1ea1i ch\u1eef k\u00fd \u0111\u01b0\u1ee3c upload l\u00ean c\u00f9ng image. (public key \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3 ch\u1eef k\u00fd). \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y Glance ph\u1ea3i s\u1eed d\u1ee5ng signature_certificate_uuid thu \u0111\u01b0\u1ee3c trong qu\u00e1 tr\u00ecnh t\u1ea3i image l\u00ean c\u1ee7a ng\u01b0\u1eddi d\u00f9ng. B\u01b0\u1edbc 8 : Key-manager tr\u1ea3 l\u1ea1i \u201cPublic key certificate\u201d cho Glance. B\u01b0\u1edbc 9 : X\u00e1c nh\u1eadn l\u1ea1i ch\u1eef k\u00ed c\u1ee7a Image: s\u1eed d\u1ee5ng public key thu \u0111\u01b0\u1ee3c c\u00f9ng v\u1edbi c\u00e1c signature metadata khi image \u0111\u01b0\u1ee3c upload l\u00ean. Vi\u1ec7c x\u00e1c th\u1ef1c n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi module signature_utils . B\u01b0\u1edbc 10 : L\u01b0u l\u1ea1i image n\u1ebfu ch\u1ee9ng th\u1ef1c th\u00e0nh c\u00f4ng. N\u1ebfu ch\u1ee9ng th\u1ef1c th\u1ea5t b\u1ea1i, Glance s\u1ebd \u0111\u01b0a image \u0111\u00f3 v\u00e0o tr\u1ea1ng th\u00e1i killed v\u00e0 g\u1eedi th\u00f4ng b\u00e1o l\u1ea1i cho ng\u01b0\u1eddi d\u00f9ng k\u00e8m theo l\u00fd do t\u1ea1i sao image upload b\u1ecb l\u1ed7i. B\u01b0\u1edbc 11 : Nova g\u1eedi y\u00eau c\u1ea7u t\u1edbi Glance \u0111\u1ec3 l\u1ea5y Image v\u00e0 metadata \u0111\u1ec3 boot m\u00e1y \u1ea3o. B\u01b0\u1edbc 12 : Glance g\u1eedi l\u1ea1i Nova image k\u00e8m theo metadata \u0111\u1ec3 ch\u1ee9ng th\u1ef1c. B\u01b0\u1edbc 13 : Nova y\u00eau c\u1ea7u Public Key Certificate t\u1eeb Key Manager b\u1eb1ng vi\u1ec7c s\u1eed d\u1ee5ng cert_uuid t\u01b0\u01a1ng t\u00e1c v\u1edbi giao di\u1ec7n Castellan B\u01b0\u1edbc 14 : Key Manager tr\u1ea3 v\u1ec1 Public Key Certificate l\u1ea1i cho Nova B\u01b0\u1edbc 15 : Nova x\u00e1c nh\u1eadn ch\u1ee9ng ch\u1ec9. Ch\u1ee9c n\u0103ng n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n n\u1ebfu ch\u1ec9nh s\u1eeda module signature_utils c\u1ee7a Nova \u0111\u1ec3 k\u1ebft h\u1ee3p vi\u1ec7c x\u00e1c nh\u1eadn ch\u1ee9ng ch\u1ec9 (certificate validation) v\u00e0o workflow c\u1ee7a ti\u1ebfn tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd(signature verification). B\u01b0\u1edbc 16 : X\u00e1c th\u1ef1c ch\u1eef k\u00fd c\u1ee7a image. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, ta ph\u1ea3i c\u1ea5u h\u00ecnh trong file nova.conf c\u1ee7a nova, thi\u1ebft l\u1eadp gi\u00e1 tr\u1ecb verify_glance_signatures = true . Nh\u01b0 v\u1eady, Nova s\u1ebd s\u1eed d\u1ee5ng c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a image, bao g\u1ed3m c\u00e1c thu\u1ed9c t\u00ednh c\u1ea7n thi\u1ebft cho qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd image(signature metadata). Nova s\u1ebd \u0111\u01b0a d\u1eef li\u1ec7u c\u1ee7a image v\u00e0 c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a n\u00f3 t\u1edbi module signature_utils \u0111\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd. B\u01b0\u1edbc 17 : N\u1ebfu vi\u1ec7c x\u00e1c th\u1ef1c ch\u1eef k\u00fd th\u00e0nh c\u00f4ng, nova s\u1ebd ti\u1ebfn h\u00e0nh boot m\u00e1y \u1ea3o s\u1eed d\u1ee5ng image \u0111\u00f3 v\u00e0 ghi v\u00e0o log ch\u1ec9 ra r\u1eb1ng vi\u1ec7c x\u00e1c th\u1ef1c ch\u1eef k\u00fd th\u00e0nh c\u00f4ng k\u00e8m theo c\u00e1c th\u00f4ng tin v\u1ec1 signing certificate . Ng\u01b0\u1ee3c l\u1ea1i n\u1ebfu x\u00e1c nh\u1eadn th\u1ea5t b\u1ea1i, Nova s\u1ebd kh\u00f4ng boot image \u0111\u00f3 v\u00e0 l\u01b0u l\u1ea1i l\u1ed7i v\u00e0o log. 4. Task \u00b6 Task trong Glance bao g\u1ed3m c\u00e1c tr\u1ea1ng th\u00e1i sau pending : task indentifier \u0111ang \u0111\u01b0\u1ee3c d\u00e0ng cho m\u1ed9t task v\u1ee5 kh\u00e1c processing : task \u0111\u00e3 \u0111\u01b0\u1ee3c th\u1ef1c thi , \u0111ang \u0111\u01b0\u1ee3c Glance Backend c\u00f9ng c\u00e1c child service x\u1eed l\u00fd sucsess : task \u0111\u01b0\u1ee3c th\u1ef1c thi ho\u00e0n t\u1ea5t failure : qu\u00e1 tr\u00ecnh ch\u1ea1y task b\u1ecb l\u1ed7i, kh\u00f4ng th\u1ec3 ti\u1ebfp t\u1ee5c \u0111\u01b0\u1ee3c ti\u1ebfn tr\u00ecnh. S\u1ebd tr\u1ea3 v\u1ec1 message v\u1ec1 error 5. Tham kh\u1ea3o \u00b6 1:https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Glance/docs/1.Tim_hieu_Glance_trong_Openstack.md","title":"5. Glance Advanced"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#glance_advance","text":"","title":"Glance Advance"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#1_instance_and_image","text":"Khi m\u1ed9t m\u00e1y \u1ea3o kh\u1edfi \u0111\u1ed9ng, Image service s\u1ebd g\u1eedi disk image \u0111\u1ebfn compute node Th\u00f4ng th\u01b0\u1eddng , Compute service s\u1ebd g\u1eedi image indentifier t\u1edbi shuleder service v\u00e0 g\u1eedi request \u0111\u1ebfn Glance th\u00f4ng qua Glance API. - T\u00f9y v\u00e0o Glance Backend , Compute Node s\u1ebd k\u1ebft n\u1ed1i \u0111\u1ebfn Image Service v\u00e0 truy\u1ec1n nh\u1eadn Image N\u1ebfu s\u1eed d\u1ee5ng Object Storage Node l\u00e0m glance backend , v\u00e0 c\u00f3 k\u1ebft n\u1ed1i gi\u1eefa Object storage node v\u00e0 compute node. Tr\u00ean storage node c\u1ea5u h\u00ecnh my_block_storage_ip \u0111\u1ec3 cho ph\u00e9p compute node v\u00e0 storage node k\u1ebft n\u1ed1i v\u1edbi nhau M\u1ed9t s\u1ed1 backend h\u1ed7 tr\u1ee3 c\u00e1c ph\u01b0\u01a1ng th\u1ee9c tr\u1ef1c ti\u1ebfp , n\u01a1i n\u00e0o c\u00f3 request image service s\u1ebd tr\u1ea3 v\u1ec1 m\u1ed9t URL tr\u1ef1c ti\u1ebfp \u0111\u1ebfn back-end storage . C\u00e1c compoute node n\u1ebfu s\u1eed d\u1ee5ng glance cache c\u00f3 ngh\u0129a l\u00e0 n\u1ebfu image \u0111\u00e3 \u0111\u01b0\u1ee3c download 1 l\u1ea7n s\u1ebd kh\u00f4ng download trong l\u1ea7n ti\u1ebfp theo","title":"1 . Instance and Image"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#2_glance_image_cache","text":"Vi\u1ec7c k\u00edch ho\u1ea1t Glance cache th\u01b0\u1eddng \u0111\u01b0\u1ee3c khuy\u00ean khi s\u1eed d\u1ee5ng h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef m\u1eb7c \u0111\u1ecbnh l\u00e0 file, tuy nhi\u00ean n\u1ebfu s\u1eed d\u1ee5ng Ceph RBD backend s\u1ebd c\u00f3 m\u1ed9t s\u1ed1 kh\u00e1c bi\u1ec7t. K\u00edch ho\u1ea1t glance cache d\u1eabn t\u1edbi vi\u1ec7c t\u1ea1o ra cached c\u1ee7a image \u0111\u00f3 trong th\u01b0 m\u1ee5c /var/lib/glance/image-cache m\u1ed7i l\u1ea7n boot m\u00e1y \u1ea3o l\u00ean. Gi\u1ea3 s\u1eed ta c\u00f3 m\u1ed9t m\u00e1y \u1ea3o v\u1edbi k\u00edch th\u01b0\u1edbc VM image l\u00e0 c\u1ee1 50GB, n\u1ebfu nh\u01b0 m\u1ed7i l\u1ea7n boot m\u00e0 l\u1ea1i t\u1ea1o cached nh\u01b0 v\u00e2y, h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef s\u1ebd s\u1edbm b\u1ecb c\u1ea1n ki\u1ec7t, tr\u1eeb khi ta mount th\u01b0 m\u1ee5c /var v\u00e0o m\u1ed9t \u1ed5 l\u01b0u tr\u1eef l\u1edbn. Glance API server c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh \u0111\u1ec3 c\u00f3 th\u01b0 m\u1ee5c l\u01b0u tr\u1eef image cache local. M\u1ed9t th\u01b0c m\u1ee5c local image cache l\u01b0u tr\u1eef m\u1ed9t b\u1ea3n copy c\u1ee7a c\u00e1c image, v\u1ec1 c\u01a1 b\u1ea3n \u0111i\u1ec1u n\u00e0y cho ph\u00e9p nhi\u1ec1u API server ph\u1ee5c v\u1ee5 c\u00f9ng c\u00e1c file image gi\u1ed1ng nhau, \u0111\u1ec3 m\u1edf r\u1ed9ng kh\u1ea3 n\u0103ng ph\u1ee5c v\u1ee5 c\u1ee7a Glance. Local image cache l\u00e0 trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng. Ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c Glance API \u0111ang chuy\u1ec3n c\u00e1c file image t\u1eeb local cache hay t\u1eeb h\u1ec7 th\u1ed1ng backend l\u01b0u tr\u1eef th\u1ef1c s\u1ef1. Th\u1ef1c hi\u1ec7n c\u1ea5u h\u00ecnh glance-api h\u1ed7 tr\u1ee3 local image cache v\u00e0 s\u1eed d\u1ee5ng local image cache t\u1ea1i \u0111\u00e2y.","title":"2. Glance image cache"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#3_glance_image_signing_and_verification","text":"","title":"3. Glance Image Signing and Verification"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#31_at_van_e_ve_bao_mat_va_toan_ven_image","text":"Tr\u01b0\u1edbc b\u1ea3n ph\u00e1t h\u00e0nh Liberty, kh\u00f4ng h\u1ec1 c\u00f3 ph\u01b0\u01a1ng th\u1ee9c n\u00e0o cho c\u00e1c user \u0111\u1ec3 x\u00e1c nh\u1eadn r\u1eb1ng image h\u1ecd t\u1ea3i l\u00ean c\u00f3 b\u1ecb thay \u0111\u1ed5i hay kh\u00f4ng. M\u1ed9t image b\u1ecb thay \u0111\u1ed5i c\u00f3 th\u1ec3 x\u1ea3y ra trong qu\u00e1 tr\u00ecnh upload t\u1eeb user l\u00ean Glance ho\u1eb7c Glance chuy\u1ec3n image t\u1edbi Nova, ho\u1eb7c c\u0169ng c\u00f3 th\u1ec3 do ch\u00ednh Glance t\u1ef1 m\u00ecnh thay \u0111\u1ed5i m\u00e0 kh\u00f4ng c\u00f3 t\u00e1c \u0111\u1ed9ng t\u1eeb ph\u00eda ng\u01b0\u1eddi d\u00f9ng. M\u1ed9t image b\u1ecb thay \u0111\u1ed5i c\u00f3 th\u1ec3 ch\u1ee9a m\u00e3 \u0111\u1ed9c. B\u1edfi v\u1eady vi\u1ec7c cung c\u1ea5p c\u01a1 ch\u1ebf ch\u1eef k\u00fd s\u1ed1 cho image v\u00e0 x\u00e1c nh\u1eadn ch\u1eef k\u00fd s\u1ed1 cho ph\u00e9p user x\u00e1c nh\u1eadn xem image c\u00f3 b\u1ecb thay \u0111\u1ed5i kh\u00f4ng tr\u01b0\u1edbc khi boot image t\u1ea1o m\u00e1y \u1ea3o. T\u00ednh n\u0103ng n\u00e0y h\u1ed7 tr\u1ee3 m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p nh\u01b0 sau: M\u1ed9t image \u0111\u01b0\u1ee3c k\u00ed b\u1edfi end user, s\u1eed d\u1ee5ng private key (hi\u1ec3u l\u00e0 m\u00e3 h\u00f3a b\u1edfi private key). Sau \u0111\u00f3, user upload image l\u00ean Glance, c\u00f9ng v\u1edbi ch\u1eef k\u00ed v\u01b0a t\u1ea1o v\u00e0 public key certificate c\u1ee7a user. Glance s\u1eed d\u1ee5ng th\u00f4ng tin n\u00e0y \u0111\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd, v\u00e0 th\u00f4ng b\u00e1o t\u1edbi user n\u1ebfu ch\u1eef k\u00fd c\u00f3 b\u1ecb kh\u00f4ng x\u00e1c th\u1ef1c. M\u1ed9t image \u0111\u01b0\u1ee3c t\u1ea1o trong Nova, v\u00e0 Nova k\u00fd l\u00ean image t\u1ea1i request c\u1ee7a end user. Khi image \u0111\u01b0\u1ee3c upload l\u00ean Glance, ch\u1eef k\u00fd v\u00e0 public key certificate c\u0169ng \u0111\u01b0\u1ee3c cung c\u1ea5p. Glance x\u00e1c nh\u1eadn ch\u1eef k\u00fd tr\u01b0\u1edbc khi l\u01b0u tr\u1eef image, v\u00e0 th\u00f4ng b\u00e1o v\u1edbi Nova n\u1ebfu s\u1ef1 x\u00e1c th\u1ef1c x\u1ea3y ra l\u1ed7i. M\u1ed9t image \u0111\u00e3 \u0111\u01b0\u1ee3c k\u00fd \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u b\u1edfi Nova, v\u00e0 Glance cung c\u1ea5p ch\u1eef k\u00fd va public key certificate t\u1edbi Nova c\u00f9ng image \u0111\u1ec3 Nova c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd tr\u01b0\u1edbc khi booting image.","title":"3.1. \u0110\u1eb7t v\u1ea5n \u0111\u1ec1 v\u1ec1 b\u1ea3o m\u1eadt v\u00e0 to\u00e0n v\u1eb9n Image"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#32_qua_trinh_xac_thuc_chu_ky_image_trong_glance","text":"Nh\u1eefng phi\u00ean b\u1ea3n tri\u1ec3n khai \u0111\u1ea7u ti\u00ean trong Liberty, thay \u0111\u1ed5i n\u00e0y s\u1eed d\u1ee5ng t\u00ednh n\u0103ng c\u1ee7a Glance \u0111\u1ec3 l\u01b0u tr\u1eef metadate c\u00e2n thi\u1ebft cho vi\u1ec7c k\u00fd v\u00e0 x\u00e1c nh\u1eadn image. Nh\u1eefng th\u00f4ng tin n\u00e0y bao g\u1ed3m: 1 public key certificate, v\u00e0 ch\u1eef k\u00fd. Nh\u1eefng t\u00ednh n\u0103ng n\u00e0y \u0111\u01b0\u1ee3c cung c\u1ea5p khi image \u0111\u01b0\u1ee3c t\u1ea1o v\u00e0 c\u00f3 th\u1ec3 truy c\u1eadp \u0111\u01b0\u1ee3c khi image \u0111\u01b0\u1ee3c upload. L\u01b0u \u00fd r\u1eb1ng t\u00ednh n\u0103ng n\u00e0y ch\u1ec9 h\u1ed7 tr\u1ee3 upload image v\u1edbi Glance APIv2 (v\u00e0 kh\u00f4ng h\u1ed7 tr\u1ee3 Glance APIv1); v\u00e0 nhi\u1ec1u \u0111\u1ecbnh d\u1ea1ng c\u1ee7a key v\u00e0 ch\u1eef k\u00fd \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3, \u0111\u1ecbnh d\u1ea1ng ch\u1eef k\u00fd c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef nh\u01b0 l\u00e0 m\u1ed9t thu\u1ed9c t\u00ednh c\u1ee7a image. Certificate tham chi\u1ebfu \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 truy c\u1eadp t\u1edbi certificate t\u1eeb m\u1ed9t key manager, n\u1edbi m\u00e0 c\u00e1c certificate \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef. Certificate n\u00e0y \u0111\u01b0\u1ee3c th\u00eam v\u00e0o trong key manager b\u1edfi end user tr\u01b0\u1edbc khi upload image. L\u01b0u \u00fd l\u00e0 ch\u1eef k\u00ed \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n offline. Sau \u0111\u00e2y l\u00e0 lu\u1ed3ng th\u1ef1c hi\u1ec7n k\u00fd v\u00e0 x\u00e1c nh\u1eadn image trong c\u00e1c tr\u01b0\u1eddng h\u1ee3p \u0111\u1ec1 c\u1eadp \u1edf tr\u00ean (B\u01b0\u1edbc 1 t\u1edbi B\u01b0\u1edbc 10 l\u00e0 tr\u01b0\u1eddng h\u1ee3p user upload image l\u00ean Glance, t\u1eeb B\u01b0\u1edbc 11 l\u00e0 tr\u01b0\u1eddng h\u1ee3p Nova request image t\u1eeb Glance \u0111\u1ec3 boot m\u00e1y \u1ea3o): B\u01b0\u1edbc 1 : User t\u1ea1o image \u0111\u1ec3 upload l\u00ean Glance. B\u01b0\u1edbc 2 : User t\u1ea1o c\u1eb7p key theo thu\u1eadt to\u00e1n m\u00e3 h\u00f3a kh\u00f3a c\u00f4ng khai (kh\u00f3a b\u1ea5t \u0111\u1ed1i x\u1ee9ng). B\u01b0\u1edbc 3 : User s\u1eed d\u1ee5ng c\u00e1c th\u00f4ng tin c\u1ee7a m\u00ecnh \u0111\u1ec3 t\u1ea1o certificate x\u00e1c minh b\u1ea3n th\u00e2n. B\u01b0\u1edbc 4 : K\u00fd l\u00ean image s\u1eed d\u1ee5ng Private Key (m\u00e3 h\u00f3a image) . Ch\u00fa \u00fd b\u01b0\u1edbc n\u00e0y c\u00f3 s\u1ef1 kh\u00e1c bi\u1ec7t gi\u1eefa Liberty v\u00e0 c\u00e1c b\u1ea3n t\u1eeb Mitaka v\u1ec1 sau: Liberty : Tr\u01b0\u1edbc khi k\u00fd l\u00ean image, d\u1eef li\u1ec7u c\u1ee7a image s\u1ebd \u0111\u01b0\u1ee3c b\u0103m s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n MD5. D\u1eef li\u1ec7u c\u1ee7a image s\u1ebd \u0111\u01b0\u1ee3c chia th\u00e0nh t\u1eebng ph\u1ea7n nh\u1ecf r\u1ed3i b\u0103m. Cu\u1ed1i c\u00f9ng ta s\u1ebd thu l\u1ea1i \u0111\u01b0\u1ee3c m\u1ed9t m\u00e3 b\u0103m checksum_hash c\u1ee7a d\u1eef li\u1ec7u image. Ti\u1ebfp \u0111\u00f3 m\u00e3 n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng v\u00e0o thu\u1eadt to\u00e1n b\u0103m th\u1ee9 hai l\u00e0 SHA-256. Mitaka v\u00e0 c\u00e1c phi\u00ean b\u1ea3n v\u1ec1 sau : Kh\u00f4ng s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n MD5 \u0111\u1ec3 b\u0103m d\u1eef li\u1ec7u c\u1ee7a image. Tuy nhi\u00ean d\u1eef li\u1ec7u c\u1ee7a image s\u1ebd b\u1ecb b\u0103m m\u1ed9t l\u1ea7n s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n SHA-256. Ti\u1ebfp \u0111\u00f3 s\u1eed d\u1ee5ng Private Key \u0111\u00e3 t\u1ea1o \u1edf b\u01b0\u1edbc 2 \u0111\u1ec3 k\u00fd l\u00ean image \u0111\u00e3 b\u1ecb b\u0103m. B\u01b0\u1edbc 5 : G\u1eedi Public Key certificate l\u00ean Key Manager \u0111\u1ec3 l\u01b0u tr\u1eef s\u1eed d\u1ee5ng giao di\u1ec7n Castellan (g\u1eedi th\u00f4ng tin certificate v\u00e0 public key), \u0111\u1ed3ng th\u1eddi thu l\u1ea1i gi\u00e1 tr\u1ecb signature_certificate_uuid s\u1eed d\u1ee5ng cho qu\u00e1 tr\u00ecnh upload image v\u00e0 c\u00e1c \u0111\u1ed1i t\u01b0\u1ee3ng kh\u00e1c thu th\u1eadp Public Key certificate s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e1c th\u1ef1c sau n\u00e0y. B\u01b0\u1edbc 6 : Upload Image l\u00ean Glance k\u00e8m theo c\u00e1c thu\u1ed9c t\u00ednh li\u00ean quan t\u1edbi ch\u1eef k\u00fd s\u1ed1 (c\u00e1c Signature metadata). C\u00e1c thu\u1ed9c t\u00ednh n\u00e0y bao g\u1ed3m: signature : ch\u00ednh l\u00e0 ch\u1eef k\u00fd s\u1ed1 ta thu \u0111\u01b0\u1ee3c. T\u00f9y thu\u1ed9c phi\u00ean b\u1ea3n Liberty hay t\u1eeb phi\u00ean b\u1ea3n Mitaka m\u00e0 ch\u1eef k\u00fd s\u1ed1 n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o ra kh\u00e1c nhau(theo gi\u1ea3i th\u00edch \u1edf b\u01b0\u1edbc 4). V\u1edbi Liberty: signature = RSA-PSS(SHA-256(MD5(IMAGE-CONTENT))) . V\u1edbi c\u00e1c phi\u00ean b\u1ea3n t\u1eeb Mitaka tr\u1edf \u0111i: signature = RSA-PSS(SHA-256(IMAGE-CONTENT)) signature_key_type : l\u00e0 lo\u1ea1i key \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1ea1o ch\u1eef k\u00fd s\u1ed1. V\u00ed d\u1ee5: RSA-PSS signature_hash_method : l\u00e0 ph\u01b0\u01a1ng th\u1ee9c b\u0103m \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1ea1o ch\u1eef k\u1ef9. V\u00ed d\u1ee5: SHA-256 signature_certificate_uuid : ch\u00ednh l\u00e0 cert_uuid thu \u0111\u01b0\u1ee3c \u1edf b\u01b0\u1edbc 5 khi ti\u1ebfn h\u00e0nh l\u01b0u tr\u1eef certificate. mask_gen_algorithm : gi\u00e1 tr\u1ecb n\u00e0y ch\u1ec9 ra thu\u1eadt to\u00e1n t\u1ea1o m\u1eb7t n\u1ea1 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh t\u1ea1o ra ch\u1eef k\u00fd s\u1ed1. V\u00ed d\u1ee5: MGF1. Gi\u00e1 tr\u1ecb n\u00e0y ch\u1ec9 s\u1eed d\u1ee5ng cho m\u00f4 h\u00ecnh RSA-PSS. pss_salt_length : \u0111\u1ecbnh ngh\u0129a sal length s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh t\u1ea1o ch\u1eef k\u00fd v\u00e0 ch\u1ec9 \u00e1p d\u1ee5ng cho m\u00f4 h\u00ecnh RSA-PSS. Gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh l\u00e0 PSS.MAX_LENGTH . B\u01b0\u1edbc 7 : Glance g\u1eedi request \u201cPublic key certificate\u201d t\u1eeb Key-manager \u0111\u1ec3 x\u00e1c nh\u1eadn l\u1ea1i ch\u1eef k\u00fd \u0111\u01b0\u1ee3c upload l\u00ean c\u00f9ng image. (public key \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3 ch\u1eef k\u00fd). \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y Glance ph\u1ea3i s\u1eed d\u1ee5ng signature_certificate_uuid thu \u0111\u01b0\u1ee3c trong qu\u00e1 tr\u00ecnh t\u1ea3i image l\u00ean c\u1ee7a ng\u01b0\u1eddi d\u00f9ng. B\u01b0\u1edbc 8 : Key-manager tr\u1ea3 l\u1ea1i \u201cPublic key certificate\u201d cho Glance. B\u01b0\u1edbc 9 : X\u00e1c nh\u1eadn l\u1ea1i ch\u1eef k\u00ed c\u1ee7a Image: s\u1eed d\u1ee5ng public key thu \u0111\u01b0\u1ee3c c\u00f9ng v\u1edbi c\u00e1c signature metadata khi image \u0111\u01b0\u1ee3c upload l\u00ean. Vi\u1ec7c x\u00e1c th\u1ef1c n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi module signature_utils . B\u01b0\u1edbc 10 : L\u01b0u l\u1ea1i image n\u1ebfu ch\u1ee9ng th\u1ef1c th\u00e0nh c\u00f4ng. N\u1ebfu ch\u1ee9ng th\u1ef1c th\u1ea5t b\u1ea1i, Glance s\u1ebd \u0111\u01b0a image \u0111\u00f3 v\u00e0o tr\u1ea1ng th\u00e1i killed v\u00e0 g\u1eedi th\u00f4ng b\u00e1o l\u1ea1i cho ng\u01b0\u1eddi d\u00f9ng k\u00e8m theo l\u00fd do t\u1ea1i sao image upload b\u1ecb l\u1ed7i. B\u01b0\u1edbc 11 : Nova g\u1eedi y\u00eau c\u1ea7u t\u1edbi Glance \u0111\u1ec3 l\u1ea5y Image v\u00e0 metadata \u0111\u1ec3 boot m\u00e1y \u1ea3o. B\u01b0\u1edbc 12 : Glance g\u1eedi l\u1ea1i Nova image k\u00e8m theo metadata \u0111\u1ec3 ch\u1ee9ng th\u1ef1c. B\u01b0\u1edbc 13 : Nova y\u00eau c\u1ea7u Public Key Certificate t\u1eeb Key Manager b\u1eb1ng vi\u1ec7c s\u1eed d\u1ee5ng cert_uuid t\u01b0\u01a1ng t\u00e1c v\u1edbi giao di\u1ec7n Castellan B\u01b0\u1edbc 14 : Key Manager tr\u1ea3 v\u1ec1 Public Key Certificate l\u1ea1i cho Nova B\u01b0\u1edbc 15 : Nova x\u00e1c nh\u1eadn ch\u1ee9ng ch\u1ec9. Ch\u1ee9c n\u0103ng n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n n\u1ebfu ch\u1ec9nh s\u1eeda module signature_utils c\u1ee7a Nova \u0111\u1ec3 k\u1ebft h\u1ee3p vi\u1ec7c x\u00e1c nh\u1eadn ch\u1ee9ng ch\u1ec9 (certificate validation) v\u00e0o workflow c\u1ee7a ti\u1ebfn tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd(signature verification). B\u01b0\u1edbc 16 : X\u00e1c th\u1ef1c ch\u1eef k\u00fd c\u1ee7a image. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, ta ph\u1ea3i c\u1ea5u h\u00ecnh trong file nova.conf c\u1ee7a nova, thi\u1ebft l\u1eadp gi\u00e1 tr\u1ecb verify_glance_signatures = true . Nh\u01b0 v\u1eady, Nova s\u1ebd s\u1eed d\u1ee5ng c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a image, bao g\u1ed3m c\u00e1c thu\u1ed9c t\u00ednh c\u1ea7n thi\u1ebft cho qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd image(signature metadata). Nova s\u1ebd \u0111\u01b0a d\u1eef li\u1ec7u c\u1ee7a image v\u00e0 c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a n\u00f3 t\u1edbi module signature_utils \u0111\u1ec3 x\u00e1c th\u1ef1c ch\u1eef k\u00fd. B\u01b0\u1edbc 17 : N\u1ebfu vi\u1ec7c x\u00e1c th\u1ef1c ch\u1eef k\u00fd th\u00e0nh c\u00f4ng, nova s\u1ebd ti\u1ebfn h\u00e0nh boot m\u00e1y \u1ea3o s\u1eed d\u1ee5ng image \u0111\u00f3 v\u00e0 ghi v\u00e0o log ch\u1ec9 ra r\u1eb1ng vi\u1ec7c x\u00e1c th\u1ef1c ch\u1eef k\u00fd th\u00e0nh c\u00f4ng k\u00e8m theo c\u00e1c th\u00f4ng tin v\u1ec1 signing certificate . Ng\u01b0\u1ee3c l\u1ea1i n\u1ebfu x\u00e1c nh\u1eadn th\u1ea5t b\u1ea1i, Nova s\u1ebd kh\u00f4ng boot image \u0111\u00f3 v\u00e0 l\u01b0u l\u1ea1i l\u1ed7i v\u00e0o log.","title":"3.2. Qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c ch\u1eef k\u00fd image trong Glance"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#4_task","text":"Task trong Glance bao g\u1ed3m c\u00e1c tr\u1ea1ng th\u00e1i sau pending : task indentifier \u0111ang \u0111\u01b0\u1ee3c d\u00e0ng cho m\u1ed9t task v\u1ee5 kh\u00e1c processing : task \u0111\u00e3 \u0111\u01b0\u1ee3c th\u1ef1c thi , \u0111ang \u0111\u01b0\u1ee3c Glance Backend c\u00f9ng c\u00e1c child service x\u1eed l\u00fd sucsess : task \u0111\u01b0\u1ee3c th\u1ef1c thi ho\u00e0n t\u1ea5t failure : qu\u00e1 tr\u00ecnh ch\u1ea1y task b\u1ecb l\u1ed7i, kh\u00f4ng th\u1ec3 ti\u1ebfp t\u1ee5c \u0111\u01b0\u1ee3c ti\u1ebfn tr\u00ecnh. S\u1ebd tr\u1ea3 v\u1ec1 message v\u1ec1 error","title":"4. Task"},{"location":"Openstack_Research/Glance/5. Glance-Advanced/#5_tham_khao","text":"1:https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Openstack/Glance/docs/1.Tim_hieu_Glance_trong_Openstack.md","title":"5. Tham kh\u1ea3o"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/","text":"Gi\u1edbi thi\u1ec7u v\u1ec1 High Avaibility \u00b6 1. Gi\u1edbi thi\u1ec7u v\u1ec1 High Availability \u00b6 1.1 : Kh\u00e1i ni\u1ec7m v\u1ec1 High Availability \u00b6 Trong khoa h\u1ecdc m\u00e1y t\u00ednh, kh\u00e1i ni\u1ec7m \"Availability\" \u0111\u01b0\u1ee3c d\u00f9ng d\u1ec3 di\u1ec5n t\u1ea3 m\u1ed9t kho\u1ea3ng th\u1eddi gian m\u00e0 d\u1ecbch v\u1ee5 lu\u00f4n s\u1eb5n s\u00e0ng \u0111\u1ec3 ph\u1ea3n h\u1ed3i l\u1ea1i nh\u1eefng request t\u1eeb ph\u00eda ng\u01b0\u1eddi d\u00f9ng. \"High Availability\" l\u00e0 ch\u1ea5t l\u01b0\u1ee3ng c\u1ee7a h\u1ec7 th\u1ed1ng ho\u1eb7c c\u00e1c th\u00e0nh ph\u1ea7n c\u00f3 th\u1ec3 \u0111\u1ea3m b\u1ea3o hi\u1ec7u n\u0103ng v\u1eadn h\u00e0nh c\u1ee7a h\u1ec7 th\u1ed1ng lu\u00f4n cao trong m\u1ed9t kho\u1ea3ng th\u1eddi gian nh\u1ea5t \u0111\u1ecbnh. 1.2 : C\u1ea7n High Availability khi n\u00e0o \u00b6 Khi thi\u1ebft l\u1eadp h\u1ec7 th\u1ed1ng production, gi\u1ea3m thi\u1ec3u th\u1eddi gian ch\u1ebft v\u00e0 gi\u00e1n \u0111o\u1ea1n d\u1ecbch v\u1ee5 th\u01b0\u1eddng l\u00e0 \u01b0u ti\u00ean cao. B\u1ea5t k\u1ec3 th\u1ebf n\u00e0o h\u1ec7 th\u1ed1ng v\u00e0 ph\u1ea7n m\u1ec1m \u0111\u00e1ng tin c\u1eady \u0111\u1ebfn m\u1ee9c n\u00e0o th\u00ec v\u1eabn c\u00f3 th\u1ec3 x\u1ea3y ra c\u00e1c v\u1ea5n \u0111\u1ec1 l\u00e0m l\u1ed7i c\u00e1c \u1ee9ng d\u1ee5ng v\u00e0 h\u1ea1 t\u1ea7ng . Th\u1ef1c hi\u1ec7n t\u00ednh s\u1eb5n s\u00e0ng cao cho c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng l\u00e0 m\u1ed9t chi\u1ebfn l\u01b0\u1ee3c h\u1eefu \u00edch \u0111\u1ec3 gi\u1ea3m t\u00e1c \u0111\u1ed9ng c\u1ee7a c\u00e1c lo\u1ea1i s\u1ef1 ki\u1ec7n n\u00e0y. C\u00e1c h\u1ec7 th\u1ed1ng kh\u1ea3 d\u1ee5ng cao c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng ph\u1ee5c h\u1ed3i t\u1eeb l\u1ed7i m\u00e1y ch\u1ee7 ho\u1eb7c c\u00e1c d\u1ecbch v\u1ee5 ho\u1eb7c \u1ee9ng d\u1ee5ng, t\u0103ng t\u00ednh \u0111\u1ea3m b\u1ea3o v\u00e0 tin c\u00e2y. 1.3 : M\u1ee5c ti\u00eau c\u1ee7a High Availability \u00b6 M\u1ed9t trong nh\u1eefng m\u1ee5c ti\u00eau c\u1ee7a t\u00ednh s\u1eb5n s\u00e0ng cao l\u00e0 lo\u1ea1i b\u1ecf c\u00e1c single point of failure (c\u00f3 th\u1ec3 hi\u1ec3u l\u00e0 1 \u0111i\u1ec3m l\u1ed7i nh\u1ecf) trong c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng c\u1ee7a b\u1ea1n. M\u1ed9t single point of failure c\u00f3 th\u1ec3 g\u00e2y ra s\u1ef1 gi\u00e1n \u0111o\u1ea1n d\u1ecbch v\u1ee5 n\u1ebfu n\u00f3 kh\u00f4ng kh\u1ea3 d\u1ee5ng. Nh\u01b0 v\u1eady, b\u1ea5t k\u00ec m\u1ed9t th\u00e0nh ph\u1ea7n n\u00e0o quan tr\u1ecdng cho h\u1ec7 th\u1ed1ng c\u1ee7a b\u1ea1n m\u00e0 kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng d\u1ef1 ph\u00f2ng c\u00f3 th\u1ec3 tr\u1edf th\u00e0nh m\u1ed9t singe point of failure. \u0110\u1ec3 lo\u1ea1i b\u1ecf c\u00e1c single point of failure, m\u1ed7i ph\u1ea7n nh\u1ecf trong \u1ee9ng d\u1ee5ng c\u1ee7a b\u1ea1n c\u1ea7n c\u00f3 s\u1ef1 chu\u1ea9n b\u1ecb d\u1ef1 ph\u00f2ng. 1.4 : C\u00e1c th\u00e0nh ph\u1ea7n y\u00eau c\u1ea7u High Avaibability \u00b6 C\u00f3 m\u1ed9t s\u1ed1 th\u00e0nh ph\u1ea7n ph\u1ea3i \u0111\u01b0\u1ee3c xem x\u00e9t c\u1ea9n th\u1eadn \u0111\u1ec3 th\u1ef1c hi\u1ec7n t\u00ednh s\u1eb5n s\u00e0ng cao trong th\u1ef1c t\u1ebf. T\u00ednh s\u1eb5n s\u00e0ng cao ph\u1ee5 thu\u1ed9c v\u00e0o c\u00e1c th\u00e0nh ph\u1ea7n sau : - Enviroment : n\u00eau t\u1ea5t c\u1ea3 c\u00e1c m\u00e1y ch\u1ee7 c\u00f9ng \u0111\u1eb7t t\u1ea1i m\u1ed9t v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd , m\u1ed9t th\u1ea3m h\u1ecda t\u1ef1 nhi\u00ean c\u00f3 th\u1ec3 l\u00e0m h\u1ecfng h\u00f3c c\u00e1c server n\u00e0y . C\u00f3 c\u00e1ch server \u0111\u1eb7t t\u1ea1i c\u00e1c v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd kh\u00e1c nhau s\u1ebd t\u0103ng \u0111\u1ed9 tin c\u1eady - Hardware : t\u0103ng t\u00ednh kh\u1ea3 d\u1ee5ng cao cho server c\u00f3 th\u1ec3 li\u00ean quan \u0111\u1ebfn v\u1ea5n \u0111\u1ec1 ngu\u1ed3n, l\u1ed7i ph\u1ea7n c\u1ee9ng nh\u01b0 disk ho\u1eb7c network interface - Software : h\u1ec7 th\u1ed1ng x\u00e2y d\u1ef1ng l\u00ean c\u00e1c \u1ee9ng d\u1ee5ng k\u1ec3 c\u1ea3 h\u1ec7 \u0111i\u1ec1u h\u00e0nh c\u1ea7n ph\u1ea3i chu\u1ea9n b\u1ecb \u0111\u1ec3 ch\u1ed1ng l\u1ea1i x\u00e1c l\u1ed7i kh\u00f4ng mong mu\u1ed1n , \u0111\u1ea3m b\u1ea3o t\u00ednh d\u1ef1 ph\u00f2ng v\u00e0 to\u00e0n v\u1eb9n d\u1eef li\u1ec7u - Data : m\u1ea5t d\u1eef li\u1ec7u s\u1ebd l\u00e0m to\u00e0n b\u1ed9 h\u1ed1ng th\u1ed1ng \u0111i v\u00e0o ng\u1eebng ho\u1ea1t \u0111\u1ed9ng, ch\u00fang ta c\u1ea7n \u0111\u1ea3m b\u1ea3o \u1ed5 \u0111\u0129a c\u1ee7a ch\u00fang ta kh\u00f4ng x\u1ea3y ra l\u1ed7i kh\u00f4ng mong mu\u1ed1n - Network : \u0111\u1ea3m b\u1ea3o h\u1ea1 t\u1ea7ng m\u1ea1ng lu\u00f4n lu\u00f4n s\u1eb5ng s\u00e0ng \u0111\u1ecbnh tuy\u1ebfn v\u00e0 li\u00ean h\u1ec7 2. X\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng \u1ee9ng d\u1ee5ng Hight Avaibility \u00b6 2.1. C\u00e1c nguy\u00ean nh\u00e2n g\u00e2y tr\u00ecnh tr\u1ea1ng downtime \u00b6 \u0110\u1ed1i v\u1edbi tr\u00ecnh down h\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 chia th\u00e0nh 2 d\u1ea1ng : \u0111\u00e3 l\u00ean l\u1ecbch v\u00e0 kh\u00f4ng l\u00ean l\u1ecbch \u0110\u1ed1i v\u1edbi t\u00ecnh tr\u1ea1ng d\u00e2y ra tr\u00ecnh tr\u1ea1ng down kh\u00f4ng l\u00ean l\u1ecbch c\u00f3 th\u1ec3 do c\u00e1c nguy\u00ean nh\u00e2n li\u00ean qu\u00e1 \u0111\u1ebfn l\u1ed7i h\u1ec7 th\u1ed1ng, d\u1eef li\u1ec7u , v\u00e0 m\u1ea5t \u0111i\u1ec7n \u0110\u1ed1i v\u1edbi c\u00e1c ho\u1ea1t \u0111\u1ed9ng g\u00e2y ra down h\u1ec7 th\u1ed1ng c\u00f3 ch\u1ee7 \u0111\u00edch c\u00f3 th\u1ec3 do n\u00e2ng c\u1ea5p h\u1ec7 th\u1ed1ng, n\u00e2ng c\u1ea5p h\u1ea1 t\u1ea7ng m\u1ea1ng ho\u1eb7c ki\u1ec3m th\u1eed c\u00f3 k\u1ebf ho\u1ea1ch 2.2. M\u1ed9t s\u1ed1 m\u00f4 h\u00ecnh \u00b6 3. T\u00e0i li\u1ec7u \u00b6 - https://www.digitalocean.com/community/tutorials/what-is-high-availability \u00b6","title":"1. Introduction HA"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#gioi_thieu_ve_high_avaibility","text":"","title":"Gi\u1edbi thi\u1ec7u v\u1ec1 High Avaibility"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#1_gioi_thieu_ve_high_availability","text":"","title":"1. Gi\u1edbi thi\u1ec7u v\u1ec1 High Availability"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#11_khai_niem_ve_high_availability","text":"Trong khoa h\u1ecdc m\u00e1y t\u00ednh, kh\u00e1i ni\u1ec7m \"Availability\" \u0111\u01b0\u1ee3c d\u00f9ng d\u1ec3 di\u1ec5n t\u1ea3 m\u1ed9t kho\u1ea3ng th\u1eddi gian m\u00e0 d\u1ecbch v\u1ee5 lu\u00f4n s\u1eb5n s\u00e0ng \u0111\u1ec3 ph\u1ea3n h\u1ed3i l\u1ea1i nh\u1eefng request t\u1eeb ph\u00eda ng\u01b0\u1eddi d\u00f9ng. \"High Availability\" l\u00e0 ch\u1ea5t l\u01b0\u1ee3ng c\u1ee7a h\u1ec7 th\u1ed1ng ho\u1eb7c c\u00e1c th\u00e0nh ph\u1ea7n c\u00f3 th\u1ec3 \u0111\u1ea3m b\u1ea3o hi\u1ec7u n\u0103ng v\u1eadn h\u00e0nh c\u1ee7a h\u1ec7 th\u1ed1ng lu\u00f4n cao trong m\u1ed9t kho\u1ea3ng th\u1eddi gian nh\u1ea5t \u0111\u1ecbnh.","title":"1.1 : Kh\u00e1i ni\u1ec7m v\u1ec1  High Availability"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#12_can_high_availability_khi_nao","text":"Khi thi\u1ebft l\u1eadp h\u1ec7 th\u1ed1ng production, gi\u1ea3m thi\u1ec3u th\u1eddi gian ch\u1ebft v\u00e0 gi\u00e1n \u0111o\u1ea1n d\u1ecbch v\u1ee5 th\u01b0\u1eddng l\u00e0 \u01b0u ti\u00ean cao. B\u1ea5t k\u1ec3 th\u1ebf n\u00e0o h\u1ec7 th\u1ed1ng v\u00e0 ph\u1ea7n m\u1ec1m \u0111\u00e1ng tin c\u1eady \u0111\u1ebfn m\u1ee9c n\u00e0o th\u00ec v\u1eabn c\u00f3 th\u1ec3 x\u1ea3y ra c\u00e1c v\u1ea5n \u0111\u1ec1 l\u00e0m l\u1ed7i c\u00e1c \u1ee9ng d\u1ee5ng v\u00e0 h\u1ea1 t\u1ea7ng . Th\u1ef1c hi\u1ec7n t\u00ednh s\u1eb5n s\u00e0ng cao cho c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng l\u00e0 m\u1ed9t chi\u1ebfn l\u01b0\u1ee3c h\u1eefu \u00edch \u0111\u1ec3 gi\u1ea3m t\u00e1c \u0111\u1ed9ng c\u1ee7a c\u00e1c lo\u1ea1i s\u1ef1 ki\u1ec7n n\u00e0y. C\u00e1c h\u1ec7 th\u1ed1ng kh\u1ea3 d\u1ee5ng cao c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng ph\u1ee5c h\u1ed3i t\u1eeb l\u1ed7i m\u00e1y ch\u1ee7 ho\u1eb7c c\u00e1c d\u1ecbch v\u1ee5 ho\u1eb7c \u1ee9ng d\u1ee5ng, t\u0103ng t\u00ednh \u0111\u1ea3m b\u1ea3o v\u00e0 tin c\u00e2y.","title":"1.2 : C\u1ea7n  High Availability khi n\u00e0o"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#13_muc_tieu_cua_high_availability","text":"M\u1ed9t trong nh\u1eefng m\u1ee5c ti\u00eau c\u1ee7a t\u00ednh s\u1eb5n s\u00e0ng cao l\u00e0 lo\u1ea1i b\u1ecf c\u00e1c single point of failure (c\u00f3 th\u1ec3 hi\u1ec3u l\u00e0 1 \u0111i\u1ec3m l\u1ed7i nh\u1ecf) trong c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng c\u1ee7a b\u1ea1n. M\u1ed9t single point of failure c\u00f3 th\u1ec3 g\u00e2y ra s\u1ef1 gi\u00e1n \u0111o\u1ea1n d\u1ecbch v\u1ee5 n\u1ebfu n\u00f3 kh\u00f4ng kh\u1ea3 d\u1ee5ng. Nh\u01b0 v\u1eady, b\u1ea5t k\u00ec m\u1ed9t th\u00e0nh ph\u1ea7n n\u00e0o quan tr\u1ecdng cho h\u1ec7 th\u1ed1ng c\u1ee7a b\u1ea1n m\u00e0 kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng d\u1ef1 ph\u00f2ng c\u00f3 th\u1ec3 tr\u1edf th\u00e0nh m\u1ed9t singe point of failure. \u0110\u1ec3 lo\u1ea1i b\u1ecf c\u00e1c single point of failure, m\u1ed7i ph\u1ea7n nh\u1ecf trong \u1ee9ng d\u1ee5ng c\u1ee7a b\u1ea1n c\u1ea7n c\u00f3 s\u1ef1 chu\u1ea9n b\u1ecb d\u1ef1 ph\u00f2ng.","title":"1.3 : M\u1ee5c ti\u00eau c\u1ee7a  High Availability"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#14_cac_thanh_phan_yeu_cau_high_avaibability","text":"C\u00f3 m\u1ed9t s\u1ed1 th\u00e0nh ph\u1ea7n ph\u1ea3i \u0111\u01b0\u1ee3c xem x\u00e9t c\u1ea9n th\u1eadn \u0111\u1ec3 th\u1ef1c hi\u1ec7n t\u00ednh s\u1eb5n s\u00e0ng cao trong th\u1ef1c t\u1ebf. T\u00ednh s\u1eb5n s\u00e0ng cao ph\u1ee5 thu\u1ed9c v\u00e0o c\u00e1c th\u00e0nh ph\u1ea7n sau : - Enviroment : n\u00eau t\u1ea5t c\u1ea3 c\u00e1c m\u00e1y ch\u1ee7 c\u00f9ng \u0111\u1eb7t t\u1ea1i m\u1ed9t v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd , m\u1ed9t th\u1ea3m h\u1ecda t\u1ef1 nhi\u00ean c\u00f3 th\u1ec3 l\u00e0m h\u1ecfng h\u00f3c c\u00e1c server n\u00e0y . C\u00f3 c\u00e1ch server \u0111\u1eb7t t\u1ea1i c\u00e1c v\u1ecb tr\u00ed \u0111\u1ecba l\u00fd kh\u00e1c nhau s\u1ebd t\u0103ng \u0111\u1ed9 tin c\u1eady - Hardware : t\u0103ng t\u00ednh kh\u1ea3 d\u1ee5ng cao cho server c\u00f3 th\u1ec3 li\u00ean quan \u0111\u1ebfn v\u1ea5n \u0111\u1ec1 ngu\u1ed3n, l\u1ed7i ph\u1ea7n c\u1ee9ng nh\u01b0 disk ho\u1eb7c network interface - Software : h\u1ec7 th\u1ed1ng x\u00e2y d\u1ef1ng l\u00ean c\u00e1c \u1ee9ng d\u1ee5ng k\u1ec3 c\u1ea3 h\u1ec7 \u0111i\u1ec1u h\u00e0nh c\u1ea7n ph\u1ea3i chu\u1ea9n b\u1ecb \u0111\u1ec3 ch\u1ed1ng l\u1ea1i x\u00e1c l\u1ed7i kh\u00f4ng mong mu\u1ed1n , \u0111\u1ea3m b\u1ea3o t\u00ednh d\u1ef1 ph\u00f2ng v\u00e0 to\u00e0n v\u1eb9n d\u1eef li\u1ec7u - Data : m\u1ea5t d\u1eef li\u1ec7u s\u1ebd l\u00e0m to\u00e0n b\u1ed9 h\u1ed1ng th\u1ed1ng \u0111i v\u00e0o ng\u1eebng ho\u1ea1t \u0111\u1ed9ng, ch\u00fang ta c\u1ea7n \u0111\u1ea3m b\u1ea3o \u1ed5 \u0111\u0129a c\u1ee7a ch\u00fang ta kh\u00f4ng x\u1ea3y ra l\u1ed7i kh\u00f4ng mong mu\u1ed1n - Network : \u0111\u1ea3m b\u1ea3o h\u1ea1 t\u1ea7ng m\u1ea1ng lu\u00f4n lu\u00f4n s\u1eb5ng s\u00e0ng \u0111\u1ecbnh tuy\u1ebfn v\u00e0 li\u00ean h\u1ec7","title":"1.4 : C\u00e1c th\u00e0nh ph\u1ea7n y\u00eau c\u1ea7u High Avaibability"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#2_xay_dung_he_thong_ung_dung_hight_avaibility","text":"","title":"2. X\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng \u1ee9ng d\u1ee5ng Hight Avaibility"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#21_cac_nguyen_nhan_gay_trinh_trang_downtime","text":"\u0110\u1ed1i v\u1edbi tr\u00ecnh down h\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 chia th\u00e0nh 2 d\u1ea1ng : \u0111\u00e3 l\u00ean l\u1ecbch v\u00e0 kh\u00f4ng l\u00ean l\u1ecbch \u0110\u1ed1i v\u1edbi t\u00ecnh tr\u1ea1ng d\u00e2y ra tr\u00ecnh tr\u1ea1ng down kh\u00f4ng l\u00ean l\u1ecbch c\u00f3 th\u1ec3 do c\u00e1c nguy\u00ean nh\u00e2n li\u00ean qu\u00e1 \u0111\u1ebfn l\u1ed7i h\u1ec7 th\u1ed1ng, d\u1eef li\u1ec7u , v\u00e0 m\u1ea5t \u0111i\u1ec7n \u0110\u1ed1i v\u1edbi c\u00e1c ho\u1ea1t \u0111\u1ed9ng g\u00e2y ra down h\u1ec7 th\u1ed1ng c\u00f3 ch\u1ee7 \u0111\u00edch c\u00f3 th\u1ec3 do n\u00e2ng c\u1ea5p h\u1ec7 th\u1ed1ng, n\u00e2ng c\u1ea5p h\u1ea1 t\u1ea7ng m\u1ea1ng ho\u1eb7c ki\u1ec3m th\u1eed c\u00f3 k\u1ebf ho\u1ea1ch","title":"2.1. C\u00e1c nguy\u00ean nh\u00e2n g\u00e2y tr\u00ecnh tr\u1ea1ng downtime"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#22_mot_so_mo_hinh","text":"","title":"2.2. M\u1ed9t s\u1ed1 m\u00f4 h\u00ecnh"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#3_tai_lieu","text":"","title":"3. T\u00e0i li\u1ec7u"},{"location":"Openstack_Research/High-availability/1. Introduction-HA/#-_httpswwwdigitaloceancomcommunitytutorialswhat-is-high-availability","text":"","title":"- https://www.digitalocean.com/community/tutorials/what-is-high-availability"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/","text":"T\u00ecm hi\u1ec3u HA Proxy v\u00e0 Keep Alive \u00b6 1. Load Balancing v\u00e0 c\u00e1c kh\u00e1i ni\u1ec7m li\u00ean quan \u00b6 C\u00e2n B\u1eb1ng T\u1ea3i l\u00e0 vi\u1ec7c ph\u00e2n b\u1ed1 \u0111\u1ed3ng \u0111\u1ec1u l\u01b0u l\u01b0\u1ee3ng truy c\u1eadp gi\u1eefa hai hay nhi\u1ec1u c\u00e1c m\u00e1y ch\u1ee7 c\u00f3 c\u00f9ng ch\u1ee9c n\u0103ng trong c\u00f9ng m\u1ed9t h\u1ec7 th\u1ed1ng. B\u1eb1ng c\u00e1ch \u0111\u00f3, s\u1ebd gi\u00fap cho h\u1ec7 th\u1ed1ng gi\u1ea3m thi\u1ec3u t\u1ed1i \u0111a t\u00ecnh tr\u1ea1ng m\u1ed9t m\u00e1y ch\u1ee7 b\u1ecb qu\u00e1 t\u1ea3i v\u00e0 ng\u01b0ng ho\u1ea1t \u0111\u1ed9ng. Ho\u1eb7c khi m\u1ed9t m\u00e1y ch\u1ee7 g\u1eb7p s\u1ef1 c\u1ed1, C\u00e2n B\u1eb1ng T\u1ea3i s\u1ebd ch\u1ec9 \u0111\u1ea1o ph\u00e2n ph\u1ed1i c\u00f4ng vi\u1ec7c c\u1ee7a m\u00e1y ch\u1ee7 \u0111\u00f3 cho c\u00e1c m\u00e1y ch\u1ee7 c\u00f2n l\u1ea1i, \u0111\u1ea9y th\u1eddi gian uptime c\u1ee7a h\u1ec7 th\u1ed1ng l\u00ean cao nh\u1ea5t v\u00e0 c\u1ea3i thi\u1ec7n n\u0103ng su\u1ea5t ho\u1ea1t \u0111\u1ed9ng t\u1ed5ng th\u1ec3. C\u00e2n B\u1eb1ng T\u1ea3i c\u0169ng l\u00e0 c\u01a1 ch\u1ebf r\u1ea5t quan tr\u1ecdng trong vi\u1ec7c m\u1edf r\u1ed9ng quy m\u00f4 c\u1ee7a m\u1ea1ng m\u00e1y t\u00ednh. Khi l\u1eafp \u0111\u1eb7t m\u1ed9t m\u00e1y ch\u1ee7 m\u1edbi v\u00e0o h\u1ec7 th\u1ed1ng, C\u00e2n B\u1eb1ng T\u1ea3i s\u1ebd t\u1ef1 \u0111\u1ed9ng c\u1eaft gi\u1ea3m kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c t\u1eeb c\u00e1c m\u00e1y ch\u1ee7 c\u0169 v\u00e0 chuy\u1ec3n sang m\u00e1y ch\u1ee7 m\u1edbi. M\u1ed9t b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng tr\u00ean : Link level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 link load balancing, n\u00f3 g\u1ed3m vi\u1ec7c ch\u1ecdn c\u00e1c network link \u0111\u1ec3 g\u1eedi c\u00e1c c\u00e1c packet Network level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 network load balancing, n\u00f3 bao g\u1ed3m c\u00e1c c\u00f4ng vi\u1ec7c ch\u1ecdn tuy\u1ec1n \u0111\u01b0\u1eddng m\u00e0 c\u00e1c packet s\u1ebd \u0111i ( packet flow ) Server level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 server local balancing, n\u00f3 bao g\u1ed3m c\u00e1c c\u00f4ng vi\u1ec7c x\u00e1c \u0111\u1ecbnh server n\u00e0o s\u1ebd x\u1eed l\u00fd t\u00e1c v\u1ee5 ho\u1eb7c request . Load balancing c\u00f3 2 lo\u1ea1i th\u1ec3 hi\u1ec7n qua c\u00e1ch l\u00e0m v Layer 4: TCP (layer transport - m\u00f4 h\u00ecnh OSI) Layer 7: HTTP (layer application - m\u00f4 h\u00ecnh OSI) Load balancing tr\u00ean layer 4: s\u1ebd chuy\u1ec3n ti\u1ebfp nh\u1eefng l\u01b0u l\u01b0\u1ee3ng, d\u1eef li\u1ec7u \u0111i qua n\u00f3 d\u1ef1a tr\u00ean IP v\u00e0 port t\u01b0\u01a1ng \u1ee9ng (v\u00ed d\u1ee5 c\u00f3 1 request t\u1edbi abc.com th\u00ec t\u1ea5t c\u1ea3 traffic s\u1ebd \u0111\u01b0\u1ee3c truy\u1ec1n t\u1edbi 1 trong c\u00e1c server backend \u0111\u1ec3 x\u1eed l\u00fd t\u1ea5t c\u1ea3 request cho abc.com tr\u00ean port 80). T\u1ea5t c\u1ea3 c\u00e1c server trong web-backend s\u1ebd ph\u1ea3i c\u00f3 n\u1ed9i dung gi\u1ed1ng h\u1ec7t nhau n\u1ebfu kh\u00f4ng ng\u01b0\u1eddi d\u00f9ng s\u1ebd c\u00f3 th\u1ec3 nh\u1eadn ra s\u1ef1 kh\u00e1c nhau \u0111\u00f3 khi truy c\u1eadp t\u1edbi domain t\u01b0\u01a1ng \u1ee9ng. L\u01b0u \u00fd l\u00e0 c\u00e1c web-backend ph\u1ea3i connect t\u1edbi c\u00f9ng 1 database. Load balancing tr\u00ean layer 7: cho ph\u00e9p c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ec3 chuy\u1ec3n ti\u1ebfp c\u00e1c request t\u1edbi nh\u1eefng server backend t\u01b0\u01a1ng \u1ee9ng d\u1ef1a tr\u00ean n\u1ed9i dung c\u1ee7a request t\u1eeb ng\u01b0\u1eddi d\u00f9ng. Ch\u1ebf \u0111\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i n\u00e0y cho ph\u00e9p b\u1ea1n ch\u1ea1y nhi\u1ec1u m\u00e1y ch\u1ee7 web d\u01b0\u1edbi c\u00f9ng m\u1ed9t t\u00ean mi\u1ec1n v\u00e0 c\u1ed5ng. Proxy l\u00e0 1 internet server l\u00e0m nhi\u1ec7m v\u1ee5 chuy\u1ec3n ti\u1ebfp, ki\u1ec3m so\u00e1t th\u00f4ng tin gi\u1eefa client v\u00e0 server, proxy c\u00f3 1 \u0111\u1ecba ch\u1ec9 IP v\u00e0 1 port c\u1ed1 \u0111\u1ecbnh. C\u00e1ch th\u1ee9c ho\u1ea1t \u0111\u1ed9ng: t\u1ea5t c\u1ea3 c\u00e1c y\u00eau c\u1ea7u t\u1eeb client g\u1eedi \u0111\u1ebfn server tr\u01b0\u1edbc h\u1ebft ph\u1ea3i th\u00f4ng qua proxy, proxy ki\u1ebfm tra xem y\u00eau c\u1ea7u n\u1ebfu \u0111\u01b0\u1ee3c ph\u00e9p s\u1ebd g\u1eedi \u0111\u1ebfn server v\u00e0 c\u0169ng t\u01b0\u01a1ng t\u1ef1 cho server. \u2013 Forward proxy: \u0111\u00e2y l\u00e0 m\u1ed9t server nh\u1eb1m nhi\u1ec7m v\u1ee5 chuy\u1ec3n ti\u1ebfp c\u00e1c packet t\u1eeb client \u0111\u1ebfn c\u00e1c server kh\u00e1c \u2013 Reverse proxy: \u0111ay l\u00e0 m\u1ed9t server \u0111\u1ee9ng tr\u01b0\u1edbc m\u1ed9t ho\u1eb7c nhi\u1ec1u server, l\u1eafng nghe v\u00e0 ki\u1ec3m so\u00e1t c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb c\u00e1c client kh\u00e1c. - Fail-over l\u00e0 cho ph\u00e9p c\u00f4ng vi\u1ec7c th\u01b0\u1eddng ch\u1ec9 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 kh\u00e1c khi m\u1ed9t trong 2 m\u00e1y ch\u1ee7 x\u1ea3y ra s\u1ef1 c\u1ed1. 2. HA Proxy \u00b6 2.1 . M\u1edf \u0111\u1ea7u v\u1ec1 HA Proxy \u00b6 HAProxy ( Hight Availability Proxy ) l\u00e0 m\u1ed9t ph\u1ea7n m\u1ec1m mi\u1ec5n ph\u00ed v\u00e0 m\u00e3 ngu\u1ed3n m\u1edf, n\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i v\u00e0 proxy server cho TCP v\u00e0 HTTP. \u0110\u00e2y l\u00e0 gi\u1ea3i ph\u00e1p ph\u00f9 h\u1ee3p cho c\u00e1c website c\u00f3 l\u01b0\u1ee3ng truy c\u1eadp l\u1edbn tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m . Trong nh\u1eefng n\u0103m g\u1ea7n \u0111\u00e2y HA Proxy \u0111ang ph\u1edf th\u00e0nh b\u1ed9 c\u00f4ng c\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean n\u1ec1n t\u1ea3ng m\u00e3 ngu\u1ed3n m\u1edf ph\u1ed5 bi\u1ebfn, hi\u1ec7n nay HA Proxy \u0111\u01b0\u1ee3c ph\u00e2n ph\u1ed1i h\u1ea7u h\u1ebft tr\u00ean c\u00e1c b\u1ea3n distrobution ch\u00ednh g\u1ed1c c\u1ee7a Linux . 2.2 . HA Proxy l\u00e0m \u0111\u01b0\u1ee3c g\u00ec g\u00ec ? \u00b6 HA \u0111\u01b0\u1ee3c c\u1ea5u th\u00e0nh t\u1eeb nhi\u1ec1u th\u00e0nh ph\u1ea7n, v\u00e0 \u0111\u1ea3m nhi\u1ec7m \u0111\u01b0\u1ee3c nhi\u1ec1u c\u00f4ng vi\u1ec7c kh\u00e1c nhau : - TCP Proxy: c\u00f3 c\u00f3 th\u1ec3 ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i tcp t\u1eeb listening socket, k\u1ebft n\u1ed1i n\u00f3 t\u1edbi server v\u00e0 g\u00e1n c\u00e1c sockets n\u00e0y l\u1ea1i v\u1edbi nhau cho ph\u00e9p traffic di chuy\u1ec3n theo c\u1ea3 hai chi\u1ec1u - HTTP reverse-proxy: Hay c\u00f2n g\u1ecdi l\u00e0 gateway, t\u1ef1 b\u1ea3n th\u00e2n n\u00f3 c\u00f3 th\u1ec3 l\u00e0 server, nh\u1eadn c\u00e1c http requests t\u1eeb k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c th\u00f4ng qua b\u1edfi listening TCP socket v\u00e0 chuy\u1ec3n c\u00e1c requests n\u00e0y t\u1edbi c\u00e1c server b\u1eb1ng nhi\u1ec1u k\u1ebft n\u1ed1i kh\u00e1c nhau. - SSL terminator / initiator / offloader : s\u1eed d\u1ee5ng SSL/TLS tr\u00ean c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb client - TCP normalizer : b\u1ea3o v\u1ec7 c\u00e1c TCP stack kh\u1ecfi c\u00e1c cu\u1ed9c t\u1ea5n c\u00f4ng, - HTTP normalizer : khi c\u1ea5u h\u00ecnh \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c HTTP traffic, ch\u1ec9 c\u00e1c request h\u1ee3p l\u1ec7 m\u1edbi \u0111\u01b0\u1ee3c ch\u1ea5p nh\u1eadn, \u0111i\u1ec1u n\u00e0y ch\u1ed1ng l\u1ea1i c\u00e1c protocol kh\u00e1c c\u00f3 m\u1ee5c \u0111\u00edch t\u1ea5n c\u00f4ng. - HTTP fixing tool : c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh c\u00e1c c\u00e1c request ho\u1eb7c c\u00e1c reponse header - content-based switch: d\u1ef1a v\u00e0o th\u00e0nh ph\u1ea7n c\u1ee7a request \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh server nh\u1eadn - server load balancer : n\u00f3 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean c\u00e1c k\u1ebft n\u1ed1i TCP v\u00e0 HTTP . Tr\u00ean TCP n\u00f3 s\u1ebd nh\u1eadn t\u1ea5t c\u1ea3 c\u00e1c request , tr\u00ean HTTP s\u1ebd quy\u1ebft \u0111\u1ecbnh ch\u1ea5p nh\u1eadn tr\u00ean t\u1eebng k\u1ebft n\u1ed1i . - traffic regulator: th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 rule \u0111\u1ec3 limit traffic, ch\u1ed1ng l\u1ea1i vi\u1ec7c qu\u00e1 t\u1ea3i , d\u1ef1a tr\u00ean n\u1ed9i dung header \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c banwith c\u1ee7a c\u00e1c k\u1ebft n - protection against DDoS: n\u00f3 c\u00f3 th\u1ec3 l\u01b0u gi\u1eef danh s\u1ed1 li\u1ec7u v\u1ec1 \u0111\u1ecba ch\u1ec9 ip, url,... v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng (l\u00e0m ch\u1eadm, block,...) - network troubleshooting : x\u1eed l\u00fd c\u00e1c log - HTTP compression offloader : n\u1ebfn c\u00e1c reponse kh\u00f4ng \u0111\u01b0\u1ee3c n\u00e9n b\u1edfi c\u00e1c server 2.3 . HA Proxy ho\u1ea1t \u0111\u1ed9ng nh\u01b0 th\u1ebf n\u00e0o . \u00b6 HA Proxy l\u00e0 m\u1ed9t c\u00f4ng ngh\u1ec7 \u0111\u01a1n lu\u1ed3ng, h\u01b0\u1edbng s\u1ef1 ki\u1ec7n v\u00e0 non-blocking ( tham kh\u1ea3o thu\u1eadt ng\u1eef t\u1ea1i \u0111\u00e2y ) k\u1ebft h\u1ee3p v\u1edbi I/O d\u1ef1a tr\u00ean \u0111\u1ed9 \u01b0u ti\u00ean c\u1ee7a c\u00e1c sheduler . HA proxy ch\u1ec9 y\u00eau c\u1ea7u m\u1ed9t haproxy package v\u00e0 m\u1ed9t t\u1eadp tin c\u1ea5u h\u00ecnh \u0111\u1ec3 ho\u1ea1t \u0111\u1ed9ng. \u0110\u1ec3 ghi ch\u00fa log c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng syslog Trong HAproxy Front-end v\u00e0 back-end \u0111\u01b0\u1ee3c xem l\u00e0 m\u1ed9t n\u1eeda c\u1ee7a proxy, v\u00ec ch\u00fang ch\u1ec9 quan t\u00e2m k\u1ebft n\u1ed1i \u1edf \u0111\u1ea7u c\u00f2n l\u1ea1i ( front to client, back-end to server ) . Front-end ch\u1ec9 quan t\u00e2m t\u1edbi client trong khi \u0111\u00f3 back-end quan t\u00e2m t\u1edbi c\u00e1c server. HA proxy ch\u1ec9 h\u1ed7 tr\u1ee3 kh\u1edfi t\u1ea1o m\u1ed9t proxy \u0111\u1ea7y \u0111\u1ee7 khi c\u00f3 front-end v\u00e0 back-end. V\u1edbi c\u00e1c HTTP request th\u00ec front-end s\u1ebd l\u00e0m nhi\u1ec7m v\u1ee5 filter, trong \u0111\u00f3 m\u1ecdi front-end c\u00f3 th\u1ec3 g\u1eedi c\u00e1c k\u1ebft n\u1ed1i t\u1edbi m\u1ecdi back-end. Ngo\u00e0i font-end v\u00e0 back-end ,c\u00f2n c\u00f3 Access Control List (ACL) Trong c\u00e2n b\u1eb1ng t\u1ea3i, ACL \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 ki\u1ec3m tra \u0111i\u1ec1u ki\u1ec7n v\u00e0 th\u1ef1c hi\u1ec7n m\u1ed9t h\u00e0nh \u0111\u1ed9ng (v\u00ed d\u1ee5 nh\u01b0 l\u1ef1a ch\u1ecdn m\u1ed9t server hay ch\u1eb7n m\u1ed9t request) d\u1ef1a tr\u00ean k\u1ebft qu\u1ea3 c\u1ee7a vi\u1ec7c ki\u1ec3m tra \u0111\u00f3. Vi\u1ec7c s\u1eed d\u1ee5ng ACL cho ph\u00e9p t\u1ea1o m\u1ed9t m\u00f4i tr\u01b0\u1eddng c\u00f3 kh\u1ea3 n\u0103ng chuy\u1ec3n ti\u1ebfp c\u00e1c request m\u1ed9t c\u00e1ch linh ho\u1ea1t d\u1ef1a tr\u00ean c\u00e1c y\u1ebfu t\u1ed1 kh\u00e1c nhau m\u00e0 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng. M\u1ed7i khi HA proxy \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng , n\u00f3 th\u1ef1c hi\u1ec7n 3 q\u00faa tr\u00ecnh x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn ki\u1ec3m tra tr\u1ea1ng th\u00e1i c\u1ee7a c\u00e1c server ( heath check ) trao \u0111\u1ed5i c\u00e1c th\u00f4ng tin v\u1edbi c\u00e1c ha proxy node kh\u00e1c \u0110\u1ec3 x\u1eed l\u00fd m\u1ed9t k\u1ebft n\u1ed1i \u0111\u1ebfn c\u1ea7n tr\u1ea9i qua r\u1ea5t nhi\u00eafu qu\u00e1 tr\u00ecnh, t\u00f9y v\u00e0o t\u1eebng c\u1ea5u h\u00ecnh qu\u00e1 tr\u00ecnh n\u00e0y c\u00f3 th\u1ec3 ph\u1ea3i x\u1eed l\u00fd nhi\u1ec1u ho\u1eb7c \u00edt c\u00e1c t\u00e1c v\u1ee5 ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb c\u00e1c socket t\u1eeb entry \"frontend\", tuyf v\u00e0o c\u1ea5u h\u00ecnh s\u1ebd l\u1eafng nghe tr\u00ean m\u1ed9t ho\u1eb7c nhi\u1ec1u \u0111\u1ecba ch\u1ec9 d\u1ef1a v\u00e0o c\u00e1c rule front-end s\u1ebd x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i n\u00e0y : ch\u1eb7n, ch\u1ec9nh s\u1eeda c\u00e1c header.... ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1edbi entry \"back-end\" n\u01a1i ch\u1ee9a c\u00e1c server v\u00e0 c\u00e1c quy t\u1eafc \u0111\u1ec3 c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean c\u00e1c server n\u00e0y \u00e1p d\u1ee5ng c\u00e1c rule back-end \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i x\u00e1c \u0111\u1ecbnh server s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c chi\u1ebfn l\u01b0\u1ee3c c\u00e2n b\u1eb1ng t\u1ea3i \u00e1p d\u1ee5ng c\u00e1c back-end rule cho c\u00e1c response data \u00e1p d\u1ee5ng c\u00e1c front-end rule cho c\u00e1c response data x\u1eed l\u00fd log \u0111\u1ec3 xem ti\u1ebfn tr\u00ecnh trong HTTP, s\u1ebd tr\u1edf l\u1ea1i b\u01b0\u1edbc 2 \u0111\u1ec3 nghe c\u00e1c k\u1ebft n\u1ed1i ti\u1ebfp theo ho\u1eb7c l\u00e0 \u0111\u00f3ng k\u1ebft n\u1ed1i 2.4 C\u00e1c t\u00ednh n\u0103ng c\u01a1 b\u1ea3n \u00b6 Proxying SSL Monitoring HA Load balancing Sampling and converting information Maps ACLs and conditions Content switching HTTP rewriting and redirection Server protection Logging Statistics Tham kh\u1ea3o th\u00eam 2.5 . Thu\u1eadt t\u00f3an s\u1eed d\u1ee5ng trong HA Proxy \u00b6 Back-end l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c server farm v\u00e0 x\u1eed l\u00fd c\u00e1c request t\u1edbi ch\u00fang b\u1eb1ng c\u00e1ch l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c th Round Robin: \u0110\u00e2y l\u00e0 thu\u1eadt to\u00e1n c\u00e2n b\u1eb1ng \u0111\u01a1n gi\u1ea3n nh\u1ea5t. \u0110\u1ed1i v\u1edbi m\u1ed7i k\u1ebft n\u1ed1i m\u1edbi, n\u00f3 s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi c\u00e1c m\u00e1y ch\u1ee7 backend ti\u1ebfp theo. N\u1ebfu m\u00e1y ch\u1ee7 backend cu\u1ed1i c\u00f9ng trong danh s\u00e1ch \u0111\u01b0\u1ee3c \u0111\u1ea1t t\u1edbi, n\u00f3 s\u1ebd b\u1eaft \u0111\u1ea7u l\u1ea1i t\u1eeb \u0111\u1ea7u danh s\u00e1ch backend. Least Connections: C\u00e1c k\u1ebft n\u1ed1i m\u1edbi s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi c\u00e1c m\u00e1y ch\u1ee7 backend v\u1edbi s\u1ed1 l\u01b0\u1ee3ng k\u1ebft n\u1ed1i \u00edt nh\u1ea5t. \u0110i\u1ec1u n\u00e0y r\u1ea5t h\u1eefu \u00edch khi th\u1eddi gian v\u00e0 c\u00e1c request r\u1ea5t l\u1edbn. Source: \u0110\u00e2y l\u00e0 phi\u00ean d\u00ednh, c\u00e1c IP c\u1ee7a client s\u1ebd \u0111\u01b0\u1ee3c b\u0103m \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh m\u00e1y ch\u1ee7 backend \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u cu\u1ed1i c\u00f9ng t\u1eeb IP n\u00e0y. V\u00ec v\u1eady, m\u1ed9t IP A s\u1ebd lu\u00f4n \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi backend1, v\u00e0 IP B s\u1ebd lu\u00f4n lu\u00f4n \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi banckend2 \u0111\u1ec3 kh\u00f4ng l\u00e0m gi\u00e1n \u0111o\u1ea1n phi\u00ean. Static Round Robin: T\u01b0\u01a1ng t\u1ef1 nh\u01b0 Round Robin, m\u1ed7i m\u00e1y ch\u1ee7 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong v\u00f2ng l\u1eb7p d\u1ef1a tr\u00ean weight. Nh\u01b0ng thay \u0111\u1ed5i weight c\u1ee7a m\u00e1y ch\u1ee7 tr\u00ean c\u0169ng kh\u00f4ng \u1ea3nh h\u01b0\u1edfng g\u00ec. B\u1ea1n c\u00f3 th\u1ec3 t\u1ef1 x\u00e1c \u0111\u1ecbnh bao nhi\u00eau server m\u00e0 b\u1ea1n mu\u1ed1n. Khi m\u1ed9t m\u00e1y ch\u1ee7 t\u0103ng l\u00ean, n\u00f3 s\u1ebd lu\u00f4n lu\u00f4n \u0111\u01b0\u1ee3c ngay l\u1eadp t\u1ee9c \u0111\u01b0a l\u1ea1i v\u00e0o 1 b\u1ea3ng sau khi \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n l\u1ea1i weight. URI: Thu\u1eadt to\u00e1n n\u00e0y b\u0103m ho\u1eb7c ph\u1ea7n b\u00ean tr\u00e1i c\u1ee7a URI, ho\u1eb7c to\u00e0n b\u1ed9 URI v\u00e0 chia gi\u00e1 tr\u1ecb b\u0103m b\u1eb1ng t\u1ed5ng weight c\u1ee7a m\u00e1y ch\u1ee7 \u0111ang ch\u1ea1y. C\u00f9ng URI lu\u00f4n h\u01b0\u1edbng \u0111\u1ebfn c\u00f9ng m\u1ed9t server mi\u1ec5n l\u00e0 kh\u00f4ng c\u00f3 m\u00e1y ch\u1ee7 up ho\u1eb7c down. N\u00f3 c\u0169ng l\u00e0 m\u1ed9t thu\u1eadt to\u00e1n t\u0129nh v\u00e0 ho\u1ea1t \u0111\u1ed9ng theo c\u00e1ch t\u01b0\u01a1ng t\u1ef1 nh\u01b0 c\u00e1c thu\u1eadt to\u00e1n Source. URL Parameter: Thu\u1eadt to\u00e1n t\u0129nh n\u00e0y ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng tr\u00ean m\u1ed9t backend HTTP. C\u00e1c tham s\u1ed1 URL \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh s\u1ebd \u0111\u01b0\u1ee3c nh\u00ecn trong chu\u1ed7i truy v\u1ea5n c\u1ee7a m\u1ed7i y\u00eau c\u1ea7u HTTP GET. N\u1ebfu tham s\u1ed1 \u0111\u00f3 \u0111\u01b0\u1ee3c t\u00ecm th\u1ea5y b\u1edfi m\u1ed9t d\u1ea5u hi\u1ec7u v\u00e0 gi\u00e1 tr\u1ecb nh\u01b0 nhau, gi\u00e1 tr\u1ecb \u0111\u01b0\u1ee3c b\u0103m v\u00e0 chia cho t\u1ed5ng tr\u1ecdng l\u01b0\u1ee3ng c\u1ee7a m\u00e1y ch\u1ee7 \u0111ang ch\u1ea1y. 3. Keep Alive \u00b6 3.1. C\u00e1c thu\u1eadt ng\u1eef \u00b6 VIP : Virtual IP, s\u1eed d\u1ee5ng cho c\u00e1c client truy c\u1eadp Keep Alived s\u1eed d\u1ee5ng 4 module kernel \u0111\u1ec3 l\u00e0m vi\u1ec7c LVS framework : d\u00f9ng \u0111\u1ec3 giao ti\u1ebfp socket Netfilter framework : s\u1eed d\u1ee5ng \u0111\u1ec3 ho\u1ea1t \u0111\u1ed9ng IP Virtual Server Netlink interface : \u0111i\u1ec1u khi\u1ec3n , th\u00eam x\u00f3a VRRRP VIP tr\u00ean card m\u1ea1ng Multicast : g\u1eedi c\u00e1c b\u1ea3n tin VRRP \u0111\u1ebfn \u0111\u1ecba ch\u1ec9 multicast Virtual Router Redundancy Protocol \u2013 VRRP c\u00f3 ch\u1ee9c n\u0103ng t\u01b0\u01a1ng t\u1ef1 nh\u01b0 v\u1edbi HSRP l\u00e0 cho ph\u00e9p c\u00e1c Router cisco c\u00f9ng tham gia m\u1ed9t nh\u00f3m x\u00e2y d\u1ef1ng m\u1ed9t router \u1ea3o l\u00e0m gateway cho c\u00e1c host n\u1eb1m tr\u00ean m\u1ea1ng LAN, th\u1ef1c hi\u1ec7n d\u1ef1 ph\u00f2ng gateway cho c\u00e1c host \u0111\u1ea7u cu\u1ed1i n\u00e0y. \u0110i\u1ec3m kh\u00e1c bi\u1ec7t l\u00e0 n\u1ebfu HSRP l\u00e0 giao th\u1ee9c c\u1ee7a Cisco ch\u1ec9 ch\u1ea1y tr\u00ean thi\u1ebft b\u1ecb Cisco, th\u00ec VRRP l\u00e0 giao th\u1ee9c qu\u1ed1c t\u1ebf c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean nhi\u1ec1u s\u1ea3n ph\u1ea9m c\u1ee7a nhi\u1ec1u nh\u00e0 s\u1ea3n xu\u1ea5t kh\u00e1c nhau. VRRP \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 trong RFC \u2013 3768 c\u1ee7a IETF. 3.2 M\u1edf \u0111\u1ea7u v\u1ec1 Keep Alive \u00b6 C\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean t\u1ea7ng 4 v\u00e0 t\u1ea7ng 7 \u0111\u01b0\u1ee3c mi\u00eau t\u1ea3 \u1edf tr\u00ean \u0111\u1ec1u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ec3 chuy\u1ec3n c\u00e1c request t\u1edbi c\u00e1c backend server. Tuy nhi\u00ean, ch\u00ednh c\u00e2ng b\u1eb1ng t\u1ea3i c\u1ee7a b\u1ea1n l\u00e0 m\u1ed9t \u0111i\u1ec3m l\u1ed7i (single point of failure), v\u00ec n\u1ebfu c\u00e2n b\u1eb1ng t\u1ea3i g\u1eb7p s\u1ef1 c\u1ed1 nh\u01b0ng c\u00e1c server \u0111\u1ec1u ch\u1ea1y b\u00ecnh th\u01b0\u1eddng th\u00ec ng\u01b0\u1eddi d\u00f9ng c\u0169ng kh\u00f4ng th\u1ec3 k\u1ebft n\u1ed1i \u0111\u1ebfn \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng web trong khi web server v\u1eabn \u0111ang ch\u1ea1y b\u00ecnh th\u01b0\u1eddng. Keep Alive \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t heat beat packet trong m\u1ed9t m\u00f4 h\u00ecnh m\u1ea1ng, \u0111\u01b0\u1ee3c m\u1ed9t thi\u1ebft b\u1ecb nh\u01b0 Router g\u1eedi m\u1ed9t packet \u0111\u1ebfn c\u00e1c thi\u1ebft b\u1ecb kh\u00e1c trong m\u1ed9t m\u00f4 h\u00ecnh m\u1ea1ng , m\u1ee5c \u0111\u00edch c\u1ee7a keep alive nh\u1eb1m ki\u1ec3m tra tr\u1ea1ng th\u00e1i k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c thi\u1ebft b\u1ecb v\u1edbi nhau . \u0110\u1ec3 ho\u1ea1t \u0111\u1ed9ng keep alive c\u00f3 2 ki\u1ec3m c\u1ea7n ch\u00fa \u00fd : keep alive interval : th\u1eddi gian g\u1eedi packet ki\u1ec3m tra gi\u1eefa c\u00e1c packet. keep alive retries : s\u1ed1 l\u1ea7n c\u1ed1 g\u1eafn g\u1eedi packet \u0111\u1ebfn m\u1ed9t thi\u1ebft b\u1ecb khi kh\u00f4ng \u0111\u01b0\u1ee3c reply \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh l\u00e0m m\u1ed9t h\u00e0nh \u0111\u1ed9ng thi\u1ebfp theo. Nh\u01b0 v\u1eady keep alive s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 sau : M\u1ed9t g\u00f3i tin keep alive \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb A \u0111\u1ebfn B v\u1edbi m\u1ed1c th\u1eddi gianj theo \u0111\u1ecbnh k\u1ef3 Sau khi thi\u1ebft b\u1ecb A g\u1eedi g\u00f3i tin s\u1ebd ch\u1edd ph\u1ea3n ph\u1ed3i t\u1eeb thi\u1ebft b\u1ecb B, l\u00fac n\u00e0y s\u1ebd x\u1ea3y ra 2 tr\u01b0\u1eddng h\u1ee3p : Thi\u1ebft b\u1ecb B s\u1ebd tr\u1ea3 v\u1ec1 m\u1ed9t response \u0111\u1ec3 thi\u1ebft b\u1ecb A bi\u1ebft tr\u1ea1ng th\u00e1i Sau n l\u1ea7n th\u1eed thi\u1ebft b\u1ecb A kh\u00f4ng th\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c response t\u1eeb thi\u1ebft b\u1ecb B, thi\u1ebft b\u1ecb A s\u1ebd s\u1ebd nh\u01b0 \u0111\u01b0\u1eddng n\u00e0y \u0111ang \u1edf tr\u1ea1ng th\u00e1i down Sau \u0111\u00f3 thi\u1ebft b\u1ecb A s\u1ebd quy\u1ebft \u0111\u1ecbnh chuy\u1ec3n h\u01b0\u01a1ngs data d\u1ef1a v\u00e0o output \u1edf b\u01b0\u1edbc 2 IP VIP : Th\u1ef1c s\u1ef1 n\u00f3 l\u00e0 m\u1ed9t IP \u0111\u01b0\u1ee3c g\u00e1n th\u00eam tr\u00ean m\u1ed9t network alias (virtual interface) c\u1ee7a haproxy. T\u00ednh ch\u1ea5t virtual c\u1ee7a n\u00f3 n\u1eb1m \u1edf ch\u1ed7 n\u00f3 kh\u00f4ng g\u1eafn c\u1ed1 \u0111\u1ecbnh tr\u00ean m\u1ed9t network interface th\u1eadt s\u1ef1 n\u00e0o c\u1ea3. Khi c\u00f3 s\u1ef1 c\u1ed1 x\u1ea3y ra, keepalived s\u1ebd h\u1ee7y ip tr\u00ean network alias c\u1ee7a haproxy down v\u00e0 t\u1ea1o tr\u00ean haproxy backup Trong HA, keep alive cung c\u1ea5p VIP ) cho m\u1ed9t Cluser . Cho ph\u00e9p c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i ho\u1ea1t \u0111\u1ed9ng theo c\u01a1 ch\u1ebf Active-Backup. N\u1ebfu b\u1ed9 load balancer ch\u00ednh b\u1ecb down , th\u00ec IP Floating s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n v\u1ec1 v\u1ec1 b\u1ed9 load blancer ph\u1ee5, nh\u1edd \u0111\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng failure cho h\u1ec7 th\u1ed1ng n\u00e0y. - END.","title":"1.Intro"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#tim_hieu_ha_proxy_va_keep_alive","text":"","title":"T\u00ecm hi\u1ec3u HA Proxy v\u00e0 Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#1_load_balancing_va_cac_khai_niem_lien_quan","text":"C\u00e2n B\u1eb1ng T\u1ea3i l\u00e0 vi\u1ec7c ph\u00e2n b\u1ed1 \u0111\u1ed3ng \u0111\u1ec1u l\u01b0u l\u01b0\u1ee3ng truy c\u1eadp gi\u1eefa hai hay nhi\u1ec1u c\u00e1c m\u00e1y ch\u1ee7 c\u00f3 c\u00f9ng ch\u1ee9c n\u0103ng trong c\u00f9ng m\u1ed9t h\u1ec7 th\u1ed1ng. B\u1eb1ng c\u00e1ch \u0111\u00f3, s\u1ebd gi\u00fap cho h\u1ec7 th\u1ed1ng gi\u1ea3m thi\u1ec3u t\u1ed1i \u0111a t\u00ecnh tr\u1ea1ng m\u1ed9t m\u00e1y ch\u1ee7 b\u1ecb qu\u00e1 t\u1ea3i v\u00e0 ng\u01b0ng ho\u1ea1t \u0111\u1ed9ng. Ho\u1eb7c khi m\u1ed9t m\u00e1y ch\u1ee7 g\u1eb7p s\u1ef1 c\u1ed1, C\u00e2n B\u1eb1ng T\u1ea3i s\u1ebd ch\u1ec9 \u0111\u1ea1o ph\u00e2n ph\u1ed1i c\u00f4ng vi\u1ec7c c\u1ee7a m\u00e1y ch\u1ee7 \u0111\u00f3 cho c\u00e1c m\u00e1y ch\u1ee7 c\u00f2n l\u1ea1i, \u0111\u1ea9y th\u1eddi gian uptime c\u1ee7a h\u1ec7 th\u1ed1ng l\u00ean cao nh\u1ea5t v\u00e0 c\u1ea3i thi\u1ec7n n\u0103ng su\u1ea5t ho\u1ea1t \u0111\u1ed9ng t\u1ed5ng th\u1ec3. C\u00e2n B\u1eb1ng T\u1ea3i c\u0169ng l\u00e0 c\u01a1 ch\u1ebf r\u1ea5t quan tr\u1ecdng trong vi\u1ec7c m\u1edf r\u1ed9ng quy m\u00f4 c\u1ee7a m\u1ea1ng m\u00e1y t\u00ednh. Khi l\u1eafp \u0111\u1eb7t m\u1ed9t m\u00e1y ch\u1ee7 m\u1edbi v\u00e0o h\u1ec7 th\u1ed1ng, C\u00e2n B\u1eb1ng T\u1ea3i s\u1ebd t\u1ef1 \u0111\u1ed9ng c\u1eaft gi\u1ea3m kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c t\u1eeb c\u00e1c m\u00e1y ch\u1ee7 c\u0169 v\u00e0 chuy\u1ec3n sang m\u00e1y ch\u1ee7 m\u1edbi. M\u1ed9t b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng tr\u00ean : Link level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 link load balancing, n\u00f3 g\u1ed3m vi\u1ec7c ch\u1ecdn c\u00e1c network link \u0111\u1ec3 g\u1eedi c\u00e1c c\u00e1c packet Network level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 network load balancing, n\u00f3 bao g\u1ed3m c\u00e1c c\u00f4ng vi\u1ec7c ch\u1ecdn tuy\u1ec1n \u0111\u01b0\u1eddng m\u00e0 c\u00e1c packet s\u1ebd \u0111i ( packet flow ) Server level : \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 server local balancing, n\u00f3 bao g\u1ed3m c\u00e1c c\u00f4ng vi\u1ec7c x\u00e1c \u0111\u1ecbnh server n\u00e0o s\u1ebd x\u1eed l\u00fd t\u00e1c v\u1ee5 ho\u1eb7c request . Load balancing c\u00f3 2 lo\u1ea1i th\u1ec3 hi\u1ec7n qua c\u00e1ch l\u00e0m v Layer 4: TCP (layer transport - m\u00f4 h\u00ecnh OSI) Layer 7: HTTP (layer application - m\u00f4 h\u00ecnh OSI) Load balancing tr\u00ean layer 4: s\u1ebd chuy\u1ec3n ti\u1ebfp nh\u1eefng l\u01b0u l\u01b0\u1ee3ng, d\u1eef li\u1ec7u \u0111i qua n\u00f3 d\u1ef1a tr\u00ean IP v\u00e0 port t\u01b0\u01a1ng \u1ee9ng (v\u00ed d\u1ee5 c\u00f3 1 request t\u1edbi abc.com th\u00ec t\u1ea5t c\u1ea3 traffic s\u1ebd \u0111\u01b0\u1ee3c truy\u1ec1n t\u1edbi 1 trong c\u00e1c server backend \u0111\u1ec3 x\u1eed l\u00fd t\u1ea5t c\u1ea3 request cho abc.com tr\u00ean port 80). T\u1ea5t c\u1ea3 c\u00e1c server trong web-backend s\u1ebd ph\u1ea3i c\u00f3 n\u1ed9i dung gi\u1ed1ng h\u1ec7t nhau n\u1ebfu kh\u00f4ng ng\u01b0\u1eddi d\u00f9ng s\u1ebd c\u00f3 th\u1ec3 nh\u1eadn ra s\u1ef1 kh\u00e1c nhau \u0111\u00f3 khi truy c\u1eadp t\u1edbi domain t\u01b0\u01a1ng \u1ee9ng. L\u01b0u \u00fd l\u00e0 c\u00e1c web-backend ph\u1ea3i connect t\u1edbi c\u00f9ng 1 database. Load balancing tr\u00ean layer 7: cho ph\u00e9p c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ec3 chuy\u1ec3n ti\u1ebfp c\u00e1c request t\u1edbi nh\u1eefng server backend t\u01b0\u01a1ng \u1ee9ng d\u1ef1a tr\u00ean n\u1ed9i dung c\u1ee7a request t\u1eeb ng\u01b0\u1eddi d\u00f9ng. Ch\u1ebf \u0111\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i n\u00e0y cho ph\u00e9p b\u1ea1n ch\u1ea1y nhi\u1ec1u m\u00e1y ch\u1ee7 web d\u01b0\u1edbi c\u00f9ng m\u1ed9t t\u00ean mi\u1ec1n v\u00e0 c\u1ed5ng. Proxy l\u00e0 1 internet server l\u00e0m nhi\u1ec7m v\u1ee5 chuy\u1ec3n ti\u1ebfp, ki\u1ec3m so\u00e1t th\u00f4ng tin gi\u1eefa client v\u00e0 server, proxy c\u00f3 1 \u0111\u1ecba ch\u1ec9 IP v\u00e0 1 port c\u1ed1 \u0111\u1ecbnh. C\u00e1ch th\u1ee9c ho\u1ea1t \u0111\u1ed9ng: t\u1ea5t c\u1ea3 c\u00e1c y\u00eau c\u1ea7u t\u1eeb client g\u1eedi \u0111\u1ebfn server tr\u01b0\u1edbc h\u1ebft ph\u1ea3i th\u00f4ng qua proxy, proxy ki\u1ebfm tra xem y\u00eau c\u1ea7u n\u1ebfu \u0111\u01b0\u1ee3c ph\u00e9p s\u1ebd g\u1eedi \u0111\u1ebfn server v\u00e0 c\u0169ng t\u01b0\u01a1ng t\u1ef1 cho server. \u2013 Forward proxy: \u0111\u00e2y l\u00e0 m\u1ed9t server nh\u1eb1m nhi\u1ec7m v\u1ee5 chuy\u1ec3n ti\u1ebfp c\u00e1c packet t\u1eeb client \u0111\u1ebfn c\u00e1c server kh\u00e1c \u2013 Reverse proxy: \u0111ay l\u00e0 m\u1ed9t server \u0111\u1ee9ng tr\u01b0\u1edbc m\u1ed9t ho\u1eb7c nhi\u1ec1u server, l\u1eafng nghe v\u00e0 ki\u1ec3m so\u00e1t c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb c\u00e1c client kh\u00e1c. - Fail-over l\u00e0 cho ph\u00e9p c\u00f4ng vi\u1ec7c th\u01b0\u1eddng ch\u1ec9 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 kh\u00e1c khi m\u1ed9t trong 2 m\u00e1y ch\u1ee7 x\u1ea3y ra s\u1ef1 c\u1ed1.","title":"1. Load Balancing v\u00e0 c\u00e1c kh\u00e1i ni\u1ec7m li\u00ean quan"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#2_ha_proxy","text":"","title":"2. HA Proxy"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#21_mo_au_ve_ha_proxy","text":"HAProxy ( Hight Availability Proxy ) l\u00e0 m\u1ed9t ph\u1ea7n m\u1ec1m mi\u1ec5n ph\u00ed v\u00e0 m\u00e3 ngu\u1ed3n m\u1edf, n\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i v\u00e0 proxy server cho TCP v\u00e0 HTTP. \u0110\u00e2y l\u00e0 gi\u1ea3i ph\u00e1p ph\u00f9 h\u1ee3p cho c\u00e1c website c\u00f3 l\u01b0\u1ee3ng truy c\u1eadp l\u1edbn tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m . Trong nh\u1eefng n\u0103m g\u1ea7n \u0111\u00e2y HA Proxy \u0111ang ph\u1edf th\u00e0nh b\u1ed9 c\u00f4ng c\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean n\u1ec1n t\u1ea3ng m\u00e3 ngu\u1ed3n m\u1edf ph\u1ed5 bi\u1ebfn, hi\u1ec7n nay HA Proxy \u0111\u01b0\u1ee3c ph\u00e2n ph\u1ed1i h\u1ea7u h\u1ebft tr\u00ean c\u00e1c b\u1ea3n distrobution ch\u00ednh g\u1ed1c c\u1ee7a Linux .","title":"2.1 . M\u1edf \u0111\u1ea7u v\u1ec1 HA Proxy"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#22_ha_proxy_lam_uoc_gi_gi","text":"HA \u0111\u01b0\u1ee3c c\u1ea5u th\u00e0nh t\u1eeb nhi\u1ec1u th\u00e0nh ph\u1ea7n, v\u00e0 \u0111\u1ea3m nhi\u1ec7m \u0111\u01b0\u1ee3c nhi\u1ec1u c\u00f4ng vi\u1ec7c kh\u00e1c nhau : - TCP Proxy: c\u00f3 c\u00f3 th\u1ec3 ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i tcp t\u1eeb listening socket, k\u1ebft n\u1ed1i n\u00f3 t\u1edbi server v\u00e0 g\u00e1n c\u00e1c sockets n\u00e0y l\u1ea1i v\u1edbi nhau cho ph\u00e9p traffic di chuy\u1ec3n theo c\u1ea3 hai chi\u1ec1u - HTTP reverse-proxy: Hay c\u00f2n g\u1ecdi l\u00e0 gateway, t\u1ef1 b\u1ea3n th\u00e2n n\u00f3 c\u00f3 th\u1ec3 l\u00e0 server, nh\u1eadn c\u00e1c http requests t\u1eeb k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c th\u00f4ng qua b\u1edfi listening TCP socket v\u00e0 chuy\u1ec3n c\u00e1c requests n\u00e0y t\u1edbi c\u00e1c server b\u1eb1ng nhi\u1ec1u k\u1ebft n\u1ed1i kh\u00e1c nhau. - SSL terminator / initiator / offloader : s\u1eed d\u1ee5ng SSL/TLS tr\u00ean c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb client - TCP normalizer : b\u1ea3o v\u1ec7 c\u00e1c TCP stack kh\u1ecfi c\u00e1c cu\u1ed9c t\u1ea5n c\u00f4ng, - HTTP normalizer : khi c\u1ea5u h\u00ecnh \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c HTTP traffic, ch\u1ec9 c\u00e1c request h\u1ee3p l\u1ec7 m\u1edbi \u0111\u01b0\u1ee3c ch\u1ea5p nh\u1eadn, \u0111i\u1ec1u n\u00e0y ch\u1ed1ng l\u1ea1i c\u00e1c protocol kh\u00e1c c\u00f3 m\u1ee5c \u0111\u00edch t\u1ea5n c\u00f4ng. - HTTP fixing tool : c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh c\u00e1c c\u00e1c request ho\u1eb7c c\u00e1c reponse header - content-based switch: d\u1ef1a v\u00e0o th\u00e0nh ph\u1ea7n c\u1ee7a request \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh server nh\u1eadn - server load balancer : n\u00f3 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean c\u00e1c k\u1ebft n\u1ed1i TCP v\u00e0 HTTP . Tr\u00ean TCP n\u00f3 s\u1ebd nh\u1eadn t\u1ea5t c\u1ea3 c\u00e1c request , tr\u00ean HTTP s\u1ebd quy\u1ebft \u0111\u1ecbnh ch\u1ea5p nh\u1eadn tr\u00ean t\u1eebng k\u1ebft n\u1ed1i . - traffic regulator: th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 rule \u0111\u1ec3 limit traffic, ch\u1ed1ng l\u1ea1i vi\u1ec7c qu\u00e1 t\u1ea3i , d\u1ef1a tr\u00ean n\u1ed9i dung header \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c banwith c\u1ee7a c\u00e1c k\u1ebft n - protection against DDoS: n\u00f3 c\u00f3 th\u1ec3 l\u01b0u gi\u1eef danh s\u1ed1 li\u1ec7u v\u1ec1 \u0111\u1ecba ch\u1ec9 ip, url,... v\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0nh \u0111\u1ed9ng (l\u00e0m ch\u1eadm, block,...) - network troubleshooting : x\u1eed l\u00fd c\u00e1c log - HTTP compression offloader : n\u1ebfn c\u00e1c reponse kh\u00f4ng \u0111\u01b0\u1ee3c n\u00e9n b\u1edfi c\u00e1c server","title":"2.2 . HA Proxy l\u00e0m \u0111\u01b0\u1ee3c g\u00ec g\u00ec ?"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#23_ha_proxy_hoat_ong_nhu_the_nao","text":"HA Proxy l\u00e0 m\u1ed9t c\u00f4ng ngh\u1ec7 \u0111\u01a1n lu\u1ed3ng, h\u01b0\u1edbng s\u1ef1 ki\u1ec7n v\u00e0 non-blocking ( tham kh\u1ea3o thu\u1eadt ng\u1eef t\u1ea1i \u0111\u00e2y ) k\u1ebft h\u1ee3p v\u1edbi I/O d\u1ef1a tr\u00ean \u0111\u1ed9 \u01b0u ti\u00ean c\u1ee7a c\u00e1c sheduler . HA proxy ch\u1ec9 y\u00eau c\u1ea7u m\u1ed9t haproxy package v\u00e0 m\u1ed9t t\u1eadp tin c\u1ea5u h\u00ecnh \u0111\u1ec3 ho\u1ea1t \u0111\u1ed9ng. \u0110\u1ec3 ghi ch\u00fa log c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng syslog Trong HAproxy Front-end v\u00e0 back-end \u0111\u01b0\u1ee3c xem l\u00e0 m\u1ed9t n\u1eeda c\u1ee7a proxy, v\u00ec ch\u00fang ch\u1ec9 quan t\u00e2m k\u1ebft n\u1ed1i \u1edf \u0111\u1ea7u c\u00f2n l\u1ea1i ( front to client, back-end to server ) . Front-end ch\u1ec9 quan t\u00e2m t\u1edbi client trong khi \u0111\u00f3 back-end quan t\u00e2m t\u1edbi c\u00e1c server. HA proxy ch\u1ec9 h\u1ed7 tr\u1ee3 kh\u1edfi t\u1ea1o m\u1ed9t proxy \u0111\u1ea7y \u0111\u1ee7 khi c\u00f3 front-end v\u00e0 back-end. V\u1edbi c\u00e1c HTTP request th\u00ec front-end s\u1ebd l\u00e0m nhi\u1ec7m v\u1ee5 filter, trong \u0111\u00f3 m\u1ecdi front-end c\u00f3 th\u1ec3 g\u1eedi c\u00e1c k\u1ebft n\u1ed1i t\u1edbi m\u1ecdi back-end. Ngo\u00e0i font-end v\u00e0 back-end ,c\u00f2n c\u00f3 Access Control List (ACL) Trong c\u00e2n b\u1eb1ng t\u1ea3i, ACL \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 ki\u1ec3m tra \u0111i\u1ec1u ki\u1ec7n v\u00e0 th\u1ef1c hi\u1ec7n m\u1ed9t h\u00e0nh \u0111\u1ed9ng (v\u00ed d\u1ee5 nh\u01b0 l\u1ef1a ch\u1ecdn m\u1ed9t server hay ch\u1eb7n m\u1ed9t request) d\u1ef1a tr\u00ean k\u1ebft qu\u1ea3 c\u1ee7a vi\u1ec7c ki\u1ec3m tra \u0111\u00f3. Vi\u1ec7c s\u1eed d\u1ee5ng ACL cho ph\u00e9p t\u1ea1o m\u1ed9t m\u00f4i tr\u01b0\u1eddng c\u00f3 kh\u1ea3 n\u0103ng chuy\u1ec3n ti\u1ebfp c\u00e1c request m\u1ed9t c\u00e1ch linh ho\u1ea1t d\u1ef1a tr\u00ean c\u00e1c y\u1ebfu t\u1ed1 kh\u00e1c nhau m\u00e0 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u00f9y ch\u1ec9nh m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng. M\u1ed7i khi HA proxy \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng , n\u00f3 th\u1ef1c hi\u1ec7n 3 q\u00faa tr\u00ecnh x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn ki\u1ec3m tra tr\u1ea1ng th\u00e1i c\u1ee7a c\u00e1c server ( heath check ) trao \u0111\u1ed5i c\u00e1c th\u00f4ng tin v\u1edbi c\u00e1c ha proxy node kh\u00e1c \u0110\u1ec3 x\u1eed l\u00fd m\u1ed9t k\u1ebft n\u1ed1i \u0111\u1ebfn c\u1ea7n tr\u1ea9i qua r\u1ea5t nhi\u00eafu qu\u00e1 tr\u00ecnh, t\u00f9y v\u00e0o t\u1eebng c\u1ea5u h\u00ecnh qu\u00e1 tr\u00ecnh n\u00e0y c\u00f3 th\u1ec3 ph\u1ea3i x\u1eed l\u00fd nhi\u1ec1u ho\u1eb7c \u00edt c\u00e1c t\u00e1c v\u1ee5 ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb c\u00e1c socket t\u1eeb entry \"frontend\", tuyf v\u00e0o c\u1ea5u h\u00ecnh s\u1ebd l\u1eafng nghe tr\u00ean m\u1ed9t ho\u1eb7c nhi\u1ec1u \u0111\u1ecba ch\u1ec9 d\u1ef1a v\u00e0o c\u00e1c rule front-end s\u1ebd x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i n\u00e0y : ch\u1eb7n, ch\u1ec9nh s\u1eeda c\u00e1c header.... ch\u1ea5p nh\u1eadn c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1edbi entry \"back-end\" n\u01a1i ch\u1ee9a c\u00e1c server v\u00e0 c\u00e1c quy t\u1eafc \u0111\u1ec3 c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean c\u00e1c server n\u00e0y \u00e1p d\u1ee5ng c\u00e1c rule back-end \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c k\u1ebft n\u1ed1i x\u00e1c \u0111\u1ecbnh server s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c chi\u1ebfn l\u01b0\u1ee3c c\u00e2n b\u1eb1ng t\u1ea3i \u00e1p d\u1ee5ng c\u00e1c back-end rule cho c\u00e1c response data \u00e1p d\u1ee5ng c\u00e1c front-end rule cho c\u00e1c response data x\u1eed l\u00fd log \u0111\u1ec3 xem ti\u1ebfn tr\u00ecnh trong HTTP, s\u1ebd tr\u1edf l\u1ea1i b\u01b0\u1edbc 2 \u0111\u1ec3 nghe c\u00e1c k\u1ebft n\u1ed1i ti\u1ebfp theo ho\u1eb7c l\u00e0 \u0111\u00f3ng k\u1ebft n\u1ed1i","title":"2.3 . HA Proxy ho\u1ea1t \u0111\u1ed9ng nh\u01b0 th\u1ebf n\u00e0o ."},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#24_cac_tinh_nang_co_ban","text":"Proxying SSL Monitoring HA Load balancing Sampling and converting information Maps ACLs and conditions Content switching HTTP rewriting and redirection Server protection Logging Statistics Tham kh\u1ea3o th\u00eam","title":"2.4 C\u00e1c t\u00ednh n\u0103ng c\u01a1 b\u1ea3n"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#25_thuat_toan_su_dung_trong_ha_proxy","text":"Back-end l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c server farm v\u00e0 x\u1eed l\u00fd c\u00e1c request t\u1edbi ch\u00fang b\u1eb1ng c\u00e1ch l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c th Round Robin: \u0110\u00e2y l\u00e0 thu\u1eadt to\u00e1n c\u00e2n b\u1eb1ng \u0111\u01a1n gi\u1ea3n nh\u1ea5t. \u0110\u1ed1i v\u1edbi m\u1ed7i k\u1ebft n\u1ed1i m\u1edbi, n\u00f3 s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi c\u00e1c m\u00e1y ch\u1ee7 backend ti\u1ebfp theo. N\u1ebfu m\u00e1y ch\u1ee7 backend cu\u1ed1i c\u00f9ng trong danh s\u00e1ch \u0111\u01b0\u1ee3c \u0111\u1ea1t t\u1edbi, n\u00f3 s\u1ebd b\u1eaft \u0111\u1ea7u l\u1ea1i t\u1eeb \u0111\u1ea7u danh s\u00e1ch backend. Least Connections: C\u00e1c k\u1ebft n\u1ed1i m\u1edbi s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi c\u00e1c m\u00e1y ch\u1ee7 backend v\u1edbi s\u1ed1 l\u01b0\u1ee3ng k\u1ebft n\u1ed1i \u00edt nh\u1ea5t. \u0110i\u1ec1u n\u00e0y r\u1ea5t h\u1eefu \u00edch khi th\u1eddi gian v\u00e0 c\u00e1c request r\u1ea5t l\u1edbn. Source: \u0110\u00e2y l\u00e0 phi\u00ean d\u00ednh, c\u00e1c IP c\u1ee7a client s\u1ebd \u0111\u01b0\u1ee3c b\u0103m \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh m\u00e1y ch\u1ee7 backend \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u cu\u1ed1i c\u00f9ng t\u1eeb IP n\u00e0y. V\u00ec v\u1eady, m\u1ed9t IP A s\u1ebd lu\u00f4n \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi backend1, v\u00e0 IP B s\u1ebd lu\u00f4n lu\u00f4n \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi banckend2 \u0111\u1ec3 kh\u00f4ng l\u00e0m gi\u00e1n \u0111o\u1ea1n phi\u00ean. Static Round Robin: T\u01b0\u01a1ng t\u1ef1 nh\u01b0 Round Robin, m\u1ed7i m\u00e1y ch\u1ee7 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong v\u00f2ng l\u1eb7p d\u1ef1a tr\u00ean weight. Nh\u01b0ng thay \u0111\u1ed5i weight c\u1ee7a m\u00e1y ch\u1ee7 tr\u00ean c\u0169ng kh\u00f4ng \u1ea3nh h\u01b0\u1edfng g\u00ec. B\u1ea1n c\u00f3 th\u1ec3 t\u1ef1 x\u00e1c \u0111\u1ecbnh bao nhi\u00eau server m\u00e0 b\u1ea1n mu\u1ed1n. Khi m\u1ed9t m\u00e1y ch\u1ee7 t\u0103ng l\u00ean, n\u00f3 s\u1ebd lu\u00f4n lu\u00f4n \u0111\u01b0\u1ee3c ngay l\u1eadp t\u1ee9c \u0111\u01b0a l\u1ea1i v\u00e0o 1 b\u1ea3ng sau khi \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n l\u1ea1i weight. URI: Thu\u1eadt to\u00e1n n\u00e0y b\u0103m ho\u1eb7c ph\u1ea7n b\u00ean tr\u00e1i c\u1ee7a URI, ho\u1eb7c to\u00e0n b\u1ed9 URI v\u00e0 chia gi\u00e1 tr\u1ecb b\u0103m b\u1eb1ng t\u1ed5ng weight c\u1ee7a m\u00e1y ch\u1ee7 \u0111ang ch\u1ea1y. C\u00f9ng URI lu\u00f4n h\u01b0\u1edbng \u0111\u1ebfn c\u00f9ng m\u1ed9t server mi\u1ec5n l\u00e0 kh\u00f4ng c\u00f3 m\u00e1y ch\u1ee7 up ho\u1eb7c down. N\u00f3 c\u0169ng l\u00e0 m\u1ed9t thu\u1eadt to\u00e1n t\u0129nh v\u00e0 ho\u1ea1t \u0111\u1ed9ng theo c\u00e1ch t\u01b0\u01a1ng t\u1ef1 nh\u01b0 c\u00e1c thu\u1eadt to\u00e1n Source. URL Parameter: Thu\u1eadt to\u00e1n t\u0129nh n\u00e0y ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng tr\u00ean m\u1ed9t backend HTTP. C\u00e1c tham s\u1ed1 URL \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh s\u1ebd \u0111\u01b0\u1ee3c nh\u00ecn trong chu\u1ed7i truy v\u1ea5n c\u1ee7a m\u1ed7i y\u00eau c\u1ea7u HTTP GET. N\u1ebfu tham s\u1ed1 \u0111\u00f3 \u0111\u01b0\u1ee3c t\u00ecm th\u1ea5y b\u1edfi m\u1ed9t d\u1ea5u hi\u1ec7u v\u00e0 gi\u00e1 tr\u1ecb nh\u01b0 nhau, gi\u00e1 tr\u1ecb \u0111\u01b0\u1ee3c b\u0103m v\u00e0 chia cho t\u1ed5ng tr\u1ecdng l\u01b0\u1ee3ng c\u1ee7a m\u00e1y ch\u1ee7 \u0111ang ch\u1ea1y.","title":"2.5 . Thu\u1eadt t\u00f3an s\u1eed d\u1ee5ng trong HA Proxy"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#3_keep_alive","text":"","title":"3. Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#31_cac_thuat_ngu","text":"VIP : Virtual IP, s\u1eed d\u1ee5ng cho c\u00e1c client truy c\u1eadp Keep Alived s\u1eed d\u1ee5ng 4 module kernel \u0111\u1ec3 l\u00e0m vi\u1ec7c LVS framework : d\u00f9ng \u0111\u1ec3 giao ti\u1ebfp socket Netfilter framework : s\u1eed d\u1ee5ng \u0111\u1ec3 ho\u1ea1t \u0111\u1ed9ng IP Virtual Server Netlink interface : \u0111i\u1ec1u khi\u1ec3n , th\u00eam x\u00f3a VRRRP VIP tr\u00ean card m\u1ea1ng Multicast : g\u1eedi c\u00e1c b\u1ea3n tin VRRP \u0111\u1ebfn \u0111\u1ecba ch\u1ec9 multicast Virtual Router Redundancy Protocol \u2013 VRRP c\u00f3 ch\u1ee9c n\u0103ng t\u01b0\u01a1ng t\u1ef1 nh\u01b0 v\u1edbi HSRP l\u00e0 cho ph\u00e9p c\u00e1c Router cisco c\u00f9ng tham gia m\u1ed9t nh\u00f3m x\u00e2y d\u1ef1ng m\u1ed9t router \u1ea3o l\u00e0m gateway cho c\u00e1c host n\u1eb1m tr\u00ean m\u1ea1ng LAN, th\u1ef1c hi\u1ec7n d\u1ef1 ph\u00f2ng gateway cho c\u00e1c host \u0111\u1ea7u cu\u1ed1i n\u00e0y. \u0110i\u1ec3m kh\u00e1c bi\u1ec7t l\u00e0 n\u1ebfu HSRP l\u00e0 giao th\u1ee9c c\u1ee7a Cisco ch\u1ec9 ch\u1ea1y tr\u00ean thi\u1ebft b\u1ecb Cisco, th\u00ec VRRP l\u00e0 giao th\u1ee9c qu\u1ed1c t\u1ebf c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean nhi\u1ec1u s\u1ea3n ph\u1ea9m c\u1ee7a nhi\u1ec1u nh\u00e0 s\u1ea3n xu\u1ea5t kh\u00e1c nhau. VRRP \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 trong RFC \u2013 3768 c\u1ee7a IETF.","title":"3.1. C\u00e1c thu\u1eadt ng\u1eef"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/1.Intro/#32_mo_au_ve_keep_alive","text":"C\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean t\u1ea7ng 4 v\u00e0 t\u1ea7ng 7 \u0111\u01b0\u1ee3c mi\u00eau t\u1ea3 \u1edf tr\u00ean \u0111\u1ec1u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ec3 chuy\u1ec3n c\u00e1c request t\u1edbi c\u00e1c backend server. Tuy nhi\u00ean, ch\u00ednh c\u00e2ng b\u1eb1ng t\u1ea3i c\u1ee7a b\u1ea1n l\u00e0 m\u1ed9t \u0111i\u1ec3m l\u1ed7i (single point of failure), v\u00ec n\u1ebfu c\u00e2n b\u1eb1ng t\u1ea3i g\u1eb7p s\u1ef1 c\u1ed1 nh\u01b0ng c\u00e1c server \u0111\u1ec1u ch\u1ea1y b\u00ecnh th\u01b0\u1eddng th\u00ec ng\u01b0\u1eddi d\u00f9ng c\u0169ng kh\u00f4ng th\u1ec3 k\u1ebft n\u1ed1i \u0111\u1ebfn \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng web trong khi web server v\u1eabn \u0111ang ch\u1ea1y b\u00ecnh th\u01b0\u1eddng. Keep Alive \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t heat beat packet trong m\u1ed9t m\u00f4 h\u00ecnh m\u1ea1ng, \u0111\u01b0\u1ee3c m\u1ed9t thi\u1ebft b\u1ecb nh\u01b0 Router g\u1eedi m\u1ed9t packet \u0111\u1ebfn c\u00e1c thi\u1ebft b\u1ecb kh\u00e1c trong m\u1ed9t m\u00f4 h\u00ecnh m\u1ea1ng , m\u1ee5c \u0111\u00edch c\u1ee7a keep alive nh\u1eb1m ki\u1ec3m tra tr\u1ea1ng th\u00e1i k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c thi\u1ebft b\u1ecb v\u1edbi nhau . \u0110\u1ec3 ho\u1ea1t \u0111\u1ed9ng keep alive c\u00f3 2 ki\u1ec3m c\u1ea7n ch\u00fa \u00fd : keep alive interval : th\u1eddi gian g\u1eedi packet ki\u1ec3m tra gi\u1eefa c\u00e1c packet. keep alive retries : s\u1ed1 l\u1ea7n c\u1ed1 g\u1eafn g\u1eedi packet \u0111\u1ebfn m\u1ed9t thi\u1ebft b\u1ecb khi kh\u00f4ng \u0111\u01b0\u1ee3c reply \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh l\u00e0m m\u1ed9t h\u00e0nh \u0111\u1ed9ng thi\u1ebfp theo. Nh\u01b0 v\u1eady keep alive s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 sau : M\u1ed9t g\u00f3i tin keep alive \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb A \u0111\u1ebfn B v\u1edbi m\u1ed1c th\u1eddi gianj theo \u0111\u1ecbnh k\u1ef3 Sau khi thi\u1ebft b\u1ecb A g\u1eedi g\u00f3i tin s\u1ebd ch\u1edd ph\u1ea3n ph\u1ed3i t\u1eeb thi\u1ebft b\u1ecb B, l\u00fac n\u00e0y s\u1ebd x\u1ea3y ra 2 tr\u01b0\u1eddng h\u1ee3p : Thi\u1ebft b\u1ecb B s\u1ebd tr\u1ea3 v\u1ec1 m\u1ed9t response \u0111\u1ec3 thi\u1ebft b\u1ecb A bi\u1ebft tr\u1ea1ng th\u00e1i Sau n l\u1ea7n th\u1eed thi\u1ebft b\u1ecb A kh\u00f4ng th\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c response t\u1eeb thi\u1ebft b\u1ecb B, thi\u1ebft b\u1ecb A s\u1ebd s\u1ebd nh\u01b0 \u0111\u01b0\u1eddng n\u00e0y \u0111ang \u1edf tr\u1ea1ng th\u00e1i down Sau \u0111\u00f3 thi\u1ebft b\u1ecb A s\u1ebd quy\u1ebft \u0111\u1ecbnh chuy\u1ec3n h\u01b0\u01a1ngs data d\u1ef1a v\u00e0o output \u1edf b\u01b0\u1edbc 2 IP VIP : Th\u1ef1c s\u1ef1 n\u00f3 l\u00e0 m\u1ed9t IP \u0111\u01b0\u1ee3c g\u00e1n th\u00eam tr\u00ean m\u1ed9t network alias (virtual interface) c\u1ee7a haproxy. T\u00ednh ch\u1ea5t virtual c\u1ee7a n\u00f3 n\u1eb1m \u1edf ch\u1ed7 n\u00f3 kh\u00f4ng g\u1eafn c\u1ed1 \u0111\u1ecbnh tr\u00ean m\u1ed9t network interface th\u1eadt s\u1ef1 n\u00e0o c\u1ea3. Khi c\u00f3 s\u1ef1 c\u1ed1 x\u1ea3y ra, keepalived s\u1ebd h\u1ee7y ip tr\u00ean network alias c\u1ee7a haproxy down v\u00e0 t\u1ea1o tr\u00ean haproxy backup Trong HA, keep alive cung c\u1ea5p VIP ) cho m\u1ed9t Cluser . Cho ph\u00e9p c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i ho\u1ea1t \u0111\u1ed9ng theo c\u01a1 ch\u1ebf Active-Backup. N\u1ebfu b\u1ed9 load balancer ch\u00ednh b\u1ecb down , th\u00ec IP Floating s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n v\u1ec1 v\u1ec1 b\u1ed9 load blancer ph\u1ee5, nh\u1edd \u0111\u00f3 cung c\u1ea5p kh\u1ea3 n\u0103ng failure cho h\u1ec7 th\u1ed1ng n\u00e0y. - END.","title":"3.2 M\u1edf \u0111\u1ea7u v\u1ec1 Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/","text":"C\u1ea5u h\u00ecnh HA Proxy s\u1eed d\u1ee5ng Keep Alive \u00b6 1. Note \u00b6 2. M\u00f4 h\u00ecnh \u00b6 Load Balancer-1: \u00b6 ens192 : 192.168.30.133 ens224: 192.168.69.133 Load Balancer-2: \u00b6 ens192 : 192.168.30.134 ens224 : 192.168.69.134 Web Server-1: \u00b6 ens192 : 192.168.69.131 Web Server-2: \u00b6 ens192 : 192.168.69.132 3. C\u1ea5u h\u00ecnh tr\u00ean Web Server Node \u00b6 C\u00e0i \u0111\u1eb7t Web Server yum install httpd -y Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start httpd systemctl enable httpd C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service http --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh n\u1ed9i dung Web Server echo Day la `hostname` > /var/www/html/index.html 4. C\u1ea5u h\u00ecnh tr\u00ean Load Balancer Node \u00b6 ### 4.1. C\u1ea5u h\u00ecnh HA Proxy v\u00e0 Web Server C\u00e0i \u0111\u1eb7t HA Proxy yum install haproxy -y C\u1ea5u h\u00ecnh enty front-end t\u1ea1i /etc/haproxy/haproxy.cfg frontend main *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js stats enable # auth info for statistics site stats auth admin:adminpassword # hide version of HAProxy stats hide-version # display HAProxy hostname stats show-node # refresh time stats refresh 60s # statistics reports' URI stats uri /haproxy?stats default_backend app Trong \u0111\u00f3 : - s\u1eed d\u1ee5ng port 80 \u0111\u1ec3 nh\u1eadn c\u00e1c request cho front-end - M\u1eb7c \u0111\u1ecbnh s\u1eed d\u1ee5ng use_backend static if url_static \u0111\u1ec3 nh\u1eadn c\u00e1c static , do c\u00e1c static file nh\u1eadn t\u1eeb webserver n\u00ean comment t\u00f9y ch\u1ecdn n\u00e0y C\u1ea5u h\u00ecnh enty back-end t\u1ea1i /etc/haproxy/haproxy.cfg backend app balance roundrobin server web1 192.168.69.131:80 check server web2 192.168.69.132:80 check C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service http --permanent firewall-cmd --reload Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 HA Proxy systemctl start haproxy systemctl enable haproxy 4.2 . C\u1ea5u h\u00ecnh Keep Alive \u00b6 C\u00e0i \u0111\u1eb7t Keep Alive yum install keepalived psmisc -y echo \"net.ipv4.ip_nonlocal_bind=1\" >> /etc/sysctl.conf sysctl -p Backup file c\u1ea5u h\u00ecnh cp -p /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak Begin Section Tr\u00ean Load Balancer 1 \u00b6 T\u1ea1i /etc/keepalived/keepalived.conf cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface ens192 state MASTER virtual_router_id 51 priority 100 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.150 } unicast_src_ip 192.168.30.133 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.134 } track_script { chk_haproxy } } EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start keepalived systemctl enable keepalived Ki\u1ec3m tra \u0111\u1ecba ch\u1ec9 IP, s\u1ebd xu\u1ea5t hi\u1ec7n th\u00eam IP VIP tr\u00ean interface ens192 [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet 192.168.30.150/32 scope global ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever Tr\u00ean Load Balancer 2 \u00b6 T\u1ea1i /etc/keepalived/keepalived.conf cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface ens192 state BACKUP virtual_router_id 51 priority 99 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.150 } unicast_src_ip 192.168.30.134 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.133 } track_script { chk_haproxy } } EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start keepalived systemctl enable keepalived Tr\u00ean interface ens192 c\u1ee7a LB 2 s\u1ebd kh\u00f4ng c\u00f3 IP VIP [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever End Section 5. Ki\u1ec3m th\u1eed \u00b6 5.1 : Load Balancer \u00b6 Ki\u1ec3m th\u1eed c\u00e2n b\u1eb1ng t\u1ea3i ( do theo c\u01a1 ch\u1ebf roundrobin n\u00ean c\u00e1c request s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp l\u1ea7n l\u01b0\u1ee3t t\u1edbi c\u00e1c server ) L\u1ea7n 1 : L\u1ea7n 2 : 5.2. Keep Alive \u00b6 Tr\u00ean Load Balancer 1, t\u1eaft service ha proxy systemctl stop haproxy Ki\u1ec3m tra tr\u00ean log message c\u1ee7a LB 1 Keepalived_vrrp[6280]: /usr/sbin/pidof haproxy exited with status 1 Ki\u1ec3m tra tr\u00ean L2 s\u1ebd th\u1ea5y IP VIP xu\u1ea5t hi\u1ec7n tr\u00ean interfac ens192 [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet 192.168.30.150/32 scope global ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever END.","title":"2. Setup HA Proxy && KeepAlive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#cau_hinh_ha_proxy_su_dung_keep_alive","text":"","title":"C\u1ea5u h\u00ecnh HA Proxy s\u1eed d\u1ee5ng Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#1_note","text":"","title":"1. Note"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#2_mo_hinh","text":"","title":"2. M\u00f4 h\u00ecnh"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#load_balancer-1","text":"ens192 : 192.168.30.133 ens224: 192.168.69.133","title":"Load Balancer-1:"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#load_balancer-2","text":"ens192 : 192.168.30.134 ens224 : 192.168.69.134","title":"Load Balancer-2:"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#web_server-1","text":"ens192 : 192.168.69.131","title":"Web Server-1:"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#web_server-2","text":"ens192 : 192.168.69.132","title":"Web Server-2:"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#3_cau_hinh_tren_web_server_node","text":"C\u00e0i \u0111\u1eb7t Web Server yum install httpd -y Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start httpd systemctl enable httpd C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service http --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh n\u1ed9i dung Web Server echo Day la `hostname` > /var/www/html/index.html","title":"3. C\u1ea5u h\u00ecnh tr\u00ean Web Server Node"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#4_cau_hinh_tren_load_balancer_node","text":"### 4.1. C\u1ea5u h\u00ecnh HA Proxy v\u00e0 Web Server C\u00e0i \u0111\u1eb7t HA Proxy yum install haproxy -y C\u1ea5u h\u00ecnh enty front-end t\u1ea1i /etc/haproxy/haproxy.cfg frontend main *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js stats enable # auth info for statistics site stats auth admin:adminpassword # hide version of HAProxy stats hide-version # display HAProxy hostname stats show-node # refresh time stats refresh 60s # statistics reports' URI stats uri /haproxy?stats default_backend app Trong \u0111\u00f3 : - s\u1eed d\u1ee5ng port 80 \u0111\u1ec3 nh\u1eadn c\u00e1c request cho front-end - M\u1eb7c \u0111\u1ecbnh s\u1eed d\u1ee5ng use_backend static if url_static \u0111\u1ec3 nh\u1eadn c\u00e1c static , do c\u00e1c static file nh\u1eadn t\u1eeb webserver n\u00ean comment t\u00f9y ch\u1ecdn n\u00e0y C\u1ea5u h\u00ecnh enty back-end t\u1ea1i /etc/haproxy/haproxy.cfg backend app balance roundrobin server web1 192.168.69.131:80 check server web2 192.168.69.132:80 check C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service http --permanent firewall-cmd --reload Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 HA Proxy systemctl start haproxy systemctl enable haproxy","title":"4. C\u1ea5u h\u00ecnh tr\u00ean Load Balancer Node"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#42_cau_hinh_keep_alive","text":"C\u00e0i \u0111\u1eb7t Keep Alive yum install keepalived psmisc -y echo \"net.ipv4.ip_nonlocal_bind=1\" >> /etc/sysctl.conf sysctl -p Backup file c\u1ea5u h\u00ecnh cp -p /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak Begin Section","title":"4.2 . C\u1ea5u h\u00ecnh Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#tren_load_balancer_1","text":"T\u1ea1i /etc/keepalived/keepalived.conf cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface ens192 state MASTER virtual_router_id 51 priority 100 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.150 } unicast_src_ip 192.168.30.133 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.134 } track_script { chk_haproxy } } EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start keepalived systemctl enable keepalived Ki\u1ec3m tra \u0111\u1ecba ch\u1ec9 IP, s\u1ebd xu\u1ea5t hi\u1ec7n th\u00eam IP VIP tr\u00ean interface ens192 [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet 192.168.30.150/32 scope global ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever","title":"Tr\u00ean Load Balancer 1"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#tren_load_balancer_2","text":"T\u1ea1i /etc/keepalived/keepalived.conf cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface ens192 state BACKUP virtual_router_id 51 priority 99 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.150 } unicast_src_ip 192.168.30.134 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.133 } track_script { chk_haproxy } } EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start keepalived systemctl enable keepalived Tr\u00ean interface ens192 c\u1ee7a LB 2 s\u1ebd kh\u00f4ng c\u00f3 IP VIP [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever End Section","title":"Tr\u00ean Load Balancer 2"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#5_kiem_thu","text":"","title":"5. Ki\u1ec3m th\u1eed"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#51_load_balancer","text":"Ki\u1ec3m th\u1eed c\u00e2n b\u1eb1ng t\u1ea3i ( do theo c\u01a1 ch\u1ebf roundrobin n\u00ean c\u00e1c request s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp l\u1ea7n l\u01b0\u1ee3t t\u1edbi c\u00e1c server ) L\u1ea7n 1 : L\u1ea7n 2 :","title":"5.1 :  Load Balancer"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/2. Setup-HA-Proxy-&&-KeepAlive/#52_keep_alive","text":"Tr\u00ean Load Balancer 1, t\u1eaft service ha proxy systemctl stop haproxy Ki\u1ec3m tra tr\u00ean log message c\u1ee7a LB 1 Keepalived_vrrp[6280]: /usr/sbin/pidof haproxy exited with status 1 Ki\u1ec3m tra tr\u00ean L2 s\u1ebd th\u1ea5y IP VIP xu\u1ea5t hi\u1ec7n tr\u00ean interfac ens192 [root@cinder2 ~]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:03:5a:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.134/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet 192.168.30.150/32 scope global ens192 valid_lft forever preferred_lft forever inet6 fe80::ef02:1925:c44b:c21f/64 scope link noprefixroute valid_lft forever preferred_lft forever END.","title":"5.2. Keep Alive"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/","text":"HA - Proxy v\u00e0 Keep Alived tr\u00ean c\u00e1c Openstack Instance \u00b6 1. M\u00f4 h\u00ecnh \u00b6 VM 1 : Web Server 1 + HA Proxy 1 + Keepalive Master : IP : 192.168.30.148 VM 2 : Web Server 2 + HA Proxy 2 + Keepalive Backup : IP : 192.168.30.149 2. C\u1ea5u h\u00ecnh tr\u00ean Controller Node \u00b6 2.1. Kh\u1edfi t\u1ea1o IP VIP \u00b6 Kh\u1edfi t\u1ea1o Rule cho giao th\u1ee9c VRRP openstack security group rule create --protocol 112 --ingress --ethertype IPv4 --src-group LB_group LB_group Li\u1ec7t k\u00ea danh s\u00e1ch network [root@localhost ~]# openstack network list +--------------------------------------+----------------------------------------------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------------------------------------------------+--------------------------------------+ | 672a0c64-2d47-4712-96ff-161fa23ecfed | HA network tenant 438de521107643ee8348114ba022de1b | 2a1c1fa3-fdcf-4079-878e-9dd3bcd9b900 | | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | provider | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | | b98d66ff-2add-496a-a819-cefadcfe69f5 | local | 995891c9-ea38-453d-82cc-e5147ae10353 | +--------------------------------------+----------------------------------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t port d\u00e0nh cho IP VIP [root@localhost ~]# neutron port-create provider --fixed-ip ip_address=192.168.30.155 neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. Created a new port: +-----------------------+---------------------------------------------------------------------------------------+ | Field | Value | +-----------------------+---------------------------------------------------------------------------------------+ | admin_state_up | True | | allowed_address_pairs | | | binding:host_id | | | binding:profile | {} | | binding:vif_details | {} | | binding:vif_type | unbound | | binding:vnic_type | normal | | created_at | 2019-01-04T09:25:54Z | | description | | | device_id | | | device_owner | | | extra_dhcp_opts | | | fixed_ips | {\"subnet_id\": \"eb785a68-e5f2-4b35-be67-28adfd06c5f4\", \"ip_address\": \"192.168.30.155\"} | | id | 352d23af-df0e-4ee2-8169-5e39fcfc0c0d | | mac_address | fa:16:3e:dd:93:dd | | name | | | network_id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | port_security_enabled | True | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | qos_policy_id | | | revision_number | 6 | | security_groups | c3b14f24-ebc1-49b9-924a-1e9cc7f158a1 | | status | DOWN | | tags | | | tenant_id | 43d21d33e36c4c6097acb1746a50f2b3 | | updated_at | 2019-01-04T09:25:55Z | +-----------------------+---------------------------------------------------------------------------------------+ 2.2. Binding IP VIP cho c\u00e1c port m\u00e1y \u1ea3o \u00b6 Haproxy c\u1ea7n ph\u1ea3i c\u00f3 VIP, \u0111\u00f3 l\u00e0 m\u1ed9t \u0111\u1ecba ch\u1ec9 IP b\u1ed5 sung. Theo m\u1eb7c \u0111\u1ecbnh, Neutron s\u1ebd kh\u00f4ng cho ph\u00e9p m\u1ed9t c\u1ed5ng ph\u1ea3n h\u1ed3i c\u00e1c packet n\u1ebfu n\u00f3 kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh Ki\u1ec3m tra c\u00e1c m\u00e1y \u1ea3o [root@localhost ~]# nova list +--------------------------------------+------+--------+------------+-------------+-------------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+------+--------+------------+-------------+-------------------------+ | 651b5128-7005-4a63-828d-9dca06adf3e8 | ha1 | ACTIVE | - | Running | provider=192.168.30.149 | | f8ad2a47-e50a-4951-9eaf-327cf589fb0e | ha2 | ACTIVE | - | Running | provider=192.168.30.148 | +--------------------------------------+------+--------+------------+-------------+-------------------------+ Ki\u1ec3m tra interface tr\u00ean c\u00e1c m\u00e1y \u1ea3o [root@localhost ~]# nova interface-list ha1 +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | Port State | Port ID | Net ID | IP addresses | MAC Addr | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | ACTIVE | 18b4eee8-5d0e-4758-ae3c-1fd4d858a995 | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | 192.168.30.149 | fa:16:3e:6d:2d:ee | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ [root@localhost ~]# nova interface-list ha2 +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | Port State | Port ID | Net ID | IP addresses | MAC Addr | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | ACTIVE | 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | 192.168.30.148 | fa:16:3e:ae:18:ce | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ Th\u00eam IP VIP c\u1ee7a m\u1ed7i port tr\u00ean tr\u1eebng m\u00e1y \u1ea3o neutron port-update 18b4eee8-5d0e-4758-ae3c-1fd4d858a995 --allowed_address_pairs list=true type=dict ip_address=192.168.30.155 neutron port-update 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 --allowed_address_pairs list=true type=dict ip_address=192.168.30.155 Ki\u1ec3m tra IP Pair [root@localhost ~]# openstack port show 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 +-----------------------+-------------------------------------------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | ip_address='192.168.30.155', mac_address='fa:16:3e:ae:18:ce' | | binding_host_id | compute1 | | binding_profile | | | binding_vif_details | datapath_type='system', ovs_hybrid_plug='True', port_filter='True' | | binding_vif_type | ovs | | binding_vnic_type | normal | | created_at | 2019-01-04T09:35:49Z | | data_plane_status | None | | description | | | device_id | f8ad2a47-e50a-4951-9eaf-327cf589fb0e | | device_owner | compute:nova | | dns_assignment | None | | dns_name | None | | extra_dhcp_opts | | | fixed_ips | ip_address='192.168.30.148', subnet_id='eb785a68-e5f2-4b35-be67-28adfd06c5f4' | | id | 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 | | ip_address | None | | mac_address | fa:16:3e:ae:18:ce | | name | | | network_id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | option_name | None | | option_value | None | | port_security_enabled | True | | project_id | 438de521107643ee8348114ba022de1b | | qos_policy_id | None | | revision_number | 12 | | security_group_ids | 32c7144d-a976-48d5-a3f1-9eb10114822d | | status | ACTIVE | | subnet_id | None | | tags | | | trunk_details | None | | updated_at | 2019-01-04T10:31:21Z | +-----------------------+-------------------------------------------------------------------------------+ 3. C\u1ea5u h\u00ecnh tr\u00ean c\u00e1c instance \u00b6 C\u00e0i \u0111\u1eb7t HA Proxy Keep Alived v\u00e0 Web Server yum install -y httpd keepalived psmisc haproxy Tr\u00ean HA1 \u00b6 C\u1ea5u h\u00ecnh Keep Alived cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface eth0 state MASTER virtual_router_id 51 priority 100 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.155 } unicast_src_ip 192.168.30.148 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.149 } track_script { chk_haproxy } } EOF Tr\u00ean HA2 \u00b6 C\u1ea5u h\u00ecnh Keep Alived cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface eth0 state BACKUP virtual_router_id 51 priority 99 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.155 } unicast_src_ip 192.168.30.149 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.148 } track_script { chk_haproxy } } EOF Tr\u00ean c\u1ea3 2 node HA \u00b6 C\u1ea5u h\u00ecnh entry front-end cho HA Proxy frontend main *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js stats enable # auth info for statistics site stats auth admin:adminpassword # hide version of HAProxy stats hide-version # display HAProxy hostname stats show-node # refresh time stats refresh 60s # statistics reports' URI stats uri /haproxy?stats default_backend app C\u1ea5u h\u00ecnh entry backend cho HA Proxy backend app balance roundrobin server ha2 192.168.30.148:80 check server ha1 192.168.30.149:80 check C\u1ea5u h\u00ecnh n\u1ed9i dung Web Server echo Day la `hostname` > /var/www/html/index.html Kh\u1edfi \u0111\u1ed9ng dich v\u1ee5 systemctl start keealived haproxy httpd systemctl enable keealived haproxy httpd","title":"3.HA Proxy OPS"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#ha_-_proxy_va_keep_alived_tren_cac_openstack_instance","text":"","title":"HA - Proxy v\u00e0 Keep Alived tr\u00ean c\u00e1c Openstack Instance"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#1_mo_hinh","text":"VM 1 : Web Server 1 + HA Proxy 1 + Keepalive Master : IP : 192.168.30.148 VM 2 : Web Server 2 + HA Proxy 2 + Keepalive Backup : IP : 192.168.30.149","title":"1. M\u00f4 h\u00ecnh"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#2_cau_hinh_tren_controller_node","text":"","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Controller Node"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#21_khoi_tao_ip_vip","text":"Kh\u1edfi t\u1ea1o Rule cho giao th\u1ee9c VRRP openstack security group rule create --protocol 112 --ingress --ethertype IPv4 --src-group LB_group LB_group Li\u1ec7t k\u00ea danh s\u00e1ch network [root@localhost ~]# openstack network list +--------------------------------------+----------------------------------------------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------------------------------------------------+--------------------------------------+ | 672a0c64-2d47-4712-96ff-161fa23ecfed | HA network tenant 438de521107643ee8348114ba022de1b | 2a1c1fa3-fdcf-4079-878e-9dd3bcd9b900 | | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | provider | eb785a68-e5f2-4b35-be67-28adfd06c5f4 | | b98d66ff-2add-496a-a819-cefadcfe69f5 | local | 995891c9-ea38-453d-82cc-e5147ae10353 | +--------------------------------------+----------------------------------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t port d\u00e0nh cho IP VIP [root@localhost ~]# neutron port-create provider --fixed-ip ip_address=192.168.30.155 neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. Created a new port: +-----------------------+---------------------------------------------------------------------------------------+ | Field | Value | +-----------------------+---------------------------------------------------------------------------------------+ | admin_state_up | True | | allowed_address_pairs | | | binding:host_id | | | binding:profile | {} | | binding:vif_details | {} | | binding:vif_type | unbound | | binding:vnic_type | normal | | created_at | 2019-01-04T09:25:54Z | | description | | | device_id | | | device_owner | | | extra_dhcp_opts | | | fixed_ips | {\"subnet_id\": \"eb785a68-e5f2-4b35-be67-28adfd06c5f4\", \"ip_address\": \"192.168.30.155\"} | | id | 352d23af-df0e-4ee2-8169-5e39fcfc0c0d | | mac_address | fa:16:3e:dd:93:dd | | name | | | network_id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | port_security_enabled | True | | project_id | 43d21d33e36c4c6097acb1746a50f2b3 | | qos_policy_id | | | revision_number | 6 | | security_groups | c3b14f24-ebc1-49b9-924a-1e9cc7f158a1 | | status | DOWN | | tags | | | tenant_id | 43d21d33e36c4c6097acb1746a50f2b3 | | updated_at | 2019-01-04T09:25:55Z | +-----------------------+---------------------------------------------------------------------------------------+","title":"2.1. Kh\u1edfi t\u1ea1o IP VIP"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#22_binding_ip_vip_cho_cac_port_may_ao","text":"Haproxy c\u1ea7n ph\u1ea3i c\u00f3 VIP, \u0111\u00f3 l\u00e0 m\u1ed9t \u0111\u1ecba ch\u1ec9 IP b\u1ed5 sung. Theo m\u1eb7c \u0111\u1ecbnh, Neutron s\u1ebd kh\u00f4ng cho ph\u00e9p m\u1ed9t c\u1ed5ng ph\u1ea3n h\u1ed3i c\u00e1c packet n\u1ebfu n\u00f3 kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh Ki\u1ec3m tra c\u00e1c m\u00e1y \u1ea3o [root@localhost ~]# nova list +--------------------------------------+------+--------+------------+-------------+-------------------------+ | ID | Name | Status | Task State | Power State | Networks | +--------------------------------------+------+--------+------------+-------------+-------------------------+ | 651b5128-7005-4a63-828d-9dca06adf3e8 | ha1 | ACTIVE | - | Running | provider=192.168.30.149 | | f8ad2a47-e50a-4951-9eaf-327cf589fb0e | ha2 | ACTIVE | - | Running | provider=192.168.30.148 | +--------------------------------------+------+--------+------------+-------------+-------------------------+ Ki\u1ec3m tra interface tr\u00ean c\u00e1c m\u00e1y \u1ea3o [root@localhost ~]# nova interface-list ha1 +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | Port State | Port ID | Net ID | IP addresses | MAC Addr | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | ACTIVE | 18b4eee8-5d0e-4758-ae3c-1fd4d858a995 | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | 192.168.30.149 | fa:16:3e:6d:2d:ee | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ [root@localhost ~]# nova interface-list ha2 +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | Port State | Port ID | Net ID | IP addresses | MAC Addr | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ | ACTIVE | 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | 192.168.30.148 | fa:16:3e:ae:18:ce | +------------+--------------------------------------+--------------------------------------+----------------+-------------------+ Th\u00eam IP VIP c\u1ee7a m\u1ed7i port tr\u00ean tr\u1eebng m\u00e1y \u1ea3o neutron port-update 18b4eee8-5d0e-4758-ae3c-1fd4d858a995 --allowed_address_pairs list=true type=dict ip_address=192.168.30.155 neutron port-update 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 --allowed_address_pairs list=true type=dict ip_address=192.168.30.155 Ki\u1ec3m tra IP Pair [root@localhost ~]# openstack port show 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 +-----------------------+-------------------------------------------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | ip_address='192.168.30.155', mac_address='fa:16:3e:ae:18:ce' | | binding_host_id | compute1 | | binding_profile | | | binding_vif_details | datapath_type='system', ovs_hybrid_plug='True', port_filter='True' | | binding_vif_type | ovs | | binding_vnic_type | normal | | created_at | 2019-01-04T09:35:49Z | | data_plane_status | None | | description | | | device_id | f8ad2a47-e50a-4951-9eaf-327cf589fb0e | | device_owner | compute:nova | | dns_assignment | None | | dns_name | None | | extra_dhcp_opts | | | fixed_ips | ip_address='192.168.30.148', subnet_id='eb785a68-e5f2-4b35-be67-28adfd06c5f4' | | id | 728b0a1e-f1a3-4c3e-9fe0-bfd8cfc3a2a7 | | ip_address | None | | mac_address | fa:16:3e:ae:18:ce | | name | | | network_id | 751cc1ca-c4e4-4623-be31-20c657bcf2c2 | | option_name | None | | option_value | None | | port_security_enabled | True | | project_id | 438de521107643ee8348114ba022de1b | | qos_policy_id | None | | revision_number | 12 | | security_group_ids | 32c7144d-a976-48d5-a3f1-9eb10114822d | | status | ACTIVE | | subnet_id | None | | tags | | | trunk_details | None | | updated_at | 2019-01-04T10:31:21Z | +-----------------------+-------------------------------------------------------------------------------+","title":"2.2. Binding IP VIP cho c\u00e1c port m\u00e1y \u1ea3o"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#3_cau_hinh_tren_cac_instance","text":"C\u00e0i \u0111\u1eb7t HA Proxy Keep Alived v\u00e0 Web Server yum install -y httpd keepalived psmisc haproxy","title":"3. C\u1ea5u h\u00ecnh tr\u00ean c\u00e1c instance"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#tren_ha1","text":"C\u1ea5u h\u00ecnh Keep Alived cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface eth0 state MASTER virtual_router_id 51 priority 100 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.155 } unicast_src_ip 192.168.30.148 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.149 } track_script { chk_haproxy } } EOF","title":"Tr\u00ean HA1"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#tren_ha2","text":"C\u1ea5u h\u00ecnh Keep Alived cat <<EOF > /etc/keepalived/keepalived.conf vrrp_script chk_haproxy { # Requires keepalived-1.1.13 script \"killall -0 haproxy\" # cheaper than pidof interval 2 # check every 2 seconds weight 2 # add 2 points of prio if OK } vrrp_instance VI_1 { interface eth0 state BACKUP virtual_router_id 51 priority 99 # 100 on master, 99 on backup virtual_ipaddress { 192.168.30.155 } unicast_src_ip 192.168.30.149 # IP address of local interface unicast_peer { # IP address of peer interface 192.168.30.148 } track_script { chk_haproxy } } EOF","title":"Tr\u00ean HA2"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/3.HA-Proxy-OPS/#tren_ca_2_node_ha","text":"C\u1ea5u h\u00ecnh entry front-end cho HA Proxy frontend main *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js stats enable # auth info for statistics site stats auth admin:adminpassword # hide version of HAProxy stats hide-version # display HAProxy hostname stats show-node # refresh time stats refresh 60s # statistics reports' URI stats uri /haproxy?stats default_backend app C\u1ea5u h\u00ecnh entry backend cho HA Proxy backend app balance roundrobin server ha2 192.168.30.148:80 check server ha1 192.168.30.149:80 check C\u1ea5u h\u00ecnh n\u1ed9i dung Web Server echo Day la `hostname` > /var/www/html/index.html Kh\u1edfi \u0111\u1ed9ng dich v\u1ee5 systemctl start keealived haproxy httpd systemctl enable keealived haproxy httpd","title":"Tr\u00ean c\u1ea3 2 node HA"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/","text":"https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#1 1. S\u01a1 qua v\u1ec1 HTTP \u00b6 Khi HAproxy ch\u1ea1y v\u1edbi HTTP mode, c\u00e1c request v\u00e0 reponse \u0111\u1ec1u \u0111\u01b0\u1ee3c ph\u00e2n t\u00edch v\u00e0 g\u00e1n c\u00e1c ch\u1ec9 m\u1ee5c. v\u00ec v\u1eady c\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c to\u00e1n matching m\u1ecdi th\u1ee9 trong li\u00ean h\u1ec7 2 chi\u1ec1u n\u00e0y. Tuy nhi\u00ean, ch\u00fang ta c\u1ea7n hi\u1ec3u l\u00e0m sao HTTP request v\u00e0 reponse c\u00f3 th\u1ec3 h\u00ecnh th\u00e0nh v\u00e0 HAproxy c\u00f3 th\u1ec3 b\u00f3c t\u00e1ch c\u00e1c n\u1ed9i dung c\u00e1c packet n\u00e0y ra \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c to\u00e1n matching 1.1. M\u00f4 h\u00ecnh giao d\u1ecbch trong HTTP \u00b6 HTTP Protocol ho\u1ea1t \u0111\u1ed9ng theo ki\u1ec3u giao d\u1ecbch k\u00edn .\u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 m\u1ed7i request s\u1ebd ch\u1ec9 c\u00f3 duy nh\u1eadt m\u1ed9t response. Th\u00f4ng th\u01b0\u1eddng khi m\u1ed9t k\u1ebft n\u1ed1i TCP \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp t\u1eeb m\u1ed9t m\u00e1y kh\u00e1ch \u0111\u1ebfn server , m\u1ed9t HTTP request \u0111\u01b0\u1ee3c m\u00e1y kh\u00e1ch g\u1eedi qua k\u1ebft n\u1ed1i n\u00e0y , server tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 v\u1ec1 k\u1ebft n\u1ed1i n\u00e0y \u0111\u01b0\u1ee3c \u0111\u00f3ng. Sau \u0111\u00f3 m\u1ed9t request m\u1edbi \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh. [CON1] [REQ1] ... [RESP1] [CLO1] [CON2] [REQ2] ... [RESP2] [CLO2] ... V\u1edbi m\u00f4 h\u00ecnh , \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 ch\u1ebf \u0111\u1ed9 \"HTTP close\", c\u00f3 nhi\u1ec1u k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp. K\u1ec3 t\u1eeb khi m\u1ed9t k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c \u0111\u00f3ng k\u1ec3 t\u1eeb khi server tr\u1ea3 v\u1ec1 response , client s\u1ebd kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c chi\u1ec1u d\u00e0i c\u1ee7a n\u1ed9i dung n\u00e0y. Do nh\u1edd t\u00ednh giao d\u1ecbch k\u00edn trong c\u1ee7a giao th\u1ee9c n\u00e0y, ch\u00fang ta c\u00f3 th\u1ec3 c\u1ea3i ti\u1ebfn gi\u00fap ch\u00fang kh\u00f4ng \u0111\u00f3ng k\u1ebft n\u1ed1i gi\u1eefa 2 l\u1ea7n giao d\u1ecbch v\u1edbi nhau. Tuy nhi\u00ean trong ch\u1ebf \u0111\u1ed9 n\u00e0y, \u0111\u1ec3 ch\u1eafc ch\u1eafn c\u00e1c client kh\u00f4ng \u0111\u1ee3i ch\u1edd v\u00f4 h\u1ea1n c\u00e1c content \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1, server ph\u1ea3i quy\u1ebft \u0111\u1ecbnh s\u1ebd g\u1eafn HEADER r\u0103ng content n\u00e0y c\u00f3 d\u1ed9 \u0111\u00e0i bao nhi\u00eau V\u1edbi ph\u01b0\u01a1ng ph\u00e1p n\u00e0y s\u1ebd gi\u1ea3m \u0111\u01b0\u1ee3c \u0111\u1ed9 tr\u1ec5 gi\u1eefa c\u00e1c giao d\u1ecbch , c\u1ea7n \u00edt t\u00e0i nguy\u00ean \u0111\u1ec3 x\u1eed l\u00fd \u1edf b\u00ean server. N\u00f3 s\u1ebd t\u1ed1t h\u01a1n so v\u1edbi HTTP Close tuy nhi\u00ean \u0111\u00e2y kh\u00f4ng th\u1eadt s\u1ef1 ch\u00ednh x\u00e1c, b\u1edfi v\u00ec c\u00e1c client th\u01b0\u1eddng s\u1ebd gi\u1edbi h\u1ea1n nhi\u1ec1u k\u1ebft n\u1ed1i \u0111\u1ed3ng th\u1eddi v\u00e0 k\u00e9o d\u00e0i. M\u1ed9t c\u1ea3i ti\u1ebfn n\u01b0\u00e3 \u0111\u00f3 ch\u00ednh l\u00e0 giao ti\u1ebfp ki\u1ec3u \u0111\u01b0\u1eddng \u1ed1ng, n\u00f3 s\u1eed d\u1ee5ng keep-alive, nh\u01b0ng client kh\u00f4ng \u0111\u1ee3i ph\u1ea3n h\u1ed3i \u0111\u1ea7u ti\u00ean g\u1eedi \u0111\u1ec1 ngh\u1ecb th\u1ee9 hai. \u0110i\u1ec1u n\u00e0y r\u00f5 r\u00e0ng c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t l\u1ee3i \u00edch to l\u1edbn v\u1ec1 hi\u1ec7u su\u1ea5t v\u00ec \u0111\u1ed9 tr\u1ec5 m\u1ea1ng \u0111\u01b0\u1ee3c lo\u1ea1i b\u1ecf gi\u1eefa c\u00e1c y\u00eau c\u1ea7u ti\u1ebfp theo. Nhi\u1ec1u t\u00e1c nh\u00e2n HTTP kh\u00f4ng h\u1ed7 tr\u1ee3 ch\u00ednh x\u00e1c \u0111\u01b0\u1eddng \u1ed1ng v\u00ec kh\u00f4ng c\u00f3 c\u00e1ch n\u00e0o \u0111\u1ec3 li\u00ean k\u1ebft ph\u1ea3n h\u1ed3i v\u1edbi y\u00eau c\u1ea7u t\u01b0\u01a1ng \u1ee9ng trong HTTP. V\u00ec l\u00fd do n\u00e0y, m\u00e1y ch\u1ee7 b\u1eaft bu\u1ed9c ph\u1ea3i tr\u1ea3 l\u1eddi theo \u0111\u00fang th\u1ee9 t\u1ef1 nh\u01b0 c\u00e1c y\u00eau c\u1ea7u \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c. C\u1ea3i ti\u1ebfn ti\u1ebfp theo l\u00e0 ch\u1ebf \u0111\u1ed9 gh\u00e9p k\u00eanh, \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n trong HTTP / 2. L\u1ea7n n\u00e0y, m\u1ed7i giao d\u1ecbch \u0111\u01b0\u1ee3c g\u00e1n m\u1ed9t m\u00e3 \u0111\u1ecbnh danh lu\u1ed3ng duy nh\u1ea5t v\u00e0 t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c gh\u00e9p qua m\u1ed9t k\u1ebft n\u1ed1i hi\u1ec7n c\u00f3. Nhi\u1ec1u y\u00eau c\u1ea7u c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eedi song song b\u1edfi kh\u00e1ch h\u00e0ng v\u00e0 c\u00e1c ph\u1ea3n h\u1ed3i c\u00f3 th\u1ec3 \u0111\u1ebfn theo b\u1ea5t k\u1ef3 th\u1ee9 t\u1ef1 n\u00e0o v\u00ec ch\u00fang c\u0169ng mang m\u00e3 \u0111\u1ecbnh danh lu\u1ed3ng. M\u1eb7c \u0111\u1ecbnh HAproxy s\u1eed d\u1ee5ng keep-alive mode \u0111\u1ec3 duy tr\u00ec k\u1ebft n\u1ed1i : v\u1edbi m\u1ed7i k\u1ebft n\u1ed1i n\u00f3 x\u1eed l\u00fd m\u1ed9t request v\u00e0 m\u1ed9t response. v\u00e0 tho\u00e1t kh\u1ecfi k\u1ebft n\u1ed1i sau \u0111\u00f3 th\u00e0nh l\u1eadp nhanh m\u1ed9t k\u1ebft n\u1ed1i m\u1edbi. HAproxy h\u1ed7 tr\u1ee3 4 mode k\u1ebft n\u1ed1i keep-alived : t\u1ea5t c\u1ea3 c\u00e1c request v\u00e0 response \u0111\u01b0\u1ee3c x\u1eed l\u00fd tunnel : ch\u1ec9 giao d\u1ecbch \u0111\u1ea7u \u0111\u01b0\u1ee3c x\u1eed l\u00fd, c\u00f2n c\u00e1c giao d\u1ecbch sau kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e2n t\u00edch server close : k\u1ebft n\u1ed1i h\u01b0\u1edbng m\u00e1y ch\u1ee7 b\u1ecb \u0111\u00f3ng sau khi ph\u1ea3n h\u1ed3i. close : k\u1ebft b\u1ecb \u0111\u00f3ng sau khi ph\u1ea3n h\u1ed3i. 1.2. HTTP request \u00b6 N\u1ed9i dung c\u1ee7a m\u1ed9t HTTP Request th\u01b0\u1eddng s\u1ebd nh\u01b0 sau : Line Contents number 1 GET /serv/login.php?lang=en&profile=2 HTTP/1.1 2 Host: www.mydomain.com 3 User-agent: my small browser 4 Accept: image/jpeg, image/gif 5 Accept: image/png 1.2.1 : C\u00e1c n\u1ed9i dung trong HTTP Request \u00b6 D\u00f2ng 1 - y\u00eau c\u1ea7u : s\u1ebd c\u00f3 3 tr\u01b0\u1eddng bao g\u1ed3m : METHOD, URL , HTTP version . C\u00e1c tr\u01b0\u1eddng trong n\u00e0y \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi d\u1ea5u c\u00e1ch ho\u1eb7c tab gi\u1eefa ch\u00fang. URI s\u1ebd c\u00f3 2 d\u1ea1ng : \"RELATIVE URI\" : \u0111\u01b0\u1eddng d\u1eabn s\u1ebd kh\u00f4ng k\u00e8m host \u0111\u00edch /serv/login.php?lang=en&profile=2 HTTP/1.1 \"absolute URI\" : hay \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 URL : http://.mydomain.com/serv/login.php?lang=en&profile=2 HTTP/1.1 V\u1edbi URL \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n d\u01b0\u1edbi h\u1ea1ng schema : protocol://host:port/relative URI 1.2.2. Request Header \u00b6 Request Header \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u t\u1ea1i d\u00f2ng th\u1ee9 2 . C\u00e1c header \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi d\u1ea5u : v\u1edbi ki\u1ec3u c\u1eb7p pair key : value V\u00ec v\u1eady HAproxy s\u1ebd can thi\u1ec7p v\u00e0o c\u00e1c header n\u00e0y b\u1eb1ng c\u00e1ch l\u1eadp ch\u1ec9 m\u1ee5c , ki\u1ec3m tra value . Tr\u00edch d\u1eabn c\u00e2u n\u00f3i c\u1ee7a t\u00e1c gi\u1ea3 : so there is no reason to worry.about the way they could be written, but it is important not to accuse an application of being buggy if it does unusual, valid things. mu\u1ed1n d\u00f9ng th\u00ec \u0111\u1eebng ph\u00e0n n\u00e0n nh\u1eefng \u0111\u1ec1u n\u00f3 l\u00e0m 1.3 HTTP Response \u00b6 N\u1ed9i dung c\u1ee7a HTTP response s\u1ebd nh\u01b0 sau : Line Contents number 1 HTTP/1.1 200 OK 2 Content-length: 350 3 Content-Type: text/html \u0110\u1ed1i v\u1edbi line 1 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 response line bao g\u1ed3m 3 tr\u01b0\u1eddng - a version tag : HTTP/1.1 - a status code : 200 - a reason : OK C\u00e1c status code trong HTTP Protocol - 1xx = informational message to be skipped (e.g. 100, 101) - 2xx = OK, content is following (e.g. 200, 206) - 3xx = OK, no content following (e.g. 302, 304) - 4xx = error caused by the client (e.g. 401, 403, 404) - 5xx = error caused by the server (e.g. 500, 502, 503) \u0110\u1ec3 ki\u1ec3m so\u00e1t n\u1ed9i dung v\u00e0 tr\u1ea3 response v\u1ec1 cho HTTP Protocol , HAproxy c\u0169ng x\u00e2y d\u1ef1ng list status code Code When / reason 200 access to stats page, and when replying to monitoring requests 301 when performing a redirection, depending on the configured code 302 when performing a redirection, depending on the configured code 303 when performing a redirection, depending on the configured code 307 when performing a redirection, depending on the configured code 308 when performing a redirection, depending on the configured code 400 for an invalid or too large request 401 when an authentication is required to perform the action (when accessing the stats page) 403 when a request is forbidden by a \"[block](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#block)\" ACL or \"[reqdeny](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#reqdeny)\" filter 408 when the request timeout strikes before the request is complete 500 when haproxy encounters an unrecoverable internal error, such as a memory allocation failure, which should never happen 502 when the server returns an empty, invalid or incomplete response, or when an \"[rspdeny](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#rspdeny)\" filter blocks the response. 503 when no server was available to handle the request, or in response to monitoring requests which match the \"[monitor fail](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#monitor%20fail)\" condition 504 when the response timeout strikes before the server responds The error 4xx and 5xx codes above may be customized (see \"[errorloc](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#errorloc)\" in section 4.2). 2. C\u1ea5u h\u00ecnh HAProy \u00b6 2.1 . Format t\u1eadp tin c\u1ea5u h\u00ecnh \u00b6 Qu\u00e1 tr\u00ecnh c\u1ea5u h\u00ecnh c\u1ee7a HAProxy bao g\u1ed3m 3 ngu\u1ed3n tham s\u1ed1 ch\u00ednh: nh\u1eadn c\u00e1c parameter t\u1eeb command-line, c\u00e1c tham s\u1ed1 n\u00e0y \u0111\u01b0\u1ee3c \u01b0u ti\u00ean ph\u1ea7n \"to\u00e0n c\u1ea7u\", thi\u1ebft l\u1eadp c\u00e1c tham s\u1ed1 to\u00e0n quy tr\u00ecnh global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 ## : Thi\u1ebft l\u1eadp s\u1ed1 k\u1ebft n\u1ed1i \u0111\u1ed3ng th\u1eddi t\u1ed1i \u0111a tr\u00ean m\u1ed9t process m\u00e0 HAProxy ch\u1ea5p nh\u1eadn x\u1eed l\u00fd user haproxy ## user kh\u1edfi t\u1ea1o process group haproxy ## nh\u00f3m user kh\u1edfi t\u1ea1o process daemon ## N\u00f3 s\u1eed d\u1ee5ng thi\u1ebft l\u1eadp process haproxy \u1edf ch\u1ebf \u0111\u1ed9 ch\u1ea1y n\u1ec1n (background), # turn on stats unix socket stats socket /var/lib/haproxy/stats c\u00e1c ph\u1ea7n proxy c\u00f3 th\u1ec3 \u1edf d\u1ea1ng \"default\", \"listenner\", \"Frontend\" frontend main *:5000 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static default_backend app #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- backend static balance roundrobin server static 127.0.0.1:4331 check #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check 2.2 . Quoting and escaping \u00b6 2.3: Bi\u1ebfn m\u00f4i tr\u01b0\u1eddng \u00b6 HAproxy h\u1ed7 tr\u1ee3 bi\u1ebfn m\u00f4i tr\u01b0\u1eddng trong t\u1eadp tin c\u1ea5u h\u00ecnh c\u1ee7a m\u00ecnh . Nh\u1eefng bi\u1ebfn n\u00e0y ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u1ee9ng trong \" \" . T\u00ean bi\u1ebfn ph\u1ea3i \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u b\u1eb1ng m\u1ed9t \u0111\u00f4 la (\"$\") v\u00e0 \u0111\u01b0\u1ee3c t\u00f9y \u00fd k\u00e8m theo d\u1ea5u ngo\u1eb7c (\"{}\") . T\u00ean bi\u1ebfn c\u00f3 th\u1ec3 ch\u1ee9a c\u00e1c k\u00fd t\u1ef1 ch\u1eef v\u00e0 s\u1ed1 ho\u1eb7c k\u00fd t\u1ef1 g\u1ea1ch d\u01b0\u1edbi (\"_\") nh\u01b0ng kh\u00f4ng n\u00ean b\u1eaft \u0111\u1ea7u b\u1eb1ng m\u1ed9t ch\u1eef s\u1ed1. bind \"fd@${FD_APP1}\" log \"${LOCAL_SYSLOG}:514\" local0 notice # send to local server user \"$HAPROXY_USER\" 2.4 : Time Format \u00b6 C\u00e1c m\u1ed1c th\u1eddi gian \u0111\u01b0\u1ee3c HAproxy h\u1ed7 tr\u1ee3 - us : microseconds. 1 microsecond = 1/1000000 second - ms : milliseconds. 1 millisecond = 1/1000 second. This is the default. - s : seconds. 1s = 1000ms - m : minutes. 1m = 60s = 60000ms - h : hours. 1h = 60m = 3600s = 3600000ms - d : days. 1d = 24h = 1440m = 86400s = 86400000ms 3. Global Parameters \u00b6 C\u00e1c keywork \u0111\u01b0\u1ee3c global section h\u1ed7 tr\u1ee3 The following keywords are supported in the \"global\" section : Process management and security ca-base chroot crt-base cpu-map daemon description deviceatlas-json-file deviceatlas-log-level deviceatlas-separator deviceatlas-properties-cookie external-check gid group hard-stop-after log log-tag log-send-hostname lua-load nbproc nbthread node pidfile presetenv resetenv uid ulimit-n user setenv stats ssl-default-bind-ciphers ssl-default-bind-ciphersuites ssl-default-bind-options ssl-default-server-ciphers ssl-default-server-ciphersuites ssl-default-server-options ssl-dh-param-file ssl-server-verify unix-bind unsetenv 51degrees-data-file 51degrees-property-name-list 51degrees-property-separator 51degrees-cache-size wurfl-data-file wurfl-information-list wurfl-information-list-separator wurfl-engine-mode wurfl-cache-size wurfl-useragent-priority Performance tuning max-spread-checks maxconn maxconnrate maxcomprate maxcompcpuusage maxpipes maxsessrate maxsslconn maxsslrate maxzlibmem noepoll nokqueue nopoll nosplice nogetaddrinfo noreuseport profiling.tasks spread-checks server-state-base server-state-file ssl-engine ssl-mode-async tune.buffers.limit tune.buffers.reserve tune.bufsize tune.chksize tune.comp.maxlevel tune.h2.header-table-size tune.h2.initial-window-size tune.h2.max-concurrent-streams tune.http.cookielen tune.http.logurilen tune.http.maxhdr tune.idletimer tune.lua.forced-yield tune.lua.maxmem tune.lua.session-timeout tune.lua.task-timeout tune.lua.service-timeout tune.maxaccept tune.maxpollevents tune.maxrewrite tune.pattern.cache-size tune.pipesize tune.rcvbuf.client tune.rcvbuf.server tune.recv_enough tune.runqueue-depth tune.sndbuf.client tune.sndbuf.server tune.ssl.cachesize tune.ssl.lifetime tune.ssl.force-private-cache tune.ssl.maxrecord tune.ssl.default-dh-param tune.ssl.ssl-ctx-cache-size tune.ssl.capture-cipherlist-size tune.vars.global-max-size tune.vars.proc-max-size tune.vars.reqres-max-size tune.vars.sess-max-size tune.vars.txn-max-size tune.zlib.memlevel tune.zlib.windowsize Debugging debug quiet 4. Proxies \u00b6 C\u00e1c proxy c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh t\u1ea1i c\u00e1c section - defaults [<name>] - frontend <name> - backend <name> - listen <name> Default section c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh m\u00e0 c\u00e1c section kh\u00e1c th\u1eeba h\u01b0\u1edfng. Front-end section : x\u00e2y d\u1ef1ng c\u00e1c listen socket, h\u1ed7 tr\u1ee3 nghe c\u00e1c k\u1ebft n\u1ed1i t\u1eeb client Back-end section : x\u00e2y d\u1ef1ng c\u00e1c farm server, sau \u0111\u00f3 forward k\u1ebft n\u1ed1i t\u1eeb front-end \u0111\u1ebfn server Listener : x\u00e1c \u0111\u1ecbnh proxy ho\u00e0n ch\u1ec9nh v\u1edbi front-end v\u00e0 backend . N\u00f3 th\u01b0\u1eddng h\u1eefu \u00edch cho l\u01b0u l\u01b0\u1ee3ng ch\u1ec9 TCP. T\u1ea5t c\u1ea3 c\u00e1c t\u00ean proxy c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u1eeb ch\u1eef in hoa v\u00e0 ch\u1eef th\u01b0\u1eddng, ch\u1eef s\u1ed1, '-' (d\u1ea5u g\u1ea1ch ngang), '_' (g\u1ea1ch d\u01b0\u1edbi), '.' (d\u1ea5u ch\u1ea5m) v\u00e0 ':' (d\u1ea5u hai ch\u1ea5m). T\u00ean ACL l\u00e0 ph\u00e2n bi\u1ec7t ch\u1eef hoa ch\u1eef th\u01b0\u1eddng, c\u00f3 ngh\u0129a l\u00e0 \"www\" v\u00e0 \"WWW\" l\u00e0 hai proxy kh\u00e1c nhau. 4.1. C\u00e1c Metric trong Proxy \u00b6 acl [flags] [operator] ... Declare or complete an access list. acl invalid_src src 0.0.0.0/7 224.0.0.0/3 acl invalid_src src_port 0:1023 acl local_dst hdr(host) -i localhost appsession len timeout [request-learn] [prefix] [mode ] Define session stickiness on an existing application cookie. Arguments : this is the name of the cookie used by the application and which HAProxy will have to learn for each new session. this is the max number of characters that will be memorized and checked in each cookie value. this is the time after which the cookie will be removed from memory if unused. If no unit is specified, this time is in milliseconds. request-learn If this option is specified, then haproxy will be able to learn the cookie found in the request in case the server does not specify any in response. This is typically what happens with PHPSESSID cookies, or when haproxy's session expires before the application's session and the correct server is selected. It is recommended to specify this option to improve reliability. prefix When this option is specified, haproxy will match on the cookie prefix (or URL parameter prefix). The appsession value is the data following this prefix. Example : appsession ASPSESSIONID len 64 timeout 3h prefix This will match the cookie ASPSESSIONIDXXX=XXXX, the appsession value will be XXX=XXXX. mode This option allows to change the URL parser mode. 2 modes are currently supported : - path-parameters : The parser looks for the appsession in the path parameters part (each parameter is separated by a semi-colon), which is convenient for JSESSIONID for example. This is the default mode if the option is not set. - query-string : In this mode, the parser will look for the appsession in the query string. backlog Give hints to the system about the approximate listen backlog desired size balance [ ] balance url_param [check_post] Define the load balancing algorithm to be used in a backend. balance roundrobin balance url_param userid balance url_param session_id check_post 64 balance hdr(User-Agent) balance hdr(host) balance hdr(Host) use_domain_only ```` - **[bind](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind)** [<address>]:<port_range> [, ...] [param*] - **[bind](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind)** /<path> [, ...] [param*] Define one or several listening addresses and/or ports in a frontend. listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy listen http_https_proxy bind :80 bind :443 ssl crt /etc/haproxy/site.pem listen http_https_proxy_explicit bind ipv6@:80 bind ipv4@public_ssl:443 ssl crt /etc/haproxy/site.pem bind unix@ssl-frontend.sock user root mode 600 accept-proxy listen external_bind_app1 bind \"fd@${FD_APP1}\" - **[bind-process](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind-process)** [ all | odd | even | <process_num>[-[<process_num>]] ] ... Limit visibility of an instance to a certain set of processes numbers. listen app_ip1 bind 10.0.0.1:80 bind-process odd listen app_ip2 bind 10.0.0.2:80 bind-process even listen management bind 10.0.0.3:80 bind-process 1 2 3 4 listen management bind 10.0.0.4:80 bind-process 1-4 - **[block](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-block)** { if | unless } <condition> (deprecated) Block a layer 7 request if/unless a condition is matched acl invalid_src src 0.0.0.0/7 224.0.0.0/3 acl invalid_src src_port 0:1023 acl local_dst hdr(host) -i localhost block is deprecated. Use http-request deny instead: \u00b6 block if invalid_src || local_dst \u00b6 http-request deny if invalid_src || local_dst - **[capture cookie](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-capture%20cookie)** <name> len <length> Capture and log a cookie in the request and in the response. capture cookie ASPSESSION len 32 - **[capture request header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-capture%20request%20header)** `<name>` len` <length>` Capture and log the last occurrence of the specified request header. capture request header Host len 15 capture request header X-Forwarded-For len 15 capture request header Referer len 15 - **[ clitimeout](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-clitimeout)** `<timeout> `(deprecated) Set the maximum inactivity time on the client side. - **[contimeout](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-contimeout)** `<timeout> `(deprecated) Set the maximum time to wait for a connection attempt to a server to succeed. - **[ cookie](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-cookie)** <name> [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain <domain> ]* [ maxidle <idle> ] [ maxlife <life> ] [ dynamic ] Enable cookie-based persistence in a backend. - **[default-server](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-default-server)**[param*] Change default options for a server in a backend default-server inter 1000 weight 13 - **[default_backend](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-default_backend)**` <backend>` Specify the backend to use when no \"[use_backend](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#use_backend)\" rule has been matched. use_backend dynamic if url_dyn use_backend static if url_css url_img extension_img default_backend dynamic - **[description](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-description)** `<string>` Describe a listen, frontend or backend. - **[enabled](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-enabled)** Enable a proxy, frontend or backend. - **[disabled](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-disabled)** Disable a proxy, frontend or backend. - **[dispatch](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-dispatch)** `<address>:<port>` Set a default server address - **[dynamic-cookie-key](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-dynamic-cookie-key)** <string> Set the dynamic cookie secret key for a backend. - **[errorfile](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorfile)**` <code> <file>` Return a file contents instead of errors generated by HAProxy errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null # work around Chrome pre-connect bug errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http - **[errorloc](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorloc)** `<code> <url>` - **[errorloc302](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorloc302)**`<code> <url>` Return an HTTP redirection to a URL instead of errors generated by HAProxy - **[email-alert from](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20from)** `<emailaddr>` Declare the from email address to be used in both the envelope and header of email alerts. This is the address that email alerts are sent from. - **[email-alert level](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20level)** `<level>` Declare the maximum log level of messages for which email alerts will besent. This acts as a filter on the sending of email alerts. **[email-alert mailers](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20mailers)** `<mailersect>` Declare the mailers to be used when sending email alerts - **[email-alert myhostname](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20myhostname)** `<hostname>` Declare the to hostname address to be used when communicating with mailers. - **[email-alert to](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20to)** `<emailaddr>` Declare both the recipient address in the envelope and to address in the header of email alerts. This is the address that email alerts are sent to. - **[force-persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-force-persist)** { if | unless } `<condition>` Declare a condition to force persistence on down servers - **[filter](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-filter)** `<name> `[param*] Add the filter <name> in the filter list attached to the proxy. listen bind *:80 filter trace name BEFORE-HTTP-COMP filter compression filter trace name AFTER-HTTP-COMP compression algo gzip compression offload server srv1 192.168.0.1:80 - **[fullconn](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-fullconn)** <conns> Specify at what backend load the servers will reach their maxconn backend dynamic fullconn 10000 server srv1 dyn1:80 minconn 100 maxconn 1000 server srv2 dyn2:80 minconn 100 maxconn 1000 - **[grace](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-grace)** `<time>` Maintain a proxy operational for some time after a soft stop - **[hash-balance-factor](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-hash-balance-factor)** `<factor>` Specify the balancing factor for bounded-load consistent hashing - **[hash-type](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-hash-type)** <method> `<function> <modifier>` Specify a method to use for mapping hashes to servers ### HTTP check - **[http-check disable-on-404](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20disable-on-404)** Enable a maintenance mode upon HTTP/404 response to health-checks - **[http-check expect](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20expect)** [!] `<match> <pattern>` Make HTTP health checks consider response contents or specific status codes only accept status 200 as valid \u00b6 http-check expect status 200 consider SQL errors as errors \u00b6 http-check expect ! string SQL\\ Error consider status 5xx only as errors \u00b6 http-check expect ! rstatus ^5 check that we have a correct hexadecimal tag before /html \u00b6 http-check expect rstring - **[http-check send-state](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20send-state)** Enable emission of a state header with HTTP health checks - **[http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-request)**` <action> [options...]` [ { if | unless } <condition> ] Access control for Layer 7 requests acl nagios src 192.168.129.3 acl local_net src 192.168.0.0/16 acl auth_ok http_auth(L1) http-request allow if nagios http-request allow if local_net auth_ok http-request auth realm Gimme if local_net auth_ok http-request deny - **[http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-response%20add-acl)** More ........... : https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4-http-request - **[http-reuse](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-reuse)** { never | safe | aggressive | always } Declare how idle HTTP connections may be shared between requests - **[http-send-name-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-send-name-header)** [<header>] Add the server name to a request. Use the header string given by <header> - **[id](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-id)** <value> Set a persistent ID to a proxy. - **[ignore-persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-ignore-persist)** { if | unless } <condition> Declare a condition to ignore persistence acl url_static path_beg /static /images /img /css acl url_static path_end .gif .png .jpg .css .js ignore-persist if url_static - **[load-server-state-from-file](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-load-server-state-from-file)** { global | local | none } Allow seamless reload of HAProxy - **[log global](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-log%20global)** - **[log](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-log)** <address> [len <length>] [format <format>] <facility> [<level> [<minlevel>]] - **[no log](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20log)** Enable per-instance logging of events and traffic. - **[max-keep-alive-queue](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-max-keep-alive-queue)** <value> Set the maximum server queue size for maintaining keep-alive connections - **[max-session-srv-conns](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-max-session-srv-conns)** <nb> Set the maximum number of outgoing connections we can keep idling for a given client session. The default is 5 (it precisely equals MAX_SRV_LIST which is defined at build time). - **[mode](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-mode)** { tcp|http|health } Set the running mode or protocol of the instance defaults http_instances mode http - **[monitor fail](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-monitor%20fail)** { if | unless } `<condition>` Add a condition to report a failure to a monitor HTTP request. frontend www mode http acl site_dead nbsrv(dynamic) lt 2 acl site_dead nbsrv(static) lt 2 monitor-uri /site_alive monitor fail if site_dead ### OPTION Cheat sheet Haproxy - **[option abortonclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20abortonclose)** **[no option abortonclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20abortonclose)** Enable or disable early dropping of aborted requests pending in queues. - **[option accept-invalid-http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20accept-invalid-http-request)** **[no option accept-invalid-http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20accept-invalid-http-request)** Enable or disable relaxing of HTTP request parsing - **[option accept-invalid-http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20accept-invalid-http-response)** **[no option accept-invalid-http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20accept-invalid-http-response)** Enable or disable relaxing of HTTP response parsing - **[option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20allbackups)** **[no option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20allbackups)** Use either all backup servers at a time or only the first one By default, the first operational backup server gets all traffic when normal servers are all down. Sometimes, it may be preferred to use multiple backups at once, because one will not be enough. When \"[option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20allbackups)\" is enabled, the load balancing will be performed among all backup servers when all normal ones are unavailable. The same load balancing algorithm will be used and the servers' weights will be respected. Thus, there will not be any priority order between the backup servers anymore. - **[option checkcache](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20checkcache)** **[no option checkcache](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20checkcache)** Analyze all server responses and block responses with cacheable cookies - **[option clitcpka](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20clitcpka)** **[no option clitcpka](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20clitcpka)** Enable or disable the sending of TCP keepalive packets on the client side - **[option contstats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20contstats)** Enable continuous traffic statistics updates - **[option dontlog-normal](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20dontlog-normal)** **[no option dontlog-normal](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20dontlog-normal)** Enable or disable logging of normal, successful connections - **[option dontlognull](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20dontlognull)** **[no option dontlognull](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20dontlognull)** Enable or disable logging of null connections. In certain environments, there are components which will regularly connect to various systems to ensure that they are still alive. It can be the case from another load balancer as well as from monitoring systems. By - **[option forwardfor](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20forwardfor)** [ `except <network> ] [ header <name> ] [ if-none ]` Enable insertion of the X-Forwarded-For header to requests sent to servers. Since HAProxy works in reverse-proxy mode, the servers see its IP address as their client address. This is sometimes annoying when the client's IP address is expected in server logs. To solve this problem, the well-known HTTP header \"X-Forwarded-For\" may be added by HAProxy to all requests sent to the server. This header contains a value representing the client's IP address. Since this header is always appended at the end of the existing header list, the server must be configured to always use the last occurrence of this header only. See the server's manual to find how to enable use of this standard header. Note that only the last occurrence of the header must be used, since it is really possible that the client has already brought one. Public HTTP address also used by stunnel on the same machine \u00b6 frontend www mode http option forwardfor except 127.0.0.1 # stunnel already adds the header Those servers want the IP Address in X-Client \u00b6 backend www mode http option forwardfor header X-Client - **[option http-buffer-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-buffer-request)** **[no option http-buffer-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-buffer-request)** Enable or disable waiting for whole HTTP request body before proceeding ( not useful ) - **[option http-ignore-probes](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-ignore-probes)** **[no option http-ignore-probes](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-ignore-probes)** Enable or disable logging of null connections and request timeouts - **[option http-keep-alive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-keep-alive)** **[no option http-keep-alive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-keep-alive)** Enable or disable HTTP keep-alive from client to server. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". This option allows to set back the keep-alive mode, which can be useful when another mode was used in a defaults section. - **[option http-no-delay](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-no-delay)** **[no option http-no-delay](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-no-delay)** Instruct the system to favor low interactive delays over performance in HTTP - **[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-server-close)** **[no option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-server-close)** Enable or disable HTTP connection closing on the server side. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". Setting \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\" enables HTTP connection-close mode on the server side while keeping the ability to support HTTP keep-alive and pipelining on the client side. This provides the lowest latency on the client side (slow network) and the fastest session reuse on the server side to save server resources, similarly to \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\". It also permits non-keepalive capable servers to be served in keep-alive mode to the clients if they conform to the requirements of RFC7230. Please note that some servers do not always conform to those requirements when they see \"Connection: close\" in the request. The effect will be that keep-alive will never be used. A workaround consists in enabling \"[option http-pretend-keepalive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-pretend-keepalive)\". - **[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-tunnel)** **[no option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-tunnel)** Disable or enable HTTP connection processing after first transaction. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". - **[option http-use-proxy-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-use-proxy-header)** **[no option http-use-proxy-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-use-proxy-header)** Make use of non-standard Proxy-Connection header instead of Connection. - **[option http-use-htx](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-use-htx)** **[no option http-use-htx](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-use-htx)** Switch to the new HTX internal representation for HTTP protocol elements - **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <uri> **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <method> <uri> **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <method> <uri> <version> Enable HTTP protocol to check on the servers health backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\\r\\nHost:\\ www server apache1 192.168.1.1:443 check port 80 - **[option httplog](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httplog)** [ clf ] Enable logging of HTTP request, session state and timers - **[option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http_proxy)** **[no option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http_proxy)** Enable or disable plain HTTP proxy mode. It sometimes happens that people need a pure HTTP proxy which understands basic proxy requests without caching nor any fancy feature. In this case, it may be worth setting up an HAProxy instance with the \"[option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http_proxy)\" set. In this mode, no server is declared, and the connection is forwarded to the IP address and port found in the URL after the \"http://\" scheme. - **[option independent-streams](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20independent-streams)** **[no option independent-streams](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20independent-streams)** Enable or disable independent timeout processing for both directions. By default, when data is sent over a socket, both the write timeout and the read timeout for that socket are refreshed, because we consider that there is activity on that socket, and we have no other means of guessing if we should receive data or not. - **[option ldap-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20ldap-check)** Use LDAPv3 health checks for server testing - **[option log-health-checks](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20log-health-checks)** **[no option log-health-checks](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20log-health-checks)** Enable or disable logging of health checks status updates - **[option log-separate-errors](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20log-separate-errors)** **[no option log-separate-errors](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20log-separate-errors)** Change log level for non-completely successful connections - **[option logasap](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20logasap)** **[no option logasap](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20logasap)** Enable or disable early logging of HTTP requests - **[option mysql-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20mysql-check)** [ user <username> [ post-41 ] ] Use MySQL health checks for server testing - **[option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20persist)** **[no option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20persist)** Enable or disable forced persistence on down servers. When an HTTP request reaches a backend with a cookie which references a dead server, by default it is redispatched to another server. It is possible to force the request to be sent to the dead server first using \"[option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20persist)\" if absolutely needed. A common use case is when servers are under extreme load and spend their time flapping. In this case, the users would still be directed to the server they opened the session on, in the hope they would be correctly served. It is recommended to use \"[option redispatch](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20redispatch)\" in conjunction with this option so that in the event it would not be possible to connect to the server at all (server definitely dead), the client would finally be redirected to another valid server. - **[option socket-stats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20socket-stats)** **[no option socket-stats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20socket-stats)** Enable or disable collecting & providing separate statistics for each socket. - **[option ssl-hello-chk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20ssl-hello-chk)** Use SSLv3 client hello health checks for server testing.When some SSL-based protocols are relayed in TCP mode through HAProxy, it is possible to test that the server correctly talks SSL instead of just testing that it accepts the TCP connection. When \"[option ssl-hello-chk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20ssl-hello-chk)\" is set, pure SSLv3 client hello messages are sent once the connection is established to the server, and the response is analyzed to find an SSL server hello message. The server is considered valid only when the response contains this server hello message. - **[option tcp-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20tcp-check)** Perform health checks using tcp-check send/expect sequences. This health check method is intended to be combined with \"[tcp-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20tcp-check)\" command lists in order to support send/expect types of health check sequences. perform a POP check (analyze only server's banner) \u00b6 option tcp-check tcp-check expect string +OK\\ POP3\\ ready comment POP\\ protocol perform an IMAP check (analyze only server's banner) \u00b6 option tcp-check tcp-check expect string *\\ OK\\ IMAP4\\ ready comment IMAP\\ protocol look for the redis master server after ensuring it speaks well \u00b6 redis protocol, then it exits properly. \u00b6 (send a command then analyze the response 3 times) \u00b6 option tcp-check tcp-check comment PING\\ phase tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check comment role\\ check tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check comment QUIT\\ phase tcp-check send QUIT\\r\\n tcp-check expect string +OK forge a HTTP request, then analyze the response (send many headers before analyzing) option tcp-check tcp-check comment forge\\ and\\ send\\ HTTP\\ request tcp-check send HEAD\\ /\\ HTTP/1.1\\r\\n tcp-check send Host:\\ www.mydomain.com\\r\\n tcp-check send User-Agent:\\ HAProxy\\ tcpcheck\\r\\n tcp-check send \\r\\n tcp-check expect rstring HTTP/1..\\ (2..|3..) comment check\\ HTTP\\ response ``` option tcpka Enable or disable the sending of TCP keepalive packets on both sides option tcplog Enable advanced logging of TCP connections with session state and timers timeout server timeout srvtimeout (deprecated) Set the maximum inactivity time on the server side. timeout queue Set the maximum time to wait in the queue for a connection slot to be free timeout http-request Set the maximum allowed time to wait for a complete HTTP request timeout http-keep-alive Set the maximum allowed time to wait for a new HTTP request to appear timeout client timeout clitimeout (deprecated) Set the maximum inactivity time on the client side. dang update \u00b6","title":"4. HAProxy HTTP&Config"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#1_so_qua_ve_http","text":"Khi HAproxy ch\u1ea1y v\u1edbi HTTP mode, c\u00e1c request v\u00e0 reponse \u0111\u1ec1u \u0111\u01b0\u1ee3c ph\u00e2n t\u00edch v\u00e0 g\u00e1n c\u00e1c ch\u1ec9 m\u1ee5c. v\u00ec v\u1eady c\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c to\u00e1n matching m\u1ecdi th\u1ee9 trong li\u00ean h\u1ec7 2 chi\u1ec1u n\u00e0y. Tuy nhi\u00ean, ch\u00fang ta c\u1ea7n hi\u1ec3u l\u00e0m sao HTTP request v\u00e0 reponse c\u00f3 th\u1ec3 h\u00ecnh th\u00e0nh v\u00e0 HAproxy c\u00f3 th\u1ec3 b\u00f3c t\u00e1ch c\u00e1c n\u1ed9i dung c\u00e1c packet n\u00e0y ra \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c to\u00e1n matching","title":"1. S\u01a1 qua v\u1ec1 HTTP"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#11_mo_hinh_giao_dich_trong_http","text":"HTTP Protocol ho\u1ea1t \u0111\u1ed9ng theo ki\u1ec3u giao d\u1ecbch k\u00edn .\u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 m\u1ed7i request s\u1ebd ch\u1ec9 c\u00f3 duy nh\u1eadt m\u1ed9t response. Th\u00f4ng th\u01b0\u1eddng khi m\u1ed9t k\u1ebft n\u1ed1i TCP \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp t\u1eeb m\u1ed9t m\u00e1y kh\u00e1ch \u0111\u1ebfn server , m\u1ed9t HTTP request \u0111\u01b0\u1ee3c m\u00e1y kh\u00e1ch g\u1eedi qua k\u1ebft n\u1ed1i n\u00e0y , server tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 v\u1ec1 k\u1ebft n\u1ed1i n\u00e0y \u0111\u01b0\u1ee3c \u0111\u00f3ng. Sau \u0111\u00f3 m\u1ed9t request m\u1edbi \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh. [CON1] [REQ1] ... [RESP1] [CLO1] [CON2] [REQ2] ... [RESP2] [CLO2] ... V\u1edbi m\u00f4 h\u00ecnh , \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 ch\u1ebf \u0111\u1ed9 \"HTTP close\", c\u00f3 nhi\u1ec1u k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp. K\u1ec3 t\u1eeb khi m\u1ed9t k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c \u0111\u00f3ng k\u1ec3 t\u1eeb khi server tr\u1ea3 v\u1ec1 response , client s\u1ebd kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c chi\u1ec1u d\u00e0i c\u1ee7a n\u1ed9i dung n\u00e0y. Do nh\u1edd t\u00ednh giao d\u1ecbch k\u00edn trong c\u1ee7a giao th\u1ee9c n\u00e0y, ch\u00fang ta c\u00f3 th\u1ec3 c\u1ea3i ti\u1ebfn gi\u00fap ch\u00fang kh\u00f4ng \u0111\u00f3ng k\u1ebft n\u1ed1i gi\u1eefa 2 l\u1ea7n giao d\u1ecbch v\u1edbi nhau. Tuy nhi\u00ean trong ch\u1ebf \u0111\u1ed9 n\u00e0y, \u0111\u1ec3 ch\u1eafc ch\u1eafn c\u00e1c client kh\u00f4ng \u0111\u1ee3i ch\u1edd v\u00f4 h\u1ea1n c\u00e1c content \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1, server ph\u1ea3i quy\u1ebft \u0111\u1ecbnh s\u1ebd g\u1eafn HEADER r\u0103ng content n\u00e0y c\u00f3 d\u1ed9 \u0111\u00e0i bao nhi\u00eau V\u1edbi ph\u01b0\u01a1ng ph\u00e1p n\u00e0y s\u1ebd gi\u1ea3m \u0111\u01b0\u1ee3c \u0111\u1ed9 tr\u1ec5 gi\u1eefa c\u00e1c giao d\u1ecbch , c\u1ea7n \u00edt t\u00e0i nguy\u00ean \u0111\u1ec3 x\u1eed l\u00fd \u1edf b\u00ean server. N\u00f3 s\u1ebd t\u1ed1t h\u01a1n so v\u1edbi HTTP Close tuy nhi\u00ean \u0111\u00e2y kh\u00f4ng th\u1eadt s\u1ef1 ch\u00ednh x\u00e1c, b\u1edfi v\u00ec c\u00e1c client th\u01b0\u1eddng s\u1ebd gi\u1edbi h\u1ea1n nhi\u1ec1u k\u1ebft n\u1ed1i \u0111\u1ed3ng th\u1eddi v\u00e0 k\u00e9o d\u00e0i. M\u1ed9t c\u1ea3i ti\u1ebfn n\u01b0\u00e3 \u0111\u00f3 ch\u00ednh l\u00e0 giao ti\u1ebfp ki\u1ec3u \u0111\u01b0\u1eddng \u1ed1ng, n\u00f3 s\u1eed d\u1ee5ng keep-alive, nh\u01b0ng client kh\u00f4ng \u0111\u1ee3i ph\u1ea3n h\u1ed3i \u0111\u1ea7u ti\u00ean g\u1eedi \u0111\u1ec1 ngh\u1ecb th\u1ee9 hai. \u0110i\u1ec1u n\u00e0y r\u00f5 r\u00e0ng c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t l\u1ee3i \u00edch to l\u1edbn v\u1ec1 hi\u1ec7u su\u1ea5t v\u00ec \u0111\u1ed9 tr\u1ec5 m\u1ea1ng \u0111\u01b0\u1ee3c lo\u1ea1i b\u1ecf gi\u1eefa c\u00e1c y\u00eau c\u1ea7u ti\u1ebfp theo. Nhi\u1ec1u t\u00e1c nh\u00e2n HTTP kh\u00f4ng h\u1ed7 tr\u1ee3 ch\u00ednh x\u00e1c \u0111\u01b0\u1eddng \u1ed1ng v\u00ec kh\u00f4ng c\u00f3 c\u00e1ch n\u00e0o \u0111\u1ec3 li\u00ean k\u1ebft ph\u1ea3n h\u1ed3i v\u1edbi y\u00eau c\u1ea7u t\u01b0\u01a1ng \u1ee9ng trong HTTP. V\u00ec l\u00fd do n\u00e0y, m\u00e1y ch\u1ee7 b\u1eaft bu\u1ed9c ph\u1ea3i tr\u1ea3 l\u1eddi theo \u0111\u00fang th\u1ee9 t\u1ef1 nh\u01b0 c\u00e1c y\u00eau c\u1ea7u \u0111\u00e3 nh\u1eadn \u0111\u01b0\u1ee3c. C\u1ea3i ti\u1ebfn ti\u1ebfp theo l\u00e0 ch\u1ebf \u0111\u1ed9 gh\u00e9p k\u00eanh, \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n trong HTTP / 2. L\u1ea7n n\u00e0y, m\u1ed7i giao d\u1ecbch \u0111\u01b0\u1ee3c g\u00e1n m\u1ed9t m\u00e3 \u0111\u1ecbnh danh lu\u1ed3ng duy nh\u1ea5t v\u00e0 t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c gh\u00e9p qua m\u1ed9t k\u1ebft n\u1ed1i hi\u1ec7n c\u00f3. Nhi\u1ec1u y\u00eau c\u1ea7u c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eedi song song b\u1edfi kh\u00e1ch h\u00e0ng v\u00e0 c\u00e1c ph\u1ea3n h\u1ed3i c\u00f3 th\u1ec3 \u0111\u1ebfn theo b\u1ea5t k\u1ef3 th\u1ee9 t\u1ef1 n\u00e0o v\u00ec ch\u00fang c\u0169ng mang m\u00e3 \u0111\u1ecbnh danh lu\u1ed3ng. M\u1eb7c \u0111\u1ecbnh HAproxy s\u1eed d\u1ee5ng keep-alive mode \u0111\u1ec3 duy tr\u00ec k\u1ebft n\u1ed1i : v\u1edbi m\u1ed7i k\u1ebft n\u1ed1i n\u00f3 x\u1eed l\u00fd m\u1ed9t request v\u00e0 m\u1ed9t response. v\u00e0 tho\u00e1t kh\u1ecfi k\u1ebft n\u1ed1i sau \u0111\u00f3 th\u00e0nh l\u1eadp nhanh m\u1ed9t k\u1ebft n\u1ed1i m\u1edbi. HAproxy h\u1ed7 tr\u1ee3 4 mode k\u1ebft n\u1ed1i keep-alived : t\u1ea5t c\u1ea3 c\u00e1c request v\u00e0 response \u0111\u01b0\u1ee3c x\u1eed l\u00fd tunnel : ch\u1ec9 giao d\u1ecbch \u0111\u1ea7u \u0111\u01b0\u1ee3c x\u1eed l\u00fd, c\u00f2n c\u00e1c giao d\u1ecbch sau kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e2n t\u00edch server close : k\u1ebft n\u1ed1i h\u01b0\u1edbng m\u00e1y ch\u1ee7 b\u1ecb \u0111\u00f3ng sau khi ph\u1ea3n h\u1ed3i. close : k\u1ebft b\u1ecb \u0111\u00f3ng sau khi ph\u1ea3n h\u1ed3i.","title":"1.1. M\u00f4 h\u00ecnh giao d\u1ecbch trong HTTP"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#12_http_request","text":"N\u1ed9i dung c\u1ee7a m\u1ed9t HTTP Request th\u01b0\u1eddng s\u1ebd nh\u01b0 sau : Line Contents number 1 GET /serv/login.php?lang=en&profile=2 HTTP/1.1 2 Host: www.mydomain.com 3 User-agent: my small browser 4 Accept: image/jpeg, image/gif 5 Accept: image/png","title":"1.2. HTTP request"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#121_cac_noi_dung_trong_http_request","text":"D\u00f2ng 1 - y\u00eau c\u1ea7u : s\u1ebd c\u00f3 3 tr\u01b0\u1eddng bao g\u1ed3m : METHOD, URL , HTTP version . C\u00e1c tr\u01b0\u1eddng trong n\u00e0y \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi d\u1ea5u c\u00e1ch ho\u1eb7c tab gi\u1eefa ch\u00fang. URI s\u1ebd c\u00f3 2 d\u1ea1ng : \"RELATIVE URI\" : \u0111\u01b0\u1eddng d\u1eabn s\u1ebd kh\u00f4ng k\u00e8m host \u0111\u00edch /serv/login.php?lang=en&profile=2 HTTP/1.1 \"absolute URI\" : hay \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 URL : http://.mydomain.com/serv/login.php?lang=en&profile=2 HTTP/1.1 V\u1edbi URL \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n d\u01b0\u1edbi h\u1ea1ng schema : protocol://host:port/relative URI","title":"1.2.1 : C\u00e1c n\u1ed9i dung trong HTTP Request"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#122_request_header","text":"Request Header \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u t\u1ea1i d\u00f2ng th\u1ee9 2 . C\u00e1c header \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi d\u1ea5u : v\u1edbi ki\u1ec3u c\u1eb7p pair key : value V\u00ec v\u1eady HAproxy s\u1ebd can thi\u1ec7p v\u00e0o c\u00e1c header n\u00e0y b\u1eb1ng c\u00e1ch l\u1eadp ch\u1ec9 m\u1ee5c , ki\u1ec3m tra value . Tr\u00edch d\u1eabn c\u00e2u n\u00f3i c\u1ee7a t\u00e1c gi\u1ea3 : so there is no reason to worry.about the way they could be written, but it is important not to accuse an application of being buggy if it does unusual, valid things. mu\u1ed1n d\u00f9ng th\u00ec \u0111\u1eebng ph\u00e0n n\u00e0n nh\u1eefng \u0111\u1ec1u n\u00f3 l\u00e0m","title":"1.2.2. Request Header"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#13_http_response","text":"N\u1ed9i dung c\u1ee7a HTTP response s\u1ebd nh\u01b0 sau : Line Contents number 1 HTTP/1.1 200 OK 2 Content-length: 350 3 Content-Type: text/html \u0110\u1ed1i v\u1edbi line 1 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 response line bao g\u1ed3m 3 tr\u01b0\u1eddng - a version tag : HTTP/1.1 - a status code : 200 - a reason : OK C\u00e1c status code trong HTTP Protocol - 1xx = informational message to be skipped (e.g. 100, 101) - 2xx = OK, content is following (e.g. 200, 206) - 3xx = OK, no content following (e.g. 302, 304) - 4xx = error caused by the client (e.g. 401, 403, 404) - 5xx = error caused by the server (e.g. 500, 502, 503) \u0110\u1ec3 ki\u1ec3m so\u00e1t n\u1ed9i dung v\u00e0 tr\u1ea3 response v\u1ec1 cho HTTP Protocol , HAproxy c\u0169ng x\u00e2y d\u1ef1ng list status code Code When / reason 200 access to stats page, and when replying to monitoring requests 301 when performing a redirection, depending on the configured code 302 when performing a redirection, depending on the configured code 303 when performing a redirection, depending on the configured code 307 when performing a redirection, depending on the configured code 308 when performing a redirection, depending on the configured code 400 for an invalid or too large request 401 when an authentication is required to perform the action (when accessing the stats page) 403 when a request is forbidden by a \"[block](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#block)\" ACL or \"[reqdeny](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#reqdeny)\" filter 408 when the request timeout strikes before the request is complete 500 when haproxy encounters an unrecoverable internal error, such as a memory allocation failure, which should never happen 502 when the server returns an empty, invalid or incomplete response, or when an \"[rspdeny](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#rspdeny)\" filter blocks the response. 503 when no server was available to handle the request, or in response to monitoring requests which match the \"[monitor fail](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#monitor%20fail)\" condition 504 when the response timeout strikes before the server responds The error 4xx and 5xx codes above may be customized (see \"[errorloc](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#errorloc)\" in section 4.2).","title":"1.3 HTTP Response"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#2_cau_hinh_haproy","text":"","title":"2. C\u1ea5u h\u00ecnh HAProy"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#21_format_tap_tin_cau_hinh","text":"Qu\u00e1 tr\u00ecnh c\u1ea5u h\u00ecnh c\u1ee7a HAProxy bao g\u1ed3m 3 ngu\u1ed3n tham s\u1ed1 ch\u00ednh: nh\u1eadn c\u00e1c parameter t\u1eeb command-line, c\u00e1c tham s\u1ed1 n\u00e0y \u0111\u01b0\u1ee3c \u01b0u ti\u00ean ph\u1ea7n \"to\u00e0n c\u1ea7u\", thi\u1ebft l\u1eadp c\u00e1c tham s\u1ed1 to\u00e0n quy tr\u00ecnh global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 ## : Thi\u1ebft l\u1eadp s\u1ed1 k\u1ebft n\u1ed1i \u0111\u1ed3ng th\u1eddi t\u1ed1i \u0111a tr\u00ean m\u1ed9t process m\u00e0 HAProxy ch\u1ea5p nh\u1eadn x\u1eed l\u00fd user haproxy ## user kh\u1edfi t\u1ea1o process group haproxy ## nh\u00f3m user kh\u1edfi t\u1ea1o process daemon ## N\u00f3 s\u1eed d\u1ee5ng thi\u1ebft l\u1eadp process haproxy \u1edf ch\u1ebf \u0111\u1ed9 ch\u1ea1y n\u1ec1n (background), # turn on stats unix socket stats socket /var/lib/haproxy/stats c\u00e1c ph\u1ea7n proxy c\u00f3 th\u1ec3 \u1edf d\u1ea1ng \"default\", \"listenner\", \"Frontend\" frontend main *:5000 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static default_backend app #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- backend static balance roundrobin server static 127.0.0.1:4331 check #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check","title":"2.1 . Format t\u1eadp tin c\u1ea5u h\u00ecnh"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#22_quoting_and_escaping","text":"","title":"2.2 . Quoting and escaping"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#23_bien_moi_truong","text":"HAproxy h\u1ed7 tr\u1ee3 bi\u1ebfn m\u00f4i tr\u01b0\u1eddng trong t\u1eadp tin c\u1ea5u h\u00ecnh c\u1ee7a m\u00ecnh . Nh\u1eefng bi\u1ebfn n\u00e0y ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u1ee9ng trong \" \" . T\u00ean bi\u1ebfn ph\u1ea3i \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u b\u1eb1ng m\u1ed9t \u0111\u00f4 la (\"$\") v\u00e0 \u0111\u01b0\u1ee3c t\u00f9y \u00fd k\u00e8m theo d\u1ea5u ngo\u1eb7c (\"{}\") . T\u00ean bi\u1ebfn c\u00f3 th\u1ec3 ch\u1ee9a c\u00e1c k\u00fd t\u1ef1 ch\u1eef v\u00e0 s\u1ed1 ho\u1eb7c k\u00fd t\u1ef1 g\u1ea1ch d\u01b0\u1edbi (\"_\") nh\u01b0ng kh\u00f4ng n\u00ean b\u1eaft \u0111\u1ea7u b\u1eb1ng m\u1ed9t ch\u1eef s\u1ed1. bind \"fd@${FD_APP1}\" log \"${LOCAL_SYSLOG}:514\" local0 notice # send to local server user \"$HAPROXY_USER\"","title":"2.3: Bi\u1ebfn m\u00f4i tr\u01b0\u1eddng"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#24_time_format","text":"C\u00e1c m\u1ed1c th\u1eddi gian \u0111\u01b0\u1ee3c HAproxy h\u1ed7 tr\u1ee3 - us : microseconds. 1 microsecond = 1/1000000 second - ms : milliseconds. 1 millisecond = 1/1000 second. This is the default. - s : seconds. 1s = 1000ms - m : minutes. 1m = 60s = 60000ms - h : hours. 1h = 60m = 3600s = 3600000ms - d : days. 1d = 24h = 1440m = 86400s = 86400000ms","title":"2.4 : Time Format"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#3_global_parameters","text":"C\u00e1c keywork \u0111\u01b0\u1ee3c global section h\u1ed7 tr\u1ee3 The following keywords are supported in the \"global\" section : Process management and security ca-base chroot crt-base cpu-map daemon description deviceatlas-json-file deviceatlas-log-level deviceatlas-separator deviceatlas-properties-cookie external-check gid group hard-stop-after log log-tag log-send-hostname lua-load nbproc nbthread node pidfile presetenv resetenv uid ulimit-n user setenv stats ssl-default-bind-ciphers ssl-default-bind-ciphersuites ssl-default-bind-options ssl-default-server-ciphers ssl-default-server-ciphersuites ssl-default-server-options ssl-dh-param-file ssl-server-verify unix-bind unsetenv 51degrees-data-file 51degrees-property-name-list 51degrees-property-separator 51degrees-cache-size wurfl-data-file wurfl-information-list wurfl-information-list-separator wurfl-engine-mode wurfl-cache-size wurfl-useragent-priority Performance tuning max-spread-checks maxconn maxconnrate maxcomprate maxcompcpuusage maxpipes maxsessrate maxsslconn maxsslrate maxzlibmem noepoll nokqueue nopoll nosplice nogetaddrinfo noreuseport profiling.tasks spread-checks server-state-base server-state-file ssl-engine ssl-mode-async tune.buffers.limit tune.buffers.reserve tune.bufsize tune.chksize tune.comp.maxlevel tune.h2.header-table-size tune.h2.initial-window-size tune.h2.max-concurrent-streams tune.http.cookielen tune.http.logurilen tune.http.maxhdr tune.idletimer tune.lua.forced-yield tune.lua.maxmem tune.lua.session-timeout tune.lua.task-timeout tune.lua.service-timeout tune.maxaccept tune.maxpollevents tune.maxrewrite tune.pattern.cache-size tune.pipesize tune.rcvbuf.client tune.rcvbuf.server tune.recv_enough tune.runqueue-depth tune.sndbuf.client tune.sndbuf.server tune.ssl.cachesize tune.ssl.lifetime tune.ssl.force-private-cache tune.ssl.maxrecord tune.ssl.default-dh-param tune.ssl.ssl-ctx-cache-size tune.ssl.capture-cipherlist-size tune.vars.global-max-size tune.vars.proc-max-size tune.vars.reqres-max-size tune.vars.sess-max-size tune.vars.txn-max-size tune.zlib.memlevel tune.zlib.windowsize Debugging debug quiet","title":"3. Global Parameters"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#4_proxies","text":"C\u00e1c proxy c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh t\u1ea1i c\u00e1c section - defaults [<name>] - frontend <name> - backend <name> - listen <name> Default section c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh m\u00e0 c\u00e1c section kh\u00e1c th\u1eeba h\u01b0\u1edfng. Front-end section : x\u00e2y d\u1ef1ng c\u00e1c listen socket, h\u1ed7 tr\u1ee3 nghe c\u00e1c k\u1ebft n\u1ed1i t\u1eeb client Back-end section : x\u00e2y d\u1ef1ng c\u00e1c farm server, sau \u0111\u00f3 forward k\u1ebft n\u1ed1i t\u1eeb front-end \u0111\u1ebfn server Listener : x\u00e1c \u0111\u1ecbnh proxy ho\u00e0n ch\u1ec9nh v\u1edbi front-end v\u00e0 backend . N\u00f3 th\u01b0\u1eddng h\u1eefu \u00edch cho l\u01b0u l\u01b0\u1ee3ng ch\u1ec9 TCP. T\u1ea5t c\u1ea3 c\u00e1c t\u00ean proxy c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u1eeb ch\u1eef in hoa v\u00e0 ch\u1eef th\u01b0\u1eddng, ch\u1eef s\u1ed1, '-' (d\u1ea5u g\u1ea1ch ngang), '_' (g\u1ea1ch d\u01b0\u1edbi), '.' (d\u1ea5u ch\u1ea5m) v\u00e0 ':' (d\u1ea5u hai ch\u1ea5m). T\u00ean ACL l\u00e0 ph\u00e2n bi\u1ec7t ch\u1eef hoa ch\u1eef th\u01b0\u1eddng, c\u00f3 ngh\u0129a l\u00e0 \"www\" v\u00e0 \"WWW\" l\u00e0 hai proxy kh\u00e1c nhau.","title":"4. Proxies"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#41_cac_metric_trong_proxy","text":"acl [flags] [operator] ... Declare or complete an access list. acl invalid_src src 0.0.0.0/7 224.0.0.0/3 acl invalid_src src_port 0:1023 acl local_dst hdr(host) -i localhost appsession len timeout [request-learn] [prefix] [mode ] Define session stickiness on an existing application cookie. Arguments : this is the name of the cookie used by the application and which HAProxy will have to learn for each new session. this is the max number of characters that will be memorized and checked in each cookie value. this is the time after which the cookie will be removed from memory if unused. If no unit is specified, this time is in milliseconds. request-learn If this option is specified, then haproxy will be able to learn the cookie found in the request in case the server does not specify any in response. This is typically what happens with PHPSESSID cookies, or when haproxy's session expires before the application's session and the correct server is selected. It is recommended to specify this option to improve reliability. prefix When this option is specified, haproxy will match on the cookie prefix (or URL parameter prefix). The appsession value is the data following this prefix. Example : appsession ASPSESSIONID len 64 timeout 3h prefix This will match the cookie ASPSESSIONIDXXX=XXXX, the appsession value will be XXX=XXXX. mode This option allows to change the URL parser mode. 2 modes are currently supported : - path-parameters : The parser looks for the appsession in the path parameters part (each parameter is separated by a semi-colon), which is convenient for JSESSIONID for example. This is the default mode if the option is not set. - query-string : In this mode, the parser will look for the appsession in the query string. backlog Give hints to the system about the approximate listen backlog desired size balance [ ] balance url_param [check_post] Define the load balancing algorithm to be used in a backend. balance roundrobin balance url_param userid balance url_param session_id check_post 64 balance hdr(User-Agent) balance hdr(host) balance hdr(Host) use_domain_only ```` - **[bind](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind)** [<address>]:<port_range> [, ...] [param*] - **[bind](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind)** /<path> [, ...] [param*] Define one or several listening addresses and/or ports in a frontend. listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy listen http_https_proxy bind :80 bind :443 ssl crt /etc/haproxy/site.pem listen http_https_proxy_explicit bind ipv6@:80 bind ipv4@public_ssl:443 ssl crt /etc/haproxy/site.pem bind unix@ssl-frontend.sock user root mode 600 accept-proxy listen external_bind_app1 bind \"fd@${FD_APP1}\" - **[bind-process](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-bind-process)** [ all | odd | even | <process_num>[-[<process_num>]] ] ... Limit visibility of an instance to a certain set of processes numbers. listen app_ip1 bind 10.0.0.1:80 bind-process odd listen app_ip2 bind 10.0.0.2:80 bind-process even listen management bind 10.0.0.3:80 bind-process 1 2 3 4 listen management bind 10.0.0.4:80 bind-process 1-4 - **[block](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-block)** { if | unless } <condition> (deprecated) Block a layer 7 request if/unless a condition is matched acl invalid_src src 0.0.0.0/7 224.0.0.0/3 acl invalid_src src_port 0:1023 acl local_dst hdr(host) -i localhost","title":"4.1. C\u00e1c Metric trong Proxy"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#block_is_deprecated_use_http-request_deny_instead","text":"","title":"block is deprecated. Use http-request deny instead:"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#block_if_invalid_src_local_dst","text":"http-request deny if invalid_src || local_dst - **[capture cookie](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-capture%20cookie)** <name> len <length> Capture and log a cookie in the request and in the response. capture cookie ASPSESSION len 32 - **[capture request header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-capture%20request%20header)** `<name>` len` <length>` Capture and log the last occurrence of the specified request header. capture request header Host len 15 capture request header X-Forwarded-For len 15 capture request header Referer len 15 - **[ clitimeout](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-clitimeout)** `<timeout> `(deprecated) Set the maximum inactivity time on the client side. - **[contimeout](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-contimeout)** `<timeout> `(deprecated) Set the maximum time to wait for a connection attempt to a server to succeed. - **[ cookie](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-cookie)** <name> [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain <domain> ]* [ maxidle <idle> ] [ maxlife <life> ] [ dynamic ] Enable cookie-based persistence in a backend. - **[default-server](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-default-server)**[param*] Change default options for a server in a backend default-server inter 1000 weight 13 - **[default_backend](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-default_backend)**` <backend>` Specify the backend to use when no \"[use_backend](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#use_backend)\" rule has been matched. use_backend dynamic if url_dyn use_backend static if url_css url_img extension_img default_backend dynamic - **[description](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-description)** `<string>` Describe a listen, frontend or backend. - **[enabled](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-enabled)** Enable a proxy, frontend or backend. - **[disabled](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-disabled)** Disable a proxy, frontend or backend. - **[dispatch](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-dispatch)** `<address>:<port>` Set a default server address - **[dynamic-cookie-key](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-dynamic-cookie-key)** <string> Set the dynamic cookie secret key for a backend. - **[errorfile](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorfile)**` <code> <file>` Return a file contents instead of errors generated by HAProxy errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null # work around Chrome pre-connect bug errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http - **[errorloc](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorloc)** `<code> <url>` - **[errorloc302](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-errorloc302)**`<code> <url>` Return an HTTP redirection to a URL instead of errors generated by HAProxy - **[email-alert from](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20from)** `<emailaddr>` Declare the from email address to be used in both the envelope and header of email alerts. This is the address that email alerts are sent from. - **[email-alert level](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20level)** `<level>` Declare the maximum log level of messages for which email alerts will besent. This acts as a filter on the sending of email alerts. **[email-alert mailers](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20mailers)** `<mailersect>` Declare the mailers to be used when sending email alerts - **[email-alert myhostname](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20myhostname)** `<hostname>` Declare the to hostname address to be used when communicating with mailers. - **[email-alert to](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-email-alert%20to)** `<emailaddr>` Declare both the recipient address in the envelope and to address in the header of email alerts. This is the address that email alerts are sent to. - **[force-persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-force-persist)** { if | unless } `<condition>` Declare a condition to force persistence on down servers - **[filter](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-filter)** `<name> `[param*] Add the filter <name> in the filter list attached to the proxy. listen bind *:80 filter trace name BEFORE-HTTP-COMP filter compression filter trace name AFTER-HTTP-COMP compression algo gzip compression offload server srv1 192.168.0.1:80 - **[fullconn](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-fullconn)** <conns> Specify at what backend load the servers will reach their maxconn backend dynamic fullconn 10000 server srv1 dyn1:80 minconn 100 maxconn 1000 server srv2 dyn2:80 minconn 100 maxconn 1000 - **[grace](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-grace)** `<time>` Maintain a proxy operational for some time after a soft stop - **[hash-balance-factor](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-hash-balance-factor)** `<factor>` Specify the balancing factor for bounded-load consistent hashing - **[hash-type](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-hash-type)** <method> `<function> <modifier>` Specify a method to use for mapping hashes to servers ### HTTP check - **[http-check disable-on-404](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20disable-on-404)** Enable a maintenance mode upon HTTP/404 response to health-checks - **[http-check expect](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20expect)** [!] `<match> <pattern>` Make HTTP health checks consider response contents or specific status codes","title":"block if invalid_src || local_dst"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#only_accept_status_200_as_valid","text":"http-check expect status 200","title":"only accept status 200 as valid"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#consider_sql_errors_as_errors","text":"http-check expect ! string SQL\\ Error","title":"consider SQL errors as errors"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#consider_status_5xx_only_as_errors","text":"http-check expect ! rstatus ^5","title":"consider status 5xx only as errors"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#check_that_we_have_a_correct_hexadecimal_tag_before_html","text":"http-check expect rstring - **[http-check send-state](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-check%20send-state)** Enable emission of a state header with HTTP health checks - **[http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-request)**` <action> [options...]` [ { if | unless } <condition> ] Access control for Layer 7 requests acl nagios src 192.168.129.3 acl local_net src 192.168.0.0/16 acl auth_ok http_auth(L1) http-request allow if nagios http-request allow if local_net auth_ok http-request auth realm Gimme if local_net auth_ok http-request deny - **[http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-response%20add-acl)** More ........... : https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4-http-request - **[http-reuse](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-reuse)** { never | safe | aggressive | always } Declare how idle HTTP connections may be shared between requests - **[http-send-name-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-http-send-name-header)** [<header>] Add the server name to a request. Use the header string given by <header> - **[id](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-id)** <value> Set a persistent ID to a proxy. - **[ignore-persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-ignore-persist)** { if | unless } <condition> Declare a condition to ignore persistence acl url_static path_beg /static /images /img /css acl url_static path_end .gif .png .jpg .css .js ignore-persist if url_static - **[load-server-state-from-file](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-load-server-state-from-file)** { global | local | none } Allow seamless reload of HAProxy - **[log global](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-log%20global)** - **[log](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-log)** <address> [len <length>] [format <format>] <facility> [<level> [<minlevel>]] - **[no log](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20log)** Enable per-instance logging of events and traffic. - **[max-keep-alive-queue](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-max-keep-alive-queue)** <value> Set the maximum server queue size for maintaining keep-alive connections - **[max-session-srv-conns](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-max-session-srv-conns)** <nb> Set the maximum number of outgoing connections we can keep idling for a given client session. The default is 5 (it precisely equals MAX_SRV_LIST which is defined at build time). - **[mode](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-mode)** { tcp|http|health } Set the running mode or protocol of the instance defaults http_instances mode http - **[monitor fail](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-monitor%20fail)** { if | unless } `<condition>` Add a condition to report a failure to a monitor HTTP request. frontend www mode http acl site_dead nbsrv(dynamic) lt 2 acl site_dead nbsrv(static) lt 2 monitor-uri /site_alive monitor fail if site_dead ### OPTION Cheat sheet Haproxy - **[option abortonclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20abortonclose)** **[no option abortonclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20abortonclose)** Enable or disable early dropping of aborted requests pending in queues. - **[option accept-invalid-http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20accept-invalid-http-request)** **[no option accept-invalid-http-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20accept-invalid-http-request)** Enable or disable relaxing of HTTP request parsing - **[option accept-invalid-http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20accept-invalid-http-response)** **[no option accept-invalid-http-response](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20accept-invalid-http-response)** Enable or disable relaxing of HTTP response parsing - **[option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20allbackups)** **[no option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20allbackups)** Use either all backup servers at a time or only the first one By default, the first operational backup server gets all traffic when normal servers are all down. Sometimes, it may be preferred to use multiple backups at once, because one will not be enough. When \"[option allbackups](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20allbackups)\" is enabled, the load balancing will be performed among all backup servers when all normal ones are unavailable. The same load balancing algorithm will be used and the servers' weights will be respected. Thus, there will not be any priority order between the backup servers anymore. - **[option checkcache](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20checkcache)** **[no option checkcache](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20checkcache)** Analyze all server responses and block responses with cacheable cookies - **[option clitcpka](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20clitcpka)** **[no option clitcpka](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20clitcpka)** Enable or disable the sending of TCP keepalive packets on the client side - **[option contstats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20contstats)** Enable continuous traffic statistics updates - **[option dontlog-normal](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20dontlog-normal)** **[no option dontlog-normal](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20dontlog-normal)** Enable or disable logging of normal, successful connections - **[option dontlognull](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20dontlognull)** **[no option dontlognull](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20dontlognull)** Enable or disable logging of null connections. In certain environments, there are components which will regularly connect to various systems to ensure that they are still alive. It can be the case from another load balancer as well as from monitoring systems. By - **[option forwardfor](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20forwardfor)** [ `except <network> ] [ header <name> ] [ if-none ]` Enable insertion of the X-Forwarded-For header to requests sent to servers. Since HAProxy works in reverse-proxy mode, the servers see its IP address as their client address. This is sometimes annoying when the client's IP address is expected in server logs. To solve this problem, the well-known HTTP header \"X-Forwarded-For\" may be added by HAProxy to all requests sent to the server. This header contains a value representing the client's IP address. Since this header is always appended at the end of the existing header list, the server must be configured to always use the last occurrence of this header only. See the server's manual to find how to enable use of this standard header. Note that only the last occurrence of the header must be used, since it is really possible that the client has already brought one.","title":"check that we have a correct hexadecimal tag before /html"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#public_http_address_also_used_by_stunnel_on_the_same_machine","text":"frontend www mode http option forwardfor except 127.0.0.1 # stunnel already adds the header","title":"Public HTTP address also used by stunnel on the same machine"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#those_servers_want_the_ip_address_in_x-client","text":"backend www mode http option forwardfor header X-Client - **[option http-buffer-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-buffer-request)** **[no option http-buffer-request](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-buffer-request)** Enable or disable waiting for whole HTTP request body before proceeding ( not useful ) - **[option http-ignore-probes](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-ignore-probes)** **[no option http-ignore-probes](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-ignore-probes)** Enable or disable logging of null connections and request timeouts - **[option http-keep-alive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-keep-alive)** **[no option http-keep-alive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-keep-alive)** Enable or disable HTTP keep-alive from client to server. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". This option allows to set back the keep-alive mode, which can be useful when another mode was used in a defaults section. - **[option http-no-delay](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-no-delay)** **[no option http-no-delay](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-no-delay)** Instruct the system to favor low interactive delays over performance in HTTP - **[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-server-close)** **[no option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-server-close)** Enable or disable HTTP connection closing on the server side. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". Setting \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\" enables HTTP connection-close mode on the server side while keeping the ability to support HTTP keep-alive and pipelining on the client side. This provides the lowest latency on the client side (slow network) and the fastest session reuse on the server side to save server resources, similarly to \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\". It also permits non-keepalive capable servers to be served in keep-alive mode to the clients if they conform to the requirements of RFC7230. Please note that some servers do not always conform to those requirements when they see \"Connection: close\" in the request. The effect will be that keep-alive will never be used. A workaround consists in enabling \"[option http-pretend-keepalive](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-pretend-keepalive)\". - **[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-tunnel)** **[no option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-tunnel)** Disable or enable HTTP connection processing after first transaction. By default HAProxy operates in keep-alive mode with regards to persistent connections: for each connection it processes each request and response, and leaves the connection idle on both sides between the end of a response and the start of a new request. This mode may be changed by several options such as \"[option http-server-close](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-server-close)\", \"[option httpclose](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20httpclose)\" or \"[option http-tunnel](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http-tunnel)\". - **[option http-use-proxy-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-use-proxy-header)** **[no option http-use-proxy-header](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-use-proxy-header)** Make use of non-standard Proxy-Connection header instead of Connection. - **[option http-use-htx](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http-use-htx)** **[no option http-use-htx](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http-use-htx)** Switch to the new HTX internal representation for HTTP protocol elements - **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <uri> **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <method> <uri> **[option httpchk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httpchk)** <method> <uri> <version> Enable HTTP protocol to check on the servers health backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\\r\\nHost:\\ www server apache1 192.168.1.1:443 check port 80 - **[option httplog](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20httplog)** [ clf ] Enable logging of HTTP request, session state and timers - **[option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20http_proxy)** **[no option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20http_proxy)** Enable or disable plain HTTP proxy mode. It sometimes happens that people need a pure HTTP proxy which understands basic proxy requests without caching nor any fancy feature. In this case, it may be worth setting up an HAProxy instance with the \"[option http_proxy](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20http_proxy)\" set. In this mode, no server is declared, and the connection is forwarded to the IP address and port found in the URL after the \"http://\" scheme. - **[option independent-streams](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20independent-streams)** **[no option independent-streams](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20independent-streams)** Enable or disable independent timeout processing for both directions. By default, when data is sent over a socket, both the write timeout and the read timeout for that socket are refreshed, because we consider that there is activity on that socket, and we have no other means of guessing if we should receive data or not. - **[option ldap-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20ldap-check)** Use LDAPv3 health checks for server testing - **[option log-health-checks](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20log-health-checks)** **[no option log-health-checks](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20log-health-checks)** Enable or disable logging of health checks status updates - **[option log-separate-errors](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20log-separate-errors)** **[no option log-separate-errors](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20log-separate-errors)** Change log level for non-completely successful connections - **[option logasap](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20logasap)** **[no option logasap](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20logasap)** Enable or disable early logging of HTTP requests - **[option mysql-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20mysql-check)** [ user <username> [ post-41 ] ] Use MySQL health checks for server testing - **[option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20persist)** **[no option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20persist)** Enable or disable forced persistence on down servers. When an HTTP request reaches a backend with a cookie which references a dead server, by default it is redispatched to another server. It is possible to force the request to be sent to the dead server first using \"[option persist](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20persist)\" if absolutely needed. A common use case is when servers are under extreme load and spend their time flapping. In this case, the users would still be directed to the server they opened the session on, in the hope they would be correctly served. It is recommended to use \"[option redispatch](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20redispatch)\" in conjunction with this option so that in the event it would not be possible to connect to the server at all (server definitely dead), the client would finally be redirected to another valid server. - **[option socket-stats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20socket-stats)** **[no option socket-stats](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-no%20option%20socket-stats)** Enable or disable collecting & providing separate statistics for each socket. - **[option ssl-hello-chk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20ssl-hello-chk)** Use SSLv3 client hello health checks for server testing.When some SSL-based protocols are relayed in TCP mode through HAProxy, it is possible to test that the server correctly talks SSL instead of just testing that it accepts the TCP connection. When \"[option ssl-hello-chk](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20ssl-hello-chk)\" is set, pure SSLv3 client hello messages are sent once the connection is established to the server, and the response is analyzed to find an SSL server hello message. The server is considered valid only when the response contains this server hello message. - **[option tcp-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4.2-option%20tcp-check)** Perform health checks using tcp-check send/expect sequences. This health check method is intended to be combined with \"[tcp-check](https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#option%20tcp-check)\" command lists in order to support send/expect types of health check sequences.","title":"Those servers want the IP Address in X-Client"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#perform_a_pop_check_analyze_only_servers_banner","text":"option tcp-check tcp-check expect string +OK\\ POP3\\ ready comment POP\\ protocol","title":"perform a POP check (analyze only server's banner)"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#perform_an_imap_check_analyze_only_servers_banner","text":"option tcp-check tcp-check expect string *\\ OK\\ IMAP4\\ ready comment IMAP\\ protocol","title":"perform an IMAP check (analyze only server's banner)"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#look_for_the_redis_master_server_after_ensuring_it_speaks_well","text":"","title":"look for the redis master server after ensuring it speaks well"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#redis_protocol_then_it_exits_properly","text":"","title":"redis protocol, then it exits properly."},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#send_a_command_then_analyze_the_response_3_times","text":"option tcp-check tcp-check comment PING\\ phase tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check comment role\\ check tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check comment QUIT\\ phase tcp-check send QUIT\\r\\n tcp-check expect string +OK forge a HTTP request, then analyze the response (send many headers before analyzing) option tcp-check tcp-check comment forge\\ and\\ send\\ HTTP\\ request tcp-check send HEAD\\ /\\ HTTP/1.1\\r\\n tcp-check send Host:\\ www.mydomain.com\\r\\n tcp-check send User-Agent:\\ HAProxy\\ tcpcheck\\r\\n tcp-check send \\r\\n tcp-check expect rstring HTTP/1..\\ (2..|3..) comment check\\ HTTP\\ response ``` option tcpka Enable or disable the sending of TCP keepalive packets on both sides option tcplog Enable advanced logging of TCP connections with session state and timers timeout server timeout srvtimeout (deprecated) Set the maximum inactivity time on the server side. timeout queue Set the maximum time to wait in the queue for a connection slot to be free timeout http-request Set the maximum allowed time to wait for a complete HTTP request timeout http-keep-alive Set the maximum allowed time to wait for a new HTTP request to appear timeout client timeout clitimeout (deprecated) Set the maximum inactivity time on the client side.","title":"(send a command then analyze the response 3 times)"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/4. HAProxy-HTTP&Config/#dang_update","text":"","title":"dang update"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/","text":"HAproxy ACL ( Access Control List ) \u00b6 1. C\u01a1 b\u1ea3n v\u1ec1 ACL \u00b6 Access Control List trong HAproxy cho ph\u00e9p ki\u1ec3m tra tr\u00ean nhi\u1ec1u \u0111i\u1ec1u ki\u1ec7n c\u00e1c nhau v\u00e0 th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 task d\u1ef1a tr\u00ean c\u00e1c b\u00e0i test n\u00e0y. Nh\u1eefng \u0111i\u1ec1u ki\u1ec7n n\u00e0y c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c content m\u1ed9t request ho\u1eb7c response d\u1ef1a vi\u1ec7c t\u00ecm ki\u1ebfm string v\u00e0 patterns. , ki\u1ec3m tra IP, TLS status , c\u00e1c status code c\u00f3 trong m\u00f4i tr\u01b0\u1eddng C\u1ea5u tr\u00fac m\u1ed9t ACL trong HAproxy acl <aclname> <criterion> [flags] [operator] [<value>] ... Trong ACL , c\u00e1c criterion c\u00f3 th\u1ec3 l\u00e0 c\u00e1c fetch, ho\u1eb7c m\u1ed9t ACL kh\u00e1c, 2. Kh\u1edfi t\u1ea1o ACL \u00b6 2.1. C\u00e1c ki\u1ec3u ACL \u00b6 C\u00f3 2 ki\u1ec3u \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t ACL : named ACL v\u00e0 in-line ACL - Ki\u1ec3u 1 : Named acl is_static path -i -m beg /static V\u1edbi ACL tr\u00ean ta s\u1ebd c\u00f3 t\u00ean : is_static . ACL n\u00e0y c\u00f3 th\u1ec3 g\u1ecdi qua tr\u00ean khi s\u1eed d\u1ee5ng if ho\u1eb7c unless condition acl is_static path -i -m beg /static use_backend be_static if is_static Ki\u1ec3u 2 : anonymouse ho\u1eb7c in-line ACL use_backend be_static if { path -i -m beg /static 2.2 : M\u1ed9t s\u1ed1 ACL c\u01a1 b\u1ea3n \u00b6 V\u1edbi c\u1ea3 2 ki\u1ec3u tr\u00ean \u0111\u1ec1u th\u1ef1c hi\u1ec7n chung m\u1ed9t m\u1ee5c \u0111\u00edch, Nh\u01b0ng ch\u1ec9 s\u1eed d\u1ee5ng m\u1ed9t condtion, ta c\u00f3 th\u1ec3 k\u1ebft h\u1ee3p c\u00e1c condtion l\u1ea1i v\u1edbi nhau , condtion t\u1ed5ng th\u1ec3 ch\u1ec9 tr\u1ea3 v\u1ec1 True n\u1ebfu c\u00e1c ACL tr\u1ea3 v\u1ec1 True http-request deny if { path -i -m beg /api } { src 10.0.0.0/16 } V\u1edbi v\u00ed d\u1ee5 tr\u00ean s\u1ebd ch\u1eb7n c\u00e1c HTTP-request t\u1eeb subnet 10.0.0.0/16 \u0111\u1ebfn path b\u1eaft \u0111\u1ea7u b\u1eb1ng /api , c\u00e1c path c\u00f2n l\u1ea1i truy c\u1eadp b\u00ecnh th\u01b0\u1eddng C\u00f3 th\u1ec3 s\u1eed d\u1ee5ng || gi\u1eefa c\u00e1c conditon, \u0111\u1ec3 ki\u1ec3m tra 1 trong 2 condition c\u00f3 th\u1ec3 d\u00fang http-request deny if { path -i -m beg /evil } || { path -i -m end /evil } V\u1edbi tr\u01b0\u1eddng h\u1ee3p tr\u00ean s\u1ebd ch\u1eb7n c\u00e1c request t\u1edbipath \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u /evil ho\u1eb7c k\u1ebft th\u00fac b\u1eb1ng /evil . Thay v\u00ec s\u1eed d\u1ee5ng in-line ACl ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng named ACL acl starts_evil path -i -m beg /evil acl ends_evil path -i -m end /evil http-request deny if starts_evil || ends_evil V\u1edbi c\u00e1c named ACL , khi c\u00e1c ACL tr\u00f9ng t\u00ean \u0111\u01b0\u1ee3c g\u1ecdi \u0111\u1ebfn c\u00e1c condtion s\u1ebd \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 to\u00e1n OR acl evil path_beg /evil acl evil path_end /evil http-request deny if evi C\u00f3 th\u1ec3 k\u1ebft h\u1ee3p NOR trong c\u00e1c condtion http-request deny if evil !{ src 10.0.0.0/16 } 3. Fetch \u00b6 Theo c\u00e1c v\u00ed d\u1ee5 tr\u00ean , path \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 ngu\u1ed3n s\u1ebd \u0111\u01b0\u1ee3c l\u1ea5y th\u00f4ng tin cho c\u00e1c condtion . Source information trong HAproxy \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 fetch. C\u00f3 th\u1ec3 xem \u0111\u1ea7y \u0111\u1ee7 c\u00e1c fetch t\u1ea1i \u0111\u00e2y : https://www.haproxy.com/documentation/hapee/1-8r1/onepage/#7.3.2 D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 fetch th\u01b0\u1eddng s\u1eed d\u1ee5ng src : tr\u1ea3 v\u1ec1 IP c\u1ee7a c\u00e1c client path : tr\u1ea3 v\u1ec1 PATH c\u1ee7a c\u00e1c request t\u1eeb client url_param(foo) : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t URL req.hdr(foo) : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t HTTP header ssl_fc : M\u1ed9t boolean tr\u1ea3 v\u1ec1 true n\u1ebfu k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c t\u1ea1o qua SSL 4 Converters \u00b6 Ta c\u00f3 th\u1ec3 chuy\u1ec3n c\u00e1c content t\u1eeb fetch th\u00e0nh nhi\u1ec1u d\u1ea1ng hi\u1ec3n th\u1ecb kh\u00e1c : lower : thay \u0111\u1ed5i th\u00e0nh ch\u1eef th\u01b0\u1eddng upper : thay \u0111\u1ed5i th\u00e0nh ch\u1eef in hoa bas64 : s\u1eed d\u1ee5ng \u0111\u1ec3 encode feild : s\u1eed d\u1ee5ng nh\u01b0 awk, n\u1ebfu c\u00f3 3 tr\u01b0\u1eddng \u201ca|b|c\u201d, ta c\u00f3 get \u0111\u01b0\u1ee3c tr\u01b0\u1eddng c v\u1edbi field(|,3) byte : s\u1eed d\u1ee5ng \u0111\u1ec3 get m\u1ed9t s\u1ed1 byte More : https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#7.3.1 5. Flags \u00b6 Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p, c\u00e1c ACL c\u1ea7n \u0111\u01b0\u1ee3c t\u00f9y bi\u1ebfn \u0111\u1ec3 ki\u1ec3m so\u00e1t c\u00e1c request \u0111\u1ebfn path d\u1ef1a v\u00e0o \u0111\u01b0\u1eddng d\u1eabn b\u1eaft \u0111\u1ea7u ho\u1eb7c k\u1ebft th\u00fac ho\u1eb7c kh\u00f4ng bi\u1ec7t ch\u1eef hoa , th\u01b0\u1eddng. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 flags -i : kh\u00f4ng ph\u00e2n bi\u1ec7t hoa, th\u01b0\u1eddng -f : s\u1eed d\u1ee5ng c\u00e1c input t\u1eeb file. -m : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t matching type 6. Matching Type \u00b6 D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 matching type th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng str : m\u1ed9t chu\u1ed7i \u0111\u1ea7y \u0111\u1ee7 beg : m\u1ed9t chu\u1ed7i \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u b\u1eaft m\u1ed9t pattern end : m\u1ed9t chu\u1ed7i \u0111\u01b0\u1ee3c k\u1ebft th\u00fac b\u1eb1ng m\u1ed9t pattern sub : m\u1ed9t chu\u1ed7i c\u00f3 ch\u01b0a pattern len : \u0111\u1ed9 d\u00e0i c\u1ee7a chu\u1ed7i End.","title":"5.  HAproxy ACL"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#haproxy_acl_access_control_list","text":"","title":"HAproxy ACL ( Access Control List )"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#1_co_ban_ve_acl","text":"Access Control List trong HAproxy cho ph\u00e9p ki\u1ec3m tra tr\u00ean nhi\u1ec1u \u0111i\u1ec1u ki\u1ec7n c\u00e1c nhau v\u00e0 th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 task d\u1ef1a tr\u00ean c\u00e1c b\u00e0i test n\u00e0y. Nh\u1eefng \u0111i\u1ec1u ki\u1ec7n n\u00e0y c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c content m\u1ed9t request ho\u1eb7c response d\u1ef1a vi\u1ec7c t\u00ecm ki\u1ebfm string v\u00e0 patterns. , ki\u1ec3m tra IP, TLS status , c\u00e1c status code c\u00f3 trong m\u00f4i tr\u01b0\u1eddng C\u1ea5u tr\u00fac m\u1ed9t ACL trong HAproxy acl <aclname> <criterion> [flags] [operator] [<value>] ... Trong ACL , c\u00e1c criterion c\u00f3 th\u1ec3 l\u00e0 c\u00e1c fetch, ho\u1eb7c m\u1ed9t ACL kh\u00e1c,","title":"1. C\u01a1 b\u1ea3n v\u1ec1 ACL"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#2_khoi_tao_acl","text":"","title":"2. Kh\u1edfi t\u1ea1o ACL"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#21_cac_kieu_acl","text":"C\u00f3 2 ki\u1ec3u \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t ACL : named ACL v\u00e0 in-line ACL - Ki\u1ec3u 1 : Named acl is_static path -i -m beg /static V\u1edbi ACL tr\u00ean ta s\u1ebd c\u00f3 t\u00ean : is_static . ACL n\u00e0y c\u00f3 th\u1ec3 g\u1ecdi qua tr\u00ean khi s\u1eed d\u1ee5ng if ho\u1eb7c unless condition acl is_static path -i -m beg /static use_backend be_static if is_static Ki\u1ec3u 2 : anonymouse ho\u1eb7c in-line ACL use_backend be_static if { path -i -m beg /static","title":"2.1. C\u00e1c ki\u1ec3u ACL"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#22_mot_so_acl_co_ban","text":"V\u1edbi c\u1ea3 2 ki\u1ec3u tr\u00ean \u0111\u1ec1u th\u1ef1c hi\u1ec7n chung m\u1ed9t m\u1ee5c \u0111\u00edch, Nh\u01b0ng ch\u1ec9 s\u1eed d\u1ee5ng m\u1ed9t condtion, ta c\u00f3 th\u1ec3 k\u1ebft h\u1ee3p c\u00e1c condtion l\u1ea1i v\u1edbi nhau , condtion t\u1ed5ng th\u1ec3 ch\u1ec9 tr\u1ea3 v\u1ec1 True n\u1ebfu c\u00e1c ACL tr\u1ea3 v\u1ec1 True http-request deny if { path -i -m beg /api } { src 10.0.0.0/16 } V\u1edbi v\u00ed d\u1ee5 tr\u00ean s\u1ebd ch\u1eb7n c\u00e1c HTTP-request t\u1eeb subnet 10.0.0.0/16 \u0111\u1ebfn path b\u1eaft \u0111\u1ea7u b\u1eb1ng /api , c\u00e1c path c\u00f2n l\u1ea1i truy c\u1eadp b\u00ecnh th\u01b0\u1eddng C\u00f3 th\u1ec3 s\u1eed d\u1ee5ng || gi\u1eefa c\u00e1c conditon, \u0111\u1ec3 ki\u1ec3m tra 1 trong 2 condition c\u00f3 th\u1ec3 d\u00fang http-request deny if { path -i -m beg /evil } || { path -i -m end /evil } V\u1edbi tr\u01b0\u1eddng h\u1ee3p tr\u00ean s\u1ebd ch\u1eb7n c\u00e1c request t\u1edbipath \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u /evil ho\u1eb7c k\u1ebft th\u00fac b\u1eb1ng /evil . Thay v\u00ec s\u1eed d\u1ee5ng in-line ACl ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng named ACL acl starts_evil path -i -m beg /evil acl ends_evil path -i -m end /evil http-request deny if starts_evil || ends_evil V\u1edbi c\u00e1c named ACL , khi c\u00e1c ACL tr\u00f9ng t\u00ean \u0111\u01b0\u1ee3c g\u1ecdi \u0111\u1ebfn c\u00e1c condtion s\u1ebd \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 to\u00e1n OR acl evil path_beg /evil acl evil path_end /evil http-request deny if evi C\u00f3 th\u1ec3 k\u1ebft h\u1ee3p NOR trong c\u00e1c condtion http-request deny if evil !{ src 10.0.0.0/16 }","title":"2.2 : M\u1ed9t s\u1ed1 ACL c\u01a1 b\u1ea3n"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#3_fetch","text":"Theo c\u00e1c v\u00ed d\u1ee5 tr\u00ean , path \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 ngu\u1ed3n s\u1ebd \u0111\u01b0\u1ee3c l\u1ea5y th\u00f4ng tin cho c\u00e1c condtion . Source information trong HAproxy \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 fetch. C\u00f3 th\u1ec3 xem \u0111\u1ea7y \u0111\u1ee7 c\u00e1c fetch t\u1ea1i \u0111\u00e2y : https://www.haproxy.com/documentation/hapee/1-8r1/onepage/#7.3.2 D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 fetch th\u01b0\u1eddng s\u1eed d\u1ee5ng src : tr\u1ea3 v\u1ec1 IP c\u1ee7a c\u00e1c client path : tr\u1ea3 v\u1ec1 PATH c\u1ee7a c\u00e1c request t\u1eeb client url_param(foo) : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t URL req.hdr(foo) : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t HTTP header ssl_fc : M\u1ed9t boolean tr\u1ea3 v\u1ec1 true n\u1ebfu k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c t\u1ea1o qua SSL","title":"3. Fetch"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#4_converters","text":"Ta c\u00f3 th\u1ec3 chuy\u1ec3n c\u00e1c content t\u1eeb fetch th\u00e0nh nhi\u1ec1u d\u1ea1ng hi\u1ec3n th\u1ecb kh\u00e1c : lower : thay \u0111\u1ed5i th\u00e0nh ch\u1eef th\u01b0\u1eddng upper : thay \u0111\u1ed5i th\u00e0nh ch\u1eef in hoa bas64 : s\u1eed d\u1ee5ng \u0111\u1ec3 encode feild : s\u1eed d\u1ee5ng nh\u01b0 awk, n\u1ebfu c\u00f3 3 tr\u01b0\u1eddng \u201ca|b|c\u201d, ta c\u00f3 get \u0111\u01b0\u1ee3c tr\u01b0\u1eddng c v\u1edbi field(|,3) byte : s\u1eed d\u1ee5ng \u0111\u1ec3 get m\u1ed9t s\u1ed1 byte More : https://cbonte.github.io/haproxy-dconv/2.0/configuration.html#7.3.1","title":"4 Converters"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#5_flags","text":"Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p, c\u00e1c ACL c\u1ea7n \u0111\u01b0\u1ee3c t\u00f9y bi\u1ebfn \u0111\u1ec3 ki\u1ec3m so\u00e1t c\u00e1c request \u0111\u1ebfn path d\u1ef1a v\u00e0o \u0111\u01b0\u1eddng d\u1eabn b\u1eaft \u0111\u1ea7u ho\u1eb7c k\u1ebft th\u00fac ho\u1eb7c kh\u00f4ng bi\u1ec7t ch\u1eef hoa , th\u01b0\u1eddng. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 flags -i : kh\u00f4ng ph\u00e2n bi\u1ec7t hoa, th\u01b0\u1eddng -f : s\u1eed d\u1ee5ng c\u00e1c input t\u1eeb file. -m : ch\u1ec9 \u0111\u1ecbnh m\u1ed9t matching type","title":"5. Flags"},{"location":"Openstack_Research/High-availability/1.HA-Proxy---KeepAlive/5.  HAproxy-ACL/#6_matching_type","text":"D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 matching type th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng str : m\u1ed9t chu\u1ed7i \u0111\u1ea7y \u0111\u1ee7 beg : m\u1ed9t chu\u1ed7i \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u b\u1eaft m\u1ed9t pattern end : m\u1ed9t chu\u1ed7i \u0111\u01b0\u1ee3c k\u1ebft th\u00fac b\u1eb1ng m\u1ed9t pattern sub : m\u1ed9t chu\u1ed7i c\u00f3 ch\u01b0a pattern len : \u0111\u1ed9 d\u00e0i c\u1ee7a chu\u1ed7i End.","title":"6. Matching Type"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/","text":"C\u00e0i \u0111\u1eb7t Octavia tr\u00ean Openstack \u00b6 1. Octavia - Load Balancing Solution For Openstack \u00b6 1.1 . M\u1edf \u0111\u1ea7u \u00b6 Octavia l\u00e0 project trong Openstack, \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m gi\u1ea3i ph\u00e1p c\u00e2n b\u1eb1ng t\u1ea3i trong Openstack. Octavia \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u t\u1eeb Neutron LBaas Project. Octavia cung c\u1ea5p d\u1ecbch v\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i b\u1eb1ng c\u00e1ch c\u00e1c m\u00e1y \u1ea3o qu\u1ea3n l\u00fd m\u00e1y \u1ea3o, container, bare metal server , \u0111\u01b0\u1ee3c g\u1ecdi chung l\u00e0 : amphorae . Octavia kh\u00e1c v\u1edbi kh\u00e1c v\u1edbi c\u00e1c gi\u1ea3i kh\u00e1c v\u00ec n\u00f3 sinh \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho m\u00f4i tr\u01b0\u1eddng cloud, t\u00f9y ch\u1ec9nh theo y\u00eau c\u1ea7u 1.2 : Octavia \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Openstack khi n\u00e0o \u00b6 C\u00e2n b\u1eb1ng t\u1ea3i ( load balancing ) l\u00e0 \u0111i\u1ec1u c\u1ea7n thi\u1ebft \u0111\u1ec3 \u0111\u1ec3 m\u1edf r\u1ed9ng quy m\u00f4 c\u00f3 th\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u1eb7c quy m\u00f4 l\u1edbn v\u00e0 t\u1ef1 \u0111\u1ed9ng. Octavia \u0111\u01b0\u1ee3c xem l\u00e0 project c\u1ea7n thi\u1ebft gi\u1ed1ng nh\u01b0 Nova, Neutron v\u00e0 c\u00e1c core project kh\u00e1c - \u0111i\u1ec1u c\u1ea7n thi\u1ebft \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t Openstack Cloud ecosystem \u0110\u1ec3 ho\u00e0n th\u00e0nh vai tr\u00f2 , Octavia c\u1ea7n l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c project kh\u00e1c : Nova : \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c t\u00e0i nguy\u00ean tr\u00ean c\u00e1c compute node theo nhu c\u1ea7u Neutron : cho c\u00e1c m\u1ea1ng tentant ( project ) v\u00e0 c\u00e1c m\u1ea1ng external Barbican : qu\u1ea3n l\u00fd TLS certificate v\u00e0 credential , v\u00e0 TLS Session Keystone : d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c Octavia API v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c project kh\u00e1c Glance : \u0111\u1ec3 l\u01b0u tr\u1eef c\u00e1c amphorae virtual image Olso : \u0111\u1ec3 giai ti\u1ebfp gi\u1eefa c\u00e1c Octavia compoment. Taskflow : Octavia \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n \u1edf tr\u00ean. V\u1edbi tr\u00ean tr\u1eebng project Octavia s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t driver interface \u0111\u1ec3 l\u00e0m vi\u1ec7c. K\u1ec3 t\u1eeb phi\u00ean b\u1ea3n Pike, Octavia \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m m\u1ed9t gi\u1ea3i ph\u00e1p c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ed9c l\u1eadp. Neutron LBaas \u0111\u01b0\u1ee3c x\u00f3a b\u1ecf t\u1ea1i phi\u00ean b\u1ea3n Queens, Octavia s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng thay th\u1ebf. 1.3 . Th\u00e0nh ph\u1ea7n trong Octavia \u00b6 Amphorea : l\u00e0 m\u1ed9t m\u00e1y \u1ea3o , container ho\u1eb7c server cung c\u1ea5p d\u1ecbch v\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i. N\u00eau l\u00e0 m\u00e1y \u1ea3o s\u1ebd ch\u1ea1y tr\u00ean c\u00e1c compute node, v\u1edbi c\u00e1c c\u1ea5u h\u00ecnh \u0111\u1ec3 c\u00f3 kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i nh\u01b0 listenner, pool, heath monitor, L7 Policies, ho\u1eb7c g\u1eedi heat beat v\u1ec1 Heah Manager Controller : \u0111\u01b0\u1ee3c xem l\u00e0 \"brain\" c\u1ee7a Octavia . C\u00f3 bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n con , v\u00e0 c\u00e1c ti\u1ebfn tr\u00ecnh daemon. N\u00f3 c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c c\u00e1c th\u00e0nh ph\u1ea7n con th\u00f4ng qua c\u00e1c drvier interface. API Controller : cung c\u1ea5p API interface, nh\u1eadn c\u00e1c request v\u00e0 g\u1eedi v\u1ec1 controller worker th\u00f4ng qua Olso message Controller worker : nh\u1eadn c\u00e1c l\u1ec7nh t\u1eeb API controller, sau \u0111\u00f3 th\u1ef1c hi\u1ec7n c\u00e1c y\u00eau \u0111\u1ea7u \u0111\u1ec1 \u0111\u1ec1 ra Heath Manager : cung c\u1ea5p kh\u1ea3 n\u0103ng heat beat t\u1edbi c\u00e1c amphorea, ki\u1ec3m tra tr\u1ea1ng th\u00e1i v\u00e0 cung c\u1ea5p kh\u0103ng failover cho c\u00e1c m\u00e1y \u1ea3o n\u00e0y Housekeeping Manager : cung c\u1ea5p kh\u1ea3 n\u0103ng scaleup ho\u1eb7c x\u00f3a d\u1eef li\u1ec7u v\u00e0 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a amphora certificate network : octavia kh\u00f4ng th\u1ec3 ho\u00e0n th\u00e0nh n\u1ebfu thi\u1ebfu network. C\u00e1c m\u00e1y \u1ea3o amphora \u0111\u01b0\u1ee3c g\u1eafn m\u1ed9t network interface t\u1eeb Load Balance network,ho\u1eb7c s\u1ebd l\u00e0 m\u1ed9t port tr\u00ean c\u00e1c tentant network. Pool : t\u1eadp h\u1ee3p c\u00e1c memeber l\u1eafng nghe request t\u1eeb load balancer . M\u1ed7i pool ch\u1ec9 \u0111\u01b0\u1ee3c li\u00ean k\u1ebft v\u1edbi m\u1ed9t listener. 2.2 : C\u00e1c thu\u1eadt ng\u1eef b\u1ed5 sung trong Octavia \u00b6 Fail-over l\u00e0 cho ph\u00e9p c\u00f4ng vi\u1ec7c th\u01b0\u1eddng ch\u1ec9 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 kh\u00e1c khi m\u1ed9t trong 2 m\u00e1y ch\u1ee7 x\u1ea3y ra s\u1ef1 c\u1ed1. Amphora Load Balancer Driver : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi controlller \u0111\u1ec3 giao ti\u1ebfp v\u1edbi amphorae. Anchor : l\u00e0 m\u1ed9t projec trong Openstack cung c\u1ea5p c\u00e1c kh\u00f3a PKI ng\u1eafn h\u1ea1n. Octavia s\u1eed d\u1ee5ng cho vi\u1ec7c authen gi\u1eefa c\u00e1c compoment Apolocation : l\u00e0 c\u00e1c amphorae kh\u00f4ng \u0111\u01b0\u1ee3c \u0111\u1eb7t l\u00ean c\u00f9ng m\u1ed9t host v\u1eadt l\u00fd L7 Policy : c\u00e1c t\u1eadp policy cho qu\u00e1 tr\u00ecnh routing cho c\u00e1c Client L7 Rule : c\u00e1c t\u1eadp policy y\u00eau c\u1ea7u tr\u00f9ng kh\u1edbp v\u1edbi c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb Client LB Network : network \u0111\u01b0\u1ee3c controlller v\u00e0 amphorae giao ti\u1ebfp , kh\u00f4ng \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o m\u1ed9t project n\u00e0o Listener : l\u00e0 c\u00e1c giao th\u1ee9c ho\u1eb7c c\u1ed5ng ( kh\u00f4ng c\u00f3 IP ) s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i VIP : Virtual IP Address : \u0111\u1ecba ch\u1ec9 IP t\u0129nh \u0111\u01b0\u1ee3c g\u1eafn cho qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i. Gi\u1ed1ng nh\u01b0 c\u00e1c giao th\u1ee9c CARP, VRRP, or HSRP s\u1ebd c\u00f3 IP ri\u00eang cho qu\u00e1 tr\u00ecnh \u0111\u1ecbnh tuy\u1ebfn . Trong otavia , VIP s\u1ebd \u0111\u01b0\u1ee3c v\u00e0o v\u00e0o m\u1ed9t network device \u0111\u1ecbnh tuy\u1ebfn packet \u0111\u1ebfn c\u00e1c m\u00e1y \u1ea3o c\u00e2n b\u1eb1ng t\u1ea3i v\u00e0 load cho c\u00e1c m\u00e1y \u1ea3o backend 2.2 : C\u00e1c mode tri\u1ec3n khai trong Octavia \u00b6 Trong Octavia hi\u1ec7n t\u1ea1i v\u1edbi b\u1ea3n Queens \u0111ang g\u1ed3m 2 mode : SINGEL v\u00e0 ACTIVE_BACKUP \u0110\u1ed1i v\u1edbi SINGEL : cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i , kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng Failover co cho c\u00e1c Load Blancer \u0110\u1ed1i v\u1edbi ACTIVE_STANDBY : cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i , c\u00f3 kh\u1ea3 n\u0103ng Failover chLoad Blancer 3. C\u00e0i \u0111\u1eb7t Octavia m\u00f4 h\u00ecnh SINGLE \u00b6 C\u01a1 s\u1edf \u0111\u1ec3 c\u1ea5u h\u00ecnh : All API calls described throughout the rest of this document require authentication with the OpenStack Identity service . After authentication, the base endpoint URL for the service type of load-balancer and service name of octavia can be extracted from the service catalog returned with the identity token. https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html URL : https://developer.openstack.org/api-ref/load-balancer/v2/index.html Y\u00eau c\u1ea7u : \u0110\u00e3 c\u00e0i \u0111\u1eb7t c\u00e1c project : Keystone, Glance, Neutron ( bao g\u1ed3m L3 Agent ) , Nova, Barbican 3.1. C\u00e0i \u0111\u1eb7t package \u00b6 Do c\u1ea7n s\u1eed d\u1ee5ng m\u1ed9t s\u1ed1 th\u01b0 vi\u1ec7c n\u00ean c\u1ea7n clone project c\u1ee7a octavia git clone https://github.com/openstack/octavia.git /root/octavia -b stable/queens Kh\u1edfi t\u1ea1o Certificate Authorities s\u1eed d\u1ee5ng \u0111\u1ec3 m\u00e3 h\u00f3a khi li\u00ean h\u1ec7 gi\u1eefa th\u00e0nh ph\u1ea7n. L\u01b0u \u00fd \u0111\u00e3 b\u1eadt service Barbican bash /root/octavia/bin/create_certificates.sh /etc/octavia/certs/ /root/octavia/etc/certificates/openssl.cnf C\u00e0i \u0111\u1eb7t package ( ki\u1ec3m tra k\u1ef9 tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t, c\u00f3 th\u1ec3 g\u00e2y xung \u0111\u1ed9t v\u1edbi c\u00e1c project kh\u00e1c ) wget https://pypi.python.org/packages/5e/5d/4e4364bb8b2a3e8d6c41ec21095aae3ac3396a6fa6983ea7f5551e929661/pyasn1-0.4.2-py2.4.egg#md5=84cf09817d8eb3b8955c5c558abd7ba7 easy_install pyasn1-0.4.2-py2.4.egg pip install pyasn1-modules==0.2.2 pip install Jinja2==2.10 pip install pyOpenSSL==17.1.0 yum install -y python-octavia openstack-octavia-common openstack-octavia-diskimage-create openstack-octavia-health-manager openstack-octavia-housekeeping openstack-octavia-ui openstack-octavia-worker openstack-octavia-amphora-agent python2-octaviaclient openstack-octavia-api Kh\u1edfi t\u1ea1o Database cho Octavia mysql -u root --password=hung <<EOF CREATE DATABASE octavia; GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'localhost' \\ IDENTIFIED BY 'octavia_123'; GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'%' \\ IDENTIFIED BY 'octavia_123'; EOF 3.2 . Kh\u1edfi t\u1ea1o User, Service ( s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin ) \u00b6 Kh\u1edfi t\u1ea1o User v\u00e0 ph\u00e2n quy\u1ec1n source admin-openrc openstack user create --domain default --password octavia_123 octavia openstack role add --project service --user octavia admin openstack service create load-balancer --name octavia Kh\u1edfi t\u1ea1o Endpoint openstack endpoint create octavia public http://controller:9876 --region RegionOne openstack endpoint create octavia admin http://controller:9876 --region RegionOne openstack endpoint create octavia internal http://controller:9876 --region RegionOne Kh\u1edfi t\u1ea1o network v\u00e0 subnet VIP openstack network create --external --default --share --provider-physical-network provider --provider-network-type flat provider openstack subnet create --subnet-range 192.168.30.0/24 --dhcp --allocation-pool start=192.168.30.140,end=192.168.30.160 --dns-nameserver 1.1.1.1 --gateway=192.168.30.1 --network provider provider-net-30 Kh\u1edfi t\u1ea1o file rc \u0111\u1ec3 \u0111\u0103ng nh\u1eadp v\u00e0o user octavia , s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o c\u00e1c Security group, Flavor, Key pair cat <<EOF > octovia-openrc export OS_PROJECT_DOMAIN_NAME=Default export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_NAME=service export OS_USERNAME=octavia export OS_PASSWORD=octavia_123 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 EOF 3.2 . Kh\u1edfi t\u1ea1o Network, Security Group ( th\u1ef1c hi\u1ec7n tr\u00ean Octavia User ) \u00b6 C\u00e1c kh\u1edfi t\u1ea1o d\u01b0\u1edbi \u0111\u00e2y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho section controller_worker trong t\u1eadp tin c\u1ea5u h\u00ecnh /etc/octavia/octavia.conf \u00b6 \u0110\u0103ng nh\u1eadp v\u00e0o user octovia source octovia-openrc Kh\u1edfi t\u1ea1o Security Group v\u00e0 Rule cho LB Network . \u0110\u00e2y l\u00e0 m\u1ea1ng li\u00ean h\u1ec7 gi\u1eefa Controller v\u00e0 c\u00e1c VM Load Balancer. B\u1ea3n th\u00e2n m\u1ea1ng LB th\u01b0\u1eddng s\u1ebd l\u00e0 d\u00f9ng cho c\u00e1c controller v\u00e0 VM li\u00ean h\u1ec7 v\u1edbi nova v\u00e0 neutron. nh\u01b0ng kh\u00f4ng \u0111\u01b0\u1ee3c li\u00ean k\u1ebft v\u1edbi b\u1ea5t k\u1ef3 m\u1ed9t tenan n\u00e0o ( ID tr\u1ea3 v\u1ec1 : ce6fd5ce-de4c-43fe-927a-f2a1103a34bd ) openstack --os-region-name=RegionOne security group create lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol icmp lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol icmpv6 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp Kh\u1edfi t\u1ea1o Security group cho Health manager ( heatbeat t\u1edbi c\u00e1c VM Load Balanacer ) openstack --os-region-name=RegionOne security group create lb-health-mgr-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 --ethertype IPv6 --remote-ip ::/0 lb-health-mgr-sec-grp Kh\u1edfi t\u1ea1o LB Network ( ID tr\u1ea3 v\u1ec1 : 5cb04d80-c822-45dd-bd61-0d7fc1f2fcd0 ) neutron --os-region-name=RegionOne net-create lb-mgmt-net1 neutron --os-region-name=RegionOne subnet-create --name lb-mgmt-subnet1 lb-mgmt-net1 192.168.199.0/24 Kh\u1edfi t\u1ea1o port tr\u00ean neutron s\u1eed d\u1ee5ng Security Group lb-health-mgr-sec-grp , sau \u0111\u00f3 g\u1eafn v\u00e0o openvswitch cho Health Manager id_and_mac=$(neutron --os-region-name=RegionOne port-create --name octavia-health-manager-region-one-listen-port --security-group lb-health-mgr-sec-grp --device-owner Octavia:health-mgr --binding:host_id=$(hostname) lb-mgmt-net1 $PORT_FIXED_IP | awk '/ id | mac_address / {print $4}') id_and_mac=($id_and_mac) MGMT_PORT_ID=${id_and_mac[0]} MGMT_PORT_MAC=${id_and_mac[1]} MGMT_PORT_IP=$(openstack --os-region-name=RegionOne port show -f value -c fixed_ips $MGMT_PORT_ID | awk '{FS=\",| \"; gsub(\",\",\"\"); gsub(\"'\\''\",\"\"); for(i = 1; i <= NF; ++i) {if ($i ~ /^ip_address/) {n=index($i, \"=\"); if (substr($i, n+1) ~ \"\\\\.\") print substr($i, n+1)}}}') neutron --os-region-name=RegionOne port-update --binding:host_id=$(hostname) $MGMT_PORT_ID sudo ovs-vsctl -- --may-exist add-port ${OVS_BRIDGE:-br-int} o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$MGMT_PORT_MAC -- set Interface o-hm0 external-ids:iface-id=$MGMT_PORT_ID -- set Interface o-hm0 external-ids:skip_cleanup=true OCTAVIA_DHCLIENT_CONF=/etc/octavia/dhcp/dhclient.conf sudo ip link set dev o-hm0 address $MGMT_PORT_MAC sudo dhclient -v o-hm0 -cf $OCTAVIA_DHCLIENT_CONF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port 5555/udp --permanent firewall-cmd --reload Kh\u1edfi t\u1ea1o flavor cho Amphora ( ID Flavor tr\u1ea3 v\u1ec1 : 7c3a80ff-822e-4ace-bffb-54739c4a1108 ) openstack flavor create --disk 4 --ram 1024 --vcpus 1 --private --project service amphora_vm Kh\u1edfi t\u1ea1o v\u00e0 upload m\u1ed9t image m\u1edbi cho m\u00e1y \u1ea3o Amphora ( \u0111\u1ea3m nhi\u1ec7m l\u00e0 Load Balancer - ID tr\u1ea3 v\u1ec1 :6c7c0a18-fe65-4065-9a1e-4dc170f1659d, tag tr\u1ea3 v\u1ec1 : amphora ) octavia-diskimage-create.sh -r 123@123Aa -o ubuntu-ha openstack image create amphora-x64 --public --container-format bare --disk-format qcow2 --file /var/log/octavia/ubuntu-ha.qcow2 openstack image set amphora-x64 --tag amphora-x64 3.2. C\u1ea5u h\u00ecnh Neutron \u00b6 Tham kh\u1ea3o th\u00eam : https://docs.openstack.org/neutron/queens/admin/config-dns-int.html C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] dns_domain = 1.1.1.1 [octavia] base_url=http://127.0.0.1:9876 C\u1ea5u h\u00ecnh ML2 /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] extension_drivers = port_security,dns_domain_ports Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server 3.3. C\u1ea5u h\u00ecnh Octavia ho\u00e0n ch\u1ec9nh \u00b6 C\u1ea5u h\u00ecnh t\u1ea1i /etc/octavia/octavia.conf cat <<EOF> /etc/octavia/octavia.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller publish_errors = true debug = False use_syslog = True [api_settings] auth_strategy = keystone bind_host = 0.0.0.0 bind_port = 9876 api_v1_enabled = true api_v2_enabled = true [database] connection = mysql+pymysql://octavia:octavia_123@controller/octavia [health_manager] event_streamer_driver = noop_event_streamer heartbeat_key = insecure controller_ip_port_list = {IP at o-hm0 }:5555 bind_ip = {IP at o-hm0} bind_port = 5555 sync_provisioning_status = true [keystone_authtoken] www_authenticate_uri = http://controller:5000/v3 auth_url = http://controller:35357/v3 username = octavia password = octavia_123 project_name = service project_domain_name = Default user_domain_name = Default auth_type = password [certificates] cert_manager = barbican_cert_manager ca_certificate = /etc/octavia/certs/ca_01.pem ca_private_key = /etc/octavia/certs/private/cakey.pem ca_private_key_passphrase = foobar [anchor] [networking] [haproxy_amphora] bind_host = 0.0.0.0 bind_port = 9443 server_ca = /etc/octavia/certs/ca_01.pem client_cert = /etc/octavia/certs/client.pem base_path = /var/lib/octavia base_cert_dir = /var/lib/octavia/certs connection_max_retries = 1500 connection_retry_interval = 1 [controller_worker] workers = 1 amp_active_retries = 100 amp_active_wait_sec = 5 loadbalancer_topology = SINGLE amp_ssh_key_name = pair_LB amp_image_tag = amphora-x64 amp_secgroup_list = 985491e0-f399-4584-8f4a-4a3aa737714e amp_boot_network_list = 18a03d0a-8ad6-41e2-93ad-1abe8edce9b6 amp_flavor_id = 6c7c0a18-fe65-4065-9a1e-4dc170f1659d network_driver = allowed_address_pairs_driver compute_driver = compute_nova_driver amphora_driver = amphora_haproxy_rest_driver amp_image_id = 7e5d5455-178b-4830-87eb-8fc1f9aefe63 [task_flow] [oslo_messaging] rpc_thread_pool_size = 2 topic = octavia_prov [oslo_messaging_rabbit] rabbit_host = controller rabbit_userid = openstack rabbit_password = rabbitmq_123 [house_keeping] load_balancer_expiry_age = 3600 [amphora_agent] [keepalived_vrrp] [service_auth] project_domain_name = Default project_name = service user_domain_name = Default username = octavia password = octavia_123 auth_type = password auth_url = http://controller:35357/v3 [nova] [cinder] [glance] [neutron] [quotas] \u0110\u1ed3ng b\u1ed9 database chown octavia:octavia /etc/octavia/certs -R octavia-db-manage upgrade head Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start octavia-api.service systemctl start octavia-worker.service systemctl start octavia-health-manager.service systemctl start octavia-housekeeping.service systemctl status octavia-api.service systemctl status octavia-worker.service systemctl status octavia-health-manager.service systemctl status octavia-housekeeping.service systemctl enable octavia-api.service systemctl enable octavia-worker.service systemctl enable octavia-health-manager.service systemctl enable octavia-housekeeping.service C\u1ea5u h\u00ecnh FirwallD firewall-cmd --add-port=9876/tcp --permanent firewall-cmd --reload C\u00e0i \u0111\u1eb7t Octavia Dashboard git clone https://github.com/openstack/octavia-dashboard.git -b stable/queens cd octavia-dashboard && python setup.py sdist cp -a \\ `pwd`/octavia_dashboard/enabled/_1482_*.py \\ /usr/share/openstack-dashboard/openstack_dashboard/enabled/ cd /usr/share/openstack-dashboard/ ./manage.py collectstatic ./manage.py compress systemctl restart httpd openstack loadbalancer create --name lb8 --vip-subnet-id f653162e-945d-495a-8a03-e29503eb429e --debug 4. C\u00e1c note tham kh\u1ea3o \u00b6 Octavia makes use of an \u201cLB Network\u201d exclusively as a management network that the controller uses to talk to amphorae and vice versa. All the amphorae that Octavia deploys will have interfaces and IP addresses on this network. Therefore, it\u2019s important that the subnet deployed on this network be sufficiently large to allow for the maximum number of amphorae and controllers likely to be deployed throughout the lifespan of the cloud installation. At the present time, only IPv4 subnets have been tested as the LB Network (for example: 172.31.0.0/16), though there are plans to eventually support IPv6 subnets for the LB Network. The LB Network is isolated from tenant networks on the amphorae by means of network namespaces on the amphorae. Therefore, operators need not be concerned about overlapping subnet ranges with tenant networks. You must also create a Neutron security group which will be applied to amphorae created on the LB network. It needs to allow amphorae to send UDP heartbeat packets to the health monitor (by default, UDP port 5555), and ingress on the amphora\u2019s API (by default, TCP port 9443). It can also be helpful to allow SSH access to the amphorae from the controller for troubleshooting purposes (ie. TCP port 22), though this is not strictly necessary in production environments. Amphorae will send periodic health checks to the controller\u2019s health manager. Any firewall protecting the interface on which the health manager listens must allow these packets from amphorae on the LB Network (by default, UDP port 5555). Finally, you need to add routing or interfaces to this network such that the Octavia controller (which will be described below) is able to communicate with hosts on this network. This also implies you should have some idea where you\u2019re going to run the Octavia controller components. You must: Create the \u2018lb-mgmt-net\u2019. Assign the \u2018lb-mgmt-net\u2019 to the admin tenant. Create a subnet and assign it to the \u2018lb-mgmt-net\u2019. Create neutron security group for amphorae created on the \u2018lb-mgmt-net\u2019. which allows appropriate access to the amphorae. Update firewall rules on the host running the octavia health manager to allow health check messages from amphorae. Add appropriate routing to / from the \u2018lb-mgmt-net\u2019 such that egress is allowed, and the controller (to be created later) can talk to hosts on this network. This spec introduces the Neutron QoS function to meet the requirements. Currently, there are 3 ports(at least) in the loadbalancer created by Octavia. One is from the lb-mgmt-net, the others are from the vip-subnet, called \u201cloadbalancer-LOADBALANCER_ID\u201d and \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d. The first one is vip port, the second one is for vrrp HA, and it will set \u201callowed_address_pairs\u201d toward vip fixed_ip. The QoS policy should focus on the attached port \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d. We could apply the Neutron QoS policy to the \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d ports, whether the topology is active-active or standalone. 5. Tham kh\u1ea3o th\u00eam \u00b6 https://github.com/openstack/octavia/blob/master/devstack/plugin.sh http://blog.51cto.com/superbigsea/1862253 http://gogosatellite.blogspot.com/2016/08/study-openstack-octavia-in-mitaka-by.html https://blog.csdn.net/Jmilk/article/details/81279795 https://docs.openstack.org/tricircle/queens/install/installation-guide.html https://blog.zufardhiyaulhaq.com/manual-instalation-octavia-openstack-queens/ https://lingxiankong.github.io/2017-09-13-octavia.html https://blog.csdn.net/Jmilk/article/details/81279795 https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd https://ask.openstack.org/en/question/94127/mitakaoctavia-octavia-worker-cannot-reach-amphora/ https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd https://docs.mirantis.com/mcp/latest/mcp-deployment-guide/configure-octavia.html https://www.codetd.com/article/4530901 https://docs.openstack.org/octavia/latest/reference/glossary.html https://docs.openstack.org/octavia/queens/configuration/configref.html https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html https://docs.openstack.org/newton/networking-guide/config-lbaas.html https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html https://docs.openstack.org/openstack-ansible-os_octavia/latest/configure-octavia.html https://docs.openstack.org/tricircle/rocky/install/installation-guide.html","title":"1.Intro+Setup"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#cai_at_octavia_tren_openstack","text":"","title":"C\u00e0i \u0111\u1eb7t Octavia tr\u00ean Openstack"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#1_octavia_-_load_balancing_solution_for_openstack","text":"","title":"1. Octavia - Load Balancing Solution For Openstack"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#11_mo_au","text":"Octavia l\u00e0 project trong Openstack, \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m gi\u1ea3i ph\u00e1p c\u00e2n b\u1eb1ng t\u1ea3i trong Openstack. Octavia \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u t\u1eeb Neutron LBaas Project. Octavia cung c\u1ea5p d\u1ecbch v\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i b\u1eb1ng c\u00e1ch c\u00e1c m\u00e1y \u1ea3o qu\u1ea3n l\u00fd m\u00e1y \u1ea3o, container, bare metal server , \u0111\u01b0\u1ee3c g\u1ecdi chung l\u00e0 : amphorae . Octavia kh\u00e1c v\u1edbi kh\u00e1c v\u1edbi c\u00e1c gi\u1ea3i kh\u00e1c v\u00ec n\u00f3 sinh \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho m\u00f4i tr\u01b0\u1eddng cloud, t\u00f9y ch\u1ec9nh theo y\u00eau c\u1ea7u","title":"1.1 . M\u1edf \u0111\u1ea7u"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#12_octavia_uoc_su_dung_trong_openstack_khi_nao","text":"C\u00e2n b\u1eb1ng t\u1ea3i ( load balancing ) l\u00e0 \u0111i\u1ec1u c\u1ea7n thi\u1ebft \u0111\u1ec3 \u0111\u1ec3 m\u1edf r\u1ed9ng quy m\u00f4 c\u00f3 th\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u1eb7c quy m\u00f4 l\u1edbn v\u00e0 t\u1ef1 \u0111\u1ed9ng. Octavia \u0111\u01b0\u1ee3c xem l\u00e0 project c\u1ea7n thi\u1ebft gi\u1ed1ng nh\u01b0 Nova, Neutron v\u00e0 c\u00e1c core project kh\u00e1c - \u0111i\u1ec1u c\u1ea7n thi\u1ebft \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t Openstack Cloud ecosystem \u0110\u1ec3 ho\u00e0n th\u00e0nh vai tr\u00f2 , Octavia c\u1ea7n l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c project kh\u00e1c : Nova : \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c t\u00e0i nguy\u00ean tr\u00ean c\u00e1c compute node theo nhu c\u1ea7u Neutron : cho c\u00e1c m\u1ea1ng tentant ( project ) v\u00e0 c\u00e1c m\u1ea1ng external Barbican : qu\u1ea3n l\u00fd TLS certificate v\u00e0 credential , v\u00e0 TLS Session Keystone : d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c Octavia API v\u00e0 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c project kh\u00e1c Glance : \u0111\u1ec3 l\u01b0u tr\u1eef c\u00e1c amphorae virtual image Olso : \u0111\u1ec3 giai ti\u1ebfp gi\u1eefa c\u00e1c Octavia compoment. Taskflow : Octavia \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n \u1edf tr\u00ean. V\u1edbi tr\u00ean tr\u1eebng project Octavia s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t driver interface \u0111\u1ec3 l\u00e0m vi\u1ec7c. K\u1ec3 t\u1eeb phi\u00ean b\u1ea3n Pike, Octavia \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m m\u1ed9t gi\u1ea3i ph\u00e1p c\u00e2n b\u1eb1ng t\u1ea3i \u0111\u1ed9c l\u1eadp. Neutron LBaas \u0111\u01b0\u1ee3c x\u00f3a b\u1ecf t\u1ea1i phi\u00ean b\u1ea3n Queens, Octavia s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng thay th\u1ebf.","title":"1.2 : Octavia \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Openstack khi n\u00e0o"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#13_thanh_phan_trong_octavia","text":"Amphorea : l\u00e0 m\u1ed9t m\u00e1y \u1ea3o , container ho\u1eb7c server cung c\u1ea5p d\u1ecbch v\u1ee5 c\u00e2n b\u1eb1ng t\u1ea3i. N\u00eau l\u00e0 m\u00e1y \u1ea3o s\u1ebd ch\u1ea1y tr\u00ean c\u00e1c compute node, v\u1edbi c\u00e1c c\u1ea5u h\u00ecnh \u0111\u1ec3 c\u00f3 kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i nh\u01b0 listenner, pool, heath monitor, L7 Policies, ho\u1eb7c g\u1eedi heat beat v\u1ec1 Heah Manager Controller : \u0111\u01b0\u1ee3c xem l\u00e0 \"brain\" c\u1ee7a Octavia . C\u00f3 bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n con , v\u00e0 c\u00e1c ti\u1ebfn tr\u00ecnh daemon. N\u00f3 c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c c\u00e1c th\u00e0nh ph\u1ea7n con th\u00f4ng qua c\u00e1c drvier interface. API Controller : cung c\u1ea5p API interface, nh\u1eadn c\u00e1c request v\u00e0 g\u1eedi v\u1ec1 controller worker th\u00f4ng qua Olso message Controller worker : nh\u1eadn c\u00e1c l\u1ec7nh t\u1eeb API controller, sau \u0111\u00f3 th\u1ef1c hi\u1ec7n c\u00e1c y\u00eau \u0111\u1ea7u \u0111\u1ec1 \u0111\u1ec1 ra Heath Manager : cung c\u1ea5p kh\u1ea3 n\u0103ng heat beat t\u1edbi c\u00e1c amphorea, ki\u1ec3m tra tr\u1ea1ng th\u00e1i v\u00e0 cung c\u1ea5p kh\u0103ng failover cho c\u00e1c m\u00e1y \u1ea3o n\u00e0y Housekeeping Manager : cung c\u1ea5p kh\u1ea3 n\u0103ng scaleup ho\u1eb7c x\u00f3a d\u1eef li\u1ec7u v\u00e0 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a amphora certificate network : octavia kh\u00f4ng th\u1ec3 ho\u00e0n th\u00e0nh n\u1ebfu thi\u1ebfu network. C\u00e1c m\u00e1y \u1ea3o amphora \u0111\u01b0\u1ee3c g\u1eafn m\u1ed9t network interface t\u1eeb Load Balance network,ho\u1eb7c s\u1ebd l\u00e0 m\u1ed9t port tr\u00ean c\u00e1c tentant network. Pool : t\u1eadp h\u1ee3p c\u00e1c memeber l\u1eafng nghe request t\u1eeb load balancer . M\u1ed7i pool ch\u1ec9 \u0111\u01b0\u1ee3c li\u00ean k\u1ebft v\u1edbi m\u1ed9t listener.","title":"1.3 . Th\u00e0nh ph\u1ea7n trong Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#22_cac_thuat_ngu_bo_sung_trong_octavia","text":"Fail-over l\u00e0 cho ph\u00e9p c\u00f4ng vi\u1ec7c th\u01b0\u1eddng ch\u1ec9 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c b\u1edfi m\u1ed9t m\u00e1y ch\u1ee7 kh\u00e1c khi m\u1ed9t trong 2 m\u00e1y ch\u1ee7 x\u1ea3y ra s\u1ef1 c\u1ed1. Amphora Load Balancer Driver : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi controlller \u0111\u1ec3 giao ti\u1ebfp v\u1edbi amphorae. Anchor : l\u00e0 m\u1ed9t projec trong Openstack cung c\u1ea5p c\u00e1c kh\u00f3a PKI ng\u1eafn h\u1ea1n. Octavia s\u1eed d\u1ee5ng cho vi\u1ec7c authen gi\u1eefa c\u00e1c compoment Apolocation : l\u00e0 c\u00e1c amphorae kh\u00f4ng \u0111\u01b0\u1ee3c \u0111\u1eb7t l\u00ean c\u00f9ng m\u1ed9t host v\u1eadt l\u00fd L7 Policy : c\u00e1c t\u1eadp policy cho qu\u00e1 tr\u00ecnh routing cho c\u00e1c Client L7 Rule : c\u00e1c t\u1eadp policy y\u00eau c\u1ea7u tr\u00f9ng kh\u1edbp v\u1edbi c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn t\u1eeb Client LB Network : network \u0111\u01b0\u1ee3c controlller v\u00e0 amphorae giao ti\u1ebfp , kh\u00f4ng \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o m\u1ed9t project n\u00e0o Listener : l\u00e0 c\u00e1c giao th\u1ee9c ho\u1eb7c c\u1ed5ng ( kh\u00f4ng c\u00f3 IP ) s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i VIP : Virtual IP Address : \u0111\u1ecba ch\u1ec9 IP t\u0129nh \u0111\u01b0\u1ee3c g\u1eafn cho qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i. Gi\u1ed1ng nh\u01b0 c\u00e1c giao th\u1ee9c CARP, VRRP, or HSRP s\u1ebd c\u00f3 IP ri\u00eang cho qu\u00e1 tr\u00ecnh \u0111\u1ecbnh tuy\u1ebfn . Trong otavia , VIP s\u1ebd \u0111\u01b0\u1ee3c v\u00e0o v\u00e0o m\u1ed9t network device \u0111\u1ecbnh tuy\u1ebfn packet \u0111\u1ebfn c\u00e1c m\u00e1y \u1ea3o c\u00e2n b\u1eb1ng t\u1ea3i v\u00e0 load cho c\u00e1c m\u00e1y \u1ea3o backend","title":"2.2 : C\u00e1c thu\u1eadt ng\u1eef b\u1ed5 sung trong Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#22_cac_mode_trien_khai_trong_octavia","text":"Trong Octavia hi\u1ec7n t\u1ea1i v\u1edbi b\u1ea3n Queens \u0111ang g\u1ed3m 2 mode : SINGEL v\u00e0 ACTIVE_BACKUP \u0110\u1ed1i v\u1edbi SINGEL : cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i , kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng Failover co cho c\u00e1c Load Blancer \u0110\u1ed1i v\u1edbi ACTIVE_STANDBY : cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i , c\u00f3 kh\u1ea3 n\u0103ng Failover chLoad Blancer","title":"2.2  : C\u00e1c mode tri\u1ec3n khai trong Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#3_cai_at_octavia_mo_hinh_single","text":"C\u01a1 s\u1edf \u0111\u1ec3 c\u1ea5u h\u00ecnh : All API calls described throughout the rest of this document require authentication with the OpenStack Identity service . After authentication, the base endpoint URL for the service type of load-balancer and service name of octavia can be extracted from the service catalog returned with the identity token. https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html URL : https://developer.openstack.org/api-ref/load-balancer/v2/index.html Y\u00eau c\u1ea7u : \u0110\u00e3 c\u00e0i \u0111\u1eb7t c\u00e1c project : Keystone, Glance, Neutron ( bao g\u1ed3m L3 Agent ) , Nova, Barbican","title":"3. C\u00e0i \u0111\u1eb7t Octavia m\u00f4 h\u00ecnh SINGLE"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#31_cai_at_package","text":"Do c\u1ea7n s\u1eed d\u1ee5ng m\u1ed9t s\u1ed1 th\u01b0 vi\u1ec7c n\u00ean c\u1ea7n clone project c\u1ee7a octavia git clone https://github.com/openstack/octavia.git /root/octavia -b stable/queens Kh\u1edfi t\u1ea1o Certificate Authorities s\u1eed d\u1ee5ng \u0111\u1ec3 m\u00e3 h\u00f3a khi li\u00ean h\u1ec7 gi\u1eefa th\u00e0nh ph\u1ea7n. L\u01b0u \u00fd \u0111\u00e3 b\u1eadt service Barbican bash /root/octavia/bin/create_certificates.sh /etc/octavia/certs/ /root/octavia/etc/certificates/openssl.cnf C\u00e0i \u0111\u1eb7t package ( ki\u1ec3m tra k\u1ef9 tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t, c\u00f3 th\u1ec3 g\u00e2y xung \u0111\u1ed9t v\u1edbi c\u00e1c project kh\u00e1c ) wget https://pypi.python.org/packages/5e/5d/4e4364bb8b2a3e8d6c41ec21095aae3ac3396a6fa6983ea7f5551e929661/pyasn1-0.4.2-py2.4.egg#md5=84cf09817d8eb3b8955c5c558abd7ba7 easy_install pyasn1-0.4.2-py2.4.egg pip install pyasn1-modules==0.2.2 pip install Jinja2==2.10 pip install pyOpenSSL==17.1.0 yum install -y python-octavia openstack-octavia-common openstack-octavia-diskimage-create openstack-octavia-health-manager openstack-octavia-housekeeping openstack-octavia-ui openstack-octavia-worker openstack-octavia-amphora-agent python2-octaviaclient openstack-octavia-api Kh\u1edfi t\u1ea1o Database cho Octavia mysql -u root --password=hung <<EOF CREATE DATABASE octavia; GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'localhost' \\ IDENTIFIED BY 'octavia_123'; GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'%' \\ IDENTIFIED BY 'octavia_123'; EOF","title":"3.1. C\u00e0i \u0111\u1eb7t package"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#32_khoi_tao_user_service_su_dung_tai_khoan_admin","text":"Kh\u1edfi t\u1ea1o User v\u00e0 ph\u00e2n quy\u1ec1n source admin-openrc openstack user create --domain default --password octavia_123 octavia openstack role add --project service --user octavia admin openstack service create load-balancer --name octavia Kh\u1edfi t\u1ea1o Endpoint openstack endpoint create octavia public http://controller:9876 --region RegionOne openstack endpoint create octavia admin http://controller:9876 --region RegionOne openstack endpoint create octavia internal http://controller:9876 --region RegionOne Kh\u1edfi t\u1ea1o network v\u00e0 subnet VIP openstack network create --external --default --share --provider-physical-network provider --provider-network-type flat provider openstack subnet create --subnet-range 192.168.30.0/24 --dhcp --allocation-pool start=192.168.30.140,end=192.168.30.160 --dns-nameserver 1.1.1.1 --gateway=192.168.30.1 --network provider provider-net-30 Kh\u1edfi t\u1ea1o file rc \u0111\u1ec3 \u0111\u0103ng nh\u1eadp v\u00e0o user octavia , s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o c\u00e1c Security group, Flavor, Key pair cat <<EOF > octovia-openrc export OS_PROJECT_DOMAIN_NAME=Default export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_NAME=service export OS_USERNAME=octavia export OS_PASSWORD=octavia_123 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 EOF","title":"3.2 . Kh\u1edfi t\u1ea1o User, Service ( s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin )"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#32_khoi_tao_network_security_group_thuc_hien_tren_octavia_user","text":"","title":"3.2 . Kh\u1edfi t\u1ea1o Network, Security Group ( th\u1ef1c hi\u1ec7n tr\u00ean Octavia User )"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#cac_khoi_tao_duoi_ay_uoc_su_dung_cho_section_controller_worker_trong_tap_tin_cau_hinh_etcoctaviaoctaviaconf","text":"\u0110\u0103ng nh\u1eadp v\u00e0o user octovia source octovia-openrc Kh\u1edfi t\u1ea1o Security Group v\u00e0 Rule cho LB Network . \u0110\u00e2y l\u00e0 m\u1ea1ng li\u00ean h\u1ec7 gi\u1eefa Controller v\u00e0 c\u00e1c VM Load Balancer. B\u1ea3n th\u00e2n m\u1ea1ng LB th\u01b0\u1eddng s\u1ebd l\u00e0 d\u00f9ng cho c\u00e1c controller v\u00e0 VM li\u00ean h\u1ec7 v\u1edbi nova v\u00e0 neutron. nh\u01b0ng kh\u00f4ng \u0111\u01b0\u1ee3c li\u00ean k\u1ebft v\u1edbi b\u1ea5t k\u1ef3 m\u1ed9t tenan n\u00e0o ( ID tr\u1ea3 v\u1ec1 : ce6fd5ce-de4c-43fe-927a-f2a1103a34bd ) openstack --os-region-name=RegionOne security group create lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol icmp lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol icmpv6 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp Kh\u1edfi t\u1ea1o Security group cho Health manager ( heatbeat t\u1edbi c\u00e1c VM Load Balanacer ) openstack --os-region-name=RegionOne security group create lb-health-mgr-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 --ethertype IPv6 --remote-ip ::/0 lb-health-mgr-sec-grp Kh\u1edfi t\u1ea1o LB Network ( ID tr\u1ea3 v\u1ec1 : 5cb04d80-c822-45dd-bd61-0d7fc1f2fcd0 ) neutron --os-region-name=RegionOne net-create lb-mgmt-net1 neutron --os-region-name=RegionOne subnet-create --name lb-mgmt-subnet1 lb-mgmt-net1 192.168.199.0/24 Kh\u1edfi t\u1ea1o port tr\u00ean neutron s\u1eed d\u1ee5ng Security Group lb-health-mgr-sec-grp , sau \u0111\u00f3 g\u1eafn v\u00e0o openvswitch cho Health Manager id_and_mac=$(neutron --os-region-name=RegionOne port-create --name octavia-health-manager-region-one-listen-port --security-group lb-health-mgr-sec-grp --device-owner Octavia:health-mgr --binding:host_id=$(hostname) lb-mgmt-net1 $PORT_FIXED_IP | awk '/ id | mac_address / {print $4}') id_and_mac=($id_and_mac) MGMT_PORT_ID=${id_and_mac[0]} MGMT_PORT_MAC=${id_and_mac[1]} MGMT_PORT_IP=$(openstack --os-region-name=RegionOne port show -f value -c fixed_ips $MGMT_PORT_ID | awk '{FS=\",| \"; gsub(\",\",\"\"); gsub(\"'\\''\",\"\"); for(i = 1; i <= NF; ++i) {if ($i ~ /^ip_address/) {n=index($i, \"=\"); if (substr($i, n+1) ~ \"\\\\.\") print substr($i, n+1)}}}') neutron --os-region-name=RegionOne port-update --binding:host_id=$(hostname) $MGMT_PORT_ID sudo ovs-vsctl -- --may-exist add-port ${OVS_BRIDGE:-br-int} o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$MGMT_PORT_MAC -- set Interface o-hm0 external-ids:iface-id=$MGMT_PORT_ID -- set Interface o-hm0 external-ids:skip_cleanup=true OCTAVIA_DHCLIENT_CONF=/etc/octavia/dhcp/dhclient.conf sudo ip link set dev o-hm0 address $MGMT_PORT_MAC sudo dhclient -v o-hm0 -cf $OCTAVIA_DHCLIENT_CONF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port 5555/udp --permanent firewall-cmd --reload Kh\u1edfi t\u1ea1o flavor cho Amphora ( ID Flavor tr\u1ea3 v\u1ec1 : 7c3a80ff-822e-4ace-bffb-54739c4a1108 ) openstack flavor create --disk 4 --ram 1024 --vcpus 1 --private --project service amphora_vm Kh\u1edfi t\u1ea1o v\u00e0 upload m\u1ed9t image m\u1edbi cho m\u00e1y \u1ea3o Amphora ( \u0111\u1ea3m nhi\u1ec7m l\u00e0 Load Balancer - ID tr\u1ea3 v\u1ec1 :6c7c0a18-fe65-4065-9a1e-4dc170f1659d, tag tr\u1ea3 v\u1ec1 : amphora ) octavia-diskimage-create.sh -r 123@123Aa -o ubuntu-ha openstack image create amphora-x64 --public --container-format bare --disk-format qcow2 --file /var/log/octavia/ubuntu-ha.qcow2 openstack image set amphora-x64 --tag amphora-x64","title":"C\u00e1c kh\u1edfi t\u1ea1o d\u01b0\u1edbi \u0111\u00e2y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho section controller_worker trong t\u1eadp tin c\u1ea5u h\u00ecnh /etc/octavia/octavia.conf"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#32_cau_hinh_neutron","text":"Tham kh\u1ea3o th\u00eam : https://docs.openstack.org/neutron/queens/admin/config-dns-int.html C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] dns_domain = 1.1.1.1 [octavia] base_url=http://127.0.0.1:9876 C\u1ea5u h\u00ecnh ML2 /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] extension_drivers = port_security,dns_domain_ports Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server","title":"3.2. C\u1ea5u h\u00ecnh Neutron"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#33_cau_hinh_octavia_hoan_chinh","text":"C\u1ea5u h\u00ecnh t\u1ea1i /etc/octavia/octavia.conf cat <<EOF> /etc/octavia/octavia.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller publish_errors = true debug = False use_syslog = True [api_settings] auth_strategy = keystone bind_host = 0.0.0.0 bind_port = 9876 api_v1_enabled = true api_v2_enabled = true [database] connection = mysql+pymysql://octavia:octavia_123@controller/octavia [health_manager] event_streamer_driver = noop_event_streamer heartbeat_key = insecure controller_ip_port_list = {IP at o-hm0 }:5555 bind_ip = {IP at o-hm0} bind_port = 5555 sync_provisioning_status = true [keystone_authtoken] www_authenticate_uri = http://controller:5000/v3 auth_url = http://controller:35357/v3 username = octavia password = octavia_123 project_name = service project_domain_name = Default user_domain_name = Default auth_type = password [certificates] cert_manager = barbican_cert_manager ca_certificate = /etc/octavia/certs/ca_01.pem ca_private_key = /etc/octavia/certs/private/cakey.pem ca_private_key_passphrase = foobar [anchor] [networking] [haproxy_amphora] bind_host = 0.0.0.0 bind_port = 9443 server_ca = /etc/octavia/certs/ca_01.pem client_cert = /etc/octavia/certs/client.pem base_path = /var/lib/octavia base_cert_dir = /var/lib/octavia/certs connection_max_retries = 1500 connection_retry_interval = 1 [controller_worker] workers = 1 amp_active_retries = 100 amp_active_wait_sec = 5 loadbalancer_topology = SINGLE amp_ssh_key_name = pair_LB amp_image_tag = amphora-x64 amp_secgroup_list = 985491e0-f399-4584-8f4a-4a3aa737714e amp_boot_network_list = 18a03d0a-8ad6-41e2-93ad-1abe8edce9b6 amp_flavor_id = 6c7c0a18-fe65-4065-9a1e-4dc170f1659d network_driver = allowed_address_pairs_driver compute_driver = compute_nova_driver amphora_driver = amphora_haproxy_rest_driver amp_image_id = 7e5d5455-178b-4830-87eb-8fc1f9aefe63 [task_flow] [oslo_messaging] rpc_thread_pool_size = 2 topic = octavia_prov [oslo_messaging_rabbit] rabbit_host = controller rabbit_userid = openstack rabbit_password = rabbitmq_123 [house_keeping] load_balancer_expiry_age = 3600 [amphora_agent] [keepalived_vrrp] [service_auth] project_domain_name = Default project_name = service user_domain_name = Default username = octavia password = octavia_123 auth_type = password auth_url = http://controller:35357/v3 [nova] [cinder] [glance] [neutron] [quotas] \u0110\u1ed3ng b\u1ed9 database chown octavia:octavia /etc/octavia/certs -R octavia-db-manage upgrade head Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start octavia-api.service systemctl start octavia-worker.service systemctl start octavia-health-manager.service systemctl start octavia-housekeeping.service systemctl status octavia-api.service systemctl status octavia-worker.service systemctl status octavia-health-manager.service systemctl status octavia-housekeeping.service systemctl enable octavia-api.service systemctl enable octavia-worker.service systemctl enable octavia-health-manager.service systemctl enable octavia-housekeeping.service C\u1ea5u h\u00ecnh FirwallD firewall-cmd --add-port=9876/tcp --permanent firewall-cmd --reload C\u00e0i \u0111\u1eb7t Octavia Dashboard git clone https://github.com/openstack/octavia-dashboard.git -b stable/queens cd octavia-dashboard && python setup.py sdist cp -a \\ `pwd`/octavia_dashboard/enabled/_1482_*.py \\ /usr/share/openstack-dashboard/openstack_dashboard/enabled/ cd /usr/share/openstack-dashboard/ ./manage.py collectstatic ./manage.py compress systemctl restart httpd openstack loadbalancer create --name lb8 --vip-subnet-id f653162e-945d-495a-8a03-e29503eb429e --debug","title":"3.3. C\u1ea5u h\u00ecnh Octavia ho\u00e0n ch\u1ec9nh"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#4_cac_note_tham_khao","text":"Octavia makes use of an \u201cLB Network\u201d exclusively as a management network that the controller uses to talk to amphorae and vice versa. All the amphorae that Octavia deploys will have interfaces and IP addresses on this network. Therefore, it\u2019s important that the subnet deployed on this network be sufficiently large to allow for the maximum number of amphorae and controllers likely to be deployed throughout the lifespan of the cloud installation. At the present time, only IPv4 subnets have been tested as the LB Network (for example: 172.31.0.0/16), though there are plans to eventually support IPv6 subnets for the LB Network. The LB Network is isolated from tenant networks on the amphorae by means of network namespaces on the amphorae. Therefore, operators need not be concerned about overlapping subnet ranges with tenant networks. You must also create a Neutron security group which will be applied to amphorae created on the LB network. It needs to allow amphorae to send UDP heartbeat packets to the health monitor (by default, UDP port 5555), and ingress on the amphora\u2019s API (by default, TCP port 9443). It can also be helpful to allow SSH access to the amphorae from the controller for troubleshooting purposes (ie. TCP port 22), though this is not strictly necessary in production environments. Amphorae will send periodic health checks to the controller\u2019s health manager. Any firewall protecting the interface on which the health manager listens must allow these packets from amphorae on the LB Network (by default, UDP port 5555). Finally, you need to add routing or interfaces to this network such that the Octavia controller (which will be described below) is able to communicate with hosts on this network. This also implies you should have some idea where you\u2019re going to run the Octavia controller components. You must: Create the \u2018lb-mgmt-net\u2019. Assign the \u2018lb-mgmt-net\u2019 to the admin tenant. Create a subnet and assign it to the \u2018lb-mgmt-net\u2019. Create neutron security group for amphorae created on the \u2018lb-mgmt-net\u2019. which allows appropriate access to the amphorae. Update firewall rules on the host running the octavia health manager to allow health check messages from amphorae. Add appropriate routing to / from the \u2018lb-mgmt-net\u2019 such that egress is allowed, and the controller (to be created later) can talk to hosts on this network. This spec introduces the Neutron QoS function to meet the requirements. Currently, there are 3 ports(at least) in the loadbalancer created by Octavia. One is from the lb-mgmt-net, the others are from the vip-subnet, called \u201cloadbalancer-LOADBALANCER_ID\u201d and \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d. The first one is vip port, the second one is for vrrp HA, and it will set \u201callowed_address_pairs\u201d toward vip fixed_ip. The QoS policy should focus on the attached port \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d. We could apply the Neutron QoS policy to the \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d ports, whether the topology is active-active or standalone.","title":"4. C\u00e1c note tham kh\u1ea3o"},{"location":"Openstack_Research/High-availability/2. Octavia/1.Intro+Setup/#5_tham_khao_them","text":"https://github.com/openstack/octavia/blob/master/devstack/plugin.sh http://blog.51cto.com/superbigsea/1862253 http://gogosatellite.blogspot.com/2016/08/study-openstack-octavia-in-mitaka-by.html https://blog.csdn.net/Jmilk/article/details/81279795 https://docs.openstack.org/tricircle/queens/install/installation-guide.html https://blog.zufardhiyaulhaq.com/manual-instalation-octavia-openstack-queens/ https://lingxiankong.github.io/2017-09-13-octavia.html https://blog.csdn.net/Jmilk/article/details/81279795 https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd https://ask.openstack.org/en/question/94127/mitakaoctavia-octavia-worker-cannot-reach-amphora/ https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd https://docs.mirantis.com/mcp/latest/mcp-deployment-guide/configure-octavia.html https://www.codetd.com/article/4530901 https://docs.openstack.org/octavia/latest/reference/glossary.html https://docs.openstack.org/octavia/queens/configuration/configref.html https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html https://docs.openstack.org/newton/networking-guide/config-lbaas.html https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html https://docs.openstack.org/openstack-ansible-os_octavia/latest/configure-octavia.html https://docs.openstack.org/tricircle/rocky/install/installation-guide.html","title":"5. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/High-availability/2. Octavia/2.Use-Octavia/","text":"Thao t\u00e1c v\u1edbi Octavia \u00b6 1. Kh\u1edfi t\u1ea1o Web Server \u00b6 Kh\u1edfi \u0111\u1ed9ng 2 m\u00e1y \u1ea3o \u0111\u00e3 c\u00e0i \u0111\u1eb7t Web Server, Security Group \u0111\u00e3 m\u1edf port 80 Trong Octavia c\u00e1c Load Balancer c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng ph\u1ee5c v\u1ee5 \u0111\u01b0\u1ee3c c\u1ea3 m\u00f4 h\u00ecnh : Self-Service v\u00e0 Provider 2. Kh\u1edfi t\u1ea1o Load Balancer tr\u00ean Self-Service \u00b6 Kh\u1edfi t\u1ea1o Load Blancer tr\u00ean Subnet 192.168.30.0 [LAB] openstack loadbalancer create --name lb2 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-14T09:41:09 | | description | | | flavor | | | id | bf0df0f3-3e21-4308-891f-4f0e0ccf2bfb | | listeners | | | name | lb1 | | operating_status | OFFLINE | | pools | | | project_id | c346047f05064784a58f7dbb6394466e | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.220.10 | | vip_network_id | ddd55611-bb96-4b52-ac1b-675e8d3184ac | | vip_port_id | e7bcc65b-fc0d-43ea-ad63-c745048c41a8 | | vip_qos_policy_id | None | | vip_subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | +---------------------+--------------------------------------+ Ki\u1ec3m tra Log tr\u00ean Worker Kh\u1edfi t\u1ea1o m\u1ed9t Listenner [LAB]openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-14T10:19:13 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | a59b5f62-0915-4050-9eb9-980c451d2d34 | | insert_headers | None | | l7policies | | | loadbalancers | bf0df0f3-3e21-4308-891f-4f0e0ccf2bfb | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool s\u1eed d\u1ee5ng ROUND_ROBIN cho Load Balancing ( s\u1eed d\u1ee5ng Listenner ID ) openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener a59b5f62-0915-4050-9eb9-980c451d2d34 --protocol HTTP Kh\u1edfi t\u1ea1o Health Monitor t\u1edbi c\u00e1c Pool Member ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 5aa99c69-d200-4969-8af9-ac429aa80487 Th\u00eam c\u00e1c Web Server l\u00e0m Pool Member ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 5aa99c69-d200-4969-8af9-ac429aa80487 openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.30 --protocol-port 80 5aa99c69-d200-4969-8af9-ac429aa80487 G\u1eafn Floating VIP v\u00e0o LB [LAB]openstack floating ip create PUBLIC_VIP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | created_at | 2019-01-14T10:31:12Z | | description | | | fixed_ip_address | None | | floating_ip_address | 192.168.30.147 | | floating_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | id | 90d2ebd0-2c44-456c-b841-975e87d23dca | | name | 192.168.30.147 | | port_id | None | | project_id | c346047f05064784a58f7dbb6394466e | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | updated_at | 2019-01-14T10:31:12Z | +---------------------+--------------------------------------+ [LAB]openstack floating ip set --port e7bcc65b-fc0d-43ea-ad63-c745048c41a8 192.168.30.147 3. Kh\u1edfi t\u1ea1o Load Balancer s\u1eed d\u1ee5ng Provider \u00b6 Kh\u1edfi t\u1ea1o m\u1ed9t Load Balancer [root@controller ~]# openstack loadbalancer create --name lb2 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T01:18:58 | | description | | | flavor | | | id | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | listeners | | | name | lb2 | | operating_status | OFFLINE | | pools | | | project_id | c346047f05064784a58f7dbb6394466e | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.30.159 | | vip_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | vip_port_id | c88f3a67-9c42-4e55-8197-1effc1e9c587 | | vip_qos_policy_id | None | | vip_subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | +---------------------+--------------------------------------+ Kh\u1edfi \u0111\u1ed9ng Listenner tr\u00ean LB2 [root@controller ~]# openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb2 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-16T01:29:25 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | 4f7e6386-37cd-4cd4-80d9-901b96f20f6c | | insert_headers | None | | l7policies | | | loadbalancers | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool s\u1eed d\u1ee5ng ROUND_ROBIN cho Listenner 1 ( s\u1eed d\u1ee5ng ID echo Listenner ) [root@controller ~]# openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener 4f7e6386-37cd-4cd4-80d9-901b96f20f6c --protocol HTTP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T01:30:05 | | description | | | healthmonitor_id | | | id | d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 | | lb_algorithm | ROUND_ROBIN | | listeners | 4f7e6386-37cd-4cd4-80d9-901b96f20f6c | | loadbalancers | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | members | | | name | pool1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | provisioning_status | PENDING_CREATE | | session_persistence | None | | updated_at | None | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Heath Monitor tr\u00ean Pools 1 ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 Kh\u1edfi t\u1ea1o Pool Member tr\u00ean Pool 1 ( s\u1eed d\u1ee5ng Pool ID ) [root@controller ~]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.8 | | admin_state_up | True | | created_at | 2019-01-16T01:33:30 | | id | c2cb897e-8dfe-48b3-9b38-92b9fd5aecde | | name | | | operating_status | NO_MONITOR | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ [root@controller ~]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.8 | | admin_state_up | True | | created_at | 2019-01-16T01:59:13 | | id | 4671aff1-6f96-46bf-b4b8-e1fe06468389 | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ V\u1edbi c\u00e1c Web Server Nginx \u0111ang s\u1eed d\u1ee5ng IP Public . C\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh th\u00eam ch\u1ec9 cho nh\u1eadn c\u00e1c request t\u1eeb VIP Load Balancer. B\u01b0\u1edbc \u0111\u1ea7u t\u1ea1o m\u1ed9t file trong folder nginx tao m\u1ed9t file server.blacklist v\u1edbi n\u1ed9i dung sau allow 1.2.3.4; # Allow a single remote host deny all; # Deny everyone else","title":"2.Use Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/2.Use-Octavia/#thao_tac_voi_octavia","text":"","title":"Thao t\u00e1c v\u1edbi Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/2.Use-Octavia/#1_khoi_tao_web_server","text":"Kh\u1edfi \u0111\u1ed9ng 2 m\u00e1y \u1ea3o \u0111\u00e3 c\u00e0i \u0111\u1eb7t Web Server, Security Group \u0111\u00e3 m\u1edf port 80 Trong Octavia c\u00e1c Load Balancer c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng ph\u1ee5c v\u1ee5 \u0111\u01b0\u1ee3c c\u1ea3 m\u00f4 h\u00ecnh : Self-Service v\u00e0 Provider","title":"1. Kh\u1edfi t\u1ea1o Web Server"},{"location":"Openstack_Research/High-availability/2. Octavia/2.Use-Octavia/#2_khoi_tao_load_balancer_tren_self-service","text":"Kh\u1edfi t\u1ea1o Load Blancer tr\u00ean Subnet 192.168.30.0 [LAB] openstack loadbalancer create --name lb2 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-14T09:41:09 | | description | | | flavor | | | id | bf0df0f3-3e21-4308-891f-4f0e0ccf2bfb | | listeners | | | name | lb1 | | operating_status | OFFLINE | | pools | | | project_id | c346047f05064784a58f7dbb6394466e | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.220.10 | | vip_network_id | ddd55611-bb96-4b52-ac1b-675e8d3184ac | | vip_port_id | e7bcc65b-fc0d-43ea-ad63-c745048c41a8 | | vip_qos_policy_id | None | | vip_subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | +---------------------+--------------------------------------+ Ki\u1ec3m tra Log tr\u00ean Worker Kh\u1edfi t\u1ea1o m\u1ed9t Listenner [LAB]openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-14T10:19:13 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | a59b5f62-0915-4050-9eb9-980c451d2d34 | | insert_headers | None | | l7policies | | | loadbalancers | bf0df0f3-3e21-4308-891f-4f0e0ccf2bfb | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool s\u1eed d\u1ee5ng ROUND_ROBIN cho Load Balancing ( s\u1eed d\u1ee5ng Listenner ID ) openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener a59b5f62-0915-4050-9eb9-980c451d2d34 --protocol HTTP Kh\u1edfi t\u1ea1o Health Monitor t\u1edbi c\u00e1c Pool Member ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 5aa99c69-d200-4969-8af9-ac429aa80487 Th\u00eam c\u00e1c Web Server l\u00e0m Pool Member ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 5aa99c69-d200-4969-8af9-ac429aa80487 openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.30 --protocol-port 80 5aa99c69-d200-4969-8af9-ac429aa80487 G\u1eafn Floating VIP v\u00e0o LB [LAB]openstack floating ip create PUBLIC_VIP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | created_at | 2019-01-14T10:31:12Z | | description | | | fixed_ip_address | None | | floating_ip_address | 192.168.30.147 | | floating_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | id | 90d2ebd0-2c44-456c-b841-975e87d23dca | | name | 192.168.30.147 | | port_id | None | | project_id | c346047f05064784a58f7dbb6394466e | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | updated_at | 2019-01-14T10:31:12Z | +---------------------+--------------------------------------+ [LAB]openstack floating ip set --port e7bcc65b-fc0d-43ea-ad63-c745048c41a8 192.168.30.147","title":"2. Kh\u1edfi t\u1ea1o Load Balancer tr\u00ean Self-Service"},{"location":"Openstack_Research/High-availability/2. Octavia/2.Use-Octavia/#3_khoi_tao_load_balancer_su_dung_provider","text":"Kh\u1edfi t\u1ea1o m\u1ed9t Load Balancer [root@controller ~]# openstack loadbalancer create --name lb2 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T01:18:58 | | description | | | flavor | | | id | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | listeners | | | name | lb2 | | operating_status | OFFLINE | | pools | | | project_id | c346047f05064784a58f7dbb6394466e | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.30.159 | | vip_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | vip_port_id | c88f3a67-9c42-4e55-8197-1effc1e9c587 | | vip_qos_policy_id | None | | vip_subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | +---------------------+--------------------------------------+ Kh\u1edfi \u0111\u1ed9ng Listenner tr\u00ean LB2 [root@controller ~]# openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb2 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-16T01:29:25 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | 4f7e6386-37cd-4cd4-80d9-901b96f20f6c | | insert_headers | None | | l7policies | | | loadbalancers | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool s\u1eed d\u1ee5ng ROUND_ROBIN cho Listenner 1 ( s\u1eed d\u1ee5ng ID echo Listenner ) [root@controller ~]# openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener 4f7e6386-37cd-4cd4-80d9-901b96f20f6c --protocol HTTP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T01:30:05 | | description | | | healthmonitor_id | | | id | d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 | | lb_algorithm | ROUND_ROBIN | | listeners | 4f7e6386-37cd-4cd4-80d9-901b96f20f6c | | loadbalancers | e26ee169-004a-4a6f-baaf-3bc6bcb42df6 | | members | | | name | pool1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | provisioning_status | PENDING_CREATE | | session_persistence | None | | updated_at | None | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Heath Monitor tr\u00ean Pools 1 ( s\u1eed d\u1ee5ng Pool ID ) openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 Kh\u1edfi t\u1ea1o Pool Member tr\u00ean Pool 1 ( s\u1eed d\u1ee5ng Pool ID ) [root@controller ~]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.8 | | admin_state_up | True | | created_at | 2019-01-16T01:33:30 | | id | c2cb897e-8dfe-48b3-9b38-92b9fd5aecde | | name | | | operating_status | NO_MONITOR | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ [root@controller ~]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.8 --protocol-port 80 d0b7ee78-27e0-4b4a-9bb8-bbba416b8995 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.8 | | admin_state_up | True | | created_at | 2019-01-16T01:59:13 | | id | 4671aff1-6f96-46bf-b4b8-e1fe06468389 | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ V\u1edbi c\u00e1c Web Server Nginx \u0111ang s\u1eed d\u1ee5ng IP Public . C\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh th\u00eam ch\u1ec9 cho nh\u1eadn c\u00e1c request t\u1eeb VIP Load Balancer. B\u01b0\u1edbc \u0111\u1ea7u t\u1ea1o m\u1ed9t file trong folder nginx tao m\u1ed9t file server.blacklist v\u1edbi n\u1ed9i dung sau allow 1.2.3.4; # Allow a single remote host deny all; # Deny everyone else","title":"3. Kh\u1edfi t\u1ea1o Load Balancer s\u1eed d\u1ee5ng Provider"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/","text":"C\u1ea5u h\u00ecnh Octavia theo mode ACTIVE_STANDBY \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean section Worker \u00b6 M\u00f4 h\u00ecnh Th\u00eam c\u00e1c option sau v\u00e0o section controller_worker workers = 2 loadbalancer_topology = ACTIVE_STANDBY Update database octavia-db-manage upgrade head Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart octavia-api.service systemctl restart octavia-worker.service systemctl restart octavia-health-manager.service systemctl restart octavia-housekeeping.service 2. Kh\u1edfi t\u1ea1o Load Blancer s\u1eed d\u1ee5ng mode ACTIVE_STANDBY \u00b6 2.1 : Kh\u1edfi t\u1ea1o Load Balancer \u00b6 Kh\u1edfi t\u1ea1o 2 m\u00e1y \u1ea3o tr\u00ean Subnet PRIVATE_VIP_220 Kh\u1edfi t\u1ea1o Load Balancer [root@controller octavia]# openstack loadbalancer create --name lb3 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T03:31:09 | | description | | | flavor | | | id | 95f399e5-094f-4dd5-ba28-830d409911e7 | | listeners | | | name | lb3 | | operating_status | OFFLINE | | pools | | | project_id | 9a3469a2c4a44995a3cd2e48cffde2e5 | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.30.145 | | vip_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | vip_port_id | 3144a1fa-a60e-49c5-90fb-90a76dd840be | | vip_qos_policy_id | None | | vip_subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Listenner [root@controller octavia]# openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb3 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-16T03:35:36 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | 799ea07e-f331-494e-941f-58cf0d0216e7 | | insert_headers | None | | l7policies | | | loadbalancers | 812e1d1a-a59e-42a9-84f5-9db1d321de4f | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool tr\u00ean Listenner [root@controller octavia]# openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener 799ea07e-f331-494e-941f-58cf0d0216e7 --protocol HTTP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T03:37:41 | | description | | | healthmonitor_id | | | id | 103549e8-c355-430b-ab63-16a9ddbc4c54 | | lb_algorithm | ROUND_ROBIN | | listeners | 799ea07e-f331-494e-941f-58cf0d0216e7 | | loadbalancers | 812e1d1a-a59e-42a9-84f5-9db1d321de4f | | members | | | name | pool1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | provisioning_status | PENDING_CREATE | | session_persistence | None | | updated_at | None | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool monitor [root@controller octavia]# openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | project_id | c346047f05064784a58f7dbb6394466e | | name | | | admin_state_up | True | | pools | 103549e8-c355-430b-ab63-16a9ddbc4c54 | | created_at | 2019-01-16T03:38:38 | | provisioning_status | PENDING_CREATE | | updated_at | None | | delay | 5 | | expected_codes | 200 | | max_retries | 4 | | http_method | GET | | timeout | 10 | | max_retries_down | 3 | | url_path | / | | type | HTTP | | id | 0724edb5-a776-4395-9a27-7c2c68081142 | | operating_status | OFFLINE | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool Member ( ch\u00ednh l\u00e0 2 webserver ) [root@controller octavia]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.6 --protocol-port 80 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.6 | | admin_state_up | True | | created_at | 2019-01-16T03:50:09 | | id | b8ead8e6-6223-49a6-942f-7fac845f320d | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ [root@controller octavia]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.26 --protocol-port 80 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.26 | | admin_state_up | True | | created_at | 2019-01-16T03:42:01 | | id | a251972f-4022-41f5-8edf-f9a6c2a628eb | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ V\u1ea5n \u0111\u1ec1 : Hi\u1ec7n t\u1ea1i \u0111\u1ed1i v\u1edbi b\u1ea3n Queens, v\u1edbi m\u1ed7i Load Balancer \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi Octavia s\u1ebd c\u00f3 \u00edt nh\u1ea5t 3 Port trong \u0111\u00f3 : v\u1edbi 1 port t\u1eeb lb-mgmnt-net, c\u00f2n l\u1ea1i t\u1eeb VIP-subnet v\u1edbi t\u00ean l\u00e0 \"loadbalancer-LOADBALANCER_ID\" v\u00e0 \"octavia-lb-vrrp-LOADBALNCER_ID\". \u0110\u1ed1i v\u1edbi QOS policy s\u1ebd \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng v\u00e0o port \"octavia-lb-vrrp-LOADBALNCER_ID\u201d 3. Ki\u1ec3m th\u1eed v\u00e0 Amphora \u00b6 3.1 . ROUND_ROBIN and Keep Alived \u00b6 Ki\u1ec3m th\u1eed ROUND_ROBIN [root@controller octavia]# curl 192.168.30.155 <h1> day la web 2 </h2> [root@controller octavia]# curl 192.168.30.155 <h1> day la web 1 </h2> T\u1eaft Service keepalived tr\u00ean Amphora 1 Ki\u1ec3m tra IP tr\u00ean Amphora 2 3.2 . Deep dive Amphora VM \u00b6 Amphora th\u1ef1c ch\u1ea5t l\u00e0 m\u1ed9t m\u00e1y \u1ea3o g\u1ed3m \u0111\u00e3 c\u00e0i HAproxy v\u00e0 KeepAlived c\u00f9ng v\u1edbi amphora-agent M\u00f4 h\u00ecnh logic c\u00e1c load balancer l\u00e0m vi\u1ec7c. C\u00e1ch Amphora giao ti\u1ebfp v\u1edbi heath-manager th\u00f4ng qua amphora-agent service T\u1ea1i 2 m\u00e1y \u1ea3o aphora \u0111\u01b0\u1ee3c t\u1ea1o bao g\u1ed3m 3 port : VIP, LB Network v\u00e0 WebServer Network Ki\u1ec3m tra namespace tr\u00ean c\u00e1c VM aphora s\u1ebd th\u1ea5y : port tham gia v\u00e0o qu\u00e1 tr\u00ecnh VRRP , port vIP v\u00e0 port WebServer Network Tr\u00ean Anphora 1 Tr\u00ean Anphora 2 Tr\u00ean c\u00e1c VM anphora s\u1ebd c\u00f3 octavia-anphora-agent nh\u1eb1m 2 nhi\u1ec7m v\u1ee5 k\u1ebft n\u1ed1i t\u1edbi octavia-heath-manager \u0111\u1ec3 tr\u1ea3 v\u1ec1 status hi\u1ec7n t\u1ea1i c\u1ee7a n\u00f3 nh\u1eadn l\u1ec7nh t\u1eeb API v\u00e0 th\u1ef1c thi c\u00e2u l\u1ec7nh d\u01b0\u1edbi d\u1ea1ng /usr/sbin/keepalived {action} \u0111\u1ec3 th\u1ef1c thi v\u1edbi keep alived v\u00e0 /usr/sbin/haproxy {action} \u0111\u1ec3 th\u1ef1c thi v\u1edbi haproxy T\u1eadp tin c\u1ea5u h\u00ecnh anphora-agent T\u1eadp tin c\u1ea5u h\u00ecnh service KeepAvlied T\u1eadp tin c\u1ea5u h\u00ecnh service HAProxy C\u00e1c t\u1eadp tin c\u1ea5u h\u00ecnh KeepAlived v\u00e0 Haproxy c\u1ee7a Anphorma \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /var/lib/octavia/ T\u1eadp tin c\u1ea5u h\u00ecnh Keep Avlied tr\u00ean Anphora 1 T\u1eadp tin c\u1ea5u h\u00ecnh Keep Avlied tr\u00ean Anphora 2 T\u1eadp tin c\u1ea5u h\u00ecnh HAProxy Ki\u1ec3m tra log VRRP ' S\u1eed d\u1ee5ng brower g\u1eedi request \u0111\u1ebfn VIP End ./","title":"3. Octavia Keep Alived"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#cau_hinh_octavia_theo_mode_active_standby","text":"","title":"C\u1ea5u h\u00ecnh Octavia theo mode ACTIVE_STANDBY"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#1_cau_hinh_tren_section_worker","text":"M\u00f4 h\u00ecnh Th\u00eam c\u00e1c option sau v\u00e0o section controller_worker workers = 2 loadbalancer_topology = ACTIVE_STANDBY Update database octavia-db-manage upgrade head Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart octavia-api.service systemctl restart octavia-worker.service systemctl restart octavia-health-manager.service systemctl restart octavia-housekeeping.service","title":"1. C\u1ea5u h\u00ecnh tr\u00ean section Worker"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#2_khoi_tao_load_blancer_su_dung_mode_active_standby","text":"","title":"2. Kh\u1edfi t\u1ea1o Load Blancer s\u1eed d\u1ee5ng  mode ACTIVE_STANDBY"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#21_khoi_tao_load_balancer","text":"Kh\u1edfi t\u1ea1o 2 m\u00e1y \u1ea3o tr\u00ean Subnet PRIVATE_VIP_220 Kh\u1edfi t\u1ea1o Load Balancer [root@controller octavia]# openstack loadbalancer create --name lb3 --vip-subnet-id PUBLIC_IP_30 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T03:31:09 | | description | | | flavor | | | id | 95f399e5-094f-4dd5-ba28-830d409911e7 | | listeners | | | name | lb3 | | operating_status | OFFLINE | | pools | | | project_id | 9a3469a2c4a44995a3cd2e48cffde2e5 | | provider | octavia | | provisioning_status | PENDING_CREATE | | updated_at | None | | vip_address | 192.168.30.145 | | vip_network_id | c608ac10-d6a4-4e96-bb38-96a869a36b36 | | vip_port_id | 3144a1fa-a60e-49c5-90fb-90a76dd840be | | vip_qos_policy_id | None | | vip_subnet_id | 33d66aab-062e-42ab-b9f6-d72dcceafdd7 | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Listenner [root@controller octavia]# openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb3 +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2019-01-16T03:35:36 | | default_pool_id | None | | default_tls_container_ref | None | | description | | | id | 799ea07e-f331-494e-941f-58cf0d0216e7 | | insert_headers | None | | l7policies | | | loadbalancers | 812e1d1a-a59e-42a9-84f5-9db1d321de4f | | name | listener1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | updated_at | None | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool tr\u00ean Listenner [root@controller octavia]# openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener 799ea07e-f331-494e-941f-58cf0d0216e7 --protocol HTTP +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | admin_state_up | True | | created_at | 2019-01-16T03:37:41 | | description | | | healthmonitor_id | | | id | 103549e8-c355-430b-ab63-16a9ddbc4c54 | | lb_algorithm | ROUND_ROBIN | | listeners | 799ea07e-f331-494e-941f-58cf0d0216e7 | | loadbalancers | 812e1d1a-a59e-42a9-84f5-9db1d321de4f | | members | | | name | pool1 | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol | HTTP | | provisioning_status | PENDING_CREATE | | session_persistence | None | | updated_at | None | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool monitor [root@controller octavia]# openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | project_id | c346047f05064784a58f7dbb6394466e | | name | | | admin_state_up | True | | pools | 103549e8-c355-430b-ab63-16a9ddbc4c54 | | created_at | 2019-01-16T03:38:38 | | provisioning_status | PENDING_CREATE | | updated_at | None | | delay | 5 | | expected_codes | 200 | | max_retries | 4 | | http_method | GET | | timeout | 10 | | max_retries_down | 3 | | url_path | / | | type | HTTP | | id | 0724edb5-a776-4395-9a27-7c2c68081142 | | operating_status | OFFLINE | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Pool Member ( ch\u00ednh l\u00e0 2 webserver ) [root@controller octavia]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.6 --protocol-port 80 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.6 | | admin_state_up | True | | created_at | 2019-01-16T03:50:09 | | id | b8ead8e6-6223-49a6-942f-7fac845f320d | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ [root@controller octavia]# openstack loadbalancer member create --subnet-id PRIVATE_VIP_200 --address 192.168.220.26 --protocol-port 80 103549e8-c355-430b-ab63-16a9ddbc4c54 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | address | 192.168.220.26 | | admin_state_up | True | | created_at | 2019-01-16T03:42:01 | | id | a251972f-4022-41f5-8edf-f9a6c2a628eb | | name | | | operating_status | OFFLINE | | project_id | c346047f05064784a58f7dbb6394466e | | protocol_port | 80 | | provisioning_status | PENDING_CREATE | | subnet_id | 5f933cdb-7aec-401c-bed1-b4f17e78194d | | updated_at | None | | weight | 1 | | monitor_port | None | | monitor_address | None | +---------------------+--------------------------------------+ V\u1ea5n \u0111\u1ec1 : Hi\u1ec7n t\u1ea1i \u0111\u1ed1i v\u1edbi b\u1ea3n Queens, v\u1edbi m\u1ed7i Load Balancer \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi Octavia s\u1ebd c\u00f3 \u00edt nh\u1ea5t 3 Port trong \u0111\u00f3 : v\u1edbi 1 port t\u1eeb lb-mgmnt-net, c\u00f2n l\u1ea1i t\u1eeb VIP-subnet v\u1edbi t\u00ean l\u00e0 \"loadbalancer-LOADBALANCER_ID\" v\u00e0 \"octavia-lb-vrrp-LOADBALNCER_ID\". \u0110\u1ed1i v\u1edbi QOS policy s\u1ebd \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng v\u00e0o port \"octavia-lb-vrrp-LOADBALNCER_ID\u201d","title":"2.1 : Kh\u1edfi t\u1ea1o Load Balancer"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#3_kiem_thu_va_amphora","text":"","title":"3. Ki\u1ec3m th\u1eed v\u00e0 Amphora"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#31_round_robin_and_keep_alived","text":"Ki\u1ec3m th\u1eed ROUND_ROBIN [root@controller octavia]# curl 192.168.30.155 <h1> day la web 2 </h2> [root@controller octavia]# curl 192.168.30.155 <h1> day la web 1 </h2> T\u1eaft Service keepalived tr\u00ean Amphora 1 Ki\u1ec3m tra IP tr\u00ean Amphora 2","title":"3.1 . ROUND_ROBIN and Keep Alived"},{"location":"Openstack_Research/High-availability/2. Octavia/3. Octavia-Keep-Alived/#32_deep_dive_amphora_vm","text":"Amphora th\u1ef1c ch\u1ea5t l\u00e0 m\u1ed9t m\u00e1y \u1ea3o g\u1ed3m \u0111\u00e3 c\u00e0i HAproxy v\u00e0 KeepAlived c\u00f9ng v\u1edbi amphora-agent M\u00f4 h\u00ecnh logic c\u00e1c load balancer l\u00e0m vi\u1ec7c. C\u00e1ch Amphora giao ti\u1ebfp v\u1edbi heath-manager th\u00f4ng qua amphora-agent service T\u1ea1i 2 m\u00e1y \u1ea3o aphora \u0111\u01b0\u1ee3c t\u1ea1o bao g\u1ed3m 3 port : VIP, LB Network v\u00e0 WebServer Network Ki\u1ec3m tra namespace tr\u00ean c\u00e1c VM aphora s\u1ebd th\u1ea5y : port tham gia v\u00e0o qu\u00e1 tr\u00ecnh VRRP , port vIP v\u00e0 port WebServer Network Tr\u00ean Anphora 1 Tr\u00ean Anphora 2 Tr\u00ean c\u00e1c VM anphora s\u1ebd c\u00f3 octavia-anphora-agent nh\u1eb1m 2 nhi\u1ec7m v\u1ee5 k\u1ebft n\u1ed1i t\u1edbi octavia-heath-manager \u0111\u1ec3 tr\u1ea3 v\u1ec1 status hi\u1ec7n t\u1ea1i c\u1ee7a n\u00f3 nh\u1eadn l\u1ec7nh t\u1eeb API v\u00e0 th\u1ef1c thi c\u00e2u l\u1ec7nh d\u01b0\u1edbi d\u1ea1ng /usr/sbin/keepalived {action} \u0111\u1ec3 th\u1ef1c thi v\u1edbi keep alived v\u00e0 /usr/sbin/haproxy {action} \u0111\u1ec3 th\u1ef1c thi v\u1edbi haproxy T\u1eadp tin c\u1ea5u h\u00ecnh anphora-agent T\u1eadp tin c\u1ea5u h\u00ecnh service KeepAvlied T\u1eadp tin c\u1ea5u h\u00ecnh service HAProxy C\u00e1c t\u1eadp tin c\u1ea5u h\u00ecnh KeepAlived v\u00e0 Haproxy c\u1ee7a Anphorma \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /var/lib/octavia/ T\u1eadp tin c\u1ea5u h\u00ecnh Keep Avlied tr\u00ean Anphora 1 T\u1eadp tin c\u1ea5u h\u00ecnh Keep Avlied tr\u00ean Anphora 2 T\u1eadp tin c\u1ea5u h\u00ecnh HAProxy Ki\u1ec3m tra log VRRP ' S\u1eed d\u1ee5ng brower g\u1eedi request \u0111\u1ebfn VIP End ./","title":"3.2 . Deep dive Amphora VM"},{"location":"Openstack_Research/High-availability/2. Octavia/4 .VIP-QOS/","text":"VIP-QOS trong Octavia \u00b6 1. QOS trong OCtavia \u00b6 Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p th\u00ec ch\u00fang ta c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n bandwith c\u1ee7a c\u00e1c VIP . Trong m\u00f4i tr\u01b0\u1eddng production, ch\u00fang ta kh\u00f4ng th\u1ec3 cho ph\u00e9p c\u00e1c server k\u1ebft n\u1ed1i ra m\u1ea1ng ngo\u00e0i m\u00e0 kh\u00f4ng c\u00f3 gi\u1edbi h\u1ea1n , v\u00ec v\u1eady ta c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng c\u00e1c VM n\u00e0y t\u1ea1i VIP Port \u0110\u1ec3 s\u1eed d\u1ee5ng QOS trong Octavia ch\u00fang ta c\u1ea7n Neutron QOS extension \u0111\u00e3 c\u00e0i \u0111\u1eb7t s\u1eb5n . Tham kh\u1ea3o c\u00e0i \u0111\u1eb7t t\u1ea1i \u0111\u00e2y Hi\u1ec7n t\u1ea1i \u0111\u1ed1i v\u1edbi b\u1ea3n Queens, v\u1edbi m\u1ed7i Load Balancer \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi Octavia s\u1ebd c\u00f3 \u00edt nh\u1ea5t 3 Port trong \u0111\u00f3 : v\u1edbi 1 port t\u1eeb lb-mgmnt-net, c\u00f2n l\u1ea1i t\u1eeb VIP-subnet v\u1edbi t\u00ean l\u00e0 \"loadbalancer-LOADBALANCER_ID\" v\u00e0 \"octavia-lb-vrrp-LOADBALNCER_ID\". \u0110\u1ed1i v\u1edbi QOS policy s\u1ebd \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng v\u00e0o port \"octavia-lb-vrrp-LOADBALNCER_ID\u201d Ch\u00fang ta c\u00f3 th\u1ec3 \u00e1p d\u1ee5ng c\u00e1c Neutron QOS v\u00e0o \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d port \u1edf c\u1ea3 2 mode : ACTIVE_STANDBY v\u00e0 SINGEL 2. \u00c1p d\u1ee5ng VIP QOS Policy \u00b6 Kh\u1edfi t\u1ea1o m\u1ed9t Policy m\u1edbi [LAB]# openstack network qos policy create vIP-normal +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | description | | | id | 1d7f5dea-2db3-4f6a-822b-bde20d50e1b7 | | is_default | False | | name | vIP-normal | | project_id | c346047f05064784a58f7dbb6394466e | | rules | [] | | shared | False | +-------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Rule m\u1edbi [LAB]openstack network qos rule create --type bandwidth-limit --max-kbps 512 \\ > --max-burst-kbits 360 --ingress vIP-normal +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | direction | egress | | id | 5ebc1c07-3aac-4979-99f0-1bdf8a031468 | | max_burst_kbps | 360 | | max_kbps | 512 | | name | None | | project_id | | +----------------+--------------------------------------+ G\u00e1n Policy cho L3 [LAB]openstack loadbalancer set --vip-qos-policy-id 1d7f5dea-2db3-4f6a-822b-bde20d50e1b7 lb3 Ki\u1ec3m th\u1eed. C\u00e0i \u0111\u1eb7t ipert3 tr\u00ean VM ( Pool member c\u1ee7a LB3 ) v\u00e0 host kh\u00e1c S\u1eed d\u1ee5ng Pool member l\u00e0m iperf server. Sau \u0111\u00f3 t\u1eeb m\u1ed9t host kh\u00e1c l\u00e0m client, call \u0111\u1ebfn IP Public c\u1ee7a Load Balancer Host Client g\u1eedi \u0111\u1ebfn IP Public c\u1ee7a Load Balancer","title":"4 .VIP QOS"},{"location":"Openstack_Research/High-availability/2. Octavia/4 .VIP-QOS/#vip-qos_trong_octavia","text":"","title":"VIP-QOS trong Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/4 .VIP-QOS/#1_qos_trong_octavia","text":"Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p th\u00ec ch\u00fang ta c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n bandwith c\u1ee7a c\u00e1c VIP . Trong m\u00f4i tr\u01b0\u1eddng production, ch\u00fang ta kh\u00f4ng th\u1ec3 cho ph\u00e9p c\u00e1c server k\u1ebft n\u1ed1i ra m\u1ea1ng ngo\u00e0i m\u00e0 kh\u00f4ng c\u00f3 gi\u1edbi h\u1ea1n , v\u00ec v\u1eady ta c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n b\u0103ng th\u00f4ng c\u00e1c VM n\u00e0y t\u1ea1i VIP Port \u0110\u1ec3 s\u1eed d\u1ee5ng QOS trong Octavia ch\u00fang ta c\u1ea7n Neutron QOS extension \u0111\u00e3 c\u00e0i \u0111\u1eb7t s\u1eb5n . Tham kh\u1ea3o c\u00e0i \u0111\u1eb7t t\u1ea1i \u0111\u00e2y Hi\u1ec7n t\u1ea1i \u0111\u1ed1i v\u1edbi b\u1ea3n Queens, v\u1edbi m\u1ed7i Load Balancer \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o b\u1edfi Octavia s\u1ebd c\u00f3 \u00edt nh\u1ea5t 3 Port trong \u0111\u00f3 : v\u1edbi 1 port t\u1eeb lb-mgmnt-net, c\u00f2n l\u1ea1i t\u1eeb VIP-subnet v\u1edbi t\u00ean l\u00e0 \"loadbalancer-LOADBALANCER_ID\" v\u00e0 \"octavia-lb-vrrp-LOADBALNCER_ID\". \u0110\u1ed1i v\u1edbi QOS policy s\u1ebd \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng v\u00e0o port \"octavia-lb-vrrp-LOADBALNCER_ID\u201d Ch\u00fang ta c\u00f3 th\u1ec3 \u00e1p d\u1ee5ng c\u00e1c Neutron QOS v\u00e0o \u201coctavia-lb-vrrp-LOADBALNCER_ID\u201d port \u1edf c\u1ea3 2 mode : ACTIVE_STANDBY v\u00e0 SINGEL","title":"1. QOS trong OCtavia"},{"location":"Openstack_Research/High-availability/2. Octavia/4 .VIP-QOS/#2_ap_dung_vip_qos_policy","text":"Kh\u1edfi t\u1ea1o m\u1ed9t Policy m\u1edbi [LAB]# openstack network qos policy create vIP-normal +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | description | | | id | 1d7f5dea-2db3-4f6a-822b-bde20d50e1b7 | | is_default | False | | name | vIP-normal | | project_id | c346047f05064784a58f7dbb6394466e | | rules | [] | | shared | False | +-------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Rule m\u1edbi [LAB]openstack network qos rule create --type bandwidth-limit --max-kbps 512 \\ > --max-burst-kbits 360 --ingress vIP-normal +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | direction | egress | | id | 5ebc1c07-3aac-4979-99f0-1bdf8a031468 | | max_burst_kbps | 360 | | max_kbps | 512 | | name | None | | project_id | | +----------------+--------------------------------------+ G\u00e1n Policy cho L3 [LAB]openstack loadbalancer set --vip-qos-policy-id 1d7f5dea-2db3-4f6a-822b-bde20d50e1b7 lb3 Ki\u1ec3m th\u1eed. C\u00e0i \u0111\u1eb7t ipert3 tr\u00ean VM ( Pool member c\u1ee7a LB3 ) v\u00e0 host kh\u00e1c S\u1eed d\u1ee5ng Pool member l\u00e0m iperf server. Sau \u0111\u00f3 t\u1eeb m\u1ed9t host kh\u00e1c l\u00e0m client, call \u0111\u1ebfn IP Public c\u1ee7a Load Balancer Host Client g\u1eedi \u0111\u1ebfn IP Public c\u1ee7a Load Balancer","title":"2. \u00c1p d\u1ee5ng VIP QOS Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/","text":"Octavia L7 Policy \u00b6 1. L7 Policy l\u00e0 g\u00ec ? \u00b6 Layer 7 Load Balancing l\u00e0 kh\u00e1i ni\u1ec7m \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb m\u00f4 h\u00ecnh m\u1ea1ng OSI, mu\u1ed1n ch\u1ec9 ra c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i ph\u00e2n ph\u1ed1i c\u00e1c request t\u1edbi c\u00e1c back-end d\u1ef1a v\u00e0o d\u1eef li\u1ec7u layer7 ( application layer ). Layer 7 Load Balancing c\u00f3 th\u1ec3 thay th\u1ebf b\u1eb1ng c\u00e1c kh\u00e1i ni\u1ec7m kh\u00e1c : request switching, application load balacing, content based routing, content based switching, content based balancing. Layer 7 load balancer bao g\u1ed3m m\u1ed9t listener m\u00e0 ch\u1ea5p nh\u1eadn c\u00e1c request v\u00e0 ph\u00e2n t\u00e1n c\u00e1c request t\u1edbi c\u00e1c back-end pool d\u1ef1a v\u00e0o c\u00e1c ch\u00ednh s\u00e1ch m\u00e0 s\u1eed d\u1ee5ng c\u00e1c d\u1eef li\u1ec7u c\u1ee7a \u1ee9ng d\u1ee5ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh pools n\u00e0o c\u00f3 th\u1ec3 \u0111\u1ea3m nhi\u1ec7m request n\u00e0y \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 gi\u00fap cho vi\u1ec7c t\u1ed1i \u01b0u,\u0111i\u1ec1u ch\u1ec9nh h\u1ea1 t\u1ea7ng t\u00f9y thu\u1ed9c v\u00e0o t\u1eebng lo\u1ea1i content. V\u00ed d\u1ee5 \u0111i\u1ec3m h\u00ecnh cho m\u1ed9t Web Application theo m\u00f4 h\u00ecnh server-side , x\u00e2y d\u1ef1ng m\u1ed9t h\u1ea1 t\u1ea7ng bao g\u1ed3m nhi\u1ec1u pool, m\u1ed7i pool s\u1ebd \u0111\u1ea3m nhi\u1ec7m \u0111\u1ea3m nhi\u1ec7m c\u00e1c nhi\u1ec7m v\u1ee5 kh\u00e1c nhau. Pools s\u1ebd \u0111\u1ea3m nhi\u1ec7m l\u01b0u tr\u1eef c\u00e1c h\u00ecnh \u1ea3nh t\u1ea3i l\u00ean t\u1eeb ng\u01b0\u1eddi d\u00f9ng, c\u00f2n Pool 2 s\u1ebd \u0111\u1ea3m nhi\u1ec7m c\u00e1c d\u1eef li\u1ec7u t\u0129nh \u00edt thay \u0111\u1ed5i Trong th\u1ef1c t\u1ebf, Layer 7 Load Balancer s\u1ebd kh\u00f4ng y\u00eau c\u1ea7u c\u00e1c pool tham gia v\u00e0o qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i c\u00f9ng m\u1ed9t n\u1ed9i dung. Layer. \u0110\u1ed1i v\u1edbi c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i c\u00f3 s\u1eed d\u1ee5ng c\u00e1c L7 Policy s\u1ebd chuy\u1ec3n c\u00e1c request d\u1ef1a v\u00e0o Header, host, URl... 2 . L7 Load Balancing trong Octavia \u00b6 Trong Octavia, Layer 7 Load Balancing hi\u1ec7n ch\u1ec9 l\u00e0m vi\u1ec7c v\u1edbi giao th\u1ee9c HTTP 2.1. L7 Rule \u00b6 Trong Octavia, c\u00e1c L7 Rule c\u00e1c ph\u00e9p ki\u1ec3m tra s\u1ebd tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 Trule ho\u1eb7c False . Cc\u00e1c rule n\u00e0y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb m\u1ed9t ph\u00e9p so s\u00e1nh v\u1edbi c\u1eb7p kh\u00f3a Rule_type = Value Octavia h\u1ed7 tr\u1ee3 c\u00e1c ki\u1ec3u so s\u00e1nh sau \u0111\u00e2y : REGEX : s\u1eed d\u1ee5ng regular expression STARTS_WITH : \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u v\u1edbi v\u1edbi chu\u1ed7i ho\u1eb7c k\u00fd t\u1ef1 n\u00e0o \u0111\u00f3 ENDS_WITH : \u0111\u01b0\u1ee3c k\u1ebft th\u00fac v\u1edbi chu\u1ed7i ho\u1eb7c k\u00fd t\u1ef1 n\u00e0o \u0111\u00f3 CONTAINS : ch\u1ee9a chu\u1ed7i n\u00e0o \u0111\u00f3 EQUAL_TO : b\u1eb1ng chu\u1ed7i n\u00e0o \u0111\u00f3 L7 Policy c\u00f3 c\u00e1c lo\u1ea1i sau: Hostname : t\u00ean hostname trong request PATH : HTTP URI FILE_TYPE : d\u1ef1a v\u00e0o ph\u1ea7n m\u1edf r\u1ed9ng c\u1ee7a HTTP URL ( txt, png, js ) HEADER : d\u1ef1a v\u00e0o c\u00e1c header c\u1ee7a request Cookie : d\u1ef1a v\u00e0o cookie trong request C\u00e1c Value t\u00f9y thu\u1ed9c v\u00e0o t\u1eebng m\u00f4i tr\u01b0\u1eddng 2.2 : L7 Policy \u00b6 L7 Policy bao g\u1ed3m c\u00e1c L7 Rule c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o m\u1ed9t Listener m\u00e0 \u0111\u00e3 g\u1eafn m\u1ed9t back-end pool. Policy s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n n\u1ebfu c\u00e1c rule \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o policy n\u00e0y tr\u1ea3 v\u1ec1 gi\u00e1 tr\u1ecb True T\u1ea5t c\u1ea3 c\u00e1c Rule trong Policy s\u1ebd nh\u01b0 m\u1ed9t ph\u00e9p to\u00e1n AND . V\u00ed d\u1ee5 matching 1 && matching 2 && return true | return false V\u1edbi k\u1ebft qu\u1ea3 \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 t\u1eeb ph\u00e9p to\u00e1n Rule l\u00e0 Trule , Policy s\u1ebd th\u1ef1c hi\u1ec7n c\u00e1c Policy Action. 2.3 . Policy Action \u00b6 C\u00e1c h\u00e0nh \u0111\u1ed9ng sau \u0111\u00e2y m\u00e0 c\u00e1c Policy c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n REJECT : c\u00f3 th\u1ec3 tr\u1ea3 v\u1ec1 m\u1ed9t response code v\u00e0 kh\u00f4ng chuy\u1ec3n ti\u1ebfp request v\u1ec1 m\u1ed9t pool n\u00e0o REDIRECT_TO_URL : s\u1eed d\u1ee5ng HTTP redirect chuy\u1ec3n ti\u1ebfp request t\u1edbi m\u1ed9t URL m\u1edbi REDIRECT_TO_POOL : chuy\u1ec3n ti\u1ebfp request t\u1edbi m\u1ed9t backend \u0111\u1ec3 x\u1eed l\u00fd V\u1edbi HAproxy th\u1ee9 t\u1ef1 \u01b0u ti\u00ean c\u00e1c Policy action t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi nh\u01b0 sau : REJECT, REDIRECT_TO_URL, REDIRECT_TO_POOL. 2.4 : Policy Postion \u00b6 Khi c\u00f3 nhi\u1ec1u c\u00e1c policy \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o m\u1ed9t listener, th\u00ec v\u1ecb tr\u00ed c\u1ee7a n\u00f3 trog list n\u00e0y tr\u1edf n\u00ean quan tr\u1ecdng. V\u1ecb tr\u00ed n\u00e0y x\u00e1c \u0111\u1ecbnh th\u1ee9 t\u1ef1 m\u00e0 c\u00e1c Policy n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 note trong khi s\u1eed d\u1ee5ng Octavia m\u00f4i tr\u01b0\u1eddng multi policies V\u1edbi HAproxy th\u1ee9 t\u1ef1 \u01b0u ti\u00ean c\u00e1c Policy action t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi nh\u01b0 sau : REJECT, REDIRECT_TO_URL, REDIRECT_TO_POOL N\u1ebfu kh\u00f4ng policy n\u00e0o x\u1eed l\u00fd \u0111\u01b0\u1ee3c request, c\u00e1c request s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn default pool ( n\u1ebfu c\u00f3 ) ho\u1eb7c kh\u00f4ng s\u1ebd tr\u1ea3 v\u1ec1 status code 503 Policy L7 \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 theo m\u1ed9t th\u1ee9 t\u1ef1 c\u1ee5 th\u1ec3 (nh\u01b0 \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi thu\u1ed9c t\u00ednh v\u1ecb tr\u00ed) v\u00e0 policy \u0111\u1ea7u ti\u00ean ph\u00f9 h\u1ee3p v\u1edbi request s\u1ebd \u0111\u1ea3m nhi\u1ec7m x\u1eed l\u00fd n\u00f3 V\u1ecb tr\u00ed c\u1ee7a Policy s\u1ebd b\u1eaft \u0111\u1ea7u b\u1eb1ng 1 N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch m\u1edbi \u0111\u01b0\u1ee3c t\u1ea1o v\u1edbi m\u1ed9t v\u1ecb tr\u00ed tr\u00f9ng v\u1edbi ch\u00ednh s\u00e1ch hi\u1ec7n c\u00f3, th\u00ec ch\u00ednh s\u00e1ch m\u1edbi s\u1ebd \u0111\u01b0\u1ee3c ch\u00e8n v\u00e0o v\u1ecb tr\u00ed \u0111\u1ea5y, \u0111\u1ea9y l\u00f9i ch\u00ednh s\u00e1ch c\u0169 N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o m\u00e0 kh\u00f4ng ch\u1ec9 \u0111\u1ecbnh v\u1ecb tr\u00ed s\u1ebd \u0111\u01b0\u1ee3c append v\u00e0o v\u1edbi v\u1ecb tr\u00ed list_range N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch tr\u01b0\u1edbc n\u00f3 b\u1ecb x\u00f3a, c\u00e1c ch\u00ednh s\u00e1ch sau s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea9y l\u00ean m\u1ed9t \u0111\u01a1n v\u1ecb End ./","title":"5.Theory Octavia L7 Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#octavia_l7_policy","text":"","title":"Octavia L7 Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#1_l7_policy_la_gi","text":"Layer 7 Load Balancing l\u00e0 kh\u00e1i ni\u1ec7m \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb m\u00f4 h\u00ecnh m\u1ea1ng OSI, mu\u1ed1n ch\u1ec9 ra c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i ph\u00e2n ph\u1ed1i c\u00e1c request t\u1edbi c\u00e1c back-end d\u1ef1a v\u00e0o d\u1eef li\u1ec7u layer7 ( application layer ). Layer 7 Load Balancing c\u00f3 th\u1ec3 thay th\u1ebf b\u1eb1ng c\u00e1c kh\u00e1i ni\u1ec7m kh\u00e1c : request switching, application load balacing, content based routing, content based switching, content based balancing. Layer 7 load balancer bao g\u1ed3m m\u1ed9t listener m\u00e0 ch\u1ea5p nh\u1eadn c\u00e1c request v\u00e0 ph\u00e2n t\u00e1n c\u00e1c request t\u1edbi c\u00e1c back-end pool d\u1ef1a v\u00e0o c\u00e1c ch\u00ednh s\u00e1ch m\u00e0 s\u1eed d\u1ee5ng c\u00e1c d\u1eef li\u1ec7u c\u1ee7a \u1ee9ng d\u1ee5ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh pools n\u00e0o c\u00f3 th\u1ec3 \u0111\u1ea3m nhi\u1ec7m request n\u00e0y \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 gi\u00fap cho vi\u1ec7c t\u1ed1i \u01b0u,\u0111i\u1ec1u ch\u1ec9nh h\u1ea1 t\u1ea7ng t\u00f9y thu\u1ed9c v\u00e0o t\u1eebng lo\u1ea1i content. V\u00ed d\u1ee5 \u0111i\u1ec3m h\u00ecnh cho m\u1ed9t Web Application theo m\u00f4 h\u00ecnh server-side , x\u00e2y d\u1ef1ng m\u1ed9t h\u1ea1 t\u1ea7ng bao g\u1ed3m nhi\u1ec1u pool, m\u1ed7i pool s\u1ebd \u0111\u1ea3m nhi\u1ec7m \u0111\u1ea3m nhi\u1ec7m c\u00e1c nhi\u1ec7m v\u1ee5 kh\u00e1c nhau. Pools s\u1ebd \u0111\u1ea3m nhi\u1ec7m l\u01b0u tr\u1eef c\u00e1c h\u00ecnh \u1ea3nh t\u1ea3i l\u00ean t\u1eeb ng\u01b0\u1eddi d\u00f9ng, c\u00f2n Pool 2 s\u1ebd \u0111\u1ea3m nhi\u1ec7m c\u00e1c d\u1eef li\u1ec7u t\u0129nh \u00edt thay \u0111\u1ed5i Trong th\u1ef1c t\u1ebf, Layer 7 Load Balancer s\u1ebd kh\u00f4ng y\u00eau c\u1ea7u c\u00e1c pool tham gia v\u00e0o qu\u00e1 tr\u00ecnh c\u00e2n b\u1eb1ng t\u1ea3i c\u00f9ng m\u1ed9t n\u1ed9i dung. Layer. \u0110\u1ed1i v\u1edbi c\u00e1c b\u1ed9 c\u00e2n b\u1eb1ng t\u1ea3i c\u00f3 s\u1eed d\u1ee5ng c\u00e1c L7 Policy s\u1ebd chuy\u1ec3n c\u00e1c request d\u1ef1a v\u00e0o Header, host, URl...","title":"1. L7 Policy l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#2_l7_load_balancing_trong_octavia","text":"Trong Octavia, Layer 7 Load Balancing hi\u1ec7n ch\u1ec9 l\u00e0m vi\u1ec7c v\u1edbi giao th\u1ee9c HTTP","title":"2 . L7 Load Balancing trong Octavia"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#21_l7_rule","text":"Trong Octavia, c\u00e1c L7 Rule c\u00e1c ph\u00e9p ki\u1ec3m tra s\u1ebd tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 Trule ho\u1eb7c False . Cc\u00e1c rule n\u00e0y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb m\u1ed9t ph\u00e9p so s\u00e1nh v\u1edbi c\u1eb7p kh\u00f3a Rule_type = Value Octavia h\u1ed7 tr\u1ee3 c\u00e1c ki\u1ec3u so s\u00e1nh sau \u0111\u00e2y : REGEX : s\u1eed d\u1ee5ng regular expression STARTS_WITH : \u0111\u01b0\u1ee3c b\u1eaft \u0111\u1ea7u v\u1edbi v\u1edbi chu\u1ed7i ho\u1eb7c k\u00fd t\u1ef1 n\u00e0o \u0111\u00f3 ENDS_WITH : \u0111\u01b0\u1ee3c k\u1ebft th\u00fac v\u1edbi chu\u1ed7i ho\u1eb7c k\u00fd t\u1ef1 n\u00e0o \u0111\u00f3 CONTAINS : ch\u1ee9a chu\u1ed7i n\u00e0o \u0111\u00f3 EQUAL_TO : b\u1eb1ng chu\u1ed7i n\u00e0o \u0111\u00f3 L7 Policy c\u00f3 c\u00e1c lo\u1ea1i sau: Hostname : t\u00ean hostname trong request PATH : HTTP URI FILE_TYPE : d\u1ef1a v\u00e0o ph\u1ea7n m\u1edf r\u1ed9ng c\u1ee7a HTTP URL ( txt, png, js ) HEADER : d\u1ef1a v\u00e0o c\u00e1c header c\u1ee7a request Cookie : d\u1ef1a v\u00e0o cookie trong request C\u00e1c Value t\u00f9y thu\u1ed9c v\u00e0o t\u1eebng m\u00f4i tr\u01b0\u1eddng","title":"2.1. L7 Rule"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#22_l7_policy","text":"L7 Policy bao g\u1ed3m c\u00e1c L7 Rule c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o m\u1ed9t Listener m\u00e0 \u0111\u00e3 g\u1eafn m\u1ed9t back-end pool. Policy s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n n\u1ebfu c\u00e1c rule \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o policy n\u00e0y tr\u1ea3 v\u1ec1 gi\u00e1 tr\u1ecb True T\u1ea5t c\u1ea3 c\u00e1c Rule trong Policy s\u1ebd nh\u01b0 m\u1ed9t ph\u00e9p to\u00e1n AND . V\u00ed d\u1ee5 matching 1 && matching 2 && return true | return false V\u1edbi k\u1ebft qu\u1ea3 \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 t\u1eeb ph\u00e9p to\u00e1n Rule l\u00e0 Trule , Policy s\u1ebd th\u1ef1c hi\u1ec7n c\u00e1c Policy Action.","title":"2.2 : L7 Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#23_policy_action","text":"C\u00e1c h\u00e0nh \u0111\u1ed9ng sau \u0111\u00e2y m\u00e0 c\u00e1c Policy c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n REJECT : c\u00f3 th\u1ec3 tr\u1ea3 v\u1ec1 m\u1ed9t response code v\u00e0 kh\u00f4ng chuy\u1ec3n ti\u1ebfp request v\u1ec1 m\u1ed9t pool n\u00e0o REDIRECT_TO_URL : s\u1eed d\u1ee5ng HTTP redirect chuy\u1ec3n ti\u1ebfp request t\u1edbi m\u1ed9t URL m\u1edbi REDIRECT_TO_POOL : chuy\u1ec3n ti\u1ebfp request t\u1edbi m\u1ed9t backend \u0111\u1ec3 x\u1eed l\u00fd V\u1edbi HAproxy th\u1ee9 t\u1ef1 \u01b0u ti\u00ean c\u00e1c Policy action t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi nh\u01b0 sau : REJECT, REDIRECT_TO_URL, REDIRECT_TO_POOL.","title":"2.3 . Policy Action"},{"location":"Openstack_Research/High-availability/2. Octavia/5.Theory-Octavia-L7-Policy/#24_policy_postion","text":"Khi c\u00f3 nhi\u1ec1u c\u00e1c policy \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o m\u1ed9t listener, th\u00ec v\u1ecb tr\u00ed c\u1ee7a n\u00f3 trog list n\u00e0y tr\u1edf n\u00ean quan tr\u1ecdng. V\u1ecb tr\u00ed n\u00e0y x\u00e1c \u0111\u1ecbnh th\u1ee9 t\u1ef1 m\u00e0 c\u00e1c Policy n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t s\u1ed1 note trong khi s\u1eed d\u1ee5ng Octavia m\u00f4i tr\u01b0\u1eddng multi policies V\u1edbi HAproxy th\u1ee9 t\u1ef1 \u01b0u ti\u00ean c\u00e1c Policy action t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi nh\u01b0 sau : REJECT, REDIRECT_TO_URL, REDIRECT_TO_POOL N\u1ebfu kh\u00f4ng policy n\u00e0o x\u1eed l\u00fd \u0111\u01b0\u1ee3c request, c\u00e1c request s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn default pool ( n\u1ebfu c\u00f3 ) ho\u1eb7c kh\u00f4ng s\u1ebd tr\u1ea3 v\u1ec1 status code 503 Policy L7 \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 theo m\u1ed9t th\u1ee9 t\u1ef1 c\u1ee5 th\u1ec3 (nh\u01b0 \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi thu\u1ed9c t\u00ednh v\u1ecb tr\u00ed) v\u00e0 policy \u0111\u1ea7u ti\u00ean ph\u00f9 h\u1ee3p v\u1edbi request s\u1ebd \u0111\u1ea3m nhi\u1ec7m x\u1eed l\u00fd n\u00f3 V\u1ecb tr\u00ed c\u1ee7a Policy s\u1ebd b\u1eaft \u0111\u1ea7u b\u1eb1ng 1 N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch m\u1edbi \u0111\u01b0\u1ee3c t\u1ea1o v\u1edbi m\u1ed9t v\u1ecb tr\u00ed tr\u00f9ng v\u1edbi ch\u00ednh s\u00e1ch hi\u1ec7n c\u00f3, th\u00ec ch\u00ednh s\u00e1ch m\u1edbi s\u1ebd \u0111\u01b0\u1ee3c ch\u00e8n v\u00e0o v\u1ecb tr\u00ed \u0111\u1ea5y, \u0111\u1ea9y l\u00f9i ch\u00ednh s\u00e1ch c\u0169 N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o m\u00e0 kh\u00f4ng ch\u1ec9 \u0111\u1ecbnh v\u1ecb tr\u00ed s\u1ebd \u0111\u01b0\u1ee3c append v\u00e0o v\u1edbi v\u1ecb tr\u00ed list_range N\u1ebfu m\u1ed9t ch\u00ednh s\u00e1ch tr\u01b0\u1edbc n\u00f3 b\u1ecb x\u00f3a, c\u00e1c ch\u00ednh s\u00e1ch sau s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea9y l\u00ean m\u1ed9t \u0111\u01a1n v\u1ecb End ./","title":"2.4 : Policy Postion"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/","text":"LAB Octavia Policy c\u01a1 b\u1ea3n \u00b6 1. Chu\u1ea9n b\u1ecb m\u00f4i tr\u01b0\u1eddng \u00b6 Web server 1 : IP : 192.168.220.21 S\u1eed d\u1ee5ng Web Server Apache2 Gi\u1ea3 l\u1eadp \u0111\u01b0\u1eddng d\u1eabn : home.html echo \"<h2> Wellcome to Homepage </h2>\" >/var/www/html/home.html 2. Kh\u1edfi t\u1ea1o L7 Policy \u00b6 2.1 . Kh\u1edfi t\u1ea1o Load Balancer \u00b6 Kh\u1edfi t\u1ea1o m\u1ed9t Load Balancer openstack loadbalancer create --name lb3 --vip-subnet-id PRIVATE_VIP_200 G\u1eafn IP Floating cho Load Balancer openstack floating ip set --port e7bcc65b-fc0d-43ea-ad63-c745048c41a8 192.168.30.154 2.2. Policy Redirect URL \u00b6 Y\u00eau c\u1ea7u : Chuy\u1ec3n c\u00e1c c\u00e1c HTTP Request \u0111\u1ebfn Load Balancer v\u1ec1 Https://Google.com Kh\u1edfi t\u1ea1o m\u1ed9t Listener m\u1edbi openstack loadbalancer listener create --name http_listener --protocol HTTP --protocol-port 80 lb3 Kh\u1edfi t\u1ea1o Policy v\u00e0 g\u00e1n v\u00e0o Listener http_listener openstack loadbalancer l7policy create --name http_listen_redirect --action REDIRECT_TO_URL --redirect-url https://google.com http_listener Kh\u1edfi t\u1ea1o Rule openstack loadbalancer l7rule create --compare-type STARTS_WITH --type PATH --value / http_listen_redirect Ki\u1ec3m th\u1eed 2.3 . Policy Redirect URL Pool \u00b6 Y\u00eau c\u1ea7u : N\u1ec5u s\u1eed d\u1ee5ng \u0111\u1eebng d\u1eabn : home.html s\u1ebd chuy\u1ec3n v\u1ec1 WebServer 1 N\u1ebfu s\u1eed d\u1ee5ng \u0111\u01b0\u1eddng d\u1eabn : index.html s\u1ebd b\u1ecb REJECT X\u00f3a Policy \u0111\u00e3 g\u00e1n tr\u00ean Listenner openstack loadbalancer l7policy delete http_listen_redirect Kh\u1edfi t\u1ea1o Pool 1 tr\u00ean Listenner openstack loadbalancer pool create --listener c42668eb-5c9c-4e9e-8524-e97540f234a8 --lb-algorithm ROUND_ROBIN --protocol HTTP Kh\u1edfi t\u1ea1o Monitor v\u00e0 Pool Member cho Pool 1 openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 4837f5af-bc53-4b0d-8736-70d7053876b3 openstack loadbalancer member create --address 192.168.220.21 --protocol-port 80 --subnet-id PRIVATE_VIP_200 4837f5af-bc53-4b0d-8736-70d7053876b3 Kh\u1edfi t\u1ea1o Policy v\u00e0 Rule chuy\u1ec3n h\u01b0\u1edbng v\u1ec1 request v\u1ec1 Pool 1 n\u1ebfu PATHNAME home.html openstack loadbalancer l7policy create --action REDIRECT_TO_POOL --redirect-pool 4837f5af-bc53-4b0d-8736-70d7053876b3 --name policy1 c42668eb-5c9c-4e9e-8524-e97540f234a8 openstack loadbalancer l7rule create --compare-type EQUAL_TO --type PATH --value home.html policy1 Ki\u1ec3m ta v\u1ecb tr\u00ed c\u1ee7a policy 1 [LAB]openstack loadbalancer l7policy show policy1 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | listener_id | c42668eb-5c9c-4e9e-8524-e97540f234a8 | | description | | | admin_state_up | True | | rules | f4331c17-a516-40cd-9b59-6c113c2e3f2d | | project_id | c346047f05064784a58f7dbb6394466e | | created_at | 2019-01-18T08:10:36 | | provisioning_status | ACTIVE | | updated_at | 2019-01-18T08:22:14 | | redirect_pool_id | 4837f5af-bc53-4b0d-8736-70d7053876b3 | | redirect_url | None | | action | REDIRECT_TO_POOL | | position | 1 | | id | a34ef314-76b3-4673-b84e-3c5ba34ec418 | | operating_status | ONLINE | | name | policy1 | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Policy v\u00e0 Rule REJECT n\u1ebfu PATHNAME home.html openstack loadbalancer l7policy create --action REJECT --name policy2 c42668eb-5c9c-4e9e-8524-e97540f234a8 openstack loadbalancer l7rule create --compare-type EQUAL_TO --type PATH --value /index.html policy2 Ki\u1ec3m th\u1eed 3. T\u00e0i li\u1ec7u \u00b6 https://docs.openstack.org/octavia/queens/user/guides/l7-cookbook.html","title":"6. LAB Octavia L7 Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#lab_octavia_policy_co_ban","text":"","title":"LAB Octavia Policy c\u01a1 b\u1ea3n"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#1_chuan_bi_moi_truong","text":"Web server 1 : IP : 192.168.220.21 S\u1eed d\u1ee5ng Web Server Apache2 Gi\u1ea3 l\u1eadp \u0111\u01b0\u1eddng d\u1eabn : home.html echo \"<h2> Wellcome to Homepage </h2>\" >/var/www/html/home.html","title":"1. Chu\u1ea9n b\u1ecb m\u00f4i tr\u01b0\u1eddng"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#2_khoi_tao_l7_policy","text":"","title":"2. Kh\u1edfi t\u1ea1o L7 Policy"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#21_khoi_tao_load_balancer","text":"Kh\u1edfi t\u1ea1o m\u1ed9t Load Balancer openstack loadbalancer create --name lb3 --vip-subnet-id PRIVATE_VIP_200 G\u1eafn IP Floating cho Load Balancer openstack floating ip set --port e7bcc65b-fc0d-43ea-ad63-c745048c41a8 192.168.30.154","title":"2.1 . Kh\u1edfi t\u1ea1o Load Balancer"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#22_policy_redirect_url","text":"Y\u00eau c\u1ea7u : Chuy\u1ec3n c\u00e1c c\u00e1c HTTP Request \u0111\u1ebfn Load Balancer v\u1ec1 Https://Google.com Kh\u1edfi t\u1ea1o m\u1ed9t Listener m\u1edbi openstack loadbalancer listener create --name http_listener --protocol HTTP --protocol-port 80 lb3 Kh\u1edfi t\u1ea1o Policy v\u00e0 g\u00e1n v\u00e0o Listener http_listener openstack loadbalancer l7policy create --name http_listen_redirect --action REDIRECT_TO_URL --redirect-url https://google.com http_listener Kh\u1edfi t\u1ea1o Rule openstack loadbalancer l7rule create --compare-type STARTS_WITH --type PATH --value / http_listen_redirect Ki\u1ec3m th\u1eed","title":"2.2. Policy Redirect URL"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#23_policy_redirect_url_pool","text":"Y\u00eau c\u1ea7u : N\u1ec5u s\u1eed d\u1ee5ng \u0111\u1eebng d\u1eabn : home.html s\u1ebd chuy\u1ec3n v\u1ec1 WebServer 1 N\u1ebfu s\u1eed d\u1ee5ng \u0111\u01b0\u1eddng d\u1eabn : index.html s\u1ebd b\u1ecb REJECT X\u00f3a Policy \u0111\u00e3 g\u00e1n tr\u00ean Listenner openstack loadbalancer l7policy delete http_listen_redirect Kh\u1edfi t\u1ea1o Pool 1 tr\u00ean Listenner openstack loadbalancer pool create --listener c42668eb-5c9c-4e9e-8524-e97540f234a8 --lb-algorithm ROUND_ROBIN --protocol HTTP Kh\u1edfi t\u1ea1o Monitor v\u00e0 Pool Member cho Pool 1 openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / 4837f5af-bc53-4b0d-8736-70d7053876b3 openstack loadbalancer member create --address 192.168.220.21 --protocol-port 80 --subnet-id PRIVATE_VIP_200 4837f5af-bc53-4b0d-8736-70d7053876b3 Kh\u1edfi t\u1ea1o Policy v\u00e0 Rule chuy\u1ec3n h\u01b0\u1edbng v\u1ec1 request v\u1ec1 Pool 1 n\u1ebfu PATHNAME home.html openstack loadbalancer l7policy create --action REDIRECT_TO_POOL --redirect-pool 4837f5af-bc53-4b0d-8736-70d7053876b3 --name policy1 c42668eb-5c9c-4e9e-8524-e97540f234a8 openstack loadbalancer l7rule create --compare-type EQUAL_TO --type PATH --value home.html policy1 Ki\u1ec3m ta v\u1ecb tr\u00ed c\u1ee7a policy 1 [LAB]openstack loadbalancer l7policy show policy1 +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | listener_id | c42668eb-5c9c-4e9e-8524-e97540f234a8 | | description | | | admin_state_up | True | | rules | f4331c17-a516-40cd-9b59-6c113c2e3f2d | | project_id | c346047f05064784a58f7dbb6394466e | | created_at | 2019-01-18T08:10:36 | | provisioning_status | ACTIVE | | updated_at | 2019-01-18T08:22:14 | | redirect_pool_id | 4837f5af-bc53-4b0d-8736-70d7053876b3 | | redirect_url | None | | action | REDIRECT_TO_POOL | | position | 1 | | id | a34ef314-76b3-4673-b84e-3c5ba34ec418 | | operating_status | ONLINE | | name | policy1 | +---------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Policy v\u00e0 Rule REJECT n\u1ebfu PATHNAME home.html openstack loadbalancer l7policy create --action REJECT --name policy2 c42668eb-5c9c-4e9e-8524-e97540f234a8 openstack loadbalancer l7rule create --compare-type EQUAL_TO --type PATH --value /index.html policy2 Ki\u1ec3m th\u1eed","title":"2.3 . Policy Redirect URL Pool"},{"location":"Openstack_Research/High-availability/2. Octavia/6. LAB-Octavia-L7-Policy/#3_tai_lieu","text":"https://docs.openstack.org/octavia/queens/user/guides/l7-cookbook.html","title":"3. T\u00e0i li\u1ec7u"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/","text":"T\u00ecm hi\u1ec3u Pacemaker 2.0 \u00b6 1. Gi\u1edbi thi\u1ec7u Pacemaker \u00b6 1.1. Pacemaker l\u00e0 g\u00ec ? \u00b6 Pacemaker l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean c\u00e1c c\u1ee5m c\u00f3 t\u00ednh m\u1edf r\u1ed9ng v\u00e0 s\u1eb5n s\u00e0ng cao. Pacemaker h\u1ed7 tr\u1ee3 \"N-node\" cluster v\u1edbi kh\u1ea3 n\u0103ng qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean v\u00e0 c\u00e1c th\u00e0nh ph\u1ea7n trong \u0111\u00f3 . Gi\u1ea3i ph\u00e1p n\u00e0y s\u1ebd ch\u1ea1y c\u00e1c script \u0111\u1ec3 kh\u1edfi t\u1ea1o, khi m\u1ed9t node trong cluser \u1edf tr\u1ea1ng th\u00e1i up ho\u1eb7c down , ho\u1eb7c c\u00e1c tr\u00ecnh tr\u1ea1ng fail c\u1ee7a t\u00e0i nguy\u00ean v\u00e0 c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ec3 ki\u1ec3m tra s\u1ee9c kh\u1ecfe theo th\u1eddi gian \u0111\u1ecbnh k\u1ef3 Pacemaker \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi ClusterLabs . Hi\u1ec7n Pacemaker \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 t\u1ea1i c\u00e1c b\u1ea3n ph\u00e2n ph\u1ed1i tr\u00ean Linux g\u1ed3m : Debian , Fedora , openSUSE , Red Hat Enterprise Linux , SUSE Linux Enterprise Server , and Ubuntu LTS . 1.2. C\u00e1c thu\u1eadt ng\u1eef h\u1ed7 tr\u1ee3 \u00b6 Clustering l\u00e0 m\u1ed9t ki\u1ebfn tr\u00fac nh\u1eb1m \u0111\u1ea3m b\u1ea3o n\u00e2ng cao kh\u1ea3 n\u0103ng s\u1eb5n s\u00e0ng cho c\u00e1c h\u1ec7 th\u1ed1ng m\u1ea1ng m\u00e1y t\u00ednh. Clustering cho ph\u00e9p s\u1eed d\u1ee5ng nhi\u1ec1u m\u00e1y ch\u1ee7 k\u1ebft h\u1ee3p v\u1edbi nhau t\u1ea1o th\u00e0nh m\u1ed9t c\u1ee5m c\u00f3 kh\u1ea3 n\u0103ng ch\u1ecbu \u0111\u1ef1ng hay ch\u1ea5p nh\u1eadn sai s\u00f3t (fault-tolerant) nh\u1eb1m n\u00e2ng cao \u0111\u1ed9 s\u1eb5n s\u00e0ng c\u1ee7a h\u1ec7 th\u1ed1ng m\u1ea1ng. Cluster l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng bao g\u1ed3m nhi\u1ec1u m\u00e1y ch\u1ee7 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi nhau theo d\u1ea1ng song song hay ph\u00e2n t\u00e1n v\u00e0 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng nh\u01b0 m\u1ed9t t\u00e0i nguy\u00ean th\u1ed1ng nh\u1ea5t. M\u1ed7i server tham gia trong cluster \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 m\u1ed9t cluster node. Ch\u00fang c\u1ea7n \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi nhau. C\u00e1c cluster node ph\u1ea3i li\u00ean l\u1ea1c th\u01b0\u1eddng xuy\u00ean v\u1edbi nhau \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh t\u00ecnh tr\u1ea1ng c\u1ee7a t\u1eebng node. K\u1ebft n\u1ed1i n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 cluster heartbeat Pacemaker h\u1ed7 tr\u1ee3 c\u00e1c m\u00f4 h\u00ecnh sau : Active/Active , Active/Passive , N+1 , N+M , N-to-1 and N-to-N . Quorum trong Cluser : Qu\u00e1 tr\u00ecnh \u0111\u00e0m ph\u00e1n quorum x\u1ea3y ra khi m\u1ed9t node \u0111ang s\u1edf h\u1eefu m\u1ed9t quorum resource b\u1ecb l\u1ed7i hay kh\u00f4ng ho\u1ea1t \u0111\u1ed9ng. C\u1ea5u h\u00ecnh qoarum trong m\u1ed9t failvoer cluser s\u1ebd x\u00e1c \u0111\u1ecbnh s\u1ed1 failure node nhi\u1ec1u nh\u1ea5t m\u00e0 cluster n\u00e0y c\u00f3 th\u1ec3 ch\u1ecbu \u0111\u1ef1ng. N\u1ebfu s\u1ed1 failure node v\u01b0\u1ee3t qua ng\u01b0\u1ee1ng th\u00ec cluser ng\u00e0y \u0111i v\u00e0o tr\u1ea1ng th\u00e1i ng\u1eebng ho\u1ea1t \u0111\u1ed9ng \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e1c node c\u00f2n l\u1ea1i kh\u00f4ng b\u1ecb tr\u00ecnh tr\u1ea1ng qu\u00e1 t\u1ea3i Fencing ho\u1eb7c STONITH : ( an acronym for Shoot The Other Node In The Head ) , \u0111\u1ea3m b\u1ea3o m\u1ed9t node kh\u00f4ng th\u1ec3 t\u1ef1 join v\u00e0o cluster . Gi\u1ed1ng nh\u01b0 m\u1ed9t h\u00e0ng r\u00e0o ch\u1eb7n c\u00e1c node mu\u1ed1n truy c\u1eadp kh\u00e1c v\u00e0o cluster 1.3. C\u00e1c ch\u1ee9c n\u0103ng \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi Pacemaker \u00b6 Ph\u00e1t hi\u1ec7n v\u00e0 kh\u00f4i ph\u1ee5c c\u00e1c node v\u00e0 \u1ee9ng d\u1ee5ng b\u1ecb l\u1ed7i H\u1ed7 tr\u1ee3 thi\u1ebft l\u1eadp Cluster Type \u0111\u00e3 n\u00eau \u1edf tr\u00ean H\u1ed7 tr\u1ee3 qu\u1ea3n l\u00fd c\u00f4ng vi\u1ec7c theo qorum v\u00e0 qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean trong c\u1ee5m H\u1ed7 tr\u1ee3 b\u1eadt/t\u1eaft c\u00e1c \u1ee9ng d\u1ee5ng theo th\u1ee9 t\u1ef1 T\u1ef1 ki\u1ec3m tra v\u00e0 c\u00f4 l\u1eadp quorum b\u1ecb l\u1ed7i H\u1ed7 tr\u1ee3 c\u00e1c application ph\u1ea3i / kh\u00f4ng ph\u1ea3i ch\u1ea1y tr\u00ean m\u1ed9t node H\u1ed7 tr\u1ee3 c\u00e1c application ch\u1ea1y tr\u00ean nhi\u1ec1u node Ph\u1ea3n h\u1ed3i ch\u00ednh x\u00e1c v\u1ec1 tr\u1ea1ng th\u00e1i fail ho\u1eb7c cluster state \u0110\u1ea3m b\u1ea3o t\u00ednh to\u00e0n v\u1eb9n ( STONITH ) H\u1ed7 tr\u1ee3 shared storage H\u1ed7 tr\u1ee3 replicated t\u1eadp tin c\u1ea5u h\u00ecnh 2 . C\u1ea5u tr\u00fac trong Pacemaker \u00b6 2.1 : C\u1ea5u tr\u00fac Pacemaker \u00b6 C\u00e1c th\u00e0nh ph\u1ea7n trong Pacemaker Pacemaker master process (pacemakerd) : kh\u1edfi t\u1ea1o c\u00e1c deamon, kh\u1edfi t\u1ea1o c\u00e1c deamon n\u00e0y n\u1ebfu b\u1ecb tho\u00e1t \u0111\u1ed9t ng\u1ed9t Cluser information base ( CIB ) : file XMl ch\u01b0a c\u00e1c cluster config v\u00e0 state c\u1ee7a c\u00e1c node v\u00e0 cluster attribute manager (pacemaker-attrd ) : duy tr\u00ec c\u00e1c DB tr\u00ean c\u00e1c node , \u0111\u1ea3m nhi\u1ec7m \u0111\u1ed3ng b\u1ed9 gi\u1eefa c\u00e1c node trong cluster scheduler (pacemaker-schedulerd) : x\u00e1c \u0111\u1ecbnh nh\u1eefng h\u00e0nh \u0111\u1ed9ng c\u1ea7n thi\u1ebft \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c tr\u1ea1ng th\u00e1i mong mu\u1ed1n c\u1ee7a c\u1ee5m. local executor (pacemaker-execd) : x\u1eed l\u00fd c\u00e1c request c\u1ea7n \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean resource agent v\u00e0 tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 fencer (pacemaker-fenced) : \u0110\u01b0a ra m\u1ed9t n\u00fat \u0111\u00edch, , fencer quy\u1ebft \u0111\u1ecbnh (c\u00e1c) n\u00fat c\u1ee5m n\u00e0o s\u1ebd th\u1ef1c thi t\u00e1c v\u1ee5 ki\u1ec3m tra d\u1ecbch v\u1ee5 controller (pacemaker-controld) : \u0110i\u1ec1u ph\u1ed1i vi\u00ean Pacemaker, duy tr\u00ec m\u1ed9t c\u00e1i nh\u00ecn nh\u1ea5t qu\u00e1n v\u1ec1 t\u01b0 c\u00e1ch th\u00e0nh vi\u00ean c\u1ee7a c\u1ee5m v\u00e0 \u0111i\u1ec1u ph\u1ed1i t\u1ea5t c\u1ea3 c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c. 2.2 : C\u1ea5u tr\u00fac Pacemaker Cluster \u00b6 M\u1ed9t cluser \u0111\u01b0\u1ee3c xem bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n sau \u0111\u00e2y : Resource : c\u00e1c t\u00e0i nguy\u00ean c\u1ea7n x\u1eed l\u00fd kh\u1ea3 d\u1ee5ng cao Resource agent : c\u00e1c script ho\u1eb7c c\u00e1c package s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1eaft , b\u1eadt, ki\u1ec3m so\u00e1t c\u00e1c t\u00e0i nguy\u00ean. Ch\u00fang cung c\u1ea5p giao di\u1ec7n th\u1ed1ng nh\u1ea5t gi\u1eefa Pacemaker v\u00e0 c\u00e1c d\u1ecbch v\u1ee5 ch\u00fang qu\u1ea3n l\u00fd Fence agent : s\u1eed d\u1ee5ng STONITH \u0111\u1ec3 ki\u1ec3m so\u00e1t d\u1ecbch v\u1ee5 Cluster membership manager : cung c\u1ea5p c\u00e1c v\u1ea5n \u0111\u1ec1 li\u00ean quan \u0111\u1ebfn c\u00e1c b\u1ea3n tin \u0111ang tin c\u1eady, c\u00e1c member v\u00e0 th\u00f4ng tin v\u1ec1 qorum c\u1ee7a cluser. Hi\u1ec7n t\u1ea1i, Pacemaker h\u1ed7 tr\u1ee3 Corosync \u0111\u1ec3 \u0111\u1ea3m nhi\u1ec7m vi\u1ec7c n\u00e0y Cluser resouce manager : cung c\u1ea5p kh\u1ea3 n\u0103ng ki\u1ec3m so\u00e1t t\u1eadp trung c\u1ee7a c\u1ea3 c\u1ee5m, c\u00e1c s\u1ef1 ki\u1ec7n trong c\u1ee5m . C\u00f3 th\u1ec3 l\u00e0 c\u00e1c node tham gia ho\u1eb7c t\u00e1ch bi\u1ec7t cluser, c\u00e1c s\u1ef1 ki\u1ec7n g\u00e2y ra b\u1edfi s\u1ef1 c\u1ed1, b\u1ea3o tr\u00ec ho\u1eb7c c\u00e1c ho\u1ea1t \u0111\u1ed9ng theo l\u1ecbch tr\u00ecnh; v\u00e0 c\u00e1c h\u00e0nh \u0111\u1ed9ng h\u00e0nh ch\u00ednh kh\u00e1c Cluster tool : cung c\u1ea5p interface cho ng\u01b0\u1eddi d\u00f9ng l\u00e0m vi\u1ec7c v\u1edbi cluster 3. T\u00e0i li\u1ec7u \u00b6 http://kcntt.duytan.edu.vn/Home/ArticleDetail/vn/128/2406/can-bang-tai-voi-pacemaker-phan-1 https://clusterlabs.org/pacemaker/ https://thatremindsme.woodwose.net/computing/2011/04/25/Stonith-and-Quorum-in-Pacemaker.html http://clusterlabs.org/pacemaker/doc/","title":"1. Intro Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#tim_hieu_pacemaker_20","text":"","title":"T\u00ecm hi\u1ec3u Pacemaker 2.0"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#1_gioi_thieu_pacemaker","text":"","title":"1. Gi\u1edbi thi\u1ec7u Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#11_pacemaker_la_gi","text":"Pacemaker l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean c\u00e1c c\u1ee5m c\u00f3 t\u00ednh m\u1edf r\u1ed9ng v\u00e0 s\u1eb5n s\u00e0ng cao. Pacemaker h\u1ed7 tr\u1ee3 \"N-node\" cluster v\u1edbi kh\u1ea3 n\u0103ng qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean v\u00e0 c\u00e1c th\u00e0nh ph\u1ea7n trong \u0111\u00f3 . Gi\u1ea3i ph\u00e1p n\u00e0y s\u1ebd ch\u1ea1y c\u00e1c script \u0111\u1ec3 kh\u1edfi t\u1ea1o, khi m\u1ed9t node trong cluser \u1edf tr\u1ea1ng th\u00e1i up ho\u1eb7c down , ho\u1eb7c c\u00e1c tr\u00ecnh tr\u1ea1ng fail c\u1ee7a t\u00e0i nguy\u00ean v\u00e0 c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ec3 ki\u1ec3m tra s\u1ee9c kh\u1ecfe theo th\u1eddi gian \u0111\u1ecbnh k\u1ef3 Pacemaker \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi ClusterLabs . Hi\u1ec7n Pacemaker \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 t\u1ea1i c\u00e1c b\u1ea3n ph\u00e2n ph\u1ed1i tr\u00ean Linux g\u1ed3m : Debian , Fedora , openSUSE , Red Hat Enterprise Linux , SUSE Linux Enterprise Server , and Ubuntu LTS .","title":"1.1. Pacemaker l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#12_cac_thuat_ngu_ho_tro","text":"Clustering l\u00e0 m\u1ed9t ki\u1ebfn tr\u00fac nh\u1eb1m \u0111\u1ea3m b\u1ea3o n\u00e2ng cao kh\u1ea3 n\u0103ng s\u1eb5n s\u00e0ng cho c\u00e1c h\u1ec7 th\u1ed1ng m\u1ea1ng m\u00e1y t\u00ednh. Clustering cho ph\u00e9p s\u1eed d\u1ee5ng nhi\u1ec1u m\u00e1y ch\u1ee7 k\u1ebft h\u1ee3p v\u1edbi nhau t\u1ea1o th\u00e0nh m\u1ed9t c\u1ee5m c\u00f3 kh\u1ea3 n\u0103ng ch\u1ecbu \u0111\u1ef1ng hay ch\u1ea5p nh\u1eadn sai s\u00f3t (fault-tolerant) nh\u1eb1m n\u00e2ng cao \u0111\u1ed9 s\u1eb5n s\u00e0ng c\u1ee7a h\u1ec7 th\u1ed1ng m\u1ea1ng. Cluster l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng bao g\u1ed3m nhi\u1ec1u m\u00e1y ch\u1ee7 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi nhau theo d\u1ea1ng song song hay ph\u00e2n t\u00e1n v\u00e0 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng nh\u01b0 m\u1ed9t t\u00e0i nguy\u00ean th\u1ed1ng nh\u1ea5t. M\u1ed7i server tham gia trong cluster \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 m\u1ed9t cluster node. Ch\u00fang c\u1ea7n \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi nhau. C\u00e1c cluster node ph\u1ea3i li\u00ean l\u1ea1c th\u01b0\u1eddng xuy\u00ean v\u1edbi nhau \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh t\u00ecnh tr\u1ea1ng c\u1ee7a t\u1eebng node. K\u1ebft n\u1ed1i n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 cluster heartbeat Pacemaker h\u1ed7 tr\u1ee3 c\u00e1c m\u00f4 h\u00ecnh sau : Active/Active , Active/Passive , N+1 , N+M , N-to-1 and N-to-N . Quorum trong Cluser : Qu\u00e1 tr\u00ecnh \u0111\u00e0m ph\u00e1n quorum x\u1ea3y ra khi m\u1ed9t node \u0111ang s\u1edf h\u1eefu m\u1ed9t quorum resource b\u1ecb l\u1ed7i hay kh\u00f4ng ho\u1ea1t \u0111\u1ed9ng. C\u1ea5u h\u00ecnh qoarum trong m\u1ed9t failvoer cluser s\u1ebd x\u00e1c \u0111\u1ecbnh s\u1ed1 failure node nhi\u1ec1u nh\u1ea5t m\u00e0 cluster n\u00e0y c\u00f3 th\u1ec3 ch\u1ecbu \u0111\u1ef1ng. N\u1ebfu s\u1ed1 failure node v\u01b0\u1ee3t qua ng\u01b0\u1ee1ng th\u00ec cluser ng\u00e0y \u0111i v\u00e0o tr\u1ea1ng th\u00e1i ng\u1eebng ho\u1ea1t \u0111\u1ed9ng \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e1c node c\u00f2n l\u1ea1i kh\u00f4ng b\u1ecb tr\u00ecnh tr\u1ea1ng qu\u00e1 t\u1ea3i Fencing ho\u1eb7c STONITH : ( an acronym for Shoot The Other Node In The Head ) , \u0111\u1ea3m b\u1ea3o m\u1ed9t node kh\u00f4ng th\u1ec3 t\u1ef1 join v\u00e0o cluster . Gi\u1ed1ng nh\u01b0 m\u1ed9t h\u00e0ng r\u00e0o ch\u1eb7n c\u00e1c node mu\u1ed1n truy c\u1eadp kh\u00e1c v\u00e0o cluster","title":"1.2. C\u00e1c thu\u1eadt ng\u1eef h\u1ed7 tr\u1ee3"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#13_cac_chuc_nang_uoc_ho_tro_boi_pacemaker","text":"Ph\u00e1t hi\u1ec7n v\u00e0 kh\u00f4i ph\u1ee5c c\u00e1c node v\u00e0 \u1ee9ng d\u1ee5ng b\u1ecb l\u1ed7i H\u1ed7 tr\u1ee3 thi\u1ebft l\u1eadp Cluster Type \u0111\u00e3 n\u00eau \u1edf tr\u00ean H\u1ed7 tr\u1ee3 qu\u1ea3n l\u00fd c\u00f4ng vi\u1ec7c theo qorum v\u00e0 qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean trong c\u1ee5m H\u1ed7 tr\u1ee3 b\u1eadt/t\u1eaft c\u00e1c \u1ee9ng d\u1ee5ng theo th\u1ee9 t\u1ef1 T\u1ef1 ki\u1ec3m tra v\u00e0 c\u00f4 l\u1eadp quorum b\u1ecb l\u1ed7i H\u1ed7 tr\u1ee3 c\u00e1c application ph\u1ea3i / kh\u00f4ng ph\u1ea3i ch\u1ea1y tr\u00ean m\u1ed9t node H\u1ed7 tr\u1ee3 c\u00e1c application ch\u1ea1y tr\u00ean nhi\u1ec1u node Ph\u1ea3n h\u1ed3i ch\u00ednh x\u00e1c v\u1ec1 tr\u1ea1ng th\u00e1i fail ho\u1eb7c cluster state \u0110\u1ea3m b\u1ea3o t\u00ednh to\u00e0n v\u1eb9n ( STONITH ) H\u1ed7 tr\u1ee3 shared storage H\u1ed7 tr\u1ee3 replicated t\u1eadp tin c\u1ea5u h\u00ecnh","title":"1.3. C\u00e1c ch\u1ee9c n\u0103ng \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#2_cau_truc_trong_pacemaker","text":"","title":"2 . C\u1ea5u tr\u00fac trong Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#21_cau_truc_pacemaker","text":"C\u00e1c th\u00e0nh ph\u1ea7n trong Pacemaker Pacemaker master process (pacemakerd) : kh\u1edfi t\u1ea1o c\u00e1c deamon, kh\u1edfi t\u1ea1o c\u00e1c deamon n\u00e0y n\u1ebfu b\u1ecb tho\u00e1t \u0111\u1ed9t ng\u1ed9t Cluser information base ( CIB ) : file XMl ch\u01b0a c\u00e1c cluster config v\u00e0 state c\u1ee7a c\u00e1c node v\u00e0 cluster attribute manager (pacemaker-attrd ) : duy tr\u00ec c\u00e1c DB tr\u00ean c\u00e1c node , \u0111\u1ea3m nhi\u1ec7m \u0111\u1ed3ng b\u1ed9 gi\u1eefa c\u00e1c node trong cluster scheduler (pacemaker-schedulerd) : x\u00e1c \u0111\u1ecbnh nh\u1eefng h\u00e0nh \u0111\u1ed9ng c\u1ea7n thi\u1ebft \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c tr\u1ea1ng th\u00e1i mong mu\u1ed1n c\u1ee7a c\u1ee5m. local executor (pacemaker-execd) : x\u1eed l\u00fd c\u00e1c request c\u1ea7n \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean resource agent v\u00e0 tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 fencer (pacemaker-fenced) : \u0110\u01b0a ra m\u1ed9t n\u00fat \u0111\u00edch, , fencer quy\u1ebft \u0111\u1ecbnh (c\u00e1c) n\u00fat c\u1ee5m n\u00e0o s\u1ebd th\u1ef1c thi t\u00e1c v\u1ee5 ki\u1ec3m tra d\u1ecbch v\u1ee5 controller (pacemaker-controld) : \u0110i\u1ec1u ph\u1ed1i vi\u00ean Pacemaker, duy tr\u00ec m\u1ed9t c\u00e1i nh\u00ecn nh\u1ea5t qu\u00e1n v\u1ec1 t\u01b0 c\u00e1ch th\u00e0nh vi\u00ean c\u1ee7a c\u1ee5m v\u00e0 \u0111i\u1ec1u ph\u1ed1i t\u1ea5t c\u1ea3 c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c.","title":"2.1 : C\u1ea5u tr\u00fac Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#22_cau_truc_pacemaker_cluster","text":"M\u1ed9t cluser \u0111\u01b0\u1ee3c xem bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n sau \u0111\u00e2y : Resource : c\u00e1c t\u00e0i nguy\u00ean c\u1ea7n x\u1eed l\u00fd kh\u1ea3 d\u1ee5ng cao Resource agent : c\u00e1c script ho\u1eb7c c\u00e1c package s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1eaft , b\u1eadt, ki\u1ec3m so\u00e1t c\u00e1c t\u00e0i nguy\u00ean. Ch\u00fang cung c\u1ea5p giao di\u1ec7n th\u1ed1ng nh\u1ea5t gi\u1eefa Pacemaker v\u00e0 c\u00e1c d\u1ecbch v\u1ee5 ch\u00fang qu\u1ea3n l\u00fd Fence agent : s\u1eed d\u1ee5ng STONITH \u0111\u1ec3 ki\u1ec3m so\u00e1t d\u1ecbch v\u1ee5 Cluster membership manager : cung c\u1ea5p c\u00e1c v\u1ea5n \u0111\u1ec1 li\u00ean quan \u0111\u1ebfn c\u00e1c b\u1ea3n tin \u0111ang tin c\u1eady, c\u00e1c member v\u00e0 th\u00f4ng tin v\u1ec1 qorum c\u1ee7a cluser. Hi\u1ec7n t\u1ea1i, Pacemaker h\u1ed7 tr\u1ee3 Corosync \u0111\u1ec3 \u0111\u1ea3m nhi\u1ec7m vi\u1ec7c n\u00e0y Cluser resouce manager : cung c\u1ea5p kh\u1ea3 n\u0103ng ki\u1ec3m so\u00e1t t\u1eadp trung c\u1ee7a c\u1ea3 c\u1ee5m, c\u00e1c s\u1ef1 ki\u1ec7n trong c\u1ee5m . C\u00f3 th\u1ec3 l\u00e0 c\u00e1c node tham gia ho\u1eb7c t\u00e1ch bi\u1ec7t cluser, c\u00e1c s\u1ef1 ki\u1ec7n g\u00e2y ra b\u1edfi s\u1ef1 c\u1ed1, b\u1ea3o tr\u00ec ho\u1eb7c c\u00e1c ho\u1ea1t \u0111\u1ed9ng theo l\u1ecbch tr\u00ecnh; v\u00e0 c\u00e1c h\u00e0nh \u0111\u1ed9ng h\u00e0nh ch\u00ednh kh\u00e1c Cluster tool : cung c\u1ea5p interface cho ng\u01b0\u1eddi d\u00f9ng l\u00e0m vi\u1ec7c v\u1edbi cluster","title":"2.2 : C\u1ea5u tr\u00fac Pacemaker Cluster"},{"location":"Openstack_Research/High-availability/3. Pacemaker/1. Intro-Pacemaker/#3_tai_lieu","text":"http://kcntt.duytan.edu.vn/Home/ArticleDetail/vn/128/2406/can-bang-tai-voi-pacemaker-phan-1 https://clusterlabs.org/pacemaker/ https://thatremindsme.woodwose.net/computing/2011/04/25/Stonith-and-Quorum-in-Pacemaker.html http://clusterlabs.org/pacemaker/doc/","title":"3. T\u00e0i li\u1ec7u"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/","text":"C\u00e0i \u0111\u1eb7t Pacemaker \u00b6 1. M\u00f4 h\u00ecnh LAB \u00b6 M\u00f4i tr\u01b0\u1eddng : Centos 7.3 M\u00f4 h\u00ecnh tri\u1ec3n khai 2. C\u00e0i \u0111\u1eb7t v\u00e0 kh\u1edfi t\u1ea1o Cluster \u00b6 2.1. : Th\u1ef1c hi\u1ec7n tr\u00ean 3 node \u00b6 C\u00e0i \u0111\u1eb7t package yum install pacemaker pcs resource-agents Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start pcsd.service systemctl enable pcsd.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=high-availability --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh file host cat <<EOF >> /etc/hosts 192.168.30.130 node1 192.168.30.132 node2 192.168.30.132 node3 EOF C\u1ea5u h\u00ecnh m\u1eadt kh\u1ea9u cho t\u00e0i kho\u1ea3n hacluster . Tr\u00ean c\u00e1c node c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng m\u1eadt kh\u1ea9u kh\u00e1c nhau echo \"hacluster:123@123Aa\" | chpasswd 2.3 . Kh\u1edfi t\u1ea1o Cluster - th\u1ef1c hi\u1ec7n tr\u00ean node 30 \u00b6 G\u1eedi request \u0111\u1ebfn c\u00e1c node v\u00e0 \u0111\u0103ng nh\u1eadp pcs cluster auth node1 node2 node3 -u hacluster -p 123@123Aa --force node1: Authorized node3: Authorized node2: Authorized Kh\u1edfi t\u1ea1o Cluster v\u00e0 c\u1ea5u h\u00ecnh ( qu\u00e1 tr\u00ecnh n\u00e0y kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh v\u00e0 \u0111\u1ed9ng b\u1ed9 \u0111i sang c\u00e1c node kh\u00e1c ) pcs cluster setup --force --name hacluster node1 node2 node3 Destroying cluster on nodes: node1, node2, node3... node3: Stopping Cluster (pacemaker)... node2: Stopping Cluster (pacemaker)... node1: Stopping Cluster (pacemaker)... node2: Successfully destroyed cluster node1: Successfully destroyed cluster node3: Successfully destroyed cluster Sending 'pacemaker_remote authkey' to 'node1', 'node2', 'node3' node1: successful distribution of the file 'pacemaker_remote authkey' node2: successful distribution of the file 'pacemaker_remote authkey' node3: successful distribution of the file 'pacemaker_remote authkey' Sending cluster config files to the nodes... node1: Succeeded node2: Succeeded node3: Succeeded Synchronizing pcsd certificates on nodes node1, node2, node3... node1: Success node3: Success node2: Success Restarting pcsd on the nodes in order to reload the certificates... node1: Success node3: Success node2: Success Kh\u1edfi \u0111\u1ed9ng Cluster pcs cluster start --all ho\u1eb7c tr\u00ean c\u00e1c node systemctl enable corosync.service pacemaker.service systemctl start pacemaker.service corosync.service Enable Cluster pcs cluster enable --all Ki\u1ec3m tra Status c\u1ee7a Cluster pcs status cluster Cluster Status: Stack: corosync Current DC: node3 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:17:08 2019 Last change: Mon Jan 28 11:17:23 2019 by hacluster via crmd on node3 3 nodes configured 0 resources configured PCSD Status: node2: Online node3: Online node1: Online Ki\u1ec3m tra c\u00e1c property tr\u00ean Cluster pcs property list Cluster Properties: cluster-infrastructure: corosync cluster-name: hacluster dc-version: 1.1.19-8.el7_6.2-c3c624ea3d have-watchdog: false Ki\u1ec3m tra c\u00e1c Member \u0111ang \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi Corosync corosync-cmapctl | grep members runtime.totem.pg.mrp.srp.members.1.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.1.ip (str) = r(0) ip(192.168.30.130) runtime.totem.pg.mrp.srp.members.1.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.1.status (str) = joined runtime.totem.pg.mrp.srp.members.2.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.2.ip (str) = r(0) ip(192.168.30.131) runtime.totem.pg.mrp.srp.members.2.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.2.status (str) = joined runtime.totem.pg.mrp.srp.members.3.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.3.ip (str) = r(0) ip(192.168.30.132) runtime.totem.pg.mrp.srp.members.3.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.3.status (str) = joined Ki\u1ec3m tra file XML pacemaker pcs cluster cib <cib crm_feature_set=\"3.0.14\" validate-with=\"pacemaker-2.10\" epoch=\"1\" num_updates=\"0\" admin_epoch=\"0\" cib-last-written=\"Mon Jan 28 11:26:50 2019\" update-origin=\"node3\" update-client=\"crmd\" update-user=\"hacluster\"> <configuration> <crm_config/> <nodes> <node id=\"1\" uname=\"node1\"/> <node id=\"2\" uname=\"node2\"/> <node id=\"3\" uname=\"node3\"/> </nodes> <resources/> <constraints/> </configuration> <status/> </cib> [root@controller ~]# pcs cluster cib <cib crm_feature_set=\"3.0.14\" validate-with=\"pacemaker-2.10\" epoch=\"5\" num_updates=\"5\" admin_epoch=\"0\" cib-last-written=\"Mon Jan 28 11:27:28 2019\" update-origin=\"node1\" update-client=\"crmd\" update-user=\"hacluster\" have-quorum=\"1\" dc-uuid=\"1\"> <configuration> <crm_config> <cluster_property_set id=\"cib-bootstrap-options\"> <nvpair id=\"cib-bootstrap-options-have-watchdog\" name=\"have-watchdog\" value=\"false\"/> <nvpair id=\"cib-bootstrap-options-dc-version\" name=\"dc-version\" value=\"1.1.19-8.el7_6.2-c3c624ea3d\"/> <nvpair id=\"cib-bootstrap-options-cluster-infrastructure\" name=\"cluster-infrastructure\" value=\"corosync\"/> <nvpair id=\"cib-bootstrap-options-cluster-name\" name=\"cluster-name\" value=\"hacluster\"/> </cluster_property_set> </crm_config> <nodes> <node id=\"1\" uname=\"node1\"/> <node id=\"2\" uname=\"node2\"/> <node id=\"3\" uname=\"node3\"/> </nodes> <resources/> <constraints/> </configuration> <status> <node_state id=\"1\" uname=\"node1\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"1\"> <lrm_resources/> </lrm> </node_state> <node_state id=\"3\" uname=\"node3\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"3\"> <lrm_resources/> </lrm> </node_state> <node_state id=\"2\" uname=\"node2\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"2\"> <lrm_resources/> </lrm> </node_state> </status> </cib> Ki\u1ec3m tra status c\u1ee7a Corosync tr\u00ean Node corosync-cfgtool -s Ki\u1ec3m tra tr\u1ea1ng th\u00e1i Corsync member pcs status corosync Membership information ---------------------- Nodeid Votes Name 1 1 192.168.30.130 (local) 2 1 192.168.30.131 3 1 192.168.30.132 Disable ch\u1ee9c n\u0103ng stonith pcs property set stonith-enabled=false --force END ./","title":"2. Install Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/#cai_at_pacemaker","text":"","title":"C\u00e0i \u0111\u1eb7t Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/#1_mo_hinh_lab","text":"M\u00f4i tr\u01b0\u1eddng : Centos 7.3 M\u00f4 h\u00ecnh tri\u1ec3n khai","title":"1. M\u00f4 h\u00ecnh LAB"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/#2_cai_at_va_khoi_tao_cluster","text":"","title":"2. C\u00e0i \u0111\u1eb7t  v\u00e0 kh\u1edfi t\u1ea1o Cluster"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/#21_thuc_hien_tren_3_node","text":"C\u00e0i \u0111\u1eb7t package yum install pacemaker pcs resource-agents Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl start pcsd.service systemctl enable pcsd.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=high-availability --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh file host cat <<EOF >> /etc/hosts 192.168.30.130 node1 192.168.30.132 node2 192.168.30.132 node3 EOF C\u1ea5u h\u00ecnh m\u1eadt kh\u1ea9u cho t\u00e0i kho\u1ea3n hacluster . Tr\u00ean c\u00e1c node c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng m\u1eadt kh\u1ea9u kh\u00e1c nhau echo \"hacluster:123@123Aa\" | chpasswd","title":"2.1. : Th\u1ef1c hi\u1ec7n tr\u00ean 3 node"},{"location":"Openstack_Research/High-availability/3. Pacemaker/2. Install-Pacemaker/#23_khoi_tao_cluster_-_thuc_hien_tren_node_30","text":"G\u1eedi request \u0111\u1ebfn c\u00e1c node v\u00e0 \u0111\u0103ng nh\u1eadp pcs cluster auth node1 node2 node3 -u hacluster -p 123@123Aa --force node1: Authorized node3: Authorized node2: Authorized Kh\u1edfi t\u1ea1o Cluster v\u00e0 c\u1ea5u h\u00ecnh ( qu\u00e1 tr\u00ecnh n\u00e0y kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh v\u00e0 \u0111\u1ed9ng b\u1ed9 \u0111i sang c\u00e1c node kh\u00e1c ) pcs cluster setup --force --name hacluster node1 node2 node3 Destroying cluster on nodes: node1, node2, node3... node3: Stopping Cluster (pacemaker)... node2: Stopping Cluster (pacemaker)... node1: Stopping Cluster (pacemaker)... node2: Successfully destroyed cluster node1: Successfully destroyed cluster node3: Successfully destroyed cluster Sending 'pacemaker_remote authkey' to 'node1', 'node2', 'node3' node1: successful distribution of the file 'pacemaker_remote authkey' node2: successful distribution of the file 'pacemaker_remote authkey' node3: successful distribution of the file 'pacemaker_remote authkey' Sending cluster config files to the nodes... node1: Succeeded node2: Succeeded node3: Succeeded Synchronizing pcsd certificates on nodes node1, node2, node3... node1: Success node3: Success node2: Success Restarting pcsd on the nodes in order to reload the certificates... node1: Success node3: Success node2: Success Kh\u1edfi \u0111\u1ed9ng Cluster pcs cluster start --all ho\u1eb7c tr\u00ean c\u00e1c node systemctl enable corosync.service pacemaker.service systemctl start pacemaker.service corosync.service Enable Cluster pcs cluster enable --all Ki\u1ec3m tra Status c\u1ee7a Cluster pcs status cluster Cluster Status: Stack: corosync Current DC: node3 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:17:08 2019 Last change: Mon Jan 28 11:17:23 2019 by hacluster via crmd on node3 3 nodes configured 0 resources configured PCSD Status: node2: Online node3: Online node1: Online Ki\u1ec3m tra c\u00e1c property tr\u00ean Cluster pcs property list Cluster Properties: cluster-infrastructure: corosync cluster-name: hacluster dc-version: 1.1.19-8.el7_6.2-c3c624ea3d have-watchdog: false Ki\u1ec3m tra c\u00e1c Member \u0111ang \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi Corosync corosync-cmapctl | grep members runtime.totem.pg.mrp.srp.members.1.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.1.ip (str) = r(0) ip(192.168.30.130) runtime.totem.pg.mrp.srp.members.1.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.1.status (str) = joined runtime.totem.pg.mrp.srp.members.2.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.2.ip (str) = r(0) ip(192.168.30.131) runtime.totem.pg.mrp.srp.members.2.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.2.status (str) = joined runtime.totem.pg.mrp.srp.members.3.config_version (u64) = 0 runtime.totem.pg.mrp.srp.members.3.ip (str) = r(0) ip(192.168.30.132) runtime.totem.pg.mrp.srp.members.3.join_count (u32) = 1 runtime.totem.pg.mrp.srp.members.3.status (str) = joined Ki\u1ec3m tra file XML pacemaker pcs cluster cib <cib crm_feature_set=\"3.0.14\" validate-with=\"pacemaker-2.10\" epoch=\"1\" num_updates=\"0\" admin_epoch=\"0\" cib-last-written=\"Mon Jan 28 11:26:50 2019\" update-origin=\"node3\" update-client=\"crmd\" update-user=\"hacluster\"> <configuration> <crm_config/> <nodes> <node id=\"1\" uname=\"node1\"/> <node id=\"2\" uname=\"node2\"/> <node id=\"3\" uname=\"node3\"/> </nodes> <resources/> <constraints/> </configuration> <status/> </cib> [root@controller ~]# pcs cluster cib <cib crm_feature_set=\"3.0.14\" validate-with=\"pacemaker-2.10\" epoch=\"5\" num_updates=\"5\" admin_epoch=\"0\" cib-last-written=\"Mon Jan 28 11:27:28 2019\" update-origin=\"node1\" update-client=\"crmd\" update-user=\"hacluster\" have-quorum=\"1\" dc-uuid=\"1\"> <configuration> <crm_config> <cluster_property_set id=\"cib-bootstrap-options\"> <nvpair id=\"cib-bootstrap-options-have-watchdog\" name=\"have-watchdog\" value=\"false\"/> <nvpair id=\"cib-bootstrap-options-dc-version\" name=\"dc-version\" value=\"1.1.19-8.el7_6.2-c3c624ea3d\"/> <nvpair id=\"cib-bootstrap-options-cluster-infrastructure\" name=\"cluster-infrastructure\" value=\"corosync\"/> <nvpair id=\"cib-bootstrap-options-cluster-name\" name=\"cluster-name\" value=\"hacluster\"/> </cluster_property_set> </crm_config> <nodes> <node id=\"1\" uname=\"node1\"/> <node id=\"2\" uname=\"node2\"/> <node id=\"3\" uname=\"node3\"/> </nodes> <resources/> <constraints/> </configuration> <status> <node_state id=\"1\" uname=\"node1\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"1\"> <lrm_resources/> </lrm> </node_state> <node_state id=\"3\" uname=\"node3\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"3\"> <lrm_resources/> </lrm> </node_state> <node_state id=\"2\" uname=\"node2\" in_ccm=\"true\" crmd=\"online\" crm-debug-origin=\"do_state_transition\" join=\"member\" expected=\"member\"> <lrm id=\"2\"> <lrm_resources/> </lrm> </node_state> </status> </cib> Ki\u1ec3m tra status c\u1ee7a Corosync tr\u00ean Node corosync-cfgtool -s Ki\u1ec3m tra tr\u1ea1ng th\u00e1i Corsync member pcs status corosync Membership information ---------------------- Nodeid Votes Name 1 1 192.168.30.130 (local) 2 1 192.168.30.131 3 1 192.168.30.132 Disable ch\u1ee9c n\u0103ng stonith pcs property set stonith-enabled=false --force END ./","title":"2.3 . Kh\u1edfi t\u1ea1o Cluster - th\u1ef1c hi\u1ec7n tr\u00ean node 30"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/","text":"Thao t\u00e1c v\u1edbi Pacemaker \u00b6 1. Resource Level \u00b6 1.1. Qu\u1ea3n l\u00fd Resource \u00b6 \u0110\u1ea7u ti\u00ean resource c\u1ea7n c\u00f3 m\u1ed9t IP \u0111\u1ec3 c\u00f3 th\u1ec3 di chuy\u1ec3n n\u1eefa c\u00e1c node trong Cluster. Ng\u01b0\u1eddi d\u00f9ng s\u1ebd d\u1ee5ng IP n\u00e0y \u0111\u1ec3 li\u00ean h\u1ec7 v\u1edbi t\u00e0i nguy\u00ean n\u00e0y c\u1ee7a c\u1ee5m. \u0110\u1ecba ch\u1ec9 IP kh\u00f4ng \u0111\u01b0\u1ee3c tr\u00f9ng v\u1edbi c\u00e1c kh\u00e1c thi\u1ebft b\u1ecb m\u1ea1ng c\u00f3 trong m\u00f4 h\u00ecnh m\u1ea1ng pcs resource create VirtualIP ocf:heartbeat:IPaddr2 ip=192.168.30.135 \\ cidr_netmask=32 op monitor interval=30s Trong \u0111\u00f3 **ocf:heartbeat:IPaddr2**. l\u00e0 m\u1ed9t tr\u01b0\u1eddng quan tr\u1ecdng . Tr\u01b0\u1eddng n\u00e0y cung c\u1ea5p : - ocf : cung c\u1ea5p ch\u01a1i ch\u1ee9a c\u00e1c script s\u1eed d\u1ee5ng cho pacemaker - heartbeat : t\u00f9y v\u00e0o c\u00e1c n\u01a1i ch\u01b0a c\u00e1c script th\u00ec s\u1ebd g\u1ed3m c\u00e1c namespacee kh\u00e1c nhau . Trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y ch\u1ec9 \u0111\u1ecbnh namespace heartbeat trong ocf - IPaddr2 : t\u00ean c\u1ee7a script \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng Ki\u1ec3m tra status resource v\u1eeba t\u1ea1o [root@controller ~]# pcs cluster start node2 node2: Starting Cluster (corosync)... node2: Starting Cluster (pacemaker)... [root@controller ~]# pcs resource VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Kh\u1edfi \u0111\u1ed9ng m\u1ed9t Resource pcs resource enable VirtualIP D\u1eebng m\u1ed9t Resource pcs resource disable VirtualIP Update m\u1ed9t Resource pcs resource update VirtualIP Chuy\u1ec3n resource pcs resource move VirtualIP node1 X\u00f3a resource kh\u1ecfi node ( chuy\u1ec3n resource v\u1ec1 v\u00f4 ch\u1ee7 ) pcs resource ban VirtualIP pcmk X\u00f3a resource c\u00f3 t\u00ean VirtualIP pcs cluster delete VirtualIP 1.2. C\u00e1c command ki\u1ec3m tra resource \u00b6 Ki\u1ec3m tra c\u00e1c resource \u0111ang \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi cluster pcs status Cluster name: hacluster Stack: corosync Current DC: node1 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:31:59 2019 Last change: Mon Jan 28 11:28:33 2019 by root via cibadmin on node1 3 nodes configured 1 resource configured Online: [ node1 node2 node3 ] Full list of resources: VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Daemon Status: corosync: active/disabled pacemaker: active/disabled pcsd: active/enabled Xem th\u00f4ng tin v\u1ec1 resource [root@controller ~]# pcs resource show VirtualIP Resource: VirtualIP (class=ocf provider=heartbeat type=IPaddr2) Attributes: cidr_netmask=32 ip=192.168.30.135 Operations: monitor interval=30s (VirtualIP-monitor-interval-30s) start interval=0s timeout=20s (VirtualIP-start-interval-0s) stop interval=0s timeout=20s (VirtualIP-stop-interval-0s) Ki\u1ec3m tra c\u00e1c resource class \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi Pacemaer [root@controller ~]# pcs resource standards lsb ocf service Ki\u1ec3m tra c\u00e1c namespace trong OCF resource classs [root@controller ~]# pcs resource providers heartbeat openstack pacemaker rabbitmq Ki\u1ec3m tra c\u00e1c resource agent ( script trong m\u1ed9t namespace ) pcs resource agents ocf:heartbeat Ki\u1ec3m tra \u0111\u1ea7y \u0111\u1ee7 c\u00e1c resource v\u00e0 resource agent pcs resource list pcs resource agents Xem th\u00f4ng tin c\u1ee7a m\u1ed9t resource agent c\u1ee5 th\u1ec3 pcs resource describe IPaddr2 1.3. Ki\u1ec3m th\u1eed Failover Resource \u00b6 Ki\u1ec3m tra node \u0111ang c\u00f3 VirtualIP pcs status T\u1eaft service Pacemaker v\u00e0 Corosync \u0111ang ch\u1ea1y tr\u00ean node node2 pcs cluster stop node2 Ki\u1ec3m tra status tr\u00ean Node node2 pcs status Error: cluster is not currently running on this node Kii\u1ec3m tra status tr\u00ean Node node1 [root@controller ~]# pcs status Cluster name: hacluster Stack: corosync Current DC: node1 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:33:58 2019 Last change: Mon Jan 28 11:28:33 2019 by root via cibadmin on node1 3 nodes configured 1 resource configured Online: [ node1 node3 ] OFFLINE: [ node2 ] Full list of resources: VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Daemon Status: corosync: active/disabled pacemaker: active/disabled pcsd: active/enabled Kh\u1edfi \u0111\u1ed9ng l\u1ea1i node2 pcs cluster start node2 Sau khi m\u1ed9t node h\u1ed3i ph\u1ee5c. Pacemaker s\u1ebd m\u1eb7c \u0111\u1ecbnh r\u1eb1ng node s\u1ebd kh\u00f4ng c\u00f3 th\u1eddi gian downtime ti\u1ebfp theo. Ta c\u00f3 th\u1ec3 ch\u1ec9nh th\u00eam th\u1eddi gian downtime pcs resource defaults resource-stickiness=100 2. Cluster Level \u00b6 Xem t\u1eadp tin c\u1ea5u h\u00ecnh c\u1ee7a Cluster theo \u0111\u1ecbnh d\u1ea1ng XML t\u1ea1i /var/lib/pacemaker/cib/cib.xml pcs cluster cib Xem t\u1eadp tin c\u1ea5u h\u00ecnh Cluster d\u01b0\u1edbi d\u1ea1ng c\u1ea5u tr\u00fac ``` pcs config - Xem tr\u1ea1ng th\u00e1i c\u1ee7a node v\u00e0 c\u00e1c resource pcs status - Chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i `standy` - kh\u00f4ng th\u1ec3 l\u01b0u tr\u1eef c\u00e1c resource. Sau khi chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i `standy` resource chuy\u1ec3n v\u1ec1 node n\u00e0y s\u1ebd chuy\u1ec3n sang tr\u1ea1ng th\u00e1i `stopped` pcs cluster standby node2 - Chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i Online pcs cluster unstandby node2 - \u0110\u00f3ng ti\u1ebfn tr\u00ecnh Pacemaker v\u00e0 Corosync tr\u00ean node hi\u1ec7n t\u1ea1i pcs kill - X\u00f3a Node kh\u1ecfi Cluster. Sau khi x\u00f3a node kh\u1ecfi cluser , c\u00e1c resource s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n sang c\u00e1c node kh\u00e1c pcs cluster node remove node3 - Th\u00eam Node v\u00e0o Cluster Truoc tien can authen vao node \u00b6 pcs cluster auth node3 -u hacluster -p 123@123Aa Them node vao Cluster \u00b6 pcs cluster node add node3 Khoi dong node 3 \u00b6 pcs cluster start node3 - Very file c\u1ea5u h\u00ecnh pacemaker pcs verify ``` Pending ./","title":"3. Use Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#thao_tac_voi_pacemaker","text":"","title":"Thao t\u00e1c v\u1edbi Pacemaker"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#1_resource_level","text":"","title":"1. Resource Level"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#11_quan_ly_resource","text":"\u0110\u1ea7u ti\u00ean resource c\u1ea7n c\u00f3 m\u1ed9t IP \u0111\u1ec3 c\u00f3 th\u1ec3 di chuy\u1ec3n n\u1eefa c\u00e1c node trong Cluster. Ng\u01b0\u1eddi d\u00f9ng s\u1ebd d\u1ee5ng IP n\u00e0y \u0111\u1ec3 li\u00ean h\u1ec7 v\u1edbi t\u00e0i nguy\u00ean n\u00e0y c\u1ee7a c\u1ee5m. \u0110\u1ecba ch\u1ec9 IP kh\u00f4ng \u0111\u01b0\u1ee3c tr\u00f9ng v\u1edbi c\u00e1c kh\u00e1c thi\u1ebft b\u1ecb m\u1ea1ng c\u00f3 trong m\u00f4 h\u00ecnh m\u1ea1ng pcs resource create VirtualIP ocf:heartbeat:IPaddr2 ip=192.168.30.135 \\ cidr_netmask=32 op monitor interval=30s Trong \u0111\u00f3 **ocf:heartbeat:IPaddr2**. l\u00e0 m\u1ed9t tr\u01b0\u1eddng quan tr\u1ecdng . Tr\u01b0\u1eddng n\u00e0y cung c\u1ea5p : - ocf : cung c\u1ea5p ch\u01a1i ch\u1ee9a c\u00e1c script s\u1eed d\u1ee5ng cho pacemaker - heartbeat : t\u00f9y v\u00e0o c\u00e1c n\u01a1i ch\u01b0a c\u00e1c script th\u00ec s\u1ebd g\u1ed3m c\u00e1c namespacee kh\u00e1c nhau . Trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y ch\u1ec9 \u0111\u1ecbnh namespace heartbeat trong ocf - IPaddr2 : t\u00ean c\u1ee7a script \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng Ki\u1ec3m tra status resource v\u1eeba t\u1ea1o [root@controller ~]# pcs cluster start node2 node2: Starting Cluster (corosync)... node2: Starting Cluster (pacemaker)... [root@controller ~]# pcs resource VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Kh\u1edfi \u0111\u1ed9ng m\u1ed9t Resource pcs resource enable VirtualIP D\u1eebng m\u1ed9t Resource pcs resource disable VirtualIP Update m\u1ed9t Resource pcs resource update VirtualIP Chuy\u1ec3n resource pcs resource move VirtualIP node1 X\u00f3a resource kh\u1ecfi node ( chuy\u1ec3n resource v\u1ec1 v\u00f4 ch\u1ee7 ) pcs resource ban VirtualIP pcmk X\u00f3a resource c\u00f3 t\u00ean VirtualIP pcs cluster delete VirtualIP","title":"1.1. Qu\u1ea3n l\u00fd  Resource"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#12_cac_command_kiem_tra_resource","text":"Ki\u1ec3m tra c\u00e1c resource \u0111ang \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi cluster pcs status Cluster name: hacluster Stack: corosync Current DC: node1 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:31:59 2019 Last change: Mon Jan 28 11:28:33 2019 by root via cibadmin on node1 3 nodes configured 1 resource configured Online: [ node1 node2 node3 ] Full list of resources: VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Daemon Status: corosync: active/disabled pacemaker: active/disabled pcsd: active/enabled Xem th\u00f4ng tin v\u1ec1 resource [root@controller ~]# pcs resource show VirtualIP Resource: VirtualIP (class=ocf provider=heartbeat type=IPaddr2) Attributes: cidr_netmask=32 ip=192.168.30.135 Operations: monitor interval=30s (VirtualIP-monitor-interval-30s) start interval=0s timeout=20s (VirtualIP-start-interval-0s) stop interval=0s timeout=20s (VirtualIP-stop-interval-0s) Ki\u1ec3m tra c\u00e1c resource class \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi Pacemaer [root@controller ~]# pcs resource standards lsb ocf service Ki\u1ec3m tra c\u00e1c namespace trong OCF resource classs [root@controller ~]# pcs resource providers heartbeat openstack pacemaker rabbitmq Ki\u1ec3m tra c\u00e1c resource agent ( script trong m\u1ed9t namespace ) pcs resource agents ocf:heartbeat Ki\u1ec3m tra \u0111\u1ea7y \u0111\u1ee7 c\u00e1c resource v\u00e0 resource agent pcs resource list pcs resource agents Xem th\u00f4ng tin c\u1ee7a m\u1ed9t resource agent c\u1ee5 th\u1ec3 pcs resource describe IPaddr2","title":"1.2. C\u00e1c command ki\u1ec3m tra resource"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#13_kiem_thu_failover_resource","text":"Ki\u1ec3m tra node \u0111ang c\u00f3 VirtualIP pcs status T\u1eaft service Pacemaker v\u00e0 Corosync \u0111ang ch\u1ea1y tr\u00ean node node2 pcs cluster stop node2 Ki\u1ec3m tra status tr\u00ean Node node2 pcs status Error: cluster is not currently running on this node Kii\u1ec3m tra status tr\u00ean Node node1 [root@controller ~]# pcs status Cluster name: hacluster Stack: corosync Current DC: node1 (version 1.1.19-8.el7_6.2-c3c624ea3d) - partition with quorum Last updated: Mon Jan 28 11:33:58 2019 Last change: Mon Jan 28 11:28:33 2019 by root via cibadmin on node1 3 nodes configured 1 resource configured Online: [ node1 node3 ] OFFLINE: [ node2 ] Full list of resources: VirtualIP (ocf::heartbeat:IPaddr2): Started node1 Daemon Status: corosync: active/disabled pacemaker: active/disabled pcsd: active/enabled Kh\u1edfi \u0111\u1ed9ng l\u1ea1i node2 pcs cluster start node2 Sau khi m\u1ed9t node h\u1ed3i ph\u1ee5c. Pacemaker s\u1ebd m\u1eb7c \u0111\u1ecbnh r\u1eb1ng node s\u1ebd kh\u00f4ng c\u00f3 th\u1eddi gian downtime ti\u1ebfp theo. Ta c\u00f3 th\u1ec3 ch\u1ec9nh th\u00eam th\u1eddi gian downtime pcs resource defaults resource-stickiness=100","title":"1.3. Ki\u1ec3m th\u1eed Failover Resource"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#2_cluster_level","text":"Xem t\u1eadp tin c\u1ea5u h\u00ecnh c\u1ee7a Cluster theo \u0111\u1ecbnh d\u1ea1ng XML t\u1ea1i /var/lib/pacemaker/cib/cib.xml pcs cluster cib Xem t\u1eadp tin c\u1ea5u h\u00ecnh Cluster d\u01b0\u1edbi d\u1ea1ng c\u1ea5u tr\u00fac ``` pcs config - Xem tr\u1ea1ng th\u00e1i c\u1ee7a node v\u00e0 c\u00e1c resource pcs status - Chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i `standy` - kh\u00f4ng th\u1ec3 l\u01b0u tr\u1eef c\u00e1c resource. Sau khi chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i `standy` resource chuy\u1ec3n v\u1ec1 node n\u00e0y s\u1ebd chuy\u1ec3n sang tr\u1ea1ng th\u00e1i `stopped` pcs cluster standby node2 - Chuy\u1ec3n node v\u1ec1 tr\u1ea1ng th\u00e1i Online pcs cluster unstandby node2 - \u0110\u00f3ng ti\u1ebfn tr\u00ecnh Pacemaker v\u00e0 Corosync tr\u00ean node hi\u1ec7n t\u1ea1i pcs kill - X\u00f3a Node kh\u1ecfi Cluster. Sau khi x\u00f3a node kh\u1ecfi cluser , c\u00e1c resource s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n sang c\u00e1c node kh\u00e1c pcs cluster node remove node3 - Th\u00eam Node v\u00e0o Cluster","title":"2. Cluster Level"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#truoc_tien_can_authen_vao_node","text":"pcs cluster auth node3 -u hacluster -p 123@123Aa","title":"Truoc tien can authen vao node"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#them_node_vao_cluster","text":"pcs cluster node add node3","title":"Them node vao Cluster"},{"location":"Openstack_Research/High-availability/3. Pacemaker/3. Use-Pacemaker/#khoi_dong_node_3","text":"pcs cluster start node3 - Very file c\u1ea5u h\u00ecnh pacemaker pcs verify ``` Pending ./","title":"Khoi dong node 3"},{"location":"Openstack_Research/High-availability/3. Pacemaker/4. Pacemaker-Apache-Active-Passive/","text":"Pacemaker Apache Active-Pasive \u00b6 1. Chu\u1ea9n b\u1ecb m\u00f4i tr\u01b0\u1eddng tr\u00ean 3 node \u00b6 C\u00e0i \u0111\u1eb7t Apache Server tr\u00ean c\u1ea3 3 node yum install -y httpd wget firewall-cmd --permanent --add-service=http firewall-cmd --reload C\u1ea5u h\u00ecnh n\u1ed9i dung tr\u00ean 3 Webserver cat <<-END >/var/www/html/index.html <html> <body>Site - $(hostname)</body> </html> END Kh\u1edfi t\u1ea1o URL cho qu\u00e1 tr\u00ecnh resource agent monitor cat <<-END >/etc/httpd/conf.d/status.conf <Location /server-status> SetHandler server-status Require local </Location> END T\u1eaft Service HTTPD systemctl stop httpd 2. C\u1ea5u h\u00ecnh Cluster \u00b6 Kh\u1edfi t\u1ea1o Resource VirtualIP pcs resource create VirtualIP ocf:heartbeat:IPaddr2 ip=192.168.30.135 \\ cidr_netmask=32 op monitor interval=30s C\u1ea5u h\u00ecnh Resource s\u1eed d\u1ee5ng agent ocf:heartbeat:apache \u0111\u1ec3 ki\u1ec3m tra \u0111\u1ecbnh k\u1ef3 30s Apache c\u00f3 b\u1ecb qu\u00e1 t\u1ea3i pcs resource create WebSite ocf:heartbeat:apache \\ configfile=/etc/httpd/conf/httpd.conf \\ statusurl=\"http://localhost/server-status\" \\ op monitor interval=30s Ki\u1ec3m tra Resource [root@compute1 ~]# pcs resource VirtualIP (ocf::heartbeat:IPaddr2): Started node2 WebSite (ocf::heartbeat:apache): Started node2 \u0110\u1ec3 gi\u1ea3m t\u1ea3i b\u1ea5t k\u1ef3 cho m\u1ed9t node n\u00e0o \u0111\u00f3, Pacemaker s\u1ebd c\u1ed1 g\u1eafng ph\u00e2n t\u00e1n c\u00e1c resource ra c\u00e1c node. Tuy nhi\u00ean s\u1ebd c\u00f3 c\u00e1c lo\u1ea1i resource li\u00ean quan v\u1edbi nhau v\u00e0 ch\u1ea1y tr\u00ean 1 node. \u1ede trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y s\u1ebd cho c\u00e1c Website resource ch\u1ea1y tr\u00ean node c\u00f3 VirtualIP resource pcs constraint colocation add WebSite with VirtualIP INFINITY Gi\u1ed1ng nh\u01b0 c\u00e1c Service kh\u00e1c, Apache c\u00f3 th\u1ec3 bind v\u00e0o m\u1ed9t \u0111\u1ecba ch\u1ec9 IP c\u1ee5 th\u1ec3 .Khi Apche \u0111\u01b0\u1ee3c bind v\u00e0o IP s\u1ebd x\u1ea3y ra v\u1ea5n \u0111\u1ec1 n\u1ebfu IP n\u00e0y g\u1eafn v\u00e0o sau khi apache \u0111\u00e3 \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng , vi\u1ec7c g\u1eafn IP l\u00e0 v\u00f4 ngh\u0129a, HTTPD s\u1ebd kh\u00f4ng tr\u1ea3 v\u1ec1 respon tr\u00ean \u0111\u1ecba ch\u1ec9 n\u00e0y. C\u00f3 ngh\u0129a vi\u1ec7c chuy\u1ec3n Apache gi\u1eefa c\u00e1c node c\u1ea7n x\u1eed l\u00fd vi\u1ec7c VirtualIP kh\u00f4ng n\u1eb1m c\u1ed1 \u0111\u1ecbnh tr\u00ean m\u1ed9t node. V\u00ec th\u1ebf ch\u00fang ta c\u1ea7n ch\u1ec9 \u0111\u1ecbnh th\u1ee9 t\u1ef1 kh\u1edfi \u0111\u1ed9ng c\u1ee7a m\u1ed9t resource khi chuy\u1ec3n qua node m\u1edbi pcs constraint order VirtualIP then WebSite pcs constraint Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p s\u1ebd c\u00f3 m\u1ed9t s\u1ed1 node trong cluster c\u00f3 hi\u1ec7u n\u0103ng t\u1ed1t h\u01a1n. C\u00f3 th\u1ec3 ch\u1ec9 \u0111\u1ecbnh \u0111i\u1ec3m s\u1ed1 tr\u00ean c\u00e1c node n\u00e0y \u0111\u1ec3 ch\u1ea1y c\u00e1c resource khi n\u00f3 \u1edf tr\u1ea1ng th\u00e1i Online pcs constraint location WebSite prefers node3=50 M\u1eb7c d\u00f9 hi\u1ec7n t\u1ea1i Resource \u0111\u00e3 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh \u01b0u ti\u00ean l\u00e0 node3 . Nh\u01b0ng hi\u1ec7n t\u1ea1i ch\u1ec9 s\u1ed1 n\u00e0y nh\u1ecf h\u01a1n resource stickiness Chuy\u1ec3n resource v\u1ec1 Node 3 pcs resource move VirtualIP node2 pcs resource move WebSite node3 C\u00e1c tri\u1ebfn tr\u00ecnh tr\u00ean c\u00e1c Node \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng b\u1edfi c\u00e1c Agent thay v\u00ec kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 . End.","title":"4. Pacemaker Apache Active Passive"},{"location":"Openstack_Research/High-availability/3. Pacemaker/4. Pacemaker-Apache-Active-Passive/#pacemaker_apache_active-pasive","text":"","title":"Pacemaker Apache Active-Pasive"},{"location":"Openstack_Research/High-availability/3. Pacemaker/4. Pacemaker-Apache-Active-Passive/#1_chuan_bi_moi_truong_tren_3_node","text":"C\u00e0i \u0111\u1eb7t Apache Server tr\u00ean c\u1ea3 3 node yum install -y httpd wget firewall-cmd --permanent --add-service=http firewall-cmd --reload C\u1ea5u h\u00ecnh n\u1ed9i dung tr\u00ean 3 Webserver cat <<-END >/var/www/html/index.html <html> <body>Site - $(hostname)</body> </html> END Kh\u1edfi t\u1ea1o URL cho qu\u00e1 tr\u00ecnh resource agent monitor cat <<-END >/etc/httpd/conf.d/status.conf <Location /server-status> SetHandler server-status Require local </Location> END T\u1eaft Service HTTPD systemctl stop httpd","title":"1. Chu\u1ea9n b\u1ecb m\u00f4i tr\u01b0\u1eddng tr\u00ean 3 node"},{"location":"Openstack_Research/High-availability/3. Pacemaker/4. Pacemaker-Apache-Active-Passive/#2_cau_hinh_cluster","text":"Kh\u1edfi t\u1ea1o Resource VirtualIP pcs resource create VirtualIP ocf:heartbeat:IPaddr2 ip=192.168.30.135 \\ cidr_netmask=32 op monitor interval=30s C\u1ea5u h\u00ecnh Resource s\u1eed d\u1ee5ng agent ocf:heartbeat:apache \u0111\u1ec3 ki\u1ec3m tra \u0111\u1ecbnh k\u1ef3 30s Apache c\u00f3 b\u1ecb qu\u00e1 t\u1ea3i pcs resource create WebSite ocf:heartbeat:apache \\ configfile=/etc/httpd/conf/httpd.conf \\ statusurl=\"http://localhost/server-status\" \\ op monitor interval=30s Ki\u1ec3m tra Resource [root@compute1 ~]# pcs resource VirtualIP (ocf::heartbeat:IPaddr2): Started node2 WebSite (ocf::heartbeat:apache): Started node2 \u0110\u1ec3 gi\u1ea3m t\u1ea3i b\u1ea5t k\u1ef3 cho m\u1ed9t node n\u00e0o \u0111\u00f3, Pacemaker s\u1ebd c\u1ed1 g\u1eafng ph\u00e2n t\u00e1n c\u00e1c resource ra c\u00e1c node. Tuy nhi\u00ean s\u1ebd c\u00f3 c\u00e1c lo\u1ea1i resource li\u00ean quan v\u1edbi nhau v\u00e0 ch\u1ea1y tr\u00ean 1 node. \u1ede trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y s\u1ebd cho c\u00e1c Website resource ch\u1ea1y tr\u00ean node c\u00f3 VirtualIP resource pcs constraint colocation add WebSite with VirtualIP INFINITY Gi\u1ed1ng nh\u01b0 c\u00e1c Service kh\u00e1c, Apache c\u00f3 th\u1ec3 bind v\u00e0o m\u1ed9t \u0111\u1ecba ch\u1ec9 IP c\u1ee5 th\u1ec3 .Khi Apche \u0111\u01b0\u1ee3c bind v\u00e0o IP s\u1ebd x\u1ea3y ra v\u1ea5n \u0111\u1ec1 n\u1ebfu IP n\u00e0y g\u1eafn v\u00e0o sau khi apache \u0111\u00e3 \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng , vi\u1ec7c g\u1eafn IP l\u00e0 v\u00f4 ngh\u0129a, HTTPD s\u1ebd kh\u00f4ng tr\u1ea3 v\u1ec1 respon tr\u00ean \u0111\u1ecba ch\u1ec9 n\u00e0y. C\u00f3 ngh\u0129a vi\u1ec7c chuy\u1ec3n Apache gi\u1eefa c\u00e1c node c\u1ea7n x\u1eed l\u00fd vi\u1ec7c VirtualIP kh\u00f4ng n\u1eb1m c\u1ed1 \u0111\u1ecbnh tr\u00ean m\u1ed9t node. V\u00ec th\u1ebf ch\u00fang ta c\u1ea7n ch\u1ec9 \u0111\u1ecbnh th\u1ee9 t\u1ef1 kh\u1edfi \u0111\u1ed9ng c\u1ee7a m\u1ed9t resource khi chuy\u1ec3n qua node m\u1edbi pcs constraint order VirtualIP then WebSite pcs constraint Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p s\u1ebd c\u00f3 m\u1ed9t s\u1ed1 node trong cluster c\u00f3 hi\u1ec7u n\u0103ng t\u1ed1t h\u01a1n. C\u00f3 th\u1ec3 ch\u1ec9 \u0111\u1ecbnh \u0111i\u1ec3m s\u1ed1 tr\u00ean c\u00e1c node n\u00e0y \u0111\u1ec3 ch\u1ea1y c\u00e1c resource khi n\u00f3 \u1edf tr\u1ea1ng th\u00e1i Online pcs constraint location WebSite prefers node3=50 M\u1eb7c d\u00f9 hi\u1ec7n t\u1ea1i Resource \u0111\u00e3 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh \u01b0u ti\u00ean l\u00e0 node3 . Nh\u01b0ng hi\u1ec7n t\u1ea1i ch\u1ec9 s\u1ed1 n\u00e0y nh\u1ecf h\u01a1n resource stickiness Chuy\u1ec3n resource v\u1ec1 Node 3 pcs resource move VirtualIP node2 pcs resource move WebSite node3 C\u00e1c tri\u1ebfn tr\u00ecnh tr\u00ean c\u00e1c Node \u0111\u01b0\u1ee3c kh\u1edfi \u0111\u1ed9ng b\u1edfi c\u00e1c Agent thay v\u00ec kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 . End.","title":"2. C\u1ea5u h\u00ecnh Cluster"},{"location":"Openstack_Research/High-availability/3. Pacemaker/corosync/","text":"T\u1eadp tin c\u1ea5u h\u00ecnh Corosync totem { version: 2 cluster_name: hacluster secauth: off transport: udpu } nodelist { node { ring0_addr: 192.168.69.130 nodeid: 1 } node { ring0_addr: 192.168.69.131 nodeid: 2 } node { ring0_addr: 192.168.69.132 nodeid: 3 } } quorum { provider: corosync_votequorum } logging { to_logfile: yes logfile: /var/log/cluster/corosync.log to_syslog: yes","title":"Corosync"},{"location":"Openstack_Research/Horizon/Introduction-horizon/","text":"OpenStack Dashboard - Horizon \u00b6 1. T\u1ed5ng quan v\u1ec1 Horizon \u00b6 1.1. Kh\u00e1i ni\u1ec7m Horizon \u00b6 Horizon l\u00e0 code-name c\u1ee7a Openstack Dashboard , cung c\u1ea5p m\u1ed9t Web-based interface cho c\u00e1c Openstack Service kh\u00e1c nhau g\u1ed3m : Nova, Swift, Keystone, etc... Horizon s\u1eed d\u1ee5ng Django Python l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c API Service, s\u1eed d\u1ee5ng openstack indentify \u0111\u1ec3 authen , kh\u00f4ng s\u1eed d\u1ee5ng database ri\u00eang 1.2 . Ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a Horzion \u00b6 Cung c\u1ea5p giao di\u1ec7n qu\u1ea3n l\u00fd d\u1ec5 d\u00e0ng C\u00f3 th\u1ec3 s\u1eed d\u1ee5ng cho m\u00f4i tr\u01b0\u1eddng production T\u00f9y ch\u1ec9nh, th\u00eam c\u00e1c compoment v\u00e0o panel theo t\u1eebng d\u1ecbch v\u1ee5 Quy tr\u00ecnh l\u00e0m vi\u1ec7c trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng Code-base theo h\u01b0\u1edbng \u0111\u1ed1i t\u01b0\u1ee3ng, d\u1ec5 ph\u00e1t tri\u1ec3n 1.3 . Ki\u1ebfm tr\u00fac l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c Service kh\u00e1c \u00b6 2. C\u00e1c th\u00e0nh ph\u1ea7n tr\u00ean Dashboard Tab \u00b6 2.1 . Compute Tab \u00b6 Overview : xong b\u00e1o c\u00e1o t\u1ed5ng quan v\u1ec1 project Instance : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a c\u00e1c m\u1ea3y \u1ea3o, k\u1ebft n\u1ed1i m\u00e1y \u1ea3o qua console Volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c volume v\u00e0 snapshot volume Image : li\u1ec7t k\u00ea c\u00e1c image, instance snapshot, volume snapshot v\u00e0 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a ch\u00fang Access & Security : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi security group, key pair, floating IP, API access request 2.2. Network Tab \u00b6 Network topology : t\u1ed5ng quan v\u1ec1 m\u00f4 h\u00ecnh m\u1ea1ng \u0111ang c\u00f3 s\u1eb5n networs : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c m\u1ea1ng \u1ea3o route : kh\u1edfi t\u1ea1o c\u00e1c \u0111i\u1ec3m routing 2.3. Identity Tab \u00b6 Projects : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c project, xem th\u1ed1ng k\u00ea c\u1ee7a project, qu\u1ea3n l\u00fd c\u00e1c user Users : qu\u1ea3n l\u00fd user, hi\u1ec3n th\u1ecb th\u00f4ng b\u00e1o n\u1ebfu kh\u00f4ng c\u00f3 \u0111\u1eb7c quy\u1ec1n 3. Tham kh\u1ea3o th\u00eam \u00b6 [1] : https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/8/html-single/introduction_to_the_openstack_dashboard/index [2] : https://docs.openstack.org/horizon/latest/","title":"OpenStack Dashboard - Horizon"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#openstack_dashboard_-_horizon","text":"","title":"OpenStack Dashboard - Horizon"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#1_tong_quan_ve_horizon","text":"","title":"1. T\u1ed5ng quan v\u1ec1 Horizon"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#11_khai_niem_horizon","text":"Horizon l\u00e0 code-name c\u1ee7a Openstack Dashboard , cung c\u1ea5p m\u1ed9t Web-based interface cho c\u00e1c Openstack Service kh\u00e1c nhau g\u1ed3m : Nova, Swift, Keystone, etc... Horizon s\u1eed d\u1ee5ng Django Python l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c API Service, s\u1eed d\u1ee5ng openstack indentify \u0111\u1ec3 authen , kh\u00f4ng s\u1eed d\u1ee5ng database ri\u00eang","title":"1.1. Kh\u00e1i ni\u1ec7m Horizon"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#12_chuc_nang_chinh_cua_horzion","text":"Cung c\u1ea5p giao di\u1ec7n qu\u1ea3n l\u00fd d\u1ec5 d\u00e0ng C\u00f3 th\u1ec3 s\u1eed d\u1ee5ng cho m\u00f4i tr\u01b0\u1eddng production T\u00f9y ch\u1ec9nh, th\u00eam c\u00e1c compoment v\u00e0o panel theo t\u1eebng d\u1ecbch v\u1ee5 Quy tr\u00ecnh l\u00e0m vi\u1ec7c trong su\u1ed1t v\u1edbi ng\u01b0\u1eddi d\u00f9ng Code-base theo h\u01b0\u1edbng \u0111\u1ed1i t\u01b0\u1ee3ng, d\u1ec5 ph\u00e1t tri\u1ec3n","title":"1.2 . Ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a Horzion"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#13_kiem_truc_lam_viec_voi_cac_service_khac","text":"","title":"1.3 . Ki\u1ebfm tr\u00fac l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c Service kh\u00e1c"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#2_cac_thanh_phan_tren_dashboard_tab","text":"","title":"2. C\u00e1c th\u00e0nh ph\u1ea7n tr\u00ean Dashboard Tab"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#21_compute_tab","text":"Overview : xong b\u00e1o c\u00e1o t\u1ed5ng quan v\u1ec1 project Instance : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a c\u00e1c m\u1ea3y \u1ea3o, k\u1ebft n\u1ed1i m\u00e1y \u1ea3o qua console Volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c volume v\u00e0 snapshot volume Image : li\u1ec7t k\u00ea c\u00e1c image, instance snapshot, volume snapshot v\u00e0 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a ch\u00fang Access & Security : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi security group, key pair, floating IP, API access request","title":"2.1 . Compute Tab"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#22_network_tab","text":"Network topology : t\u1ed5ng quan v\u1ec1 m\u00f4 h\u00ecnh m\u1ea1ng \u0111ang c\u00f3 s\u1eb5n networs : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c m\u1ea1ng \u1ea3o route : kh\u1edfi t\u1ea1o c\u00e1c \u0111i\u1ec3m routing","title":"2.2. Network Tab"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#23_identity_tab","text":"Projects : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c project, xem th\u1ed1ng k\u00ea c\u1ee7a project, qu\u1ea3n l\u00fd c\u00e1c user Users : qu\u1ea3n l\u00fd user, hi\u1ec3n th\u1ecb th\u00f4ng b\u00e1o n\u1ebfu kh\u00f4ng c\u00f3 \u0111\u1eb7c quy\u1ec1n","title":"2.3. Identity Tab"},{"location":"Openstack_Research/Horizon/Introduction-horizon/#3_tham_khao_them","text":"[1] : https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/8/html-single/introduction_to_the_openstack_dashboard/index [2] : https://docs.openstack.org/horizon/latest/","title":"3. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/","text":"1. Openstack Indentify ( Keystone ) \u00b6 1: Kh\u00e1i ni\u1ec7m Keystone \u00b6 Keystone l\u00e0 OpenStack project cung c\u1ea5p c\u00e1c d\u1ecbch v\u1ee5 Identity, Token, Catalog, Policy cho c\u00e1c project kh\u00e1c trong OpenStack. Keystone c\u00f3 2 phi\u1ec3n b\u1ea3n g\u1ed3m V2 V3 s\u1eed d\u1ee5ng UUID s\u1eed d\u1ee5ng PKI, m\u1ed7i m\u00e3 th\u00f4ng b\u00e1o \u0111\u1ea1i di\u1ec7n cho m\u1ed9t c\u1eb7p kh\u00f3a m\u1edf v\u00e0 \u0111\u00f3ng \u0111\u1ec3 x\u00e1c minh ch\u00e9o v\u00e0 x\u00e1c th\u1ef1c. Hai t\u00ednh n\u0103ng ch\u00ednh c\u1ee7a Keystone: User Management: keystone x\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 ch\u1ec9 \u0111\u1ecbnh xem ng\u01b0\u1eddi d\u00f9ng c\u00f3 quy\u1ec1n \u0111\u01b0\u1ee3c l\u00e0m g\u00ec. Service Catalog: Cung c\u1ea5p m\u1ed9t danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 s\u1eb5n s\u00e0ng c\u00f9ng v\u1edbi c\u00e1c API endpoints \u0111\u1ec3 truy c\u1eadp c\u00e1c d\u1ecbch v\u1ee5 \u0111\u00f3. 2 : C\u1ea5u tr\u00fac trong Keystone \u00b6 2.1. Project Kh\u00e1i ni\u1ec7m ch\u1ec9 s\u1ef1 gom g\u1ed9p, c\u00f4 l\u1eadp c\u00e1c ngu\u1ed3n t\u00e0i nguy\u00ean (server, images, etc.) C\u00e1c user \u0111\u01b0\u1ee3c g\u1eafn role v\u00e0 truy c\u1eadp s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean trong project role \u0111\u1ec3 quy \u0111\u1ecbnh t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c ph\u00e9p truy c\u1eadp trong project (kh\u00e1i ni\u1ec7m role assignment) B\u1ea3n th\u00e2n projects kh\u00f4ng s\u1edf h\u1eefu users hay groups m\u00e0 users v\u00e0 groups \u0111\u01b0\u1ee3c c\u1ea5p quy\u1ec1n truy c\u1eadp t\u1edbi project s\u1eed d\u1ee5ng c\u01a1 ch\u1ebf g\u00e1n role. 2.2. Domain Domain l\u00e0 t\u1eadp h\u1ee3p bao g\u1ed3m c\u00e1c user, group, project Ph\u00e2n chia t\u00e0i nguy\u00ean v\u00e0o c\u00e1c \"kho ch\u1ee9a\" \u0111\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ed9c l\u1eadp v\u1edbi c\u00e1c domain kh\u00e1c M\u1ed7i domain c\u00f3 th\u1ec3 coi l\u00e0 s\u1ef1 ph\u00e2n chia v\u1ec1 m\u1eb7t logic gi\u1eefa c\u00e1c t\u1ed5 ch\u1ee9c, doanh nghi\u1ec7p tr\u00ean cloud 2.3. Users v\u00e0 User Groups User: ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng nguy\u00ean trong project, domain \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 Group: t\u1eadp h\u1ee3p c\u00e1c user , ph\u00e2n b\u1ed5 t\u00e0i nguy\u00ean Role: c\u00e1c role g\u00e1n cho user v\u00e0 user group tr\u00ean c\u00e1c domain v\u00e0 project 2.4. Roles Kh\u00e1i ni\u1ec7m g\u1eafn li\u00ean v\u1edbi Authorization (\u1ee7y quy\u1ec1n), gi\u1edbi h\u1ea1n c\u00e1c thao t\u00e1c v\u1eadn h\u00e0nh h\u1ec7 th\u1ed1ng v\u00e0 ngu\u1ed3n t\u00e0i nguy\u00ean m\u00e0 user \u0111\u01b0\u1ee3c ph\u00e9p. Role \u0111\u01b0\u1ee3c g\u00e1n cho user v\u00e0 n\u00f3 \u0111\u01b0\u1ee3c g\u00e1n cho user \u0111\u00f3 tr\u00ean m\u1ed9t project c\u1ee5 th\u1ec3. (\"assigned to\" user, \"assigned on\" project) 2.5. Token Token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 \u1ee7y quy\u1ec1n cho ng\u01b0\u1eddi d\u00f9ng khi truy c\u1eadp t\u00e0i nguy\u00ean (th\u1ef1c hi\u1ec7n c\u00e1c API call). Token bao g\u1ed3m: - ID: \u0111\u1ecbnh danh duy nh\u1ea5t c\u1ee7a token tr\u00ean DB - payload: l\u00e0 d\u1eef li\u1ec7u v\u1ec1 ng\u01b0\u1eddi d\u00f9ng (user \u0111\u01b0\u1ee3c truy c\u1eadp tr\u00ean project n\u00e0o, danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 s\u1eb5n s\u00e0ng \u0111\u1ec3 truy c\u1eadp c\u00f9ng v\u1edbi endpoints truy c\u1eadp c\u00e1c d\u1ecbch v\u1ee5 \u0111\u00f3), th\u1eddi gian kh\u1edfi t\u1ea1o, th\u1eddi gian h\u1ebft h\u1ea1n, etc. 2.6. Catalog L\u00e0 danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 \u0111\u1ec3 ng\u01b0\u1eddi d\u00f9ng t\u00ecm ki\u1ebfm v\u00e0 truy c\u1eadp. Catalog ch\u1ec9 ra c\u00e1c endpoints truy c\u1eadp d\u1ecbch v\u1ee5, lo\u1ea1i d\u1ecbch v\u1ee5 m\u00e0 ng\u01b0\u1eddi d\u00f9ng truy c\u1eadp c\u00f9ng v\u1edbi t\u00ean t\u01b0\u01a1ng \u1ee9ng, etc. T\u1eeb \u0111\u00f3 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 request kh\u1edfi t\u1ea1o VM v\u00e0 l\u01b0u tr\u1eef object. 2.6. Services L\u00e0 m\u1ed9t d\u1ecbch kh\u00e1c nh\u01b0 Nova, Glance, Swift c\u00f3 cung c\u1ea5p c\u00e1c endpoint cho ph\u00e9p ng\u01b0\u1eddi d\u00f9ng truy c\u1eadp, s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean 2.7. Openstack Client L\u00e0 m\u1ed9t command-line , bao nhi\u1ec1u nhi\u1ec1u d\u1ecbch v\u1ee5 g\u1ed3m Indentify API, cho ph\u00e9p l\u00e0m vi\u1ec7c v\u1edbi keystone 2. Indentify Service \u00b6 Identity service trong keystone cung c\u1ea5p c\u00e1c Actors. N\u00f3 c\u00f3 th\u1ec3 t\u1edbi t\u1eeb nhi\u1ec1u d\u1ecbch v\u1ee5 kh\u00e1c nhau nh\u01b0 SQL, LDAP, v\u00e0 Federated Identity Providers. 2.1. SQL \u00b6 Keystone c\u00f3 t\u00f9y ch\u1ecdn cho ph\u00e9p l\u01b0u tr\u1eef actors trong SQL. N\u00f3 h\u1ed7 tr\u1ee3 c\u00e1c database nh\u01b0 MySQL, PostgreSQL, v\u00e0 DB2. Keystone s\u1ebd l\u01b0u nh\u1eefng th\u00f4ng tin nh\u01b0 t\u00ean, m\u1eadt kh\u1ea9u v\u00e0 m\u00f4 t\u1ea3. Nh\u1eefng c\u00e0i \u0111\u1eb7t c\u1ee7a c\u00e1c database n\u00e0y n\u1eb1m trong file config c\u1ee7a keystone V\u1ec1 b\u1ea3n ch\u1ea5t, Keystone s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 1 Identity Provider. V\u00ec th\u1ebf \u0111\u00e2y s\u1ebd kh\u00f4ng ph\u1ea3i l\u00e0 l\u1ef1a ch\u1ecdn t\u1ed1t nh\u1ea5t trong m\u1ed9t v\u00e0i tr\u01b0\u1eddng h\u1ee3p, nh\u1ea5t l\u00e0 \u0111\u1ed1i v\u1edbi c\u00e1c kh\u00e1ch h\u00e0ng l\u00e0 doanh nghi\u1ec7p Sau \u0111\u00e2y l\u00e0 \u01b0u nh\u01b0\u1ee3c \u0111i\u1ec3m: \u01afu \u0111i\u1ec3m: - D\u1ec5 set up - Qu\u1ea3n l\u00ed users, groups th\u00f4ng qua OpenStack APIs. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Keystone kh\u00f4ng n\u00ean l\u00e0 m\u1ed9t Identity Provider - H\u1ed7 tr\u1ee3 c\u1ea3 m\u1eadt kh\u1ea9u y\u1ebfu - H\u1ea7u h\u1ebft c\u00e1c doanh nghi\u1ec7p \u0111\u1ec1u s\u1eed d\u1ee5ng LDAP server - Ph\u1ea3i ghi nh\u1edb username v\u00e0 password. 2.2. LADP \u00b6 Keystone s\u1ebd truy c\u1eadp t\u1edbi LDAP nh\u01b0 b\u1ea5t k\u00ec \u1ee9ng d\u1ee5ng kh\u00e1c (System Login, Email, Web Application, etc.). C\u00e1c c\u00e0i \u0111\u1eb7t k\u1ebft n\u1ed1i s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u trong file config c\u1ee7a keystone. C\u00e1c c\u00e0i \u0111\u1eb7t n\u00e0y c\u0169ng bao g\u1ed3m t\u00f9y ch\u1ecdn cho ph\u00e9p keystone \u0111\u01b0\u1ee3c ghi ho\u1eb7c ch\u1ec9 \u0111\u1ecdc d\u1eef li\u1ec7u t\u1eeb LDAP. Th\u00f4ng th\u01b0\u1eddng LDAP ch\u1ec9 n\u00ean cho ph\u00e9p c\u00e1c c\u00e2u l\u1ec7nh \u0111\u1ecdc, v\u00ed d\u1ee5 nh\u01b0 t\u00ecm ki\u1ebfm user, group v\u00e0 x\u00e1c th\u1ef1c. N\u1ebfu s\u1eed d\u1ee5ng LDAP nh\u01b0 m\u1ed9t read-only Identity Backends th\u00ec Keystone c\u1ea7n c\u00f3 quy\u1ec1n s\u1eed d\u1ee5ng LDAP. \u01afu \u0111i\u1ec3m: - Kh\u00f4ng c\u1ea7n sao l\u01b0u t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng. - Keystone kh\u00f4ng ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t Identity Provider. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Keystone c\u00f3 th\u1ec3 th\u1ea5y m\u1eadt kh\u1ea9u ng\u01b0\u1eddi d\u00f9ng, l\u00fac m\u1eadt kh\u1ea9u \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u authentication. 2.3. Multiple Backends \u00b6 K\u1ec3 t\u1eeb b\u1ea3n Juno th\u00ec Keystone \u0111\u00e3 h\u1ed7 tr\u1ee3 nhi\u1ec1u Identity backends cho V3 Identity API. Nh\u1edd v\u1eady m\u00e0 m\u1ed7i m\u1ed9t domain c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t identity source (backend) kh\u00e1c nhau. Domain m\u1eb7c \u0111\u1ecbnh th\u01b0\u1eddng s\u1eed d\u1ee5ng SQL backend b\u1edfi n\u00f3 \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 l\u01b0u c\u00e1c host service accounts. Service accounts l\u00e0 c\u00e1c t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c d\u00f9ng b\u1edfi c\u00e1c d\u1ecbch v\u1ee5 OpenStack kh\u00e1c nhau \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi Keystone. Vi\u1ec7c s\u1eed d\u1ee5ng Multiple Backends \u0111\u01b0\u1ee3c l\u1ea5y c\u1ea3m h\u1ee9ng trong c\u00e1c m\u00f4i tr\u01b0\u1eddng doanh nghi\u1ec7p, LDAP ch\u1ec9 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u01b0u th\u00f4ng tin c\u1ee7a c\u00e1c nh\u00e2n vi\u00ean b\u1edfi LDAP admin c\u00f3 th\u1ec3 kh\u00f4ng \u1edf c\u00f9ng m\u1ed9t c\u00f4ng ty v\u1edbi nh\u00f3m tri\u1ec3n khai OpenStack. B\u00ean c\u1ea1nh \u0111\u00f3, nhi\u1ec1u LDAP c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong tr\u01b0\u1eddng h\u1ee3p c\u00f4ng ty c\u00f3 nhi\u1ec1u ph\u00f2ng ban. \u01afu \u0111i\u1ec3m: - Cho ph\u00e9p vi\u1ec7c s\u1eed d\u1ee5ng nhi\u1ec1u LDAP \u0111\u1ec3 l\u01b0u t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 SQL \u0111\u1ec3 l\u01b0u t\u00e0i kho\u1ea3n d\u1ecbch v\u1ee5 - S\u1eed d\u1ee5ng l\u1ea1i LDAP \u0111\u00e3 c\u00f3. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Ph\u1ee9c t\u1ea1p trong kh\u00e2u set up - X\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng ph\u1ea3i trong mi\u1ec1n scoped 2.4. Identity Providers \u00b6 K\u1ec3 t\u1eeb b\u1ea3n Icehouse th\u00ec Keystone \u0111\u00e3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c li\u00ean k\u1ebft x\u00e1c th\u1ef1c th\u00f4ng qua module Apache cho c\u00e1c Identity Providers kh\u00e1c nhau. C\u01a1 b\u1ea3n th\u00ec Keystone s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t b\u00ean th\u1ee9 3 \u0111\u1ec3 x\u00e1c th\u1ef1c, n\u00f3 c\u00f3 th\u1ec3 l\u00e0 nh\u1eefng ph\u1ea7n m\u1ec1m s\u1eed d\u1ee5ng c\u00e1c backends (LDAP, AD, MongoDB) ho\u1eb7c m\u1ea1ng x\u00e3 h\u1ed9i (Google, Facebook, Twitter). \u01afu \u0111i\u1ec3m: C\u00f3 th\u1ec3 t\u1eadn d\u1ee5ng ph\u1ea7n m\u1ec1m v\u00e0 c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng c\u0169 \u0111\u1ec3 x\u00e1c th\u1ef1c c\u0169ng nh\u01b0 l\u1ea5y th\u00f4ng tin c\u1ee7a users. T\u00e1ch bi\u1ec7t keystone v\u00e0 nhi\u1ec7m v\u1ee5 \u0111\u1ecbnh danh, x\u00e1c th\u1ef1c th\u00f4ng tin. M\u1edf ra c\u00e1nh c\u1eeda m\u1edbi cho nh\u1eefng kh\u1ea3 n\u0103ng m\u1edbi v\u00ed d\u1ee5 nh\u01b0 single signon v\u00e0 hybrid cloud Keystone kh\u00f4ng th\u1ec3 xem m\u1eadt kh\u1ea9u, m\u1ecdi th\u1ee9 \u0111\u1ec1u kh\u00f4ng c\u00f2n li\u00ean quan t\u1edbi keystone. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Ph\u1ee9c t\u1ea1p nh\u1ea5t v\u1ec1 vi\u1ec7c setup 3 . Keystone WorkFlow \u00b6","title":"1. Openstack Indentify ( Keystone )"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#1_openstack_indentify_keystone","text":"","title":"1. Openstack Indentify ( Keystone )"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#1_khai_niem_keystone","text":"Keystone l\u00e0 OpenStack project cung c\u1ea5p c\u00e1c d\u1ecbch v\u1ee5 Identity, Token, Catalog, Policy cho c\u00e1c project kh\u00e1c trong OpenStack. Keystone c\u00f3 2 phi\u1ec3n b\u1ea3n g\u1ed3m V2 V3 s\u1eed d\u1ee5ng UUID s\u1eed d\u1ee5ng PKI, m\u1ed7i m\u00e3 th\u00f4ng b\u00e1o \u0111\u1ea1i di\u1ec7n cho m\u1ed9t c\u1eb7p kh\u00f3a m\u1edf v\u00e0 \u0111\u00f3ng \u0111\u1ec3 x\u00e1c minh ch\u00e9o v\u00e0 x\u00e1c th\u1ef1c. Hai t\u00ednh n\u0103ng ch\u00ednh c\u1ee7a Keystone: User Management: keystone x\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 ch\u1ec9 \u0111\u1ecbnh xem ng\u01b0\u1eddi d\u00f9ng c\u00f3 quy\u1ec1n \u0111\u01b0\u1ee3c l\u00e0m g\u00ec. Service Catalog: Cung c\u1ea5p m\u1ed9t danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 s\u1eb5n s\u00e0ng c\u00f9ng v\u1edbi c\u00e1c API endpoints \u0111\u1ec3 truy c\u1eadp c\u00e1c d\u1ecbch v\u1ee5 \u0111\u00f3.","title":"1: Kh\u00e1i ni\u1ec7m Keystone"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#2_cau_truc_trong_keystone","text":"2.1. Project Kh\u00e1i ni\u1ec7m ch\u1ec9 s\u1ef1 gom g\u1ed9p, c\u00f4 l\u1eadp c\u00e1c ngu\u1ed3n t\u00e0i nguy\u00ean (server, images, etc.) C\u00e1c user \u0111\u01b0\u1ee3c g\u1eafn role v\u00e0 truy c\u1eadp s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean trong project role \u0111\u1ec3 quy \u0111\u1ecbnh t\u00e0i nguy\u00ean \u0111\u01b0\u1ee3c ph\u00e9p truy c\u1eadp trong project (kh\u00e1i ni\u1ec7m role assignment) B\u1ea3n th\u00e2n projects kh\u00f4ng s\u1edf h\u1eefu users hay groups m\u00e0 users v\u00e0 groups \u0111\u01b0\u1ee3c c\u1ea5p quy\u1ec1n truy c\u1eadp t\u1edbi project s\u1eed d\u1ee5ng c\u01a1 ch\u1ebf g\u00e1n role. 2.2. Domain Domain l\u00e0 t\u1eadp h\u1ee3p bao g\u1ed3m c\u00e1c user, group, project Ph\u00e2n chia t\u00e0i nguy\u00ean v\u00e0o c\u00e1c \"kho ch\u1ee9a\" \u0111\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ed9c l\u1eadp v\u1edbi c\u00e1c domain kh\u00e1c M\u1ed7i domain c\u00f3 th\u1ec3 coi l\u00e0 s\u1ef1 ph\u00e2n chia v\u1ec1 m\u1eb7t logic gi\u1eefa c\u00e1c t\u1ed5 ch\u1ee9c, doanh nghi\u1ec7p tr\u00ean cloud 2.3. Users v\u00e0 User Groups User: ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng nguy\u00ean trong project, domain \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 Group: t\u1eadp h\u1ee3p c\u00e1c user , ph\u00e2n b\u1ed5 t\u00e0i nguy\u00ean Role: c\u00e1c role g\u00e1n cho user v\u00e0 user group tr\u00ean c\u00e1c domain v\u00e0 project 2.4. Roles Kh\u00e1i ni\u1ec7m g\u1eafn li\u00ean v\u1edbi Authorization (\u1ee7y quy\u1ec1n), gi\u1edbi h\u1ea1n c\u00e1c thao t\u00e1c v\u1eadn h\u00e0nh h\u1ec7 th\u1ed1ng v\u00e0 ngu\u1ed3n t\u00e0i nguy\u00ean m\u00e0 user \u0111\u01b0\u1ee3c ph\u00e9p. Role \u0111\u01b0\u1ee3c g\u00e1n cho user v\u00e0 n\u00f3 \u0111\u01b0\u1ee3c g\u00e1n cho user \u0111\u00f3 tr\u00ean m\u1ed9t project c\u1ee5 th\u1ec3. (\"assigned to\" user, \"assigned on\" project) 2.5. Token Token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 \u1ee7y quy\u1ec1n cho ng\u01b0\u1eddi d\u00f9ng khi truy c\u1eadp t\u00e0i nguy\u00ean (th\u1ef1c hi\u1ec7n c\u00e1c API call). Token bao g\u1ed3m: - ID: \u0111\u1ecbnh danh duy nh\u1ea5t c\u1ee7a token tr\u00ean DB - payload: l\u00e0 d\u1eef li\u1ec7u v\u1ec1 ng\u01b0\u1eddi d\u00f9ng (user \u0111\u01b0\u1ee3c truy c\u1eadp tr\u00ean project n\u00e0o, danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 s\u1eb5n s\u00e0ng \u0111\u1ec3 truy c\u1eadp c\u00f9ng v\u1edbi endpoints truy c\u1eadp c\u00e1c d\u1ecbch v\u1ee5 \u0111\u00f3), th\u1eddi gian kh\u1edfi t\u1ea1o, th\u1eddi gian h\u1ebft h\u1ea1n, etc. 2.6. Catalog L\u00e0 danh m\u1ee5c c\u00e1c d\u1ecbch v\u1ee5 \u0111\u1ec3 ng\u01b0\u1eddi d\u00f9ng t\u00ecm ki\u1ebfm v\u00e0 truy c\u1eadp. Catalog ch\u1ec9 ra c\u00e1c endpoints truy c\u1eadp d\u1ecbch v\u1ee5, lo\u1ea1i d\u1ecbch v\u1ee5 m\u00e0 ng\u01b0\u1eddi d\u00f9ng truy c\u1eadp c\u00f9ng v\u1edbi t\u00ean t\u01b0\u01a1ng \u1ee9ng, etc. T\u1eeb \u0111\u00f3 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 request kh\u1edfi t\u1ea1o VM v\u00e0 l\u01b0u tr\u1eef object. 2.6. Services L\u00e0 m\u1ed9t d\u1ecbch kh\u00e1c nh\u01b0 Nova, Glance, Swift c\u00f3 cung c\u1ea5p c\u00e1c endpoint cho ph\u00e9p ng\u01b0\u1eddi d\u00f9ng truy c\u1eadp, s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean 2.7. Openstack Client L\u00e0 m\u1ed9t command-line , bao nhi\u1ec1u nhi\u1ec1u d\u1ecbch v\u1ee5 g\u1ed3m Indentify API, cho ph\u00e9p l\u00e0m vi\u1ec7c v\u1edbi keystone","title":"2 : C\u1ea5u tr\u00fac trong Keystone"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#2_indentify_service","text":"Identity service trong keystone cung c\u1ea5p c\u00e1c Actors. N\u00f3 c\u00f3 th\u1ec3 t\u1edbi t\u1eeb nhi\u1ec1u d\u1ecbch v\u1ee5 kh\u00e1c nhau nh\u01b0 SQL, LDAP, v\u00e0 Federated Identity Providers.","title":"2. Indentify Service"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#21_sql","text":"Keystone c\u00f3 t\u00f9y ch\u1ecdn cho ph\u00e9p l\u01b0u tr\u1eef actors trong SQL. N\u00f3 h\u1ed7 tr\u1ee3 c\u00e1c database nh\u01b0 MySQL, PostgreSQL, v\u00e0 DB2. Keystone s\u1ebd l\u01b0u nh\u1eefng th\u00f4ng tin nh\u01b0 t\u00ean, m\u1eadt kh\u1ea9u v\u00e0 m\u00f4 t\u1ea3. Nh\u1eefng c\u00e0i \u0111\u1eb7t c\u1ee7a c\u00e1c database n\u00e0y n\u1eb1m trong file config c\u1ee7a keystone V\u1ec1 b\u1ea3n ch\u1ea5t, Keystone s\u1ebd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 1 Identity Provider. V\u00ec th\u1ebf \u0111\u00e2y s\u1ebd kh\u00f4ng ph\u1ea3i l\u00e0 l\u1ef1a ch\u1ecdn t\u1ed1t nh\u1ea5t trong m\u1ed9t v\u00e0i tr\u01b0\u1eddng h\u1ee3p, nh\u1ea5t l\u00e0 \u0111\u1ed1i v\u1edbi c\u00e1c kh\u00e1ch h\u00e0ng l\u00e0 doanh nghi\u1ec7p Sau \u0111\u00e2y l\u00e0 \u01b0u nh\u01b0\u1ee3c \u0111i\u1ec3m: \u01afu \u0111i\u1ec3m: - D\u1ec5 set up - Qu\u1ea3n l\u00ed users, groups th\u00f4ng qua OpenStack APIs. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Keystone kh\u00f4ng n\u00ean l\u00e0 m\u1ed9t Identity Provider - H\u1ed7 tr\u1ee3 c\u1ea3 m\u1eadt kh\u1ea9u y\u1ebfu - H\u1ea7u h\u1ebft c\u00e1c doanh nghi\u1ec7p \u0111\u1ec1u s\u1eed d\u1ee5ng LDAP server - Ph\u1ea3i ghi nh\u1edb username v\u00e0 password.","title":"2.1. SQL"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#22_ladp","text":"Keystone s\u1ebd truy c\u1eadp t\u1edbi LDAP nh\u01b0 b\u1ea5t k\u00ec \u1ee9ng d\u1ee5ng kh\u00e1c (System Login, Email, Web Application, etc.). C\u00e1c c\u00e0i \u0111\u1eb7t k\u1ebft n\u1ed1i s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u trong file config c\u1ee7a keystone. C\u00e1c c\u00e0i \u0111\u1eb7t n\u00e0y c\u0169ng bao g\u1ed3m t\u00f9y ch\u1ecdn cho ph\u00e9p keystone \u0111\u01b0\u1ee3c ghi ho\u1eb7c ch\u1ec9 \u0111\u1ecdc d\u1eef li\u1ec7u t\u1eeb LDAP. Th\u00f4ng th\u01b0\u1eddng LDAP ch\u1ec9 n\u00ean cho ph\u00e9p c\u00e1c c\u00e2u l\u1ec7nh \u0111\u1ecdc, v\u00ed d\u1ee5 nh\u01b0 t\u00ecm ki\u1ebfm user, group v\u00e0 x\u00e1c th\u1ef1c. N\u1ebfu s\u1eed d\u1ee5ng LDAP nh\u01b0 m\u1ed9t read-only Identity Backends th\u00ec Keystone c\u1ea7n c\u00f3 quy\u1ec1n s\u1eed d\u1ee5ng LDAP. \u01afu \u0111i\u1ec3m: - Kh\u00f4ng c\u1ea7n sao l\u01b0u t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng. - Keystone kh\u00f4ng ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t Identity Provider. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Keystone c\u00f3 th\u1ec3 th\u1ea5y m\u1eadt kh\u1ea9u ng\u01b0\u1eddi d\u00f9ng, l\u00fac m\u1eadt kh\u1ea9u \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u authentication.","title":"2.2. LADP"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#23_multiple_backends","text":"K\u1ec3 t\u1eeb b\u1ea3n Juno th\u00ec Keystone \u0111\u00e3 h\u1ed7 tr\u1ee3 nhi\u1ec1u Identity backends cho V3 Identity API. Nh\u1edd v\u1eady m\u00e0 m\u1ed7i m\u1ed9t domain c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t identity source (backend) kh\u00e1c nhau. Domain m\u1eb7c \u0111\u1ecbnh th\u01b0\u1eddng s\u1eed d\u1ee5ng SQL backend b\u1edfi n\u00f3 \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 l\u01b0u c\u00e1c host service accounts. Service accounts l\u00e0 c\u00e1c t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c d\u00f9ng b\u1edfi c\u00e1c d\u1ecbch v\u1ee5 OpenStack kh\u00e1c nhau \u0111\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi Keystone. Vi\u1ec7c s\u1eed d\u1ee5ng Multiple Backends \u0111\u01b0\u1ee3c l\u1ea5y c\u1ea3m h\u1ee9ng trong c\u00e1c m\u00f4i tr\u01b0\u1eddng doanh nghi\u1ec7p, LDAP ch\u1ec9 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u01b0u th\u00f4ng tin c\u1ee7a c\u00e1c nh\u00e2n vi\u00ean b\u1edfi LDAP admin c\u00f3 th\u1ec3 kh\u00f4ng \u1edf c\u00f9ng m\u1ed9t c\u00f4ng ty v\u1edbi nh\u00f3m tri\u1ec3n khai OpenStack. B\u00ean c\u1ea1nh \u0111\u00f3, nhi\u1ec1u LDAP c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong tr\u01b0\u1eddng h\u1ee3p c\u00f4ng ty c\u00f3 nhi\u1ec1u ph\u00f2ng ban. \u01afu \u0111i\u1ec3m: - Cho ph\u00e9p vi\u1ec7c s\u1eed d\u1ee5ng nhi\u1ec1u LDAP \u0111\u1ec3 l\u01b0u t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng v\u00e0 SQL \u0111\u1ec3 l\u01b0u t\u00e0i kho\u1ea3n d\u1ecbch v\u1ee5 - S\u1eed d\u1ee5ng l\u1ea1i LDAP \u0111\u00e3 c\u00f3. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Ph\u1ee9c t\u1ea1p trong kh\u00e2u set up - X\u00e1c th\u1ef1c t\u00e0i kho\u1ea3n ng\u01b0\u1eddi d\u00f9ng ph\u1ea3i trong mi\u1ec1n scoped","title":"2.3. Multiple Backends"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#24_identity_providers","text":"K\u1ec3 t\u1eeb b\u1ea3n Icehouse th\u00ec Keystone \u0111\u00e3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c li\u00ean k\u1ebft x\u00e1c th\u1ef1c th\u00f4ng qua module Apache cho c\u00e1c Identity Providers kh\u00e1c nhau. C\u01a1 b\u1ea3n th\u00ec Keystone s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t b\u00ean th\u1ee9 3 \u0111\u1ec3 x\u00e1c th\u1ef1c, n\u00f3 c\u00f3 th\u1ec3 l\u00e0 nh\u1eefng ph\u1ea7n m\u1ec1m s\u1eed d\u1ee5ng c\u00e1c backends (LDAP, AD, MongoDB) ho\u1eb7c m\u1ea1ng x\u00e3 h\u1ed9i (Google, Facebook, Twitter). \u01afu \u0111i\u1ec3m: C\u00f3 th\u1ec3 t\u1eadn d\u1ee5ng ph\u1ea7n m\u1ec1m v\u00e0 c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng c\u0169 \u0111\u1ec3 x\u00e1c th\u1ef1c c\u0169ng nh\u01b0 l\u1ea5y th\u00f4ng tin c\u1ee7a users. T\u00e1ch bi\u1ec7t keystone v\u00e0 nhi\u1ec7m v\u1ee5 \u0111\u1ecbnh danh, x\u00e1c th\u1ef1c th\u00f4ng tin. M\u1edf ra c\u00e1nh c\u1eeda m\u1edbi cho nh\u1eefng kh\u1ea3 n\u0103ng m\u1edbi v\u00ed d\u1ee5 nh\u01b0 single signon v\u00e0 hybrid cloud Keystone kh\u00f4ng th\u1ec3 xem m\u1eadt kh\u1ea9u, m\u1ecdi th\u1ee9 \u0111\u1ec1u kh\u00f4ng c\u00f2n li\u00ean quan t\u1edbi keystone. Nh\u01b0\u1ee3c \u0111i\u1ec3m: - Ph\u1ee9c t\u1ea1p nh\u1ea5t v\u1ec1 vi\u1ec7c setup","title":"2.4. Identity Providers"},{"location":"Openstack_Research/Keystone/1. Introduction-Keystone/#3_keystone_workflow","text":"","title":"3 . Keystone WorkFlow"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/","text":"C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Keystone \u00b6 1. Openstack Indentity Overview \u00b6 Openstack indentity cung c\u1ea5p m\u1ed9t \u0111i\u1ec3m t\u00edch h\u1ee3p \u0111\u1ec3 x\u00e1c th\u1ef1c, ph\u00e2n quy\u1ec1n ho\u1eb7c v\u00e0 danh m\u1ee5c d\u1ecbch v\u1ee5. Openstack indentity service t\u01b0\u1eddng l\u00e0 d\u1ecbch v\u1ee5 \u0111\u1ea7u ti\u00ean m\u00e0 ng\u01b0\u1eddi d\u00f9ng t\u01b0\u01a1ng t\u00e1c \u0111\u1ebfn. M\u1ed7i khi \u0111\u00e3 x\u00e1c th\u1ef1c, c\u00e1c end-user c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng indentify token \u0111\u1ec3 truy c\u1eadp v\u00e0o c\u00e1c Openstack Service kh\u00e1c. . T\u01b0\u01a1ng t\u1ee5 nh\u01b0 v\u1eady c\u00e1c - - Openstack service kh\u00e1c s\u1eed dung c\u00e1c indentity kh\u00e1c \u0111\u1ec3 ch\u1eafc ch\u1eafn r\u1eb1ng ng\u01b0\u1eddi d\u00f9ng v\u00e0 quy\u1ec1n c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u00f3. Indentifty serivce c\u00f3 th\u1ec3 t\u00edch h\u1ee3p v\u00e0o c\u00e1c management system kh\u00e1c nh\u01b0 ( LAPD ) Ng\u01b0\u1eddi d\u00f9ng v\u00e0 d\u1ecbch v\u1ee5 trong openstack c\u00f3 th\u1ec3 nh\u1eadn d\u1ea1ng c\u00e1c Services kh\u00e1c qua c\u00e1c catalog service m\u00e0 \u0111\u01b0\u1ee3c qu\u1ea3n tr\u1ecb b\u1edfi Indentity service. Catalog n\u1eafm nhi\u1ec7m v\u1ee5 n\u1eafm d\u1eef danh s\u00e1ch serive trong qu\u00e1 tr\u00ecnh deployment. M\u1ed7i service s\u1ebd c\u00f3 nhi\u1ec1u endpoint , c\u00e1c endpoint s\u1ebd n\u1eb1m trong 3 d\u1ea1ng sau : public, ijnternal, admin. Trong m\u00f4i tr\u01b0\u1eddng production, c\u00e1c endpoint s\u1ebd n\u1eb1m tr\u00ean c\u00e1c m\u1ea1ng ri\u00eang bi\u1ec7t \u0111\u1ec3 b\u1ea3n b\u1ea3o b\u1ea3o m\u1eadt. V\u00ed d\u1ee5 . public API c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c ti\u1ebfp c\u1eadn t\u1eeb m\u00f4i tr\u01b0\u1eddng internet, kh\u00e1c h\u00e0ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng s\u1ea3n ph\u1ea9n cloud qua API n\u00e0y. Admin API s\u1eed d\u1ee5ng cho c\u00e1c sysadmin \u0111\u1ec3 qu\u1ea3n tr\u1ecb infractructure cloud. Internal API s\u1ebd s\u1eed d\u1ee5ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c host \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi c\u00e1c Openstack Service Openstack Indentity cung c\u1ea5p region \u0111\u1ec3 t\u0103ng kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng. M\u1eb7c \u0111\u1ecbnh RegionOne \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m Region \u0111\u00e2u ti\u00ean M\u1ed7i Openstack Service c\u00e0i l\u00ean c\u1ea7n c\u00f3 m\u1ed9t endpoint tr\u00ean indentity service Trong Indentity g\u1ed3m c\u00f3 3 th\u00e0nh ph\u1ea7n Server : m\u1ed9t server t\u1eadp trung cung c\u1ea5p ch\u1ee9c n\u0103ng x\u00e1c th\u1ef1c v\u00e0 ph\u00e2n quy\u1ec1n s\u1eed d\u1ee5ng Restful API Drivers : driver ho\u1eb7c back-end \u0111\u01b0\u1ee3c t\u00edch h\u1ee3p v\u00e0o server d\u00f9ng \u0111\u1ec3 truy c\u1eadp v\u00e0o DB indentity c\u00f3 th\u1ec3 l\u00e0 external service ho\u1eb7c c\u00e1c d\u1ecbch v\u1ee5 internal ( SQL, LADP ) Modules : middleware module c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean c\u00e1c Openstack compoment \u0111ang s\u1eed d\u1ee5ng indentity services. Nh\u1eefng module n\u00e0y ch\u1eb7n c\u00e1c reques , xu\u1ea5t ra c\u00e1c credential sau \u0111\u00f3 g\u1eedi \u0111\u1ebfn Server . 2. C\u00e0i \u0111\u1eb7t Openstack Queens tr\u00ean Controller \u00b6 Tri\u1ec3n khai tr\u00ean m\u00f4 h\u00ecnh C\u00e0i \u0111\u1eb7t Openstack Queens v\u00e0 Openstack Client yum install centos-release-openstack-queens -y yum upgrade yum install python-openstackclient -y M\u1eb7c \u0111\u1ecbnh tr\u00ean Centos v\u00e0 RHEL \u0111\u00e3 b\u1eadt SElinux , c\u00e0i \u0111\u1eb7t openstack-selinux \u0111\u1ec3 apply c\u00e1c policies cho c\u00e1c Openstack Service yum install openstack-selinux -y Disable SeLinux /etc/selinux/config Sau do reboot server This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted C\u1ea5u h\u00ecnh hostname resolution echo \" 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute2 \" >> /etc/hosts 3. C\u00e0i \u0111\u1eb7t Openstack Indentity - Keystone \u00b6 Trong lo\u1ea1t b\u00e0i n\u00e0y s\u1ebd c\u00e0i \u0111\u1eb7t Keystone tr\u00ean Controller Node . \u0110\u1ec3 ph\u1ee5c v\u1ee5 cho kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng, Fernet tokens v\u00e0 Apache HTTP Server s\u1eed \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng 3.1 . Chu\u1ea9n b\u1ecb \u00b6 Tr\u00ean h\u1ea7u h\u1ebft c\u00e1c Openstack Service \u0111\u1ec3u s\u1eed d\u1ee5ng SQL database \u0111\u1ec3 l\u01b0u th\u00f4ng tin. C\u01a1 s\u1edf d\u1eef li\u1ec7u th\u01b0\u1eddng \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean Controller Node. Tr\u00ean lo\u1ea1t t\u00ecm hi\u1ec3u n\u00e0y s\u1ebd s\u1eed d\u1ee5ng Mysql v\u00e0 MarriaDB . C\u00e0i \u0111\u1eb7t MarriaDB yum install mariadb mariadb-server python2-PyMySQL -y C\u1ea5u h\u00ecnh MarriaDB Server echo \"[mysqld] bind-address = 192.168.69.130 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8\" >> /etc/my.cnf.d/openstack.cnf Trong \u0111\u00f3 : bind-address : IP c\u1ee7a network interface management Start MarriaDB v\u00e0 cho ph\u00e9p enable trong boot systemctl enable mariadb.service systemctl start mariadb.service C\u1ea5u h\u00ecnh t\u00e0i kho\u1ea3n root cho c\u00e1c Database /usr/bin/mysqladmin -u root -h localhost password 123@123Aa 3.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Keystone \u00b6 3.2.1. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh c\u00e1c th\u00e0nh ph\u1ea7n \u00b6 Tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t Keystone, c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t DB ri\u00eang cho Keystone v\u1edbi t\u00e0i kho\u1ea3n root mysql -u root --password=123@123Aa -e \"CREATE DATABASE keystone\"; mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \\ IDENTIFIED BY 'keystone_123';GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \\ IDENTIFIED BY 'keystone_123';\" C\u00e0i \u0111\u1eb7t Openstack_keystone, httpd, mod_wsgi v\u00e0 c\u1ea5u h\u00ecnh ban d\u1ea7u yum install openstack-keystone httpd mod_wsgi crudini crudini --set /etc/keystone/keystone.conf \"database\" \"connection\" \"mysql+pymysql://keystone:keystone_123@controller/keystone\" crudini --set /etc/keystone/keystone.conf \"token\" \"provider\" \"fernet\" su -s /bin/sh -c \"keystone-manage db_sync\" keystone Kh\u1edfi t\u1ea1o kho l\u01b0u tr\u1eef Fernet Token keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone Kh\u1edfi \u0111\u1ed9ng c\u00e1c d\u1ecbch v\u1ee5 trong Openstack Indentity keystone-manage bootstrap --bootstrap-password keystone_123 \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne 3.2.2. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Apace HTTP Server \u00b6 C\u1ea5u h\u00ecnh Apache Conf v\u00e0 enable service ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ systemctl enable httpd.service systemctl start httpd.service 3.2.3 . Set bi\u1ebfn m\u00f4i tr\u01b0\u1eddng cho t\u00e0i kho\u1ea3n admin \u00b6 S\u1eed d\u1ee5ng password \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t cho t\u00e0i kho\u1ea3n admin echo \" export OS_USERNAME=admin export OS_PASSWORD=keystone_123 export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 \" > admin-openrc . admin-openrc Ki\u1ec3m tra authentication token: [root@localhost my.cnf.d]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-19T11:48:31+0000 | | id | gAAAAABbybZ_QDUHiAbszPy2R0fG0bsCJ5Lb38zjUXSkBFiaPXstEUKGipLLvp5U4OB0UKWRRNjTHgLPPnggOP3_n9wJJCPYpy9Oitml1DYJZ-i0TBgr_CU7HU7-IpttwtKW3ywaksEyqrkaKEOpdgCe6KREkFY_qDaQ60gBZx2E9uC9EVGXjPE | | project_id | baedd3b48fbc4134ac1eba01798addea | | user_id | b495617610354ec08b6d9512e31d93eb | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=5000/tcp --permanent firewall-cmd --add-port=35357/tcp --permanent firewall-cmd --reload 3.3 . Kh\u1edfi t\u1ea1o Project cho c\u00e1c Openstack Service kh\u00e1c \u00b6 [root@localhost my.cnf.d]# openstack project create --domain default --description \"Service Project\" service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 2f6d32f44a074bcab270084b989c2fd2 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+","title":"C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Keystone"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#cai_at_va_cau_hinh_keystone","text":"","title":"C\u00e0i \u0111\u1eb7t v\u00e0 c\u1ea5u h\u00ecnh Keystone"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#1_openstack_indentity_overview","text":"Openstack indentity cung c\u1ea5p m\u1ed9t \u0111i\u1ec3m t\u00edch h\u1ee3p \u0111\u1ec3 x\u00e1c th\u1ef1c, ph\u00e2n quy\u1ec1n ho\u1eb7c v\u00e0 danh m\u1ee5c d\u1ecbch v\u1ee5. Openstack indentity service t\u01b0\u1eddng l\u00e0 d\u1ecbch v\u1ee5 \u0111\u1ea7u ti\u00ean m\u00e0 ng\u01b0\u1eddi d\u00f9ng t\u01b0\u01a1ng t\u00e1c \u0111\u1ebfn. M\u1ed7i khi \u0111\u00e3 x\u00e1c th\u1ef1c, c\u00e1c end-user c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng indentify token \u0111\u1ec3 truy c\u1eadp v\u00e0o c\u00e1c Openstack Service kh\u00e1c. . T\u01b0\u01a1ng t\u1ee5 nh\u01b0 v\u1eady c\u00e1c - - Openstack service kh\u00e1c s\u1eed dung c\u00e1c indentity kh\u00e1c \u0111\u1ec3 ch\u1eafc ch\u1eafn r\u1eb1ng ng\u01b0\u1eddi d\u00f9ng v\u00e0 quy\u1ec1n c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u00f3. Indentifty serivce c\u00f3 th\u1ec3 t\u00edch h\u1ee3p v\u00e0o c\u00e1c management system kh\u00e1c nh\u01b0 ( LAPD ) Ng\u01b0\u1eddi d\u00f9ng v\u00e0 d\u1ecbch v\u1ee5 trong openstack c\u00f3 th\u1ec3 nh\u1eadn d\u1ea1ng c\u00e1c Services kh\u00e1c qua c\u00e1c catalog service m\u00e0 \u0111\u01b0\u1ee3c qu\u1ea3n tr\u1ecb b\u1edfi Indentity service. Catalog n\u1eafm nhi\u1ec7m v\u1ee5 n\u1eafm d\u1eef danh s\u00e1ch serive trong qu\u00e1 tr\u00ecnh deployment. M\u1ed7i service s\u1ebd c\u00f3 nhi\u1ec1u endpoint , c\u00e1c endpoint s\u1ebd n\u1eb1m trong 3 d\u1ea1ng sau : public, ijnternal, admin. Trong m\u00f4i tr\u01b0\u1eddng production, c\u00e1c endpoint s\u1ebd n\u1eb1m tr\u00ean c\u00e1c m\u1ea1ng ri\u00eang bi\u1ec7t \u0111\u1ec3 b\u1ea3n b\u1ea3o b\u1ea3o m\u1eadt. V\u00ed d\u1ee5 . public API c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c ti\u1ebfp c\u1eadn t\u1eeb m\u00f4i tr\u01b0\u1eddng internet, kh\u00e1c h\u00e0ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng s\u1ea3n ph\u1ea9n cloud qua API n\u00e0y. Admin API s\u1eed d\u1ee5ng cho c\u00e1c sysadmin \u0111\u1ec3 qu\u1ea3n tr\u1ecb infractructure cloud. Internal API s\u1ebd s\u1eed d\u1ee5ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c host \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi c\u00e1c Openstack Service Openstack Indentity cung c\u1ea5p region \u0111\u1ec3 t\u0103ng kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng. M\u1eb7c \u0111\u1ecbnh RegionOne \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m Region \u0111\u00e2u ti\u00ean M\u1ed7i Openstack Service c\u00e0i l\u00ean c\u1ea7n c\u00f3 m\u1ed9t endpoint tr\u00ean indentity service Trong Indentity g\u1ed3m c\u00f3 3 th\u00e0nh ph\u1ea7n Server : m\u1ed9t server t\u1eadp trung cung c\u1ea5p ch\u1ee9c n\u0103ng x\u00e1c th\u1ef1c v\u00e0 ph\u00e2n quy\u1ec1n s\u1eed d\u1ee5ng Restful API Drivers : driver ho\u1eb7c back-end \u0111\u01b0\u1ee3c t\u00edch h\u1ee3p v\u00e0o server d\u00f9ng \u0111\u1ec3 truy c\u1eadp v\u00e0o DB indentity c\u00f3 th\u1ec3 l\u00e0 external service ho\u1eb7c c\u00e1c d\u1ecbch v\u1ee5 internal ( SQL, LADP ) Modules : middleware module c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean c\u00e1c Openstack compoment \u0111ang s\u1eed d\u1ee5ng indentity services. Nh\u1eefng module n\u00e0y ch\u1eb7n c\u00e1c reques , xu\u1ea5t ra c\u00e1c credential sau \u0111\u00f3 g\u1eedi \u0111\u1ebfn Server .","title":"1. Openstack Indentity Overview"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#2_cai_at_openstack_queens_tren_controller","text":"Tri\u1ec3n khai tr\u00ean m\u00f4 h\u00ecnh C\u00e0i \u0111\u1eb7t Openstack Queens v\u00e0 Openstack Client yum install centos-release-openstack-queens -y yum upgrade yum install python-openstackclient -y M\u1eb7c \u0111\u1ecbnh tr\u00ean Centos v\u00e0 RHEL \u0111\u00e3 b\u1eadt SElinux , c\u00e0i \u0111\u1eb7t openstack-selinux \u0111\u1ec3 apply c\u00e1c policies cho c\u00e1c Openstack Service yum install openstack-selinux -y Disable SeLinux /etc/selinux/config Sau do reboot server This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted C\u1ea5u h\u00ecnh hostname resolution echo \" 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute2 \" >> /etc/hosts","title":"2.  C\u00e0i \u0111\u1eb7t Openstack Queens tr\u00ean Controller"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#3_cai_at_openstack_indentity_-_keystone","text":"Trong lo\u1ea1t b\u00e0i n\u00e0y s\u1ebd c\u00e0i \u0111\u1eb7t Keystone tr\u00ean Controller Node . \u0110\u1ec3 ph\u1ee5c v\u1ee5 cho kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng, Fernet tokens v\u00e0 Apache HTTP Server s\u1eed \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng","title":"3. C\u00e0i \u0111\u1eb7t Openstack Indentity - Keystone"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#31_chuan_bi","text":"Tr\u00ean h\u1ea7u h\u1ebft c\u00e1c Openstack Service \u0111\u1ec3u s\u1eed d\u1ee5ng SQL database \u0111\u1ec3 l\u01b0u th\u00f4ng tin. C\u01a1 s\u1edf d\u1eef li\u1ec7u th\u01b0\u1eddng \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean Controller Node. Tr\u00ean lo\u1ea1t t\u00ecm hi\u1ec3u n\u00e0y s\u1ebd s\u1eed d\u1ee5ng Mysql v\u00e0 MarriaDB . C\u00e0i \u0111\u1eb7t MarriaDB yum install mariadb mariadb-server python2-PyMySQL -y C\u1ea5u h\u00ecnh MarriaDB Server echo \"[mysqld] bind-address = 192.168.69.130 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8\" >> /etc/my.cnf.d/openstack.cnf Trong \u0111\u00f3 : bind-address : IP c\u1ee7a network interface management Start MarriaDB v\u00e0 cho ph\u00e9p enable trong boot systemctl enable mariadb.service systemctl start mariadb.service C\u1ea5u h\u00ecnh t\u00e0i kho\u1ea3n root cho c\u00e1c Database /usr/bin/mysqladmin -u root -h localhost password 123@123Aa","title":"3.1 . Chu\u1ea9n b\u1ecb"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#32_cai_at_cau_hinh_keystone","text":"","title":"3.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Keystone"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#321_cai_at_cau_hinh_cac_thanh_phan","text":"Tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t Keystone, c\u1ea7n kh\u1edfi t\u1ea1o m\u1ed9t DB ri\u00eang cho Keystone v\u1edbi t\u00e0i kho\u1ea3n root mysql -u root --password=123@123Aa -e \"CREATE DATABASE keystone\"; mysql -u root --password=123@123Aa -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \\ IDENTIFIED BY 'keystone_123';GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \\ IDENTIFIED BY 'keystone_123';\" C\u00e0i \u0111\u1eb7t Openstack_keystone, httpd, mod_wsgi v\u00e0 c\u1ea5u h\u00ecnh ban d\u1ea7u yum install openstack-keystone httpd mod_wsgi crudini crudini --set /etc/keystone/keystone.conf \"database\" \"connection\" \"mysql+pymysql://keystone:keystone_123@controller/keystone\" crudini --set /etc/keystone/keystone.conf \"token\" \"provider\" \"fernet\" su -s /bin/sh -c \"keystone-manage db_sync\" keystone Kh\u1edfi t\u1ea1o kho l\u01b0u tr\u1eef Fernet Token keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone Kh\u1edfi \u0111\u1ed9ng c\u00e1c d\u1ecbch v\u1ee5 trong Openstack Indentity keystone-manage bootstrap --bootstrap-password keystone_123 \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne","title":"3.2.1. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh c\u00e1c th\u00e0nh ph\u1ea7n"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#322_cai_at_cau_hinh_apace_http_server","text":"C\u1ea5u h\u00ecnh Apache Conf v\u00e0 enable service ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ systemctl enable httpd.service systemctl start httpd.service","title":"3.2.2. C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Apace HTTP Server"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#323_set_bien_moi_truong_cho_tai_khoan_admin","text":"S\u1eed d\u1ee5ng password \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh c\u00e0i \u0111\u1eb7t cho t\u00e0i kho\u1ea3n admin echo \" export OS_USERNAME=admin export OS_PASSWORD=keystone_123 export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 \" > admin-openrc . admin-openrc Ki\u1ec3m tra authentication token: [root@localhost my.cnf.d]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-19T11:48:31+0000 | | id | gAAAAABbybZ_QDUHiAbszPy2R0fG0bsCJ5Lb38zjUXSkBFiaPXstEUKGipLLvp5U4OB0UKWRRNjTHgLPPnggOP3_n9wJJCPYpy9Oitml1DYJZ-i0TBgr_CU7HU7-IpttwtKW3ywaksEyqrkaKEOpdgCe6KREkFY_qDaQ60gBZx2E9uC9EVGXjPE | | project_id | baedd3b48fbc4134ac1eba01798addea | | user_id | b495617610354ec08b6d9512e31d93eb | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=5000/tcp --permanent firewall-cmd --add-port=35357/tcp --permanent firewall-cmd --reload","title":"3.2.3 . Set bi\u1ebfn m\u00f4i tr\u01b0\u1eddng cho t\u00e0i kho\u1ea3n admin"},{"location":"Openstack_Research/Keystone/2.Install-Keystone/#33_khoi_tao_project_cho_cac_openstack_service_khac","text":"[root@localhost my.cnf.d]# openstack project create --domain default --description \"Service Project\" service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 2f6d32f44a074bcab270084b989c2fd2 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+","title":"3.3 . Kh\u1edfi t\u1ea1o Project cho c\u00e1c Openstack Service kh\u00e1c"},{"location":"Openstack_Research/Keystone/3. Architecture-Keystone( additional )/","text":"1. Ki\u1ebfn tr\u00fac trong Keystone ( b\u1ed5 sung ) \u00b6 Keystone \u0111\u01b0\u1ee3c xem l\u00e0 m\u1ed9t giao di\u1ec7n HTTP cho nhi\u1ec1u service kh\u00e1c. . Gi\u1ed1ng nh\u01b0 c\u00e1c service kh\u00e1c, keystone \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb WSGI,. Nh\u1eefng endpoint c\u1ee7a Keystone \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng b\u1edfi pipeline c\u1ee7a WSGI middeware M\u1ed7i m\u1ed9t services c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh m\u1ed9t backen \u0111\u1ec3 cho ph\u00e9p keystone c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c m\u00f4i tr\u01b0\u1eddng, m\u1ee5c \u0111\u00edch kh\u00e1c nhau Keystone \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n \u0111\u1ec3 \u0111\u1ea3m nhi\u1ec7m nhi\u1ec1u nhi\u1ec7m v\u1ee5 v\u1edbi nhi\u1ec1u ph\u1ea7n b\u1ed7 tr\u1ee3 kh\u00e1c nhau. Nh\u01b0 v\u1eadt nhi\u1ec1u ph\u01b0\u01a1ng th\u1ee9c v\u00e0 ki\u1ec3u d\u1eef li\u1ec7u s\u1ebd \u0111\u01b0\u1ee3c di\u1ec5n ra trong qu\u00e1 tr\u00ecnh l\u00e0m vi\u1ec7c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi backend. M\u1ed9t data-model cho ph\u00e9p t\u1ea1o li\u00ean k\u1ebft gi\u1eefa c\u00e1c b\u1ea3ng. Service trong h\u1ec7 th\u1ed1ng s\u1ebd c\u00f3 c\u00e1c action kh\u00e1c nhau, c\u00f3 th\u1ec3 d\u00f9ng ## Policy \u0111\u1ec3 ki\u1ebfm so\u00e1t user c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n h\u00e0nh \u0111\u1ed9ng \u0111\u00f3 kh\u00f4ng kh\u00f4ng C\u00f3 th\u1ec3 \u0111\u01b0a ra m\u1ed9t list rule h\u01b0\u1edbng ki\u1ec3m tra, ch\u1ec9 c\u1ea7n x\u00e1c minh c\u00e1c credintal \u0111\u00fang y\u00eau c\u1ea7u th\u00ec s\u1ebd \u0111\u01b0\u1ee3c c\u1ea5p quy\u1ec1n th\u1ef1c hi\u1ec7n.","title":"1. Ki\u1ebfn tr\u00fac trong Keystone ( b\u1ed5 sung )"},{"location":"Openstack_Research/Keystone/3. Architecture-Keystone( additional )/#1_kien_truc_trong_keystone_bo_sung","text":"Keystone \u0111\u01b0\u1ee3c xem l\u00e0 m\u1ed9t giao di\u1ec7n HTTP cho nhi\u1ec1u service kh\u00e1c. . Gi\u1ed1ng nh\u01b0 c\u00e1c service kh\u00e1c, keystone \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eeb WSGI,. Nh\u1eefng endpoint c\u1ee7a Keystone \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng b\u1edfi pipeline c\u1ee7a WSGI middeware M\u1ed7i m\u1ed9t services c\u00f3 th\u1ec3 c\u1ea5u h\u00ecnh m\u1ed9t backen \u0111\u1ec3 cho ph\u00e9p keystone c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c m\u00f4i tr\u01b0\u1eddng, m\u1ee5c \u0111\u00edch kh\u00e1c nhau Keystone \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n \u0111\u1ec3 \u0111\u1ea3m nhi\u1ec7m nhi\u1ec1u nhi\u1ec7m v\u1ee5 v\u1edbi nhi\u1ec1u ph\u1ea7n b\u1ed7 tr\u1ee3 kh\u00e1c nhau. Nh\u01b0 v\u1eadt nhi\u1ec1u ph\u01b0\u01a1ng th\u1ee9c v\u00e0 ki\u1ec3u d\u1eef li\u1ec7u s\u1ebd \u0111\u01b0\u1ee3c di\u1ec5n ra trong qu\u00e1 tr\u00ecnh l\u00e0m vi\u1ec7c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi backend. M\u1ed9t data-model cho ph\u00e9p t\u1ea1o li\u00ean k\u1ebft gi\u1eefa c\u00e1c b\u1ea3ng. Service trong h\u1ec7 th\u1ed1ng s\u1ebd c\u00f3 c\u00e1c action kh\u00e1c nhau, c\u00f3 th\u1ec3 d\u00f9ng ## Policy \u0111\u1ec3 ki\u1ebfm so\u00e1t user c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n h\u00e0nh \u0111\u1ed9ng \u0111\u00f3 kh\u00f4ng kh\u00f4ng C\u00f3 th\u1ec3 \u0111\u01b0a ra m\u1ed9t list rule h\u01b0\u1edbng ki\u1ec3m tra, ch\u1ec9 c\u1ea7n x\u00e1c minh c\u00e1c credintal \u0111\u00fang y\u00eau c\u1ea7u th\u00ec s\u1ebd \u0111\u01b0\u1ee3c c\u1ea5p quy\u1ec1n th\u1ef1c hi\u1ec7n.","title":"1. Ki\u1ebfn tr\u00fac trong Keystone ( b\u1ed5 sung )"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/","text":"1. C\u1ea5u tr\u00fac file c\u1ea5u h\u00ecnh \u00b6 Openstack ch\u1ee7 y\u1ebfu s\u1eed d\u1ee5ng c\u00e1c c\u1eb7p g\u00eda tr\u1ecb key = value cho c\u00e1c section trong file c\u1ea5u h\u00ecnh . C\u00e1c options c\u00f3 th\u1ec3 c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb kh\u00e1c nhau, d\u01b0\u1edbi \u0111\u00e2y l\u00e0 c\u00e1c lo\u1ea1i th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi OpenStack: boolean : Gi\u00e1 tr\u1ecb cho ph\u00e9p l\u1ef1a ch\u1ecdn l\u00e0 true v\u00e0 fale . float : S\u1ed1 th\u1ef1c (v\u00ed d\u1ee5 0.25 ho\u1eb7c 1000) interger : s\u1ed1 nguy\u00ean list : danh s\u00e1ch c\u00e1c values \u0111\u01b0\u1ee3c ph\u00e2n t\u00e1ch nhau b\u1edfi d\u1ea5u ph\u1ea9y muilti valued : l\u00e0 m\u1ed9t string value v\u00e0 c\u00f3 th\u1ec3 g\u00e1n nhi\u1ec1u h\u01a1n 1 gi\u00e1 tr\u1ecb, t\u1ea5t c\u1ea3 s\u1ebd \u0111\u1ec1u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. string : c\u00f3 th\u1ec3 c\u00f3 ho\u1eb7c kh\u00f4ng \u0111\u1eb7t trong d\u1ea5u \"\" ho\u1eb7c '' Section C\u00e1c t\u00f9y ch\u1ecdn c\u00e0i \u0111\u1eb7t \u0111\u01b0\u1ee3c nh\u00f3m l\u1ea1i th\u00e0nh c\u00e1c section. Th\u00f4ng th\u01b0\u1eddng h\u1ea7u h\u1ebft c\u00e1c file config c\u1ee7a OpenStack \u0111\u1ec1u c\u00f3 2 section [DEFAULT] v\u00e0 [database] Substitution File config h\u1ed7 tr\u1ee3 variable substitution. Sau khi thi\u1ebft l\u1eadp, t\u00f9y ch\u1ecdn c\u1ea5u h\u00ecnh \u0111\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c d\u00f9ng l\u1ea1i trong c\u00e1c gi\u00e1 t\u00f9y ch\u1ecdn kh\u00e1c b\u1eb1ng c\u00e1ch th\u00eam d\u1ea5u $ , v\u00ed d\u1ee5 nh\u01b0 rabbit_hosts = $rabbit_host:$rabbit_port \u0110\u1ec3 tr\u00e1nh substitution, d\u00f9ng $$ . V\u00ed d\u1ee5 ldap_dns_password = $$xkj432 Whitespace \u0110\u1ec3 s\u1eed d\u1ee5ng kho\u1ea3ng tr\u1eafng trong ph\u1ea7n value, s\u1eed d\u1ee5ng d\u1ea5u nh\u00e1y \u0111\u01a1n '' . V\u00ed d\u1ee5: ldap_dns_passsword='a password with spaces' 2. Default Section \u00b6 [#]Key = Default Value Description #admin_token = None kh\u00f4ng \u0111\u01b0\u1ee3c khuy\u1ebfn ngh\u1ecb s\u1eed d\u1ee5ng. S\u1eed d\u1ee5ng \u0111o\u1ea1n m\u00e3 n\u00e0y c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 kh\u1edfi \u0111\u1ed9ng Keystone th\u00f4ng qua API . Token n\u00e0y kh\u00f4ng thu\u1ed9c v\u1ec1 m\u1ed9t user c\u1ee5 th\u1ec3 , \u0111\u00e2y l\u00e0 m\u1ed9t h\u00ecnh th\u1ee9c bypass h\u1ea7u nh\u01b0 c\u00e1c ph\u1ea7n ki\u1ec3m tra \u1ee7y quy\u1ec1n #public_endpoint = None cung c\u1ea5p m\u1ed9t URL API endpoint cho c\u00e1c Client. N\u00ean c\u1ea5u h\u00ecnh m\u1ed9t URL kh\u00f4ng trungf v\u1edbi c\u00e1c endpoint path default ho\u1eb7c endpoint \u0111ang s\u1eed d\u1ee5ng \u1edf m\u1ed9t host kh\u00e1c #admin_endpoint = None cung c\u1ea5p th\u00eam m\u1ed9t URL API endpoint co c\u00e1c Client. N\u00ean c\u1ea5u h\u00ecnh m\u1ed9t URL kh\u00f4ng trungf v\u1edbi c\u00e1c endpoint path default ho\u1eb7c endpoint \u0111ang s\u1eed d\u1ee5ng \u1edf m\u1ed9t host kh\u00e1c #max_project_tree_depth = 5 Gi\u1edbi h\u1ea1n s\u1ed1 l\u1ea7n ph\u00e2n c\u1ea5p trong m\u1ed9t project #max_param_size = 64 Gi\u1edbi h\u1ea1n k\u00fd t\u1ef1 c\u1ee7a ID v\u00e0 Name trong user v\u00e0 group #max_token_size = 255 Gi\u1edbi h\u1ea1n chi\u1ec1u d\u00e0i c\u1ee7a Token, v\u1edbi Fermet token 255 , UUID l\u00e0 32 #member_role_id = 9fe2ff9ee4384b1894a90878d3e92bab G\u0103n quy\u1ec1n m\u1eb7c \u0111\u1ecbnh cho c\u00e1c user cho API v2 ( API V2 kh\u00f4ng c\u00f2n h\u1ed7 tr\u1ee3 ) #member_role_name = member G\u0103n quy\u1ec1n m\u1eb7c \u0111\u1ecbnh cho c\u00e1c user cho API v2 ( API V2 kh\u00f4ng c\u00f2n h\u1ed7 tr\u1ee3 ) #crypt_strength = 10000 S\u1eed d\u1ee5ng h\u00e0m m\u00e3 h\u00f3a b\u0103m passlib #list_limit = None S\u1ed1 l\u01b0\u1ee3ng c\u00e1c user v\u00e0 group \u0111\u01b0\u1ee3c l\u01b0u t\u1ed1i \u0111a #strict_password_check = false Ki\u1ec3m tra pasword khi g\u1eedi request \u0111\u1ebfn, n\u1ebfu set True khi password g\u1eedi \u0111\u1ebfn qua k\u00fd t\u1ef1 \u0111\u1ed1i \u0111a s\u1ebd tr\u1ea3 status 403 #secure_proxy_ssl_header = HTTP_X_FORWARDED_PROTO s\u1eed d\u1ee5ng HTTP cho c\u00e1c request #insecure_debug = false Cung c\u1ea5p b\u1ed5 sung th\u00f4ng tin \u0111\u1ec3 ph\u1ee5c v\u1ee5 debug trong c\u00e1c HTTP Response #default_publisher_id = None Cung c\u1ea5p host \u0111\u1ec3 \u0111\u1ea9y c\u00e1c th\u00f4ng b\u00e1o, m\u1eb7c \u0111\u1ecbnh l\u00e0 server name 3. oslo.log section \u00b6 [#]Key = Default Value Description #debug = false N\u1ebfu enable ch\u1ee9c n\u0103ng n\u00e0y LOG s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n sang mode DEBUG #log_config_append = None Ch\u1ec9 \u0111\u1ecbnh file ch\u1ee9a log #log_date_format = %Y-%m-%d %H:%M:%S Ch\u1ec9 \u0111\u1ecbnh format th\u1eddi gian trong log #log_dir = None Ch\u1ec9 \u0111\u1ecbnh folder ch\u1ee9a LOG, s\u1ebd \u0111\u01b0\u1ee3c b\u1ecf qua n\u1ebfn \u0111\u00e3 enable log_config_append #use_syslog = false S\u1eed d\u1ee5ng syslog /var/syslog.txt \u0111\u1ec3 l\u00e0m file l\u01b0u log #use_journal = false s\u1eed d\u1ee5ng journal \u0111\u1ec3 l\u01b0u log #use_json = false s\u1eed d\u1ee5ng JSON Format \u0111\u1ec3 l\u01b0u log 4. catalog section \u00b6 [#]Key = Default Value Description #template_file = default_catalog.templates ch\u1ec9 \u0111\u1ecbnh file l\u00e0m catalog template #driver = sql ch\u1ec9 \u0111\u1ecbnh SQL backen l\u00e0m catalog entry #caching = true l\u01b0u cache c\u00e1c catalog #cache_time = None th\u1eddi gian l\u01b0u cache t\u1ed1i \u0111a #list_limit = None S\u1ed1 endpoint gi\u1edbi h\u1ea1n tr\u00ean m\u1ed7i catalog 5. credential section \u00b6 [#]Key = Default Value Description #driver = sql Entry point cho c\u00e1c Credential #provider = fernet Entry point cho c\u00e1c thu\u1eadt to\u00e1n m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 #key_repository = /etc/keystone/credential-keys/ Folder ch\u01b0a c\u00e1c keys cho vi\u1ec7c m\u00e3 h\u00f3a, gi\u1ea3i m\u00e3 trong credential backen. Fernet key cho encrypt credentials v\u00e0 Fernet key cho encrypt Fermet key kh\u00f4ng li\u00ean quan \u0111\u1ebfn nhau 6. database section \u00b6 [#]Key = Default Value Description #connection = None \u0111\u1ecbnh ngh\u0129a k\u1ebft n\u1ed1i t\u1edbi DB #backend = sqlalchemy backend s\u1eed d\u1ee5ng cho DB #slave_connection = None \u0110\u1ecbnh ngh\u0129a m\u1ed9t DB Slave #use_db_reconnect Th\u1eed k\u1ebft n\u1ed1i l\u1ea1i khi kh\u00f4ng k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c \u0111\u1ebfn DB 7. domain_config section \u00b6 [#]Key = Default Value Description #driver = sql Ch\u1ec9 h\u1ed7 tr\u1ee3 SQL \u0111\u1ec3 entry point cho c\u00e1c domain config #caching = true Th\u1eddi gian \u0111\u1ec3 l\u01b0u cache domain dataconfig 8. endpoint_filter v\u00e0 endpoint_policy section \u00b6 [#]Key = Default Value Description #driver = sql Entry point cho c\u00e1c endpoint filter , ch\u1ec9 h\u1ed7 tr\u1ee3 SQL 9. Fernet tokens section \u00b6 [#]Key = Default Value Description #key_repository = /etc/keystone/fernet-keys/ th\u01b0 m\u1ee5c ch\u01b0a Fernet token keys #max_active_keys s\u1ed1 l\u01b0\u1ee3ng key c\u00f3 th\u1ec3 active tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m 10. identity section \u00b6 [#]Key = Default Value Description #default_domain_id = default Domain m\u1eb7c d\u1ecbnh l\u1eafng nghe c\u00e1c API v2 request Identity #domain_config_dir = /etc/keystone/domains \u0110\u01b0\u1eddng d\u1eabn cho Keystone l\u01b0u domain configuration files n\u1ebfu domain_specific_drivers_enabled \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 true #driver = sql Entry point cho the identity backend #max_password_length = 4096 \u0111\u1ed9 d\u00e0i cho ph\u00e9p t\u1ed1i \u0111a c\u1ee7a user pasword #password_hash_algorithm = bcrypt h\u00e0m b\u0103m \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho password 11. memcache section \u00b6 [#]Key = Default Value Description #dead_retry = 300 s\u1ed1 gi\u00e2y th\u1eed \u0111\u1ec3 ch\u1eafc ch\u1eafn memcached server servers = *:11211 Memcache servers 12. policy section \u00b6 [#]Key = Default Value Description #driver = sql Entry point cho policy backend driver #list_limit = None s\u1ed1 l\u01b0\u1ee3ng th\u1ef1c th\u1ec3 t\u1ed1i \u0111a cho policy collection.","title":"4. Config Keystone"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#1_cau_truc_file_cau_hinh","text":"Openstack ch\u1ee7 y\u1ebfu s\u1eed d\u1ee5ng c\u00e1c c\u1eb7p g\u00eda tr\u1ecb key = value cho c\u00e1c section trong file c\u1ea5u h\u00ecnh . C\u00e1c options c\u00f3 th\u1ec3 c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb kh\u00e1c nhau, d\u01b0\u1edbi \u0111\u00e2y l\u00e0 c\u00e1c lo\u1ea1i th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi OpenStack: boolean : Gi\u00e1 tr\u1ecb cho ph\u00e9p l\u1ef1a ch\u1ecdn l\u00e0 true v\u00e0 fale . float : S\u1ed1 th\u1ef1c (v\u00ed d\u1ee5 0.25 ho\u1eb7c 1000) interger : s\u1ed1 nguy\u00ean list : danh s\u00e1ch c\u00e1c values \u0111\u01b0\u1ee3c ph\u00e2n t\u00e1ch nhau b\u1edfi d\u1ea5u ph\u1ea9y muilti valued : l\u00e0 m\u1ed9t string value v\u00e0 c\u00f3 th\u1ec3 g\u00e1n nhi\u1ec1u h\u01a1n 1 gi\u00e1 tr\u1ecb, t\u1ea5t c\u1ea3 s\u1ebd \u0111\u1ec1u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. string : c\u00f3 th\u1ec3 c\u00f3 ho\u1eb7c kh\u00f4ng \u0111\u1eb7t trong d\u1ea5u \"\" ho\u1eb7c '' Section C\u00e1c t\u00f9y ch\u1ecdn c\u00e0i \u0111\u1eb7t \u0111\u01b0\u1ee3c nh\u00f3m l\u1ea1i th\u00e0nh c\u00e1c section. Th\u00f4ng th\u01b0\u1eddng h\u1ea7u h\u1ebft c\u00e1c file config c\u1ee7a OpenStack \u0111\u1ec1u c\u00f3 2 section [DEFAULT] v\u00e0 [database] Substitution File config h\u1ed7 tr\u1ee3 variable substitution. Sau khi thi\u1ebft l\u1eadp, t\u00f9y ch\u1ecdn c\u1ea5u h\u00ecnh \u0111\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c d\u00f9ng l\u1ea1i trong c\u00e1c gi\u00e1 t\u00f9y ch\u1ecdn kh\u00e1c b\u1eb1ng c\u00e1ch th\u00eam d\u1ea5u $ , v\u00ed d\u1ee5 nh\u01b0 rabbit_hosts = $rabbit_host:$rabbit_port \u0110\u1ec3 tr\u00e1nh substitution, d\u00f9ng $$ . V\u00ed d\u1ee5 ldap_dns_password = $$xkj432 Whitespace \u0110\u1ec3 s\u1eed d\u1ee5ng kho\u1ea3ng tr\u1eafng trong ph\u1ea7n value, s\u1eed d\u1ee5ng d\u1ea5u nh\u00e1y \u0111\u01a1n '' . V\u00ed d\u1ee5: ldap_dns_passsword='a password with spaces'","title":"1. C\u1ea5u tr\u00fac file c\u1ea5u h\u00ecnh"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#2_default_section","text":"[#]Key = Default Value Description #admin_token = None kh\u00f4ng \u0111\u01b0\u1ee3c khuy\u1ebfn ngh\u1ecb s\u1eed d\u1ee5ng. S\u1eed d\u1ee5ng \u0111o\u1ea1n m\u00e3 n\u00e0y c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 kh\u1edfi \u0111\u1ed9ng Keystone th\u00f4ng qua API . Token n\u00e0y kh\u00f4ng thu\u1ed9c v\u1ec1 m\u1ed9t user c\u1ee5 th\u1ec3 , \u0111\u00e2y l\u00e0 m\u1ed9t h\u00ecnh th\u1ee9c bypass h\u1ea7u nh\u01b0 c\u00e1c ph\u1ea7n ki\u1ec3m tra \u1ee7y quy\u1ec1n #public_endpoint = None cung c\u1ea5p m\u1ed9t URL API endpoint cho c\u00e1c Client. N\u00ean c\u1ea5u h\u00ecnh m\u1ed9t URL kh\u00f4ng trungf v\u1edbi c\u00e1c endpoint path default ho\u1eb7c endpoint \u0111ang s\u1eed d\u1ee5ng \u1edf m\u1ed9t host kh\u00e1c #admin_endpoint = None cung c\u1ea5p th\u00eam m\u1ed9t URL API endpoint co c\u00e1c Client. N\u00ean c\u1ea5u h\u00ecnh m\u1ed9t URL kh\u00f4ng trungf v\u1edbi c\u00e1c endpoint path default ho\u1eb7c endpoint \u0111ang s\u1eed d\u1ee5ng \u1edf m\u1ed9t host kh\u00e1c #max_project_tree_depth = 5 Gi\u1edbi h\u1ea1n s\u1ed1 l\u1ea7n ph\u00e2n c\u1ea5p trong m\u1ed9t project #max_param_size = 64 Gi\u1edbi h\u1ea1n k\u00fd t\u1ef1 c\u1ee7a ID v\u00e0 Name trong user v\u00e0 group #max_token_size = 255 Gi\u1edbi h\u1ea1n chi\u1ec1u d\u00e0i c\u1ee7a Token, v\u1edbi Fermet token 255 , UUID l\u00e0 32 #member_role_id = 9fe2ff9ee4384b1894a90878d3e92bab G\u0103n quy\u1ec1n m\u1eb7c \u0111\u1ecbnh cho c\u00e1c user cho API v2 ( API V2 kh\u00f4ng c\u00f2n h\u1ed7 tr\u1ee3 ) #member_role_name = member G\u0103n quy\u1ec1n m\u1eb7c \u0111\u1ecbnh cho c\u00e1c user cho API v2 ( API V2 kh\u00f4ng c\u00f2n h\u1ed7 tr\u1ee3 ) #crypt_strength = 10000 S\u1eed d\u1ee5ng h\u00e0m m\u00e3 h\u00f3a b\u0103m passlib #list_limit = None S\u1ed1 l\u01b0\u1ee3ng c\u00e1c user v\u00e0 group \u0111\u01b0\u1ee3c l\u01b0u t\u1ed1i \u0111a #strict_password_check = false Ki\u1ec3m tra pasword khi g\u1eedi request \u0111\u1ebfn, n\u1ebfu set True khi password g\u1eedi \u0111\u1ebfn qua k\u00fd t\u1ef1 \u0111\u1ed1i \u0111a s\u1ebd tr\u1ea3 status 403 #secure_proxy_ssl_header = HTTP_X_FORWARDED_PROTO s\u1eed d\u1ee5ng HTTP cho c\u00e1c request #insecure_debug = false Cung c\u1ea5p b\u1ed5 sung th\u00f4ng tin \u0111\u1ec3 ph\u1ee5c v\u1ee5 debug trong c\u00e1c HTTP Response #default_publisher_id = None Cung c\u1ea5p host \u0111\u1ec3 \u0111\u1ea9y c\u00e1c th\u00f4ng b\u00e1o, m\u1eb7c \u0111\u1ecbnh l\u00e0 server name","title":"2.  Default Section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#3_oslolog_section","text":"[#]Key = Default Value Description #debug = false N\u1ebfu enable ch\u1ee9c n\u0103ng n\u00e0y LOG s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n sang mode DEBUG #log_config_append = None Ch\u1ec9 \u0111\u1ecbnh file ch\u1ee9a log #log_date_format = %Y-%m-%d %H:%M:%S Ch\u1ec9 \u0111\u1ecbnh format th\u1eddi gian trong log #log_dir = None Ch\u1ec9 \u0111\u1ecbnh folder ch\u1ee9a LOG, s\u1ebd \u0111\u01b0\u1ee3c b\u1ecf qua n\u1ebfn \u0111\u00e3 enable log_config_append #use_syslog = false S\u1eed d\u1ee5ng syslog /var/syslog.txt \u0111\u1ec3 l\u00e0m file l\u01b0u log #use_journal = false s\u1eed d\u1ee5ng journal \u0111\u1ec3 l\u01b0u log #use_json = false s\u1eed d\u1ee5ng JSON Format \u0111\u1ec3 l\u01b0u log","title":"3.  oslo.log section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#4_catalog_section","text":"[#]Key = Default Value Description #template_file = default_catalog.templates ch\u1ec9 \u0111\u1ecbnh file l\u00e0m catalog template #driver = sql ch\u1ec9 \u0111\u1ecbnh SQL backen l\u00e0m catalog entry #caching = true l\u01b0u cache c\u00e1c catalog #cache_time = None th\u1eddi gian l\u01b0u cache t\u1ed1i \u0111a #list_limit = None S\u1ed1 endpoint gi\u1edbi h\u1ea1n tr\u00ean m\u1ed7i catalog","title":"4. catalog section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#5_credential_section","text":"[#]Key = Default Value Description #driver = sql Entry point cho c\u00e1c Credential #provider = fernet Entry point cho c\u00e1c thu\u1eadt to\u00e1n m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 #key_repository = /etc/keystone/credential-keys/ Folder ch\u01b0a c\u00e1c keys cho vi\u1ec7c m\u00e3 h\u00f3a, gi\u1ea3i m\u00e3 trong credential backen. Fernet key cho encrypt credentials v\u00e0 Fernet key cho encrypt Fermet key kh\u00f4ng li\u00ean quan \u0111\u1ebfn nhau","title":"5. credential section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#6_database_section","text":"[#]Key = Default Value Description #connection = None \u0111\u1ecbnh ngh\u0129a k\u1ebft n\u1ed1i t\u1edbi DB #backend = sqlalchemy backend s\u1eed d\u1ee5ng cho DB #slave_connection = None \u0110\u1ecbnh ngh\u0129a m\u1ed9t DB Slave #use_db_reconnect Th\u1eed k\u1ebft n\u1ed1i l\u1ea1i khi kh\u00f4ng k\u1ebft n\u1ed1i \u0111\u01b0\u1ee3c \u0111\u1ebfn DB","title":"6. database section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#7_domain_config_section","text":"[#]Key = Default Value Description #driver = sql Ch\u1ec9 h\u1ed7 tr\u1ee3 SQL \u0111\u1ec3 entry point cho c\u00e1c domain config #caching = true Th\u1eddi gian \u0111\u1ec3 l\u01b0u cache domain dataconfig","title":"7. domain_config section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#8_endpoint_filter_va_endpoint_policy_section","text":"[#]Key = Default Value Description #driver = sql Entry point cho c\u00e1c endpoint filter , ch\u1ec9 h\u1ed7 tr\u1ee3 SQL","title":"8. endpoint_filter  v\u00e0 endpoint_policy section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#9_fernet_tokens_section","text":"[#]Key = Default Value Description #key_repository = /etc/keystone/fernet-keys/ th\u01b0 m\u1ee5c ch\u01b0a Fernet token keys #max_active_keys s\u1ed1 l\u01b0\u1ee3ng key c\u00f3 th\u1ec3 active tr\u00ean m\u1ed9t th\u1eddi \u0111i\u1ec3m","title":"9. Fernet tokens section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#10_identity_section","text":"[#]Key = Default Value Description #default_domain_id = default Domain m\u1eb7c d\u1ecbnh l\u1eafng nghe c\u00e1c API v2 request Identity #domain_config_dir = /etc/keystone/domains \u0110\u01b0\u1eddng d\u1eabn cho Keystone l\u01b0u domain configuration files n\u1ebfu domain_specific_drivers_enabled \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 true #driver = sql Entry point cho the identity backend #max_password_length = 4096 \u0111\u1ed9 d\u00e0i cho ph\u00e9p t\u1ed1i \u0111a c\u1ee7a user pasword #password_hash_algorithm = bcrypt h\u00e0m b\u0103m \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho password","title":"10. identity section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#11_memcache_section","text":"[#]Key = Default Value Description #dead_retry = 300 s\u1ed1 gi\u00e2y th\u1eed \u0111\u1ec3 ch\u1eafc ch\u1eafn memcached server servers = *:11211 Memcache servers","title":"11. memcache section"},{"location":"Openstack_Research/Keystone/4. Config-Keystone/#12_policy_section","text":"[#]Key = Default Value Description #driver = sql Entry point cho policy backend driver #list_limit = None s\u1ed1 l\u01b0\u1ee3ng th\u1ef1c th\u1ec3 t\u1ed1i \u0111a cho policy collection.","title":"12. policy section"},{"location":"Openstack_Research/Keystone/5. Keystone-Openstack-CLI/","text":"L\u00e0m vi\u1ec7c v\u1edbi Keystone qua CLI \u00b6 1. Kh\u1edfi t\u1ea1o Token \u00b6 \u0110\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi Keystone ho\u1eb7c c\u00e1c service s\u1eed d\u1ee5ng Keystone l\u00e0m Indentity Service c\u1ea7n khai b\u00e1o c\u00e1c th\u00f4ng tin \u0111\u1ec3 xin credential echo \" export OS_USERNAME=admin export OS_PASSWORD=keystone_123@123Aa export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 \" > admin-openrc . admin-openrc Sau khi th\u1ef1c hi\u1ec7n xong bi\u1ebfn m\u1ed1i tr\u01b0\u01a1ng, ki\u1ec3m tra token \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1ea5p [root@localhost ~]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-21T08:33:21+0000 | | id | gAAAAABbzCvBtoTTuaE7Rr2KBCeA2q2VsCUyNUo8l_LsYZpU5QU5ISBaiCkU7G3hZpCUNRbaN19vBV28P51Xjykm9rxnMVsEKAT-rabcZgtejlYCgwxSCdR4wkQWR7FayPWqVVGlkeT9Gvm-HZAgARV3XnlGlthmqwRqeS7xYfNfJBZBCmt6kqc | | project_id | baedd3b48fbc4134ac1eba01798addea | | user_id | b495617610354ec08b6d9512e31d93eb | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Khi ng\u01b0\u1eddi d\u00f9ng \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, m\u1ed9t token \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn v\u00e0 \u1ee7y quy\u1ec1n \u0111\u1ec3 \u0111\u01b0\u1ee3c t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn c\u00e1c Service kh\u00e1c . M\u00e3 token c\u00f3 th\u1ec3 bi\u1ebfn \u0111\u1ed5i; tuy nhi\u00ean gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh cho h\u1ebft h\u1ea1n l\u00e0 m\u1ed9t gi\u1edd. Tr\u01b0\u1edbc khi task h\u00f2an th\u00e0nh m\u00e0 token h\u1ebft h\u1ea1n th\u00ec c\u00f3 th\u1ec3 b\u1ecb ng\u1eebng t\u00e1c t\u00e1c \u0111\u1ed9ng ti\u1ebfp theo \u0111\u1ebfn c\u00e1c service 2. Qu\u1ea3n l\u00fd User \u00b6 Kh\u1edfi t\u1ea1o m\u1ed9t user nguyenhungsync [root@localhost ~]# openstack user create --password 123@123Aa --email 123@123Aa@gmail.com nguyenhungsync +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | email | 123@123Aa@gmail.com | | enabled | True | | id | c7e3e4fd12114402916d6afa056303e7 | | name | nguyenhungsync | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t project tr\u00ean customer [root@localhost ~]# openstack project create --domain default customer +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 816290ab5cd6488ebf3f92940b223b56 | | is_domain | False | | name | customer | | parent_id | default | | tags | [] | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t role m\u1edbi [root@localhost ~]# openstack role create compute-customer +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | None | | id | efeb7cfca58a48dc838fa9be0eda0130 | | name | compute-customer | +-----------+----------------------------------+ G\u1eafn role compute-customer v\u00e0o user nguyenhungsync trong project customer [root@localhost ~]# openstack role add --project customer --user nguyenhungsync compute-customer [root@localhost ~]# openstack role list --user nguyenhungsync --project customer Listing assignments using role list is deprecated. Use role assignment list --user <user-name> --project <project-name> --names instead. +----------------------------------+------------------+----------+----------------+ | ID | Name | Project | User | +----------------------------------+------------------+----------+----------------+ | efeb7cfca58a48dc838fa9be0eda0130 | compute-customer | customer | nguyenhungsync | +----------------------------------+------------------+----------+----------------+ Ki\u1ec3m tra status project root@localhost ~]# openstack project show customer +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 816290ab5cd6488ebf3f92940b223b56 | | is_domain | False | | name | customer | | parent_id | default | | tags | [] | +-------------+----------------------------------+ 3. Qu\u1ea3n l\u00fd Service v\u00e0 Service User \u00b6 Li\u1ec7t k\u00ea danh s\u00e1ch c\u00e1c service [root@localhost ~]# openstack service list +----------------------------------+----------+----------+ | ID | Name | Type | +----------------------------------+----------+----------+ | 38481698c0ea4af2ad8101db59c14578 | keystone | identity | +----------------------------------+----------+----------+ Kh\u1edfi t\u1ea1o m\u1ed9t service cho nova [root@localhost ~]# openstack service create --name nova --descript Compute-Service compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Compute-Service | | enabled | True | | id | 5df98434b3c44abab4fc96cf48d66376 | | name | nova | | type | compute | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t project cho c\u00e1c service user [root@localhost ~]# openstack project create service --domain default +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 4f8df1897b004ca09b42f22788ea2516 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o user cho service nova [root@localhost ~]# openstack user create nova --password nova_123@123Aa --des Nova_User +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | description | Nova_User | | domain_id | default | | enabled | True | | id | d1b68aca653e4a3cbb8f04a5b5aca993 | | name | nova | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ G\u1eafn quy\u1ec1n admin cho nova \u0111\u1ec3 c\u00f3 th\u1ebb full access khi l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c service kh\u00e1c [root@localhost ~]# openstack role add --project service --user nova admin","title":"L\u00e0m vi\u1ec7c v\u1edbi Keystone qua CLI"},{"location":"Openstack_Research/Keystone/5. Keystone-Openstack-CLI/#lam_viec_voi_keystone_qua_cli","text":"","title":"L\u00e0m vi\u1ec7c v\u1edbi Keystone qua CLI"},{"location":"Openstack_Research/Keystone/5. Keystone-Openstack-CLI/#1_khoi_tao_token","text":"\u0110\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi Keystone ho\u1eb7c c\u00e1c service s\u1eed d\u1ee5ng Keystone l\u00e0m Indentity Service c\u1ea7n khai b\u00e1o c\u00e1c th\u00f4ng tin \u0111\u1ec3 xin credential echo \" export OS_USERNAME=admin export OS_PASSWORD=keystone_123@123Aa export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 \" > admin-openrc . admin-openrc Sau khi th\u1ef1c hi\u1ec7n xong bi\u1ebfn m\u1ed1i tr\u01b0\u01a1ng, ki\u1ec3m tra token \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1ea5p [root@localhost ~]# openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2018-10-21T08:33:21+0000 | | id | gAAAAABbzCvBtoTTuaE7Rr2KBCeA2q2VsCUyNUo8l_LsYZpU5QU5ISBaiCkU7G3hZpCUNRbaN19vBV28P51Xjykm9rxnMVsEKAT-rabcZgtejlYCgwxSCdR4wkQWR7FayPWqVVGlkeT9Gvm-HZAgARV3XnlGlthmqwRqeS7xYfNfJBZBCmt6kqc | | project_id | baedd3b48fbc4134ac1eba01798addea | | user_id | b495617610354ec08b6d9512e31d93eb | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Khi ng\u01b0\u1eddi d\u00f9ng \u0111\u01b0\u1ee3c x\u00e1c th\u1ef1c, m\u1ed9t token \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn v\u00e0 \u1ee7y quy\u1ec1n \u0111\u1ec3 \u0111\u01b0\u1ee3c t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn c\u00e1c Service kh\u00e1c . M\u00e3 token c\u00f3 th\u1ec3 bi\u1ebfn \u0111\u1ed5i; tuy nhi\u00ean gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh cho h\u1ebft h\u1ea1n l\u00e0 m\u1ed9t gi\u1edd. Tr\u01b0\u1edbc khi task h\u00f2an th\u00e0nh m\u00e0 token h\u1ebft h\u1ea1n th\u00ec c\u00f3 th\u1ec3 b\u1ecb ng\u1eebng t\u00e1c t\u00e1c \u0111\u1ed9ng ti\u1ebfp theo \u0111\u1ebfn c\u00e1c service","title":"1. Kh\u1edfi t\u1ea1o Token"},{"location":"Openstack_Research/Keystone/5. Keystone-Openstack-CLI/#2_quan_ly_user","text":"Kh\u1edfi t\u1ea1o m\u1ed9t user nguyenhungsync [root@localhost ~]# openstack user create --password 123@123Aa --email 123@123Aa@gmail.com nguyenhungsync +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | email | 123@123Aa@gmail.com | | enabled | True | | id | c7e3e4fd12114402916d6afa056303e7 | | name | nguyenhungsync | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t project tr\u00ean customer [root@localhost ~]# openstack project create --domain default customer +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 816290ab5cd6488ebf3f92940b223b56 | | is_domain | False | | name | customer | | parent_id | default | | tags | [] | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t role m\u1edbi [root@localhost ~]# openstack role create compute-customer +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | None | | id | efeb7cfca58a48dc838fa9be0eda0130 | | name | compute-customer | +-----------+----------------------------------+ G\u1eafn role compute-customer v\u00e0o user nguyenhungsync trong project customer [root@localhost ~]# openstack role add --project customer --user nguyenhungsync compute-customer [root@localhost ~]# openstack role list --user nguyenhungsync --project customer Listing assignments using role list is deprecated. Use role assignment list --user <user-name> --project <project-name> --names instead. +----------------------------------+------------------+----------+----------------+ | ID | Name | Project | User | +----------------------------------+------------------+----------+----------------+ | efeb7cfca58a48dc838fa9be0eda0130 | compute-customer | customer | nguyenhungsync | +----------------------------------+------------------+----------+----------------+ Ki\u1ec3m tra status project root@localhost ~]# openstack project show customer +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 816290ab5cd6488ebf3f92940b223b56 | | is_domain | False | | name | customer | | parent_id | default | | tags | [] | +-------------+----------------------------------+","title":"2. Qu\u1ea3n l\u00fd User"},{"location":"Openstack_Research/Keystone/5. Keystone-Openstack-CLI/#3_quan_ly_service_va_service_user","text":"Li\u1ec7t k\u00ea danh s\u00e1ch c\u00e1c service [root@localhost ~]# openstack service list +----------------------------------+----------+----------+ | ID | Name | Type | +----------------------------------+----------+----------+ | 38481698c0ea4af2ad8101db59c14578 | keystone | identity | +----------------------------------+----------+----------+ Kh\u1edfi t\u1ea1o m\u1ed9t service cho nova [root@localhost ~]# openstack service create --name nova --descript Compute-Service compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Compute-Service | | enabled | True | | id | 5df98434b3c44abab4fc96cf48d66376 | | name | nova | | type | compute | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t project cho c\u00e1c service user [root@localhost ~]# openstack project create service --domain default +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | enabled | True | | id | 4f8df1897b004ca09b42f22788ea2516 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+ Kh\u1edfi t\u1ea1o user cho service nova [root@localhost ~]# openstack user create nova --password nova_123@123Aa --des Nova_User +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | description | Nova_User | | domain_id | default | | enabled | True | | id | d1b68aca653e4a3cbb8f04a5b5aca993 | | name | nova | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ G\u1eafn quy\u1ec1n admin cho nova \u0111\u1ec3 c\u00f3 th\u1ebb full access khi l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c service kh\u00e1c [root@localhost ~]# openstack role add --project service --user nova admin","title":"3. Qu\u1ea3n l\u00fd Service v\u00e0 Service User"},{"location":"Openstack_Research/Keystone/6. Keystone-CURL/","text":"1. Application Credentials \u00b6 -Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c th\u00f4ng tin x\u00e1c th\u1ef1c \u0111\u1ec3 cho ph\u00e9p c\u00e1c \u1ee9ng d\u1ee5ng c\u1ee7a h\u1ecd c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c v\u1edbi keystone. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 c\u00f3 th\u1ec3 \u1ee7y nhi\u1ec7m c\u00e1c quy\u1ec1n con c\u1ee7a ng\u01b0\u1eddi d\u00f9ng tr\u00ean m\u1ed9t project cho c\u00e1c application credential, cung c\u1ea5p cho \u1ee9ng d\u1ee5ng quy\u1ec1n \u0111\u1ec3 access t\u1edbi m\u1ed9t project. - V\u1edbi application credential , c\u00e1c \u1ee9ng d\u1ee5ng c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c b\u1eb1ng APP ID v\u00e0 screet string kh\u00f4ng s\u1eed d\u1ee5ng user v\u00e0 password \u0111\u1ec3 x\u00e1c th\u1ef1c . - Kh\u1edfi t\u1ea1o m\u1ed9t credential cho vi\u1ec7c monitoring 2. Curl API \u00b6 S\u1eed d\u1ee5ng CURL \u0111\u1ebb l\u1ea5y token c\u00f3 gi\u1edbi h\u1ea1n trong ph\u1ea1m vi project , c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n tr\u1ecdng domain ho\u1eb7c kh\u00f4ng \u0111\u01b0\u1ee3c khoanh v\u00f9ng ( kh\u00f4ng c\u00f3 quy\u1ec1n th\u1ef1c thi ) curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } } } } }' \\ \"http://localhost:5000/v3/auth/tokens\" ; echo Token \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 HTTP Response : X-Subject-Token HTTP/1.1 201 Created Date: Fri, 02 Nov 2018 07:36:03 GMT Server: Apache/2.4.6 (CentOS) mod_wsgi/3.4 Python/2.7.5 X-Subject-Token: gAAAAABb2_5k-3Hnw3Iz-ETfK8ObeMmy7iWNU0pDGE_n27GEOCOTCYtCOfnwjiCx9KyAR78JdMc4U31Q9CcpIyK2VggVslOXHIM5W5tuc5ZaCynoJ6f88sDSitZ1h2w_Ib-SEEyXvoXzxqHe_JZmBeXa3puGHA0XMD12_62pckgg2pETmqIzQgs Vary: X-Auth-Token x-openstack-request-id: req-23e16631-11d4-4612-82de-da17bc01a4c6 Content-Length: 1299 Content-Type: application/json { \"token\": { \"is_domain\": false, \"methods\": [\"password\"], \"roles\": [ { \"id\": \"71361dfdcc4c4f148ecb3c5918987041\", \"name\": \"admin\" } ], \"expires_at\": \"2018-11-02T10:25:32.000000Z\", \"project\": { \"domain\": { \"id\": \"default\", \"name\": \"Default\" } , \"id\": \"baedd3b48fbc4134ac1eba01798addea\", \"name\": \"admin\" } , \"catalog\": [ { \"endpoints\": [ { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"internal\", \"id\": \"4237a9ae2c2242f0ab65278637d3dafe\" } , { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"admin\", \"id\": \"5f5e989d069a4a918729480fc2e569f2\" } , { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"public\", \"id\": \"a8581cbcb5734f46aba679af5fc40460\" } ], \"type\": \"identity\", \"id\": \"38481698c0ea4af2ad8101db59c14578\", \"name\": \"keystone\" } , { \"endpoints\": [], \"type\": \"compute\", \"id\": \"50da716315c24213957835e38fd30cfc\", \"name\": \"Compute-Service\" } , { \"endpoints\": [], \"type\": \"compute\", \"id\": \"5df98434b3c44abab4fc96cf48d66376\", \"name\": \"nova\" } ], \"user\": { \"password_expires_at\": null, \"domain\": { \"id\": \"default\", \"name\": \"Default\" } , \"id\": \"b495617610354ec08b6d9512e31d93eb\", \"name\": \"admin\" } , \"audit_ids\": [\"2MzOxAJfTPmjlUunby1l9Q\"], \"issued_at\": \"2018-11-02T09:25:32.000000Z\" } } Qua issued_at v\u00e0 expires_at ta c\u00f3 th\u1ec3 nh\u1eadn th\u1ea5y token trong openstack m\u1eb7c \u0111\u1ecbnh c\u00f3 hi\u1ec7u l\u1ef1c trong 1 ti\u1ebfng Sau khi c\u00f3 Token, c\u00f3 th\u1ec3 export th\u00e0nh m\u1ed9t bi\u1ebfn m\u00f4i tr\u01b0\u1eddng \u0111\u1ec3 c\u00f3 l\u00e0m header \"X-Auth-Token\" cho c\u00e1c request kh\u00e1c [root@localhost fernet-keys]# export TOKEN=ETfK8ObeMmy7iWNU0pDGE_n27GEOCOTCYtCOfnwjiCx9KyAR78JdMc4U31Q9CcpIyK2VggVslOXHIM5W5tuc5ZaCynoJ6f88sDSitZ1h2w_Ib-SEEyXvoXzxqHe_JZmBeXa3puGHA0XMD12_62pckgg2pETmqIzQgs root@localhost ~]# curl -X GET -i \\ > -H \"X-Auth-Token: $TOKEN\" \\ > -H 'content-type: application/json' \\ > http://localhost:5000/v3/users HTTP/1.1 200 OK Date: Fri, 02 Nov 2018 08:02:18 GMT Server: Apache/2.4.6 (CentOS) mod_wsgi/3.4 Python/2.7.5 Vary: X-Auth-Token x-openstack-request-id: req-4ebd430a-1f91-428d-8dd4-05977c4f139e Content-Length: 1190 Content-Type: application/json Danh s\u00e1ch User \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 { \"users\": [ { \"name\": \"nguyenhungsnc\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/28c4fb726eea4e1cb13d4e19215f8ecf\" }, \"domain_id\": \"default\", \"enabled\": true, \"options\": {}, \"id\": \"28c4fb726eea4e1cb13d4e19215f8ecf\", \"email\": \"123@123Aa@gmail.com\", \"password_expires_at\": null }, { \"password_expires_at\": null, \"name\": \"admin\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/b495617610354ec08b6d9512e31d93eb\" }, \"domain_id\": \"default\", \"enabled\": true, \"id\": \"b495617610354ec08b6d9512e31d93eb\", \"options\": {} }, { \"name\": \"nguyenhungsync\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/c7e3e4fd12114402916d6afa056303e7\" }, \"domain_id\": \"default\", \"enabled\": true, \"options\": {}, \"default_project_id\": \"816290ab5cd6488ebf3f92940b223b56\", \"id\": \"c7e3e4fd12114402916d6afa056303e7\", \"email\": \"123@123Aa@gmail.com\", \"password_expires_at\": null }, { \"description\": \"Nova_User\", \"name\": \"nova\", \"domain_id\": \"default\", \"enabled\": true, \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/d1b68aca653e4a3cbb8f04a5b5aca993\" }, \"options\": {}, \"id\": \"d1b68aca653e4a3cbb8f04a5b5aca993\", \"password_expires_at\": null } ], \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users\", \"previous\": null, \"next\": null } } Li\u1ec7t k\u00ea danh s\u00e1ch Project [root@localhost ~]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://localhost:5000/v3/projects | python -mjson.tool { \"links\": { \"next\": null, \"previous\": null, \"self\": \"http://localhost:5000/v3/projects\" }, \"projects\": [ { \"description\": \"\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"4f8df1897b004ca09b42f22788ea2516\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/4f8df1897b004ca09b42f22788ea2516\" }, \"name\": \"service\", \"parent_id\": \"default\", \"tags\": [] }, { \"description\": \"\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"816290ab5cd6488ebf3f92940b223b56\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/816290ab5cd6488ebf3f92940b223b56\" }, \"name\": \"customer\", \"parent_id\": \"default\", \"tags\": [] }, { \"description\": \"Bootstrap project for initializing the cloud.\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"baedd3b48fbc4134ac1eba01798addea\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/baedd3b48fbc4134ac1eba01798addea\" }, \"name\": \"admin\", \"parent_id\": \"default\", \"tags\": [] } ] } Danh c\u00e1c API v3 \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i https://developer.openstack.org/api-ref/identity/v3/?expanded=list-domains-detail Kh\u1edfi t\u1ea1o m\u1ed9t project m\u1edbi curl -i -H \"X-Auth-Token: $TOKEN\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"project\": { \"description\": \"New Project\", \"domain_id\": \"default\", \"enabled\": true, \"is_domain\": false, \"name\": \"testproject\" }}' \\ http://localhost:5000/v3/projects | pytohn -mjson.tool","title":"1. Application Credentials"},{"location":"Openstack_Research/Keystone/6. Keystone-CURL/#1_application_credentials","text":"-Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u1ea1o ra c\u00e1c th\u00f4ng tin x\u00e1c th\u1ef1c \u0111\u1ec3 cho ph\u00e9p c\u00e1c \u1ee9ng d\u1ee5ng c\u1ee7a h\u1ecd c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c v\u1edbi keystone. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 c\u00f3 th\u1ec3 \u1ee7y nhi\u1ec7m c\u00e1c quy\u1ec1n con c\u1ee7a ng\u01b0\u1eddi d\u00f9ng tr\u00ean m\u1ed9t project cho c\u00e1c application credential, cung c\u1ea5p cho \u1ee9ng d\u1ee5ng quy\u1ec1n \u0111\u1ec3 access t\u1edbi m\u1ed9t project. - V\u1edbi application credential , c\u00e1c \u1ee9ng d\u1ee5ng c\u00f3 th\u1ec3 x\u00e1c th\u1ef1c b\u1eb1ng APP ID v\u00e0 screet string kh\u00f4ng s\u1eed d\u1ee5ng user v\u00e0 password \u0111\u1ec3 x\u00e1c th\u1ef1c . - Kh\u1edfi t\u1ea1o m\u1ed9t credential cho vi\u1ec7c monitoring","title":"1. Application Credentials"},{"location":"Openstack_Research/Keystone/6. Keystone-CURL/#2_curl_api","text":"S\u1eed d\u1ee5ng CURL \u0111\u1ebb l\u1ea5y token c\u00f3 gi\u1edbi h\u1ea1n trong ph\u1ea1m vi project , c\u00f3 th\u1ec3 gi\u1edbi h\u1ea1n tr\u1ecdng domain ho\u1eb7c kh\u00f4ng \u0111\u01b0\u1ee3c khoanh v\u00f9ng ( kh\u00f4ng c\u00f3 quy\u1ec1n th\u1ef1c thi ) curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } } } } }' \\ \"http://localhost:5000/v3/auth/tokens\" ; echo Token \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 HTTP Response : X-Subject-Token HTTP/1.1 201 Created Date: Fri, 02 Nov 2018 07:36:03 GMT Server: Apache/2.4.6 (CentOS) mod_wsgi/3.4 Python/2.7.5 X-Subject-Token: gAAAAABb2_5k-3Hnw3Iz-ETfK8ObeMmy7iWNU0pDGE_n27GEOCOTCYtCOfnwjiCx9KyAR78JdMc4U31Q9CcpIyK2VggVslOXHIM5W5tuc5ZaCynoJ6f88sDSitZ1h2w_Ib-SEEyXvoXzxqHe_JZmBeXa3puGHA0XMD12_62pckgg2pETmqIzQgs Vary: X-Auth-Token x-openstack-request-id: req-23e16631-11d4-4612-82de-da17bc01a4c6 Content-Length: 1299 Content-Type: application/json { \"token\": { \"is_domain\": false, \"methods\": [\"password\"], \"roles\": [ { \"id\": \"71361dfdcc4c4f148ecb3c5918987041\", \"name\": \"admin\" } ], \"expires_at\": \"2018-11-02T10:25:32.000000Z\", \"project\": { \"domain\": { \"id\": \"default\", \"name\": \"Default\" } , \"id\": \"baedd3b48fbc4134ac1eba01798addea\", \"name\": \"admin\" } , \"catalog\": [ { \"endpoints\": [ { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"internal\", \"id\": \"4237a9ae2c2242f0ab65278637d3dafe\" } , { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"admin\", \"id\": \"5f5e989d069a4a918729480fc2e569f2\" } , { \"region_id\": \"RegionOne\", \"url\": \"http://controller:5000/v3/\", \"region\": \"RegionOne\", \"interface\": \"public\", \"id\": \"a8581cbcb5734f46aba679af5fc40460\" } ], \"type\": \"identity\", \"id\": \"38481698c0ea4af2ad8101db59c14578\", \"name\": \"keystone\" } , { \"endpoints\": [], \"type\": \"compute\", \"id\": \"50da716315c24213957835e38fd30cfc\", \"name\": \"Compute-Service\" } , { \"endpoints\": [], \"type\": \"compute\", \"id\": \"5df98434b3c44abab4fc96cf48d66376\", \"name\": \"nova\" } ], \"user\": { \"password_expires_at\": null, \"domain\": { \"id\": \"default\", \"name\": \"Default\" } , \"id\": \"b495617610354ec08b6d9512e31d93eb\", \"name\": \"admin\" } , \"audit_ids\": [\"2MzOxAJfTPmjlUunby1l9Q\"], \"issued_at\": \"2018-11-02T09:25:32.000000Z\" } } Qua issued_at v\u00e0 expires_at ta c\u00f3 th\u1ec3 nh\u1eadn th\u1ea5y token trong openstack m\u1eb7c \u0111\u1ecbnh c\u00f3 hi\u1ec7u l\u1ef1c trong 1 ti\u1ebfng Sau khi c\u00f3 Token, c\u00f3 th\u1ec3 export th\u00e0nh m\u1ed9t bi\u1ebfn m\u00f4i tr\u01b0\u1eddng \u0111\u1ec3 c\u00f3 l\u00e0m header \"X-Auth-Token\" cho c\u00e1c request kh\u00e1c [root@localhost fernet-keys]# export TOKEN=ETfK8ObeMmy7iWNU0pDGE_n27GEOCOTCYtCOfnwjiCx9KyAR78JdMc4U31Q9CcpIyK2VggVslOXHIM5W5tuc5ZaCynoJ6f88sDSitZ1h2w_Ib-SEEyXvoXzxqHe_JZmBeXa3puGHA0XMD12_62pckgg2pETmqIzQgs root@localhost ~]# curl -X GET -i \\ > -H \"X-Auth-Token: $TOKEN\" \\ > -H 'content-type: application/json' \\ > http://localhost:5000/v3/users HTTP/1.1 200 OK Date: Fri, 02 Nov 2018 08:02:18 GMT Server: Apache/2.4.6 (CentOS) mod_wsgi/3.4 Python/2.7.5 Vary: X-Auth-Token x-openstack-request-id: req-4ebd430a-1f91-428d-8dd4-05977c4f139e Content-Length: 1190 Content-Type: application/json Danh s\u00e1ch User \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 { \"users\": [ { \"name\": \"nguyenhungsnc\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/28c4fb726eea4e1cb13d4e19215f8ecf\" }, \"domain_id\": \"default\", \"enabled\": true, \"options\": {}, \"id\": \"28c4fb726eea4e1cb13d4e19215f8ecf\", \"email\": \"123@123Aa@gmail.com\", \"password_expires_at\": null }, { \"password_expires_at\": null, \"name\": \"admin\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/b495617610354ec08b6d9512e31d93eb\" }, \"domain_id\": \"default\", \"enabled\": true, \"id\": \"b495617610354ec08b6d9512e31d93eb\", \"options\": {} }, { \"name\": \"nguyenhungsync\", \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/c7e3e4fd12114402916d6afa056303e7\" }, \"domain_id\": \"default\", \"enabled\": true, \"options\": {}, \"default_project_id\": \"816290ab5cd6488ebf3f92940b223b56\", \"id\": \"c7e3e4fd12114402916d6afa056303e7\", \"email\": \"123@123Aa@gmail.com\", \"password_expires_at\": null }, { \"description\": \"Nova_User\", \"name\": \"nova\", \"domain_id\": \"default\", \"enabled\": true, \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users/d1b68aca653e4a3cbb8f04a5b5aca993\" }, \"options\": {}, \"id\": \"d1b68aca653e4a3cbb8f04a5b5aca993\", \"password_expires_at\": null } ], \"links\": { \"self\": \"http://192.168.30.130:5000/v3/users\", \"previous\": null, \"next\": null } } Li\u1ec7t k\u00ea danh s\u00e1ch Project [root@localhost ~]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://localhost:5000/v3/projects | python -mjson.tool { \"links\": { \"next\": null, \"previous\": null, \"self\": \"http://localhost:5000/v3/projects\" }, \"projects\": [ { \"description\": \"\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"4f8df1897b004ca09b42f22788ea2516\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/4f8df1897b004ca09b42f22788ea2516\" }, \"name\": \"service\", \"parent_id\": \"default\", \"tags\": [] }, { \"description\": \"\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"816290ab5cd6488ebf3f92940b223b56\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/816290ab5cd6488ebf3f92940b223b56\" }, \"name\": \"customer\", \"parent_id\": \"default\", \"tags\": [] }, { \"description\": \"Bootstrap project for initializing the cloud.\", \"domain_id\": \"default\", \"enabled\": true, \"id\": \"baedd3b48fbc4134ac1eba01798addea\", \"is_domain\": false, \"links\": { \"self\": \"http://localhost:5000/v3/projects/baedd3b48fbc4134ac1eba01798addea\" }, \"name\": \"admin\", \"parent_id\": \"default\", \"tags\": [] } ] } Danh c\u00e1c API v3 \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i https://developer.openstack.org/api-ref/identity/v3/?expanded=list-domains-detail Kh\u1edfi t\u1ea1o m\u1ed9t project m\u1edbi curl -i -H \"X-Auth-Token: $TOKEN\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"project\": { \"description\": \"New Project\", \"domain_id\": \"default\", \"enabled\": true, \"is_domain\": false, \"name\": \"testproject\" }}' \\ http://localhost:5000/v3/projects | pytohn -mjson.tool","title":"2. Curl API"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/","text":"T\u00ecm hi\u1ec3u Token trong Openstack \u00b6 1. C\u01a1 b\u1ea3n v\u1ec1 Keystone Token \u00b6 Token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Keystone \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 \u1ee7y quy\u1ec1n cho ph\u00e9p c\u00e1c t\u01b0\u01a1ng t\u00e1c c\u1ee7a ng\u01b0\u1eddi d\u00f9ng t\u1edbi c\u00e1c API endpoint. Token c\u00f3 nhi\u1ec1u lo\u1ea1i \u0111\u1ea1i di\u1ec7n cho nhi\u1ec1u ki\u1ec3u x\u00e1c th\u1ef1c v\u00e0 nh\u1eadn d\u1ea1ng . C\u00f3 r\u1ea5t nhi\u1ec1u token provider m\u1ed7i provider c\u00f3 \u0111\u1eb7c t\u00ednh rieeng cho qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n Token c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 th\u1ef1c hi\u1ec7n \u1ee7y quy\u1ec1n tr\u00ean nhi\u1ec1u ph\u1ea1m vi kh\u00e1c nhau . Ng\u01b0\u1eddi d\u00f9ng s\u1ebd c\u00f3 m\u1ed7i \u0111\u1eb7c quy\u1ec1n ri\u00eang b\u1edfi c\u00e1c role, tr\u00ean c\u00e1c project v\u00e0 domain . M\u1ed7i ph\u1ea1m vi s\u1ebd \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn c\u00e1c service n\u1eb1m trong ph\u1ea1m vi \u0111\u00f3 . Unscoped token kh\u00f4ng t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn service , catalog, project, domain . Khi s\u1eed d\u1ee5ng unscoped token th\u00ec ch\u1ec9 mang t\u00ednh \u0111\u1ea1ng danh, kh\u00f4ng \u0111\u01b0\u1ee3c t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c compoment kh\u00e1c Project-scoped token : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 c\u00f3 th\u1ec3 t\u00e1c \u0111\u1ed9ng t\u1edbi c\u00e1c serivce kh\u00e1c. Ch\u00fang ch\u01b0a c\u00e1c catalog , role v\u00e0 c\u00e1c th\u00f4ng tin c\u1ee7a project v\u00e0 \u0111\u01b0\u1ee3c \u1ee7y quy\u1ec1n Domain-scoped token : \u0111\u01b0\u1ee3c s\u1ee7 d\u1ee5ng \u00edt, c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c t\u1edbi c\u00e1c \u0111\u1ed1i t\u01b0owngj d\u01b0\u1edbi domain, 2. Token Provider \u00b6 Token provider trong keystone \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh t\u1ea1i /etc/keystone/keystone.conf . Hi\u1ec7n t\u1ea1i c\u00f3 4 ki\u1ec3u token provider h\u1ed7 tr\u1ee3 : UUID fernet , PKI v\u00e0 PKIZ 2.1 : UUID \u00b6 K\u00edch th\u01b0\u1edbc nh\u1ecf g\u1ecdn, l\u00e0 chu\u1ed7i ng\u1eabu nhi\u00ean 32 k\u00fd t\u1ef1 T\u1ea1o n\u00ean t\u1eeb c\u00e1c ch\u1ec9 s\u1ed1 h\u1ec7 th\u1eadp l\u1ee5c ph\u00e2n Tokens URL th\u00e2n thi\u1ec7n v\u00e0 an to\u00e0n khi g\u1eedi \u0111i trong m\u00f4i tr\u01b0\u1eddng non-binary. L\u01b0u tr\u1eef trong h\u1ec7 th\u1ed1ng backend (nh\u01b0 database) b\u1ec1 v\u1eefng \u0111\u1ec3 s\u1eb5n s\u00e0ng cho m\u1ee5c \u0111\u00edch x\u00e1c th\u1ef1c UUID kh\u00f4ng b\u1ecb x\u00f3a trong h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef nh\u01b0ng s\u1ebd b\u1ecb \u0111\u00e1nh d\u1ea5u l\u00e0 \"revoked\" (b\u1ecb thu h\u1ed3i) th\u00f4ng qua DELETE request v\u1edbi token ID t\u01b0\u01a1ng \u1ee9ng. UUID kh\u00f4ng mang th\u00f4ng tin g\u00ec v\u1ec1 User. Keystone ph\u1ea3i th\u1ef1c hi\u1ec7n vi\u1ec7c x\u00e1c th\u1ef1c token v\u00e0 l\u01b0u tr\u1eef, v\u1edbi k\u00edch th\u01b0\u1edbc c\u1ee7a h\u1ec7 th\u1ed1ng m\u1edf r\u1ed9ng h\u01a1n th\u00ec hi\u1ec7u xu\u1ea5t c\u1ee7a Keystone s\u1ebd b\u1ecb \u1ea3nh h\u01b0\u1edfng. Workflow t\u1ea1o UUID token di\u1ec5n ra nh\u01b0 sau: User request t\u1edbi keystone t\u1ea1o token v\u1edbi c\u00e1c th\u00f4ng tin: user name, password, project name Ch\u1ee9ng th\u1ef1c user, l\u1ea5y User ID t\u1eeb backend LDAP (d\u1ecbch v\u1ee5 Identity) Ch\u1ee9ng th\u1ef1c project, thu th\u1eadp th\u00f4ng tin Project ID v\u00e0 Domain ID t\u1eeb Backend SQL (d\u1ecbch v\u1ee5 Resources) L\u1ea5y ra Roles t\u1eeb Backend tr\u00ean Project ho\u1eb7c Domain t\u01b0\u01a1ng \u1ee9ng tr\u1ea3 v\u1ec1 cho user, n\u1ebfu user kh\u00f4ng c\u00f3 b\u1ea5t k\u1ef3 roles n\u00e0o th\u00ec tr\u1ea3 v\u1ec1 Failure(d\u1ecbch v\u1ee5 Assignment) Thu th\u1eadp c\u00e1c Services v\u00e0 c\u00e1c Endpoints c\u1ee7a c\u00e1c service \u0111\u00f3 (d\u1ecbch v\u1ee5 Catalog) T\u1ed5ng h\u1ee3p c\u00e1c th\u00f4ng tin v\u1ec1 Identity, Resources, Assignment, Catalog \u1edf tr\u00ean \u0111\u01b0a v\u00e0o Token payload, t\u1ea1o ra token s\u1eed d\u1ee5ng h\u00e0m uuid.uuid4().hex L\u01b0u th\u00f4ng tin c\u1ee7a Token v\u00e0 SQL/KVS backend v\u1edbi c\u00e1c th\u00f4ng tin: TokenID, Expiration, Valid, UserID, Extra 2.2. PKI v\u00e0 PKIZ Token \u00b6 PKI token ch\u1ee9a to\u00e0n b\u1ed9 th\u00f4ng tin x\u00e1c th\u1ef1c nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb Keystone. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 token ch\u1ee9a l\u01b0\u1ee3ng l\u1edbn c\u00e1c th\u00f4ng tin: nh\u01b0 l\u00e0 th\u1eddi gian c\u1ea5p ph\u00e1t, th\u1eddi gian h\u1ebft h\u1ea1n, \u0111\u1ecbnh danh user, th\u00f4ng tin project, domain v\u00e0 role cho user, catalog d\u1ecbch v\u1ee5, v\u00e0 nhi\u1ec1u th\u00f4ng tin kh\u00e1c. Ch\u00ednh v\u00ec mang qu\u00e1 nhi\u1ec1u th\u00f4ng tin n\u00ean n\u00f3 l\u1ea1i l\u00e0 \u0111i\u1ec3m y\u1ebfu c\u1ee7a lo\u1ea1i token n\u00e0y v\u00ec khi h\u1ec7 th\u1ed1ng \u0111\u01b0\u1ee3c m\u1edf r\u1ed9ng c\u00e1c th\u00f4ng tin user v\u00e0 catalog c\u00e0ng nhi\u1ec1u trong khi \u0111\u00f3 HTTP Header ch\u1ec9 gi\u1edbi h\u1ea1n 8KB. \u0110\u1ec3 kh\u00e1c ph\u1ee5c \u0111i\u1ec1u n\u00e0y th\u00ec Openstack c\u0169ng \u0111\u01b0a ra m\u1ed9t lo\u1ea1i token PKIZ v\u1edbi kh\u1ea3 n\u0103ng n\u00e9n token xu\u1ed1ng k\u00edch th\u01b0\u1edbc t\u1ed1i thi\u1ec3u. M\u1eb7c d\u00f9 \u0111\u00e3 \u0111\u01b0\u1ee3c n\u00e9n nh\u01b0ng PKIZ v\u1eabn b\u1ecb c\u1ed9ng \u0111\u1ed3ng Openstack \u0111\u00e1nh gi\u00e1 l\u00e0 k\u00edch th\u01b0\u1edbc qu\u00e1 l\u1edbn. \u01afu \u0111i\u1ec3m c\u1ee7a lo\u1ea1i token n\u00e0y l\u00e0 c\u00e1c OpenStack services c\u00f3 th\u1ec3 cache l\u1ea1i token n\u00e0y \u0111\u1ec3 \u0111\u01b0a ra quy\u1ebft \u0111\u1ecbnh \u1ee7y quy\u1ec1n m\u00e0 kh\u00f4ng ph\u1ea3i li\u00ean h\u1ec7 l\u1ea1i keystone n\u00ean \u0111\u00e3 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 t\u1eafc ngh\u1ebdn c\u1ed5 chai c\u1ee7a UUID token. 2.1. Qu\u00e1 tr\u00ecnh sinh token PKI v\u00e0 PKIZ \u00b6 C\u0169ng gi\u1ed1ng nh\u01b0 UUID token v\u1edbi PKI v\u00e0 PKIZ token th\u00ec User c\u1ea7n g\u1eedi c\u00e1c th\u00f4ng tin \u0111\u1ec3 Keystone x\u00e1c th\u1ef1c v\u00e0 c\u1ea5p token, nh\u01b0ng c\u00f3 m\u1ed9t \u0111i\u1ec3m kh\u00e1c l\u00e0 lo\u1ea1i token n\u00e0y s\u1eed d\u1ee5ng h\u1ec7 m\u1eadt m\u00e3 kh\u00f3a b\u1ea5t \u0111\u1ed1i x\u1ee9ng t\u1ee9c l\u00e0 d\u00f9ng kh\u00f3a Private Key c\u1ee7a keystone \u0111\u1ec3 m\u00e3 h\u00f3a Payload token, khi user s\u1eed d\u1ee5ng token n\u00e0y th\u00ec c\u00e1c service trong Openstack s\u1ebd s\u1eed d\u1ee5ng Public Key \u0111\u1ec3 gi\u1ea3i m\u00e3 v\u00e0 l\u1ea5y ra c\u00e1c th\u00f4ng tin. C\u00e1c b\u01b0\u1edbc kh\u1edfi t\u1ea1o token PKI \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n r\u1ea5t r\u00f5 \u1edf h\u00ecnh \u1ea3nh tr\u00ean. 2.2. Qu\u00e1 tr\u00ecnh validate v\u00e0 thu h\u1ed3i PKI v\u00e0 PKIZ token \u00b6 Qu\u00e1 tr\u00ecnh n\u00e0y ho\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 v\u01a1i UUID token. Qu\u00e1 tr\u00ecnh thu h\u1ed3i c\u0169ng ho\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 UUID token. 2.3 : Fernet \u00b6 2.3.1 . C\u01a1 b\u1ea3n v\u1ec1 fernet \u00b6 Fernet token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ea7u ti\u1ec1n t\u1ea1i Openstack Kilo . Kh\u00f4ng gi\u1ed1ng nh\u01b0 c\u00e1c lo\u1ea1i token kh\u00e1c fernet kh\u00f4ng y\u00eau c\u1ea7u s\u1eed d\u1ee5ng backend Fernet token ch\u01b0a m\u1ed9t s\u1ed1 l\u01b0\u1ee3ng d\u1eef li\u1ec7u nh\u1eadn d\u1ea1ng v\u00e0 \u1ee7y quy\u1ec1n trong MessagePacked . Payload s\u1ebd \u0111\u00f3ng g\u00f3i c\u00e1c Fernet token . D\u1eef li\u1ec7u trong Fernet token \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 b\u1edfi c\u00e1c thu\u1eadt to\u00e1n m\u00e3 h\u00f3a \u0111\u1ed1i x\u1ee9ng ho\u1eb7c 2 fernet key 2.3.2 . Fernet key l\u00e0 g\u00ec ? \u00b6 Fernet key \u0111\u01b0\u1ee3c d\u00f9ng trong vi\u1ec7c m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 c\u00e1c Fernet token. Trong m\u1ed7i kernet key bao g\u1ed3m 2 kh\u00f3a h\u1ecf h\u01a1n : a 128-bit AES256 encryption key v\u00e0 . 128-bit SHA256 HMAC signing key . Fernet key \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i key respo m\u00e0 payload c\u00f3 th\u1ec3 chuy\u1ec3n \u0111\u1ebfn th\u01b0 vi\u1ec7n x\u1eed l\u00fd m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 m\u00e3 token Fernet s\u1ebd \u0111\u1ebfn th\u01b0 m\u1ee5c ch\u1ee9a c\u00e1c key, th\u1ef1c hi\u1ec7n t\u1ea5t c\u1ea3 m\u00e3 h\u00f3a b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng kh\u00f3a \u0111\u1ea7u ti\u00ean trong danh s\u00e1ch v\u00e0 c\u1ed1 g\u1eafng gi\u1ea3i m\u00e3 b\u1eb1ng t\u1ea5t c\u1ea3 c\u00e1c kh\u00f3a t\u1eeb danh s\u00e1ch \u0111\u00f3. Keystone fernet token tr\u00f4ng gi\u1ed1ng nh\u01b0 sau: gAAAAABWHXT73mGHg90PE6rmS-6aeYYvdErvO1RCWbDBrM5JV6L-eGEkz9cv8598DWWF5LZH5buzYM6PmUk3w9PHd4j6zs9L0_nvqZAGOrA4gLjhE10MLk00_Qy-IIPMQ6kxjsphYVLP1uBUNyh-s4hq76-KGNUqAcYgLyN8DtgoifDseSZKNl8 2.3.3 . Fernet key repo \u00b6 Key repo l\u00e0 y\u00eau c\u1ea7u t\u1ed1i thi\u1ec3u \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t fernet token. Nh\u1eefng key \u0111\u01b0\u1ee3c l\u01b0u trong repo nh\u0103m m\u1ee5c \u0111\u00edch m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 trong qu\u00e1 tr\u00ecnh \u0111\u00f3ng g\u00f3i fernet token .M\u1ed7i key trong repo c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t trong ba tr\u1ea1ng th\u00e1i. Tr\u1ea1ng th\u00e1i c\u1ee7a kh\u00f3a x\u00e1c \u0111\u1ecbnh c\u00e1ch keystone s\u1eed d\u1ee5ng fernet token. C\u00e1c lo\u1ea1i kh\u00e1c nhau nh\u01b0 sau: Lo\u1ea1i 1 - Primary Key: s\u1eed d\u1ee5ng cho c\u1ea3 2 m\u1ee5c \u0111\u00edch m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 fernet tokens. C\u00e1c key \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u00ean theo s\u1ed1 nguy\u00ean b\u1eaft \u0111\u1ea7u t\u1eeb 0. Trong \u0111\u00f3 Primary Key c\u00f3 ch\u1ec9 s\u1ed1 cao nh\u1ea5t. Lo\u1ea1i 2 - Secondary Key: ch\u1ec9 d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3. -> Lowest Index < Secondary Key Index < Highest Index Lo\u1ea1i 3 - Stagged Key: t\u01b0\u01a1ng t\u1ef1 nh\u01b0 secondary key trong tr\u01b0\u1eddng h\u1ee3p n\u00f3 s\u1eed d\u1ee5ng \u0111\u1ec3 gi\u1ea3i m\u00e3 token. Tuy nhi\u00ean n\u00f3 s\u1ebd tr\u1edf th\u00e0nh Primary Key trong l\u1ea7n lu\u00e2n chuy\u1ec3n kh\u00f3a ti\u1ebfp theo. Stagged Key c\u00f3 ch\u1ec9 s\u1ed1 0 -- Fernet Keys \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /etc/keystone/fernet-keys/ 2.3.4 :Fernet Key Rotation \u00b6 B\u01b0\u1edbc \u0111\u1ea7u ch\u01b0a c\u00f3 key repo s\u1ebd kh\u1edfi t\u1ea1o m\u1ed9t key repo b\u1eb1ng keystone-manager \u0111\u1ec3 t\u1ea1o 2 kh\u00f3a trong repo. Khi 2 file \u0111\u01b0\u1ee3c t\u1ea1o th\u00ec s\u1ebd c\u00f3 file t\u00ean 1 s\u1ebd l\u00e0 primary key , v\u00e0 file 0 s\u1ebd l\u00e0 staged key v\u00e0 kh\u00f4ng c\u00f3 m\u1ed9t secondary key Xem \u0111\u00e2y l\u00e0 l\u1ea7n \u0111\u1ea7u xoay v\u00f2ng , hi\u1ec7n t\u1ea1i \u0111\u00e3 c\u00f3 2 file 0, 1 n\u00ean index ti\u1ebfp theo s\u1ebd l\u00e0 2 . Fernet repo th\u1ef1c hi\u1ec7n , staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key v\u1edbi t\u00ean file 2 . v\u00e0 primary key (1 ) s\u1ebd tr\u1edd th\u00e0nh secondary file. v\u00e0 th\u00eam m\u1edbi m\u1ed9t strage v\u1edbi t\u00ean file l\u00e0 0 Trong l\u1ea7n xoay ti\u1ebfp theo, index l\u1edbn nh\u1ea5t s\u1ebd l\u00e0 3 , staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key v\u1edbi file 3 , primary key ( 2 ) s\u1ebd tr\u1edf th\u00e0nh secondary ( 2 ) 2.3.5.Token Generation Workflow \u00b6 2.3.6.Token Validation Workflow \u00b6 G\u1eedi y\u00eau c\u1ea7u x\u00e1c th\u1ef1c token v\u1edbi ph\u01b0\u01a1ng th\u1ee9c: GET v3/auth/tokens Kh\u00f4i ph\u1ee5c l\u1ea1i padding, tr\u1ea3 l\u1ea1i token v\u1edbi padding ch\u00ednh x\u00e1c Decrypt s\u1eed d\u1ee5ng Fernet Keys \u0111\u1ec3 thu l\u1ea1i token payload X\u00e1c \u0111\u1ecbnh phi\u00ean b\u1ea3n c\u1ee7a token payload. (Unscoped token: 1, token trong t\u1ea7m v\u1ef1c domain: 1, token trong t\u1ea7m v\u1ef1c project: 2 ) T\u00e1ch c\u00e1c tr\u01b0\u1eddng c\u1ee7a payload \u0111\u1ec3 ch\u1ee9ng th\u1ef1c. V\u00ed d\u1ee5 v\u1edbi token trong t\u1ea7m v\u1ef1c project g\u1ed3m c\u00e1c tr\u01b0\u1eddng sau: user id, project id, method, expiry, audit id Ki\u1ec3m tra xem token \u0111\u00e3 h\u1ebft h\u1ea1n ch\u01b0a. N\u1ebfu th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i l\u1edbn h\u01a1n so v\u1edbi th\u1eddi \u0111i\u1ec3m h\u1ebft h\u1ea1n th\u00ec tr\u1ea3 v\u1ec1 th\u00f4ng b\u00e1o \"Token not found\". N\u1ebfu token ch\u01b0a h\u1ebft h\u1ea1n th\u00ec chuy\u1ec3n sang b\u01b0\u1edbc ti\u1ebfp theo Ki\u1ec3m tra xem token \u0111\u00e3 b\u1ecb thu h\u1ed3i ch\u01b0a. N\u1ebfu token \u0111\u00e3 b\u1ecb thu h\u1ed3i (t\u01b0\u01a1ng \u1ee9ng v\u1edbi 1 s\u1ef1 ki\u1ec7n thu h\u1ed3i trong b\u1ea3ng revocation_event c\u1ee7a database keystone) th\u00ec tr\u1ea3 v\u1ec1 th\u00f4ng b\u00e1o \"Token not found\". N\u1ebfu ch\u01b0a b\u1ecb thu h\u1ed3i th\u00ec tr\u1ea3 l\u1ea1i token (th\u00f4ng \u0111i\u1ec7p ph\u1ea3n h\u1ed3i th\u00e0nh c\u00f4ng HTTP/1.1 200 OK ) 3. Tham kh\u1ea3o th\u00eam \u00b6 [1] : https://developer.ibm.com/opentech/2015/11/11/deep-dive-keystone-fernet-tokens/","title":"T\u00ecm hi\u1ec3u Token trong Openstack"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#tim_hieu_token_trong_openstack","text":"","title":"T\u00ecm hi\u1ec3u Token trong Openstack"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#1_co_ban_ve_keystone_token","text":"Token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Keystone \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 \u1ee7y quy\u1ec1n cho ph\u00e9p c\u00e1c t\u01b0\u01a1ng t\u00e1c c\u1ee7a ng\u01b0\u1eddi d\u00f9ng t\u1edbi c\u00e1c API endpoint. Token c\u00f3 nhi\u1ec1u lo\u1ea1i \u0111\u1ea1i di\u1ec7n cho nhi\u1ec1u ki\u1ec3u x\u00e1c th\u1ef1c v\u00e0 nh\u1eadn d\u1ea1ng . C\u00f3 r\u1ea5t nhi\u1ec1u token provider m\u1ed7i provider c\u00f3 \u0111\u1eb7c t\u00ednh rieeng cho qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n Token c\u00f3 th\u1ec3 d\u00f9ng \u0111\u1ec3 th\u1ef1c hi\u1ec7n \u1ee7y quy\u1ec1n tr\u00ean nhi\u1ec1u ph\u1ea1m vi kh\u00e1c nhau . Ng\u01b0\u1eddi d\u00f9ng s\u1ebd c\u00f3 m\u1ed7i \u0111\u1eb7c quy\u1ec1n ri\u00eang b\u1edfi c\u00e1c role, tr\u00ean c\u00e1c project v\u00e0 domain . M\u1ed7i ph\u1ea1m vi s\u1ebd \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn c\u00e1c service n\u1eb1m trong ph\u1ea1m vi \u0111\u00f3 . Unscoped token kh\u00f4ng t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn service , catalog, project, domain . Khi s\u1eed d\u1ee5ng unscoped token th\u00ec ch\u1ec9 mang t\u00ednh \u0111\u1ea1ng danh, kh\u00f4ng \u0111\u01b0\u1ee3c t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c compoment kh\u00e1c Project-scoped token : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 c\u00f3 th\u1ec3 t\u00e1c \u0111\u1ed9ng t\u1edbi c\u00e1c serivce kh\u00e1c. Ch\u00fang ch\u01b0a c\u00e1c catalog , role v\u00e0 c\u00e1c th\u00f4ng tin c\u1ee7a project v\u00e0 \u0111\u01b0\u1ee3c \u1ee7y quy\u1ec1n Domain-scoped token : \u0111\u01b0\u1ee3c s\u1ee7 d\u1ee5ng \u00edt, c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c t\u1edbi c\u00e1c \u0111\u1ed1i t\u01b0owngj d\u01b0\u1edbi domain,","title":"1. C\u01a1 b\u1ea3n v\u1ec1 Keystone Token"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#2_token_provider","text":"Token provider trong keystone \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh t\u1ea1i /etc/keystone/keystone.conf . Hi\u1ec7n t\u1ea1i c\u00f3 4 ki\u1ec3u token provider h\u1ed7 tr\u1ee3 : UUID fernet , PKI v\u00e0 PKIZ","title":"2. Token Provider"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#21_uuid","text":"K\u00edch th\u01b0\u1edbc nh\u1ecf g\u1ecdn, l\u00e0 chu\u1ed7i ng\u1eabu nhi\u00ean 32 k\u00fd t\u1ef1 T\u1ea1o n\u00ean t\u1eeb c\u00e1c ch\u1ec9 s\u1ed1 h\u1ec7 th\u1eadp l\u1ee5c ph\u00e2n Tokens URL th\u00e2n thi\u1ec7n v\u00e0 an to\u00e0n khi g\u1eedi \u0111i trong m\u00f4i tr\u01b0\u1eddng non-binary. L\u01b0u tr\u1eef trong h\u1ec7 th\u1ed1ng backend (nh\u01b0 database) b\u1ec1 v\u1eefng \u0111\u1ec3 s\u1eb5n s\u00e0ng cho m\u1ee5c \u0111\u00edch x\u00e1c th\u1ef1c UUID kh\u00f4ng b\u1ecb x\u00f3a trong h\u1ec7 th\u1ed1ng l\u01b0u tr\u1eef nh\u01b0ng s\u1ebd b\u1ecb \u0111\u00e1nh d\u1ea5u l\u00e0 \"revoked\" (b\u1ecb thu h\u1ed3i) th\u00f4ng qua DELETE request v\u1edbi token ID t\u01b0\u01a1ng \u1ee9ng. UUID kh\u00f4ng mang th\u00f4ng tin g\u00ec v\u1ec1 User. Keystone ph\u1ea3i th\u1ef1c hi\u1ec7n vi\u1ec7c x\u00e1c th\u1ef1c token v\u00e0 l\u01b0u tr\u1eef, v\u1edbi k\u00edch th\u01b0\u1edbc c\u1ee7a h\u1ec7 th\u1ed1ng m\u1edf r\u1ed9ng h\u01a1n th\u00ec hi\u1ec7u xu\u1ea5t c\u1ee7a Keystone s\u1ebd b\u1ecb \u1ea3nh h\u01b0\u1edfng. Workflow t\u1ea1o UUID token di\u1ec5n ra nh\u01b0 sau: User request t\u1edbi keystone t\u1ea1o token v\u1edbi c\u00e1c th\u00f4ng tin: user name, password, project name Ch\u1ee9ng th\u1ef1c user, l\u1ea5y User ID t\u1eeb backend LDAP (d\u1ecbch v\u1ee5 Identity) Ch\u1ee9ng th\u1ef1c project, thu th\u1eadp th\u00f4ng tin Project ID v\u00e0 Domain ID t\u1eeb Backend SQL (d\u1ecbch v\u1ee5 Resources) L\u1ea5y ra Roles t\u1eeb Backend tr\u00ean Project ho\u1eb7c Domain t\u01b0\u01a1ng \u1ee9ng tr\u1ea3 v\u1ec1 cho user, n\u1ebfu user kh\u00f4ng c\u00f3 b\u1ea5t k\u1ef3 roles n\u00e0o th\u00ec tr\u1ea3 v\u1ec1 Failure(d\u1ecbch v\u1ee5 Assignment) Thu th\u1eadp c\u00e1c Services v\u00e0 c\u00e1c Endpoints c\u1ee7a c\u00e1c service \u0111\u00f3 (d\u1ecbch v\u1ee5 Catalog) T\u1ed5ng h\u1ee3p c\u00e1c th\u00f4ng tin v\u1ec1 Identity, Resources, Assignment, Catalog \u1edf tr\u00ean \u0111\u01b0a v\u00e0o Token payload, t\u1ea1o ra token s\u1eed d\u1ee5ng h\u00e0m uuid.uuid4().hex L\u01b0u th\u00f4ng tin c\u1ee7a Token v\u00e0 SQL/KVS backend v\u1edbi c\u00e1c th\u00f4ng tin: TokenID, Expiration, Valid, UserID, Extra","title":"2.1 : UUID"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#22_pki_va_pkiz_token","text":"PKI token ch\u1ee9a to\u00e0n b\u1ed9 th\u00f4ng tin x\u00e1c th\u1ef1c nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb Keystone. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 token ch\u1ee9a l\u01b0\u1ee3ng l\u1edbn c\u00e1c th\u00f4ng tin: nh\u01b0 l\u00e0 th\u1eddi gian c\u1ea5p ph\u00e1t, th\u1eddi gian h\u1ebft h\u1ea1n, \u0111\u1ecbnh danh user, th\u00f4ng tin project, domain v\u00e0 role cho user, catalog d\u1ecbch v\u1ee5, v\u00e0 nhi\u1ec1u th\u00f4ng tin kh\u00e1c. Ch\u00ednh v\u00ec mang qu\u00e1 nhi\u1ec1u th\u00f4ng tin n\u00ean n\u00f3 l\u1ea1i l\u00e0 \u0111i\u1ec3m y\u1ebfu c\u1ee7a lo\u1ea1i token n\u00e0y v\u00ec khi h\u1ec7 th\u1ed1ng \u0111\u01b0\u1ee3c m\u1edf r\u1ed9ng c\u00e1c th\u00f4ng tin user v\u00e0 catalog c\u00e0ng nhi\u1ec1u trong khi \u0111\u00f3 HTTP Header ch\u1ec9 gi\u1edbi h\u1ea1n 8KB. \u0110\u1ec3 kh\u00e1c ph\u1ee5c \u0111i\u1ec1u n\u00e0y th\u00ec Openstack c\u0169ng \u0111\u01b0a ra m\u1ed9t lo\u1ea1i token PKIZ v\u1edbi kh\u1ea3 n\u0103ng n\u00e9n token xu\u1ed1ng k\u00edch th\u01b0\u1edbc t\u1ed1i thi\u1ec3u. M\u1eb7c d\u00f9 \u0111\u00e3 \u0111\u01b0\u1ee3c n\u00e9n nh\u01b0ng PKIZ v\u1eabn b\u1ecb c\u1ed9ng \u0111\u1ed3ng Openstack \u0111\u00e1nh gi\u00e1 l\u00e0 k\u00edch th\u01b0\u1edbc qu\u00e1 l\u1edbn. \u01afu \u0111i\u1ec3m c\u1ee7a lo\u1ea1i token n\u00e0y l\u00e0 c\u00e1c OpenStack services c\u00f3 th\u1ec3 cache l\u1ea1i token n\u00e0y \u0111\u1ec3 \u0111\u01b0a ra quy\u1ebft \u0111\u1ecbnh \u1ee7y quy\u1ec1n m\u00e0 kh\u00f4ng ph\u1ea3i li\u00ean h\u1ec7 l\u1ea1i keystone n\u00ean \u0111\u00e3 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 t\u1eafc ngh\u1ebdn c\u1ed5 chai c\u1ee7a UUID token.","title":"2.2. PKI v\u00e0 PKIZ Token"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#21_qua_trinh_sinh_token_pki_va_pkiz","text":"C\u0169ng gi\u1ed1ng nh\u01b0 UUID token v\u1edbi PKI v\u00e0 PKIZ token th\u00ec User c\u1ea7n g\u1eedi c\u00e1c th\u00f4ng tin \u0111\u1ec3 Keystone x\u00e1c th\u1ef1c v\u00e0 c\u1ea5p token, nh\u01b0ng c\u00f3 m\u1ed9t \u0111i\u1ec3m kh\u00e1c l\u00e0 lo\u1ea1i token n\u00e0y s\u1eed d\u1ee5ng h\u1ec7 m\u1eadt m\u00e3 kh\u00f3a b\u1ea5t \u0111\u1ed1i x\u1ee9ng t\u1ee9c l\u00e0 d\u00f9ng kh\u00f3a Private Key c\u1ee7a keystone \u0111\u1ec3 m\u00e3 h\u00f3a Payload token, khi user s\u1eed d\u1ee5ng token n\u00e0y th\u00ec c\u00e1c service trong Openstack s\u1ebd s\u1eed d\u1ee5ng Public Key \u0111\u1ec3 gi\u1ea3i m\u00e3 v\u00e0 l\u1ea5y ra c\u00e1c th\u00f4ng tin. C\u00e1c b\u01b0\u1edbc kh\u1edfi t\u1ea1o token PKI \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n r\u1ea5t r\u00f5 \u1edf h\u00ecnh \u1ea3nh tr\u00ean.","title":"2.1. Qu\u00e1 tr\u00ecnh sinh token PKI v\u00e0 PKIZ"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#22_qua_trinh_validate_va_thu_hoi_pki_va_pkiz_token","text":"Qu\u00e1 tr\u00ecnh n\u00e0y ho\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 v\u01a1i UUID token. Qu\u00e1 tr\u00ecnh thu h\u1ed3i c\u0169ng ho\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 UUID token.","title":"2.2. Qu\u00e1 tr\u00ecnh validate v\u00e0 thu h\u1ed3i PKI v\u00e0 PKIZ token"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#23_fernet","text":"","title":"2.3 : Fernet"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#231_co_ban_ve_fernet","text":"Fernet token \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ea7u ti\u1ec1n t\u1ea1i Openstack Kilo . Kh\u00f4ng gi\u1ed1ng nh\u01b0 c\u00e1c lo\u1ea1i token kh\u00e1c fernet kh\u00f4ng y\u00eau c\u1ea7u s\u1eed d\u1ee5ng backend Fernet token ch\u01b0a m\u1ed9t s\u1ed1 l\u01b0\u1ee3ng d\u1eef li\u1ec7u nh\u1eadn d\u1ea1ng v\u00e0 \u1ee7y quy\u1ec1n trong MessagePacked . Payload s\u1ebd \u0111\u00f3ng g\u00f3i c\u00e1c Fernet token . D\u1eef li\u1ec7u trong Fernet token \u0111\u01b0\u1ee3c b\u1ea3o v\u1ec7 b\u1edfi c\u00e1c thu\u1eadt to\u00e1n m\u00e3 h\u00f3a \u0111\u1ed1i x\u1ee9ng ho\u1eb7c 2 fernet key","title":"2.3.1 . C\u01a1 b\u1ea3n v\u1ec1 fernet"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#232_fernet_key_la_gi","text":"Fernet key \u0111\u01b0\u1ee3c d\u00f9ng trong vi\u1ec7c m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 c\u00e1c Fernet token. Trong m\u1ed7i kernet key bao g\u1ed3m 2 kh\u00f3a h\u1ecf h\u01a1n : a 128-bit AES256 encryption key v\u00e0 . 128-bit SHA256 HMAC signing key . Fernet key \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i key respo m\u00e0 payload c\u00f3 th\u1ec3 chuy\u1ec3n \u0111\u1ebfn th\u01b0 vi\u1ec7n x\u1eed l\u00fd m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 m\u00e3 token Fernet s\u1ebd \u0111\u1ebfn th\u01b0 m\u1ee5c ch\u1ee9a c\u00e1c key, th\u1ef1c hi\u1ec7n t\u1ea5t c\u1ea3 m\u00e3 h\u00f3a b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng kh\u00f3a \u0111\u1ea7u ti\u00ean trong danh s\u00e1ch v\u00e0 c\u1ed1 g\u1eafng gi\u1ea3i m\u00e3 b\u1eb1ng t\u1ea5t c\u1ea3 c\u00e1c kh\u00f3a t\u1eeb danh s\u00e1ch \u0111\u00f3. Keystone fernet token tr\u00f4ng gi\u1ed1ng nh\u01b0 sau: gAAAAABWHXT73mGHg90PE6rmS-6aeYYvdErvO1RCWbDBrM5JV6L-eGEkz9cv8598DWWF5LZH5buzYM6PmUk3w9PHd4j6zs9L0_nvqZAGOrA4gLjhE10MLk00_Qy-IIPMQ6kxjsphYVLP1uBUNyh-s4hq76-KGNUqAcYgLyN8DtgoifDseSZKNl8","title":"2.3.2 . Fernet key l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#233_fernet_key_repo","text":"Key repo l\u00e0 y\u00eau c\u1ea7u t\u1ed1i thi\u1ec3u \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t fernet token. Nh\u1eefng key \u0111\u01b0\u1ee3c l\u01b0u trong repo nh\u0103m m\u1ee5c \u0111\u00edch m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 trong qu\u00e1 tr\u00ecnh \u0111\u00f3ng g\u00f3i fernet token .M\u1ed7i key trong repo c\u00f3 th\u1ec3 c\u00f3 m\u1ed9t trong ba tr\u1ea1ng th\u00e1i. Tr\u1ea1ng th\u00e1i c\u1ee7a kh\u00f3a x\u00e1c \u0111\u1ecbnh c\u00e1ch keystone s\u1eed d\u1ee5ng fernet token. C\u00e1c lo\u1ea1i kh\u00e1c nhau nh\u01b0 sau: Lo\u1ea1i 1 - Primary Key: s\u1eed d\u1ee5ng cho c\u1ea3 2 m\u1ee5c \u0111\u00edch m\u00e3 h\u00f3a v\u00e0 gi\u1ea3i m\u00e3 fernet tokens. C\u00e1c key \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u00ean theo s\u1ed1 nguy\u00ean b\u1eaft \u0111\u1ea7u t\u1eeb 0. Trong \u0111\u00f3 Primary Key c\u00f3 ch\u1ec9 s\u1ed1 cao nh\u1ea5t. Lo\u1ea1i 2 - Secondary Key: ch\u1ec9 d\u00f9ng \u0111\u1ec3 gi\u1ea3i m\u00e3. -> Lowest Index < Secondary Key Index < Highest Index Lo\u1ea1i 3 - Stagged Key: t\u01b0\u01a1ng t\u1ef1 nh\u01b0 secondary key trong tr\u01b0\u1eddng h\u1ee3p n\u00f3 s\u1eed d\u1ee5ng \u0111\u1ec3 gi\u1ea3i m\u00e3 token. Tuy nhi\u00ean n\u00f3 s\u1ebd tr\u1edf th\u00e0nh Primary Key trong l\u1ea7n lu\u00e2n chuy\u1ec3n kh\u00f3a ti\u1ebfp theo. Stagged Key c\u00f3 ch\u1ec9 s\u1ed1 0 -- Fernet Keys \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i /etc/keystone/fernet-keys/","title":"2.3.3 . Fernet key repo"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#234_fernet_key_rotation","text":"B\u01b0\u1edbc \u0111\u1ea7u ch\u01b0a c\u00f3 key repo s\u1ebd kh\u1edfi t\u1ea1o m\u1ed9t key repo b\u1eb1ng keystone-manager \u0111\u1ec3 t\u1ea1o 2 kh\u00f3a trong repo. Khi 2 file \u0111\u01b0\u1ee3c t\u1ea1o th\u00ec s\u1ebd c\u00f3 file t\u00ean 1 s\u1ebd l\u00e0 primary key , v\u00e0 file 0 s\u1ebd l\u00e0 staged key v\u00e0 kh\u00f4ng c\u00f3 m\u1ed9t secondary key Xem \u0111\u00e2y l\u00e0 l\u1ea7n \u0111\u1ea7u xoay v\u00f2ng , hi\u1ec7n t\u1ea1i \u0111\u00e3 c\u00f3 2 file 0, 1 n\u00ean index ti\u1ebfp theo s\u1ebd l\u00e0 2 . Fernet repo th\u1ef1c hi\u1ec7n , staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key v\u1edbi t\u00ean file 2 . v\u00e0 primary key (1 ) s\u1ebd tr\u1edd th\u00e0nh secondary file. v\u00e0 th\u00eam m\u1edbi m\u1ed9t strage v\u1edbi t\u00ean file l\u00e0 0 Trong l\u1ea7n xoay ti\u1ebfp theo, index l\u1edbn nh\u1ea5t s\u1ebd l\u00e0 3 , staged key ( 0 ) s\u1ebd tr\u1edf th\u00e0nh primary key v\u1edbi file 3 , primary key ( 2 ) s\u1ebd tr\u1edf th\u00e0nh secondary ( 2 )","title":"2.3.4 :Fernet Key Rotation"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#235token_generation_workflow","text":"","title":"2.3.5.Token Generation Workflow"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#236token_validation_workflow","text":"G\u1eedi y\u00eau c\u1ea7u x\u00e1c th\u1ef1c token v\u1edbi ph\u01b0\u01a1ng th\u1ee9c: GET v3/auth/tokens Kh\u00f4i ph\u1ee5c l\u1ea1i padding, tr\u1ea3 l\u1ea1i token v\u1edbi padding ch\u00ednh x\u00e1c Decrypt s\u1eed d\u1ee5ng Fernet Keys \u0111\u1ec3 thu l\u1ea1i token payload X\u00e1c \u0111\u1ecbnh phi\u00ean b\u1ea3n c\u1ee7a token payload. (Unscoped token: 1, token trong t\u1ea7m v\u1ef1c domain: 1, token trong t\u1ea7m v\u1ef1c project: 2 ) T\u00e1ch c\u00e1c tr\u01b0\u1eddng c\u1ee7a payload \u0111\u1ec3 ch\u1ee9ng th\u1ef1c. V\u00ed d\u1ee5 v\u1edbi token trong t\u1ea7m v\u1ef1c project g\u1ed3m c\u00e1c tr\u01b0\u1eddng sau: user id, project id, method, expiry, audit id Ki\u1ec3m tra xem token \u0111\u00e3 h\u1ebft h\u1ea1n ch\u01b0a. N\u1ebfu th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i l\u1edbn h\u01a1n so v\u1edbi th\u1eddi \u0111i\u1ec3m h\u1ebft h\u1ea1n th\u00ec tr\u1ea3 v\u1ec1 th\u00f4ng b\u00e1o \"Token not found\". N\u1ebfu token ch\u01b0a h\u1ebft h\u1ea1n th\u00ec chuy\u1ec3n sang b\u01b0\u1edbc ti\u1ebfp theo Ki\u1ec3m tra xem token \u0111\u00e3 b\u1ecb thu h\u1ed3i ch\u01b0a. N\u1ebfu token \u0111\u00e3 b\u1ecb thu h\u1ed3i (t\u01b0\u01a1ng \u1ee9ng v\u1edbi 1 s\u1ef1 ki\u1ec7n thu h\u1ed3i trong b\u1ea3ng revocation_event c\u1ee7a database keystone) th\u00ec tr\u1ea3 v\u1ec1 th\u00f4ng b\u00e1o \"Token not found\". N\u1ebfu ch\u01b0a b\u1ecb thu h\u1ed3i th\u00ec tr\u1ea3 l\u1ea1i token (th\u00f4ng \u0111i\u1ec7p ph\u1ea3n h\u1ed3i th\u00e0nh c\u00f4ng HTTP/1.1 200 OK )","title":"2.3.6.Token Validation Workflow"},{"location":"Openstack_Research/Keystone/7. Token-Keystone/#3_tham_khao_them","text":"[1] : https://developer.ibm.com/opentech/2015/11/11/deep-dive-keystone-fernet-tokens/","title":"3. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/","text":"Openstack networking - Neutron \u00b6 1. Openstack networking - Neutron \u00b6 Trong Openstack, Networking Service cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng API cho ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 c\u00e0i \u0111\u1eb7t v\u00e0 \u0111\u1ecbnh ngh\u0129a c\u00e1c network. Code-name c\u1ee7a Openstack Networking l\u00e0 neutron. Openstack networking service l\u00e0m nhi\u1ec7m v\u1ee5 t\u1ea1o v\u00e0 qu\u1ea3n l\u00fd h\u1ea1 t\u1ea7ng m\u1ea1ng \u1ea3o, bao g\u1ed3m network, switch, subnet, router Openstack networking bao g\u1ed3m : neutron-server, database storage, plug-in agent, cung c\u1ea5p m\u1ed9t s\u1ed1 service kh\u00e1c \u0111\u1ec3 giao ti\u1ebfp v\u1edbi Linux, external devices, or SDN controllers. Openstack l\u00e0 ho\u00e0n to\u00e0n \u0111\u1ed9c l\u1eadp v\u00e0 c\u00f3 tri\u1ec3n khai tr\u00ean 1 host \u0111\u1ecdc l\u1eadp Openstack Networking t\u00edch h\u1ee3p v\u1edbi m\u1ed9t s\u1ed1 copoment kh\u00e1c : Openstack Indentify : \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 \u1ee7y quy\u1ec1n cho c\u00e1c API Request Openstack Compute : li\u00ean h\u1ec7 v\u1edbi compute \u0111\u1ec3 g\u1eafn m\u1ed7i VNIC \u0111\u1ebfn t\u1eebng m\u00e1y \u1ea3o ri\u00eang Openstack dashboard : ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o v\u00e0 qu\u1ea3n l\u00fd c\u00e1c network Openstack networking bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n: API server: OpenStack Networking API bao g\u1ed3m h\u1ed7 tr\u1ee3 Layer 2 networking v\u00e0 IP address management (IPAM) , c\u0169ng nh\u01b0 1 ph\u1ea7n m\u1edf r\u1ed9ng cho Layer 3 router cho ph\u00e9p routing gi\u1eefa c\u00e1c Layer 2 networking . OpenStack Networking bao g\u1ed3m 1 danh s\u00e1ch c\u00e1c plug-in cho ph\u00e9p t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c c\u00f4ng ngh\u1ec7 m\u1ea1ng m\u00e3 ngu\u1ed3n m\u1edf kh\u00e1c nhau, bao g\u1ed3m routers, virtual switches, v\u00e0 software-defined networking (SDN) controllers. OpenStack Networking plug-in v\u00e0 agents: Plugs v\u00e0 unplugs ports, t\u1ea1o network ho\u1eb7c subnets, v\u00e0 cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP. Plug-in v\u00e0 agents \u0111\u01b0\u1ee3c ch\u1ecdn kh\u00e1c nhau t\u00f9y thu\u1ed9c v\u00e0 nh\u00e0 cung c\u1ea5p v\u00e0 c\u00f4ng ngh\u1ec7 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong cloud c\u1ee5 th\u1ec3. \u0110i\u1ec1u quan tr\u1ecdng c\u1ea7n \u0111\u1ec1 c\u1eadp l\u00e0 ch\u1ec9 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng 1 plug-in trong 1 th\u1eddi \u0111i\u1ec3m. Messaging queue: C\u1ea5p nh\u1eadn v\u00e0 \u0111\u1ecbnh tuy\u1ebfn c\u00e1c y\u00eau c\u1ea7u RPC gi\u1eefa c\u00e1c agents \u0111\u1ec3 ho\u00e0n th\u00e0nh c\u00e1c ho\u1ea1t \u0111\u1ed9ng API. Message queue l\u00e0 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Ml2 plug-in cho RPC gi\u1eefa neutron server v\u00e0 neutron agents ch\u1ea1y tr\u00ean m\u1ed7i hypervisor, ML2 mechanism drivers cho Open vSwitch v\u00e0 Linux bridge . Network agent : x\u1eed l\u00fd c\u00e1c t\u00e1c v\u1ee5 kh\u00e1c nhau \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 tri\u1ec3n khai m\u1ea1ng \u1ea3o. C\u00e1c agent bao g\u1ed3m : neutron-dhcp-agent, neutron-l3-agent, neutron-metering-agent, and neutron-lbaas-agent, among others 2. OpenStack Networking integrates \u00b6 Openstack networking \u0111\u01b0\u1ee3c th\u00edch h\u1ee3p v\u1edbi nhi\u1ec1u th\u00e0nh ph\u1ea7n kh\u00e1c \u0111\u1ec3 th\u00e0nh m\u1ed9t h\u1ec7 th\u1ed1ng ho\u00e0n ch\u1ec9nh, bao g\u1ed3m : Openstack Indentify : d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 c\u1ea5p quy\u1ec1n \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi API Openstack compute : \u0111\u1ec3 plug c\u00e1c NIC c\u1ee7a m\u00e1y \u1ea3o v\u00e0o m\u1ed9t m\u1ea1ng \u1ea3o Openstack Dashboard : s\u1eed d\u1ee5ng web-based \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a m\u1ed9t m\u1ea1ng \u1ea3o 3. C\u00e1c lo\u1ea1i network trong Openstack Networking \u00b6 Trong Openstack c\u00f3 3 lo\u1ea1i network g\u1ed3m : provider, Routed provider networks v\u00e0 self-service 2.1 : Provider Network \u00b6 Provider network cung c\u1ea5p m\u1ed9t network layer 2 t\u1edbi c\u00e1c instance v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a DHCP v\u00e0 metadata. M\u1ea1ng n\u00e0y k\u1ebft n\u1ed1i ho\u1eb7c map t\u1edbi m\u1ed9t network layer 2 c\u00f3 trong datacenter., th\u01b0\u1eddng k\u1ebft h\u1ee3p v\u1edbi 802.1Q ( VLAN ) Provider network th\u01b0\u1eddng cung c\u1ea5p s\u1ef1 \u0111\u01a1n gi\u1ea3n, hi\u1ec7u n\u0103ng v\u00e0 \u0111\u1ed9 tin c\u1eady. Ch\u1ec9 c\u00f3 admin m\u1edbi c\u00f3 th\u1ec3 qu\u1ea3n l\u00fd c\u00e1c m\u1ea1ng n\u00e0y v\u00ec n\u00f3 y\u00eau c\u1ea7u c\u1ea5u h\u00ecnh h\u1ea1ng t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd. Provider network ch\u1ec9 c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c frame layer-2 cho c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn instance, , do \u0111\u00f3 thi\u1ebfu ch\u1ee9c r\u0103ng \u0111\u1ecbnh tuy\u1ebfn v\u00e0 IP floating N\u00f3i chung, c\u00e1c th\u00e0nh ph\u1ea7n trong Openstack Networking c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c ho\u1ea1t \u0111\u1ed9ng layer-3 t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn hi\u1ec7u n\u0103ng v\u00e0 \u0111\u1ed9 tin t\u01b0\u1edfng, provider network gi\u00fap chuy\u1ec3n c\u00e1c ho\u1ea1t \u0111\u1ed9ng layer-3 sang h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd 2.2. Routed Network \u00b6 Routed provider networks cung c\u1ea5p k\u1ebft n\u1ed1i \u1edf layer 3 cho c\u00e1c m\u00e1y \u1ea3o. C\u00e1c network n\u00e0y map v\u1edbi nh\u1eefng networks layer 3 \u0111\u00e3 t\u1ed3n t\u1ea1i. C\u1ee5 th\u1ec3 h\u01a1n , m\u1ea1ng n\u00e0y map t\u1edbi c\u00e1c c\u00e1c m\u1ea1ng layer 2 \u0111\u00e3 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh l\u00e0m provider network . M\u1ed7i router c\u00f3 m\u1ed9t gateway \u0111\u1ec3 l\u00e0m nhi\u1ec7m v\u1ee5 \u0111\u1ecbnh tuy\u1ebfn . . Routed provider networks t\u1ea5t nhi\u00ean s\u1ebd c\u00f3 hi\u1ec7u su\u1ea5t th\u1ea5p h\u01a1n so v\u1edbi provider networks. 2.3. Self-service network ( tenant ) \u00b6 Self-service network cho ph\u00e9p c\u00e1c project qu\u1ea3n l\u00fd c\u00e1c m\u1ea1ng m\u00e0 kh\u00f4ng c\u1ea7n quy\u1ec1n admin. Nh\u1eefng m\u1ea1ng n\u00e0y ho\u00e0n to\u00e0n l\u00e0 m\u1ea1ng \u1ea3o v\u00e0 y\u00eau c\u1ea7u m\u1ed9t m\u1ea1ng \u1ea3o ,sau \u0111\u00f3 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network v\u00e0 m\u1ea1ng ngo\u00e0i ( internet ). Self-service th\u01b0\u1eddng s\u1eed d\u1ee5ng DHCP v\u00e0 meta cho c\u00e1c instance Mong nhi\u1ec1u tr\u01b0\u1eddng h\u1ee3p, self-service network s\u1eed d\u1ee5ng overload protocol b\u1eb1ng VXLAN, GRE v\u00ec ch\u00fang c\u00f3 th\u1ec3 h\u1ed7 tr\u1ee3 nhi\u1ec1u m\u1ea1ng h\u01a1n layer-2 khi s\u1eed d\u1ee5ng VLAN ( 802.1q) IPv4 trong self-service th\u01b0\u1eddng s\u1eed d\u1ee5ng IP Private ( RFC 1918 ) v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network b\u1eb1ng Source NAT s\u1eed d\u1ee5ng router \u1ea3o. Floating IP address cho ph\u00e9p truy c\u1eadp instance t\u1eeb provider network b\u1eb1ng Destination NAT s\u1eed d\u1ee5ng Router \u1ea3o IPv6 trong self-service s\u1eed d\u1ee5ng IP Public v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network s\u1eed d\u1ee5ng c\u00e1c static route th\u00f4ng qua c\u00e1c Router \u1ea3o Trong openstack networking t\u00edch h\u1ee3p m\u1ed9t router layer-3 th\u01b0\u1eddng n\u1eb1m \u00edt nh\u1ea5t tr\u00ean m\u1ed9t node network. Tr\u00e1i ng\u01b0\u1ee3c v\u1edbi provider network k\u1ebft n\u1ed1i t\u1edbi c\u00e1c instance th\u00f4ng qua h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd layer-2 Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u1ea1o c\u00e1c selt-network theo t\u1eebng project. B\u1edfi v\u1eady c\u00e1c k\u1ebft n\u1ed1i s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c chia s\u1ebb v\u1edbi c\u00e1c project kh\u00e1c. Trong Openstack h\u1ed7 tr\u1ee3 c\u00e1c ki\u1ec3u c\u00f4 l\u1eadp v\u00e0 overplay sau : - Flat : t\u1ea5t c\u1ea3 instance k\u1ebft n\u1ed1i v\u00e0o m\u1ed9t network chung. Kh\u00f4ng \u0111\u01b0\u1ee3c tag VLAN_ID v\u00e0o packet ho\u1eb7c ph\u00e2n chia v\u00f9ng m\u1ea1ng - VLAN : cho ph\u00e9p kh\u1edfi t\u1ea1o nhi\u1ec1u provider ho\u1eb7c tenant network2 s\u1eed d\u1ee5ng VLAN (801.2q) , t\u01b0\u01a1ng \u1ee9ng v\u1edbi VLAN \u0111ang c\u00f3 s\u1eb5n tr\u00ean m\u1ea1ng v\u1eadt l\u00fd. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p instance k\u1ebft n\u1ed1i t\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c trong m\u1ea1ng - GRE and VXLAN : l\u00e0 m\u1ed7i giao th\u1ee9c \u0111\u00f3ng g\u00f3i packet , cho ph\u00e9p t\u1ea1o ra m\u1ea1ng overlay \u0111\u1ec3 t\u1ea1o k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c instance. M\u1ed9t router \u1ea3o \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1eeb tenant network ra external network. M\u1ed9t router provider s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1eeb external network v\u00e0o c\u00e1c instance trong tenant network s\u1eed d\u1ee5ng floating IP 2.3 . M\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m b\u1ed5 sung \u00b6 Subnet : m\u00e0 m\u1ed9t block c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng cho host v\u00e0 c\u00e1c \u0111\u1ecba ch\u1ec9 li\u00ean quan . Subnet \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 g\u1eafn c\u00e1c \u0111\u1ecba ch\u1ec9 IP khi m\u1ed9t port \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o Subnet pool : enduser c\u00f3 th\u1ec3 t\u1ea1o c\u00e1c subnet v\u00e0 c\u00e1c \u0111\u1ecba ch\u1ec9 IP h\u1ee3p l\u00fd trong subnet \u0111\u00f3. Tuy nhi\u00ean, m\u1ea1ng tenant n\u00ean \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh c\u00e1c subnet tr\u01b0\u1edbc m\u00e0 t\u1ef1 g\u1eafn v\u00e0o c\u00e1c port S\u1eed d\u1ee5ng subnet pools s\u1ebd h\u1ea1n ch\u1ebf nh\u1eefng \u0111\u1ecba ch\u1ec9 n\u00e0o c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng b\u1eb1ng c\u00e1ch y\u00eau c\u1ea7u m\u1ecdi subnet ph\u1ea3i n\u1eb1m trong pool \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh. S\u1eed d\u1ee5ng nhi\u1ec1u subnet pool tr\u00ean m\u1ed9t subnet Ports : l\u00e0 m\u1ed9t \u0111i\u1ec3m k\u1ebft n\u1ed1i \u0111\u1ec3 g\u1eafn v\u00e0o m\u1ed9t thi\u1ebft b\u1ecb, ch\u1eb3ng h\u1ea1n t\u1eeb m\u1ed9t Virtual NIC \u0111\u1ebfn m\u1ed9t virtual network. Port c\u0169ng m\u00f4 t\u1ea3 c\u00e1c c\u1ea5u h\u00ecnh li\u00ean quan nh\u01b0 MAC v\u00e0 IP s\u1eed d\u1ee5ng tr\u00ean node \u0111\u00f3 Router : cung c\u1ea5p m\u1ed9t thi\u1ebft b\u1ecb layer-3 gi\u1ed1ng nh\u01b0 thi\u1ebft b\u1ecb \u0111\u1ecbnh tuy\u1ebfn s\u1eed d\u1ee5ng NAT gi\u1eefa sefl-service v\u00e0 provider network ho\u1eb7c gi\u1eefa c\u00e1c sefl-service network tr\u00ean nhi\u1ec1u project . Networking service s\u1eed d\u1ee5ng layer-3 agent \u0111\u1ec3 qu\u1ea3n l\u00fd router th\u00f4ng qua namespace Security Group : - Security groups cung c\u1ea5p v\u00f9ng l\u01b0u tr\u1eef cho virtual firewall rules \u0111\u1ec3 ki\u1ec3m so\u00e1t l\u01b0u l\u01b0\u1ee3ng truy c\u1eadp ingress (inbound to instance) v\u00e0 egress (outbound from instance) m\u1ea1ng \u1edf m\u1ee9c port. Security groups s\u1eed d\u1ee5ng default deny policy v\u00e0 ch\u1ec9 ch\u1ee9a c\u00e1c rules \u0111\u1ed3ng \u00fd ph\u00e9p l\u01b0u l\u01b0\u1ee3ng c\u1ee5 th\u1ec3. Firewall driver chuy\u1ec3n c\u00e1c group rule \u0111\u1ebfn c\u1ea5u h\u00ecnh c\u00f9ng c\u01a1 ch\u1ebf l\u1ecdc g\u00f3i tin nh\u01b0 iptables . - M\u1ed7i project c\u00f3 ch\u1ee9a 1 default security group m\u00e0 cho ph\u00e9p t\u00e1t c\u1ea3 l\u01b0u l\u01b0\u1ee3ng egress v\u00e0 t\u1eeb ch\u1ed1i t\u1ea5t c\u1ea3 c\u00e1c l\u01b0u l\u01b0\u1ee3ng ingress. B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i rules trong default security group. N\u00f3 b\u1ea1n launch instance m\u00e0 kh\u00f4ng c\u00f3 security group ch\u1ec9 \u0111\u1ecbnh, default security group s\u1ebd t\u1ef1 \u0111\u1ed9ng \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng cho instance \u0111\u00f3. T\u01b0\u01a1ng t\u1ef1, n\u1ebfu b\u1ea1n t\u1ea1o 1 port m\u00e0 kh\u00f4ng ch\u1ec9 \u0111\u1ecbnh security group, default security group t\u1ef1 \u0111\u1ed9ng \u0111\u01b0\u1ee3c \u00e1p cho port \u0111\u00f3. - M\u1eb7c \u0111\u1ecbnh khi m\u1ed9t g\u00f3i tin g\u1eedi \u0111\u1ebfn kh\u00f4ng g\u1ed3m tr\u01b0\u1eddng IP nh\u01b0ng default group s\u1ebd ng\u0103n ch\u1ea1n c\u00e1c b\u1ea3n tin ARP - M\u1eb7c \u0111\u1ecbnh, m\u1ecdi security groups ch\u1ee9a c\u00e1c rules th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 h\u00e0nh \u0111\u1ed9ng sau: - Cho ph\u00e9p traffic ra b\u00ean ngo\u00e0i ch\u1ec9 khi n\u00f3 s\u1eed d\u1ee5ng \u0111\u1ecba ch\u1ec9 MAC v\u00e0 IP c\u1ee7a port m\u00e1y \u1ea3o, c\u1ea3 hai \u0111\u1ecba ch\u1ec9 n\u00e0y \u0111\u01b0\u1ee3c k\u1ebft h\u1ee3p t\u1ea1i allowed-address-pairs - Cho ph\u00e9p t\u00edn hi\u1ec7u t\u00ecm ki\u1ebfm DHCP v\u00e0 g\u1eedi message request s\u1eed d\u1ee5ng MAC c\u1ee7a port cho m\u00e1y \u1ea3o v\u00e0 \u0111\u1ecba ch\u1ec9 IP ch\u01b0a x\u00e1c \u0111\u1ecbnh. - Cho ph\u00e9p tr\u1ea3 l\u1eddi c\u00e1c t\u00edn hi\u1ec7u DHCP v\u00e0 DHCPv6 t\u1eeb DHCP server \u0111\u1ec3 c\u00e1c m\u00e1y \u1ea3o c\u00f3 th\u1ec3 l\u1ea5y IP - T\u1eeb ch\u1ed1i vi\u1ec7c tr\u1ea3 l\u1eddi c\u00e1c t\u00edn hi\u1ec7u DHCP request t\u1eeb b\u00ean ngo\u00e0i \u0111\u1ec3 tr\u00e1nh vi\u1ec7c m\u00e1y \u1ea3o tr\u1edf th\u00e0nh DHCP server - Cho ph\u00e9p c\u00e1c t\u00edn hi\u1ec7u inbound/outbound ICMPv6 MLD, t\u00ecm ki\u1ebfm neighbors, c\u00e1c m\u00e1y \u1ea3o nh\u1edd v\u1eady c\u00f3 th\u1ec3 t\u00ecm ki\u1ebfm v\u00e0 gia nh\u1eadp c\u00e1c multicast group. - T\u1eeb ch\u1ed1i c\u00e1c t\u00edn hi\u1ec7u outbound ICMPv6 \u0111\u1ec3 ng\u0103n vi\u1ec7c m\u00e1y \u1ea3o tr\u1edf th\u00e0nh IPv6 router v\u00e0 forward c\u00e1c t\u00edn hi\u1ec7u cho m\u00e1y \u1ea3o kh\u00e1c. - Cho ph\u00e9p t\u00edn hi\u1ec7u outbound non-IP t\u1eeb \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a c\u00e1c port tr\u00ean m\u00e1y \u1ea3o . DHCP : - qu\u1ea3n l\u00fd c\u00e1c \u0111\u1ecba ch\u1ec9 IP cho provider v\u00e0 sefl-service network . Networking service s\u1eed d\u1ee5ng manages qdhcp namespaces v\u00e0 dnsmasq service. L3 Agent L3 agent l\u00e0 m\u1ed9t ph\u1ea7n c\u1ee7a package openstack-neutron. N\u00f3 \u0111\u01b0\u1ee3c xem nh\u01b0 router layer-3 chuy\u1ec3n h\u01b0\u1edbng l\u01b0u l\u01b0\u1ee3ng v\u00e0 cung c\u1ea5p d\u1ecbch v\u1ee5 gateway cho network l\u1edbp 2. C\u00e1c nodes ch\u1ea1y L3 agent kh\u00f4ng \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh IP tr\u1ef1c ti\u1ebfp tr\u00ean m\u1ed9t card m\u1ea1ng. Thay v\u00ec th\u1ebf, s\u1ebd c\u00f3 m\u1ed9t d\u1ea3i \u0111\u1ecba ch\u1ec9 IP t\u1eeb m\u1ea1ng ngo\u00e0i \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho OpenStack networking. C\u00e1c \u0111\u1ecba ch\u1ec9 n\u00e0y \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c routers m\u00e0 cung c\u1ea5p li\u00ean k\u1ebft gi\u1eefa m\u1ea1ng trong v\u00e0 m\u1ea1ng ngo\u00e0i. Mi\u1ec1n \u0111\u1ecba ch\u1ec9 \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn ph\u1ea3i \u0111\u1ee7 l\u1edbn \u0111\u1ec3 cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP duy nh\u1ea5t cho m\u1ed7i router khi tri\u1ec3n khai c\u0169ng nh\u01b0 m\u1ed7i floating IP g\u00e1n cho c\u00e1c m\u00e1y \u1ea3o. DHCP Agent: OpenStack Networking DHCP agent ch\u1ecbu tr\u00e1ch nhi\u1ec7m c\u1ea5p ph\u00e1t c\u00e1c \u0111\u1ecba ch\u1ec9 IP cho c\u00e1c m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean network. N\u1ebfu agent \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t v\u00e0 \u0111ang ho\u1ea1t \u0111\u1ed9ng khi m\u1ed9t subnet \u0111\u01b0\u1ee3c t\u1ea1o, subnet \u0111\u00f3 m\u1eb7c \u0111\u1ecbnh s\u1ebd \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t DHCP. Plugin Agent: Nhi\u1ec1u networking plug-ins \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho agent c\u1ee7a ch\u00fang, bao g\u1ed3m OVS v\u00e0 Linux bridge. C\u00e1c plug-in ch\u1ec9 \u0111\u1ecbnh agent ch\u1ea1y tr\u00ean c\u00e1c node \u0111ang qu\u1ea3n l\u00fd l\u01b0u l\u01b0\u1ee3ng m\u1ea1ng, bao g\u1ed3m c\u00e1c compute node, c\u0169ng nh\u01b0 c\u00e1c nodes ch\u1ea1y c\u00e1c agent 3. C\u1ea5u tr\u00fac th\u00e0nh ph\u1ea7n v\u00e0 d\u1ecbch v\u1ee5 \u00b6 3.1 Server \u00b6 Cung c\u1ea5p API, qu\u1ea3n l\u00ed database,... 3.2 Plug-ins \u00b6 Qu\u1ea3n l\u00ed agents 3.3 Agents \u00b6 Cung c\u1ea5p k\u1ebft n\u1ed1i layer 2/3 t\u1edbi m\u00e1y \u1ea3o X\u1eed l\u00fd truy\u1ec1n th\u00f4ng gi\u1eefa m\u1ea1ng \u1ea3o v\u00e0 m\u1ea1ng v\u1eadt l\u00fd. X\u1eed l\u00fd metadata, etc. Layer 2 (Ethernet and Switching) \u00b6 Linux Bridge OVS Layer 3 (IP and Routing) \u00b6 L3 DHCP Miscellaneous \u00b6 Metadata Services \u00b6 C\u00e1c d\u1ecbch v\u1ee5 Routing VPNaaS: Virtual Private Network-as-a-Service (VPNaaS), extension c\u1ee7a neutron cho VPN LBaaS: Load-Balancer-as-a-Service (LBaaS), API quy \u0111\u1ecbnh v\u00e0 c\u1ea5u h\u00ecnh n\u00ean c\u00e1c load balancers, \u0111\u01b0\u1ee3c tri\u1ec3n khai d\u1ef1a tr\u00ean HAProxy software load balancer. FWaaS: Firewall-as-a-Service (FWaaS), API th\u1eed nghi\u1ec7m cho ph\u00e9p c\u00e1c nh\u00e0 cung c\u1ea5p ki\u1ec3m th\u1eed tr\u00ean networking c\u1ee7a h\u1ecd.","title":"Openstack networking - Neutron"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#openstack_networking_-_neutron","text":"","title":"Openstack networking - Neutron"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#1_openstack_networking_-_neutron","text":"Trong Openstack, Networking Service cung c\u1ea5p cho ng\u01b0\u1eddi d\u00f9ng API cho ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 c\u00e0i \u0111\u1eb7t v\u00e0 \u0111\u1ecbnh ngh\u0129a c\u00e1c network. Code-name c\u1ee7a Openstack Networking l\u00e0 neutron. Openstack networking service l\u00e0m nhi\u1ec7m v\u1ee5 t\u1ea1o v\u00e0 qu\u1ea3n l\u00fd h\u1ea1 t\u1ea7ng m\u1ea1ng \u1ea3o, bao g\u1ed3m network, switch, subnet, router Openstack networking bao g\u1ed3m : neutron-server, database storage, plug-in agent, cung c\u1ea5p m\u1ed9t s\u1ed1 service kh\u00e1c \u0111\u1ec3 giao ti\u1ebfp v\u1edbi Linux, external devices, or SDN controllers. Openstack l\u00e0 ho\u00e0n to\u00e0n \u0111\u1ed9c l\u1eadp v\u00e0 c\u00f3 tri\u1ec3n khai tr\u00ean 1 host \u0111\u1ecdc l\u1eadp Openstack Networking t\u00edch h\u1ee3p v\u1edbi m\u1ed9t s\u1ed1 copoment kh\u00e1c : Openstack Indentify : \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 \u1ee7y quy\u1ec1n cho c\u00e1c API Request Openstack Compute : li\u00ean h\u1ec7 v\u1edbi compute \u0111\u1ec3 g\u1eafn m\u1ed7i VNIC \u0111\u1ebfn t\u1eebng m\u00e1y \u1ea3o ri\u00eang Openstack dashboard : ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o v\u00e0 qu\u1ea3n l\u00fd c\u00e1c network Openstack networking bao g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n: API server: OpenStack Networking API bao g\u1ed3m h\u1ed7 tr\u1ee3 Layer 2 networking v\u00e0 IP address management (IPAM) , c\u0169ng nh\u01b0 1 ph\u1ea7n m\u1edf r\u1ed9ng cho Layer 3 router cho ph\u00e9p routing gi\u1eefa c\u00e1c Layer 2 networking . OpenStack Networking bao g\u1ed3m 1 danh s\u00e1ch c\u00e1c plug-in cho ph\u00e9p t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c c\u00f4ng ngh\u1ec7 m\u1ea1ng m\u00e3 ngu\u1ed3n m\u1edf kh\u00e1c nhau, bao g\u1ed3m routers, virtual switches, v\u00e0 software-defined networking (SDN) controllers. OpenStack Networking plug-in v\u00e0 agents: Plugs v\u00e0 unplugs ports, t\u1ea1o network ho\u1eb7c subnets, v\u00e0 cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP. Plug-in v\u00e0 agents \u0111\u01b0\u1ee3c ch\u1ecdn kh\u00e1c nhau t\u00f9y thu\u1ed9c v\u00e0 nh\u00e0 cung c\u1ea5p v\u00e0 c\u00f4ng ngh\u1ec7 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong cloud c\u1ee5 th\u1ec3. \u0110i\u1ec1u quan tr\u1ecdng c\u1ea7n \u0111\u1ec1 c\u1eadp l\u00e0 ch\u1ec9 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng 1 plug-in trong 1 th\u1eddi \u0111i\u1ec3m. Messaging queue: C\u1ea5p nh\u1eadn v\u00e0 \u0111\u1ecbnh tuy\u1ebfn c\u00e1c y\u00eau c\u1ea7u RPC gi\u1eefa c\u00e1c agents \u0111\u1ec3 ho\u00e0n th\u00e0nh c\u00e1c ho\u1ea1t \u0111\u1ed9ng API. Message queue l\u00e0 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Ml2 plug-in cho RPC gi\u1eefa neutron server v\u00e0 neutron agents ch\u1ea1y tr\u00ean m\u1ed7i hypervisor, ML2 mechanism drivers cho Open vSwitch v\u00e0 Linux bridge . Network agent : x\u1eed l\u00fd c\u00e1c t\u00e1c v\u1ee5 kh\u00e1c nhau \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 tri\u1ec3n khai m\u1ea1ng \u1ea3o. C\u00e1c agent bao g\u1ed3m : neutron-dhcp-agent, neutron-l3-agent, neutron-metering-agent, and neutron-lbaas-agent, among others","title":"1. Openstack networking - Neutron"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#2_openstack_networking_integrates","text":"Openstack networking \u0111\u01b0\u1ee3c th\u00edch h\u1ee3p v\u1edbi nhi\u1ec1u th\u00e0nh ph\u1ea7n kh\u00e1c \u0111\u1ec3 th\u00e0nh m\u1ed9t h\u1ec7 th\u1ed1ng ho\u00e0n ch\u1ec9nh, bao g\u1ed3m : Openstack Indentify : d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 c\u1ea5p quy\u1ec1n \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi API Openstack compute : \u0111\u1ec3 plug c\u00e1c NIC c\u1ee7a m\u00e1y \u1ea3o v\u00e0o m\u1ed9t m\u1ea1ng \u1ea3o Openstack Dashboard : s\u1eed d\u1ee5ng web-based \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a m\u1ed9t m\u1ea1ng \u1ea3o","title":"2. OpenStack Networking integrates"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#3_cac_loai_network_trong_openstack_networking","text":"Trong Openstack c\u00f3 3 lo\u1ea1i network g\u1ed3m : provider, Routed provider networks v\u00e0 self-service","title":"3. C\u00e1c lo\u1ea1i network trong Openstack Networking"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#21_provider_network","text":"Provider network cung c\u1ea5p m\u1ed9t network layer 2 t\u1edbi c\u00e1c instance v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a DHCP v\u00e0 metadata. M\u1ea1ng n\u00e0y k\u1ebft n\u1ed1i ho\u1eb7c map t\u1edbi m\u1ed9t network layer 2 c\u00f3 trong datacenter., th\u01b0\u1eddng k\u1ebft h\u1ee3p v\u1edbi 802.1Q ( VLAN ) Provider network th\u01b0\u1eddng cung c\u1ea5p s\u1ef1 \u0111\u01a1n gi\u1ea3n, hi\u1ec7u n\u0103ng v\u00e0 \u0111\u1ed9 tin c\u1eady. Ch\u1ec9 c\u00f3 admin m\u1edbi c\u00f3 th\u1ec3 qu\u1ea3n l\u00fd c\u00e1c m\u1ea1ng n\u00e0y v\u00ec n\u00f3 y\u00eau c\u1ea7u c\u1ea5u h\u00ecnh h\u1ea1ng t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd. Provider network ch\u1ec9 c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c frame layer-2 cho c\u00e1c k\u1ebft n\u1ed1i \u0111\u1ebfn instance, , do \u0111\u00f3 thi\u1ebfu ch\u1ee9c r\u0103ng \u0111\u1ecbnh tuy\u1ebfn v\u00e0 IP floating N\u00f3i chung, c\u00e1c th\u00e0nh ph\u1ea7n trong Openstack Networking c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c ho\u1ea1t \u0111\u1ed9ng layer-3 t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn hi\u1ec7u n\u0103ng v\u00e0 \u0111\u1ed9 tin t\u01b0\u1edfng, provider network gi\u00fap chuy\u1ec3n c\u00e1c ho\u1ea1t \u0111\u1ed9ng layer-3 sang h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd","title":"2.1 : Provider Network"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#22_routed_network","text":"Routed provider networks cung c\u1ea5p k\u1ebft n\u1ed1i \u1edf layer 3 cho c\u00e1c m\u00e1y \u1ea3o. C\u00e1c network n\u00e0y map v\u1edbi nh\u1eefng networks layer 3 \u0111\u00e3 t\u1ed3n t\u1ea1i. C\u1ee5 th\u1ec3 h\u01a1n , m\u1ea1ng n\u00e0y map t\u1edbi c\u00e1c c\u00e1c m\u1ea1ng layer 2 \u0111\u00e3 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh l\u00e0m provider network . M\u1ed7i router c\u00f3 m\u1ed9t gateway \u0111\u1ec3 l\u00e0m nhi\u1ec7m v\u1ee5 \u0111\u1ecbnh tuy\u1ebfn . . Routed provider networks t\u1ea5t nhi\u00ean s\u1ebd c\u00f3 hi\u1ec7u su\u1ea5t th\u1ea5p h\u01a1n so v\u1edbi provider networks.","title":"2.2. Routed Network"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#23_self-service_network_tenant","text":"Self-service network cho ph\u00e9p c\u00e1c project qu\u1ea3n l\u00fd c\u00e1c m\u1ea1ng m\u00e0 kh\u00f4ng c\u1ea7n quy\u1ec1n admin. Nh\u1eefng m\u1ea1ng n\u00e0y ho\u00e0n to\u00e0n l\u00e0 m\u1ea1ng \u1ea3o v\u00e0 y\u00eau c\u1ea7u m\u1ed9t m\u1ea1ng \u1ea3o ,sau \u0111\u00f3 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network v\u00e0 m\u1ea1ng ngo\u00e0i ( internet ). Self-service th\u01b0\u1eddng s\u1eed d\u1ee5ng DHCP v\u00e0 meta cho c\u00e1c instance Mong nhi\u1ec1u tr\u01b0\u1eddng h\u1ee3p, self-service network s\u1eed d\u1ee5ng overload protocol b\u1eb1ng VXLAN, GRE v\u00ec ch\u00fang c\u00f3 th\u1ec3 h\u1ed7 tr\u1ee3 nhi\u1ec1u m\u1ea1ng h\u01a1n layer-2 khi s\u1eed d\u1ee5ng VLAN ( 802.1q) IPv4 trong self-service th\u01b0\u1eddng s\u1eed d\u1ee5ng IP Private ( RFC 1918 ) v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network b\u1eb1ng Source NAT s\u1eed d\u1ee5ng router \u1ea3o. Floating IP address cho ph\u00e9p truy c\u1eadp instance t\u1eeb provider network b\u1eb1ng Destination NAT s\u1eed d\u1ee5ng Router \u1ea3o IPv6 trong self-service s\u1eed d\u1ee5ng IP Public v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi provider network s\u1eed d\u1ee5ng c\u00e1c static route th\u00f4ng qua c\u00e1c Router \u1ea3o Trong openstack networking t\u00edch h\u1ee3p m\u1ed9t router layer-3 th\u01b0\u1eddng n\u1eb1m \u00edt nh\u1ea5t tr\u00ean m\u1ed9t node network. Tr\u00e1i ng\u01b0\u1ee3c v\u1edbi provider network k\u1ebft n\u1ed1i t\u1edbi c\u00e1c instance th\u00f4ng qua h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd layer-2 Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 t\u1ea1o c\u00e1c selt-network theo t\u1eebng project. B\u1edfi v\u1eady c\u00e1c k\u1ebft n\u1ed1i s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c chia s\u1ebb v\u1edbi c\u00e1c project kh\u00e1c. Trong Openstack h\u1ed7 tr\u1ee3 c\u00e1c ki\u1ec3u c\u00f4 l\u1eadp v\u00e0 overplay sau : - Flat : t\u1ea5t c\u1ea3 instance k\u1ebft n\u1ed1i v\u00e0o m\u1ed9t network chung. Kh\u00f4ng \u0111\u01b0\u1ee3c tag VLAN_ID v\u00e0o packet ho\u1eb7c ph\u00e2n chia v\u00f9ng m\u1ea1ng - VLAN : cho ph\u00e9p kh\u1edfi t\u1ea1o nhi\u1ec1u provider ho\u1eb7c tenant network2 s\u1eed d\u1ee5ng VLAN (801.2q) , t\u01b0\u01a1ng \u1ee9ng v\u1edbi VLAN \u0111ang c\u00f3 s\u1eb5n tr\u00ean m\u1ea1ng v\u1eadt l\u00fd. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p instance k\u1ebft n\u1ed1i t\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c trong m\u1ea1ng - GRE and VXLAN : l\u00e0 m\u1ed7i giao th\u1ee9c \u0111\u00f3ng g\u00f3i packet , cho ph\u00e9p t\u1ea1o ra m\u1ea1ng overlay \u0111\u1ec3 t\u1ea1o k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c instance. M\u1ed9t router \u1ea3o \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1eeb tenant network ra external network. M\u1ed9t router provider s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1eeb external network v\u00e0o c\u00e1c instance trong tenant network s\u1eed d\u1ee5ng floating IP","title":"2.3. Self-service network ( tenant )"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#23_mot_so_khai_niem_bo_sung","text":"Subnet : m\u00e0 m\u1ed9t block c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng cho host v\u00e0 c\u00e1c \u0111\u1ecba ch\u1ec9 li\u00ean quan . Subnet \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 g\u1eafn c\u00e1c \u0111\u1ecba ch\u1ec9 IP khi m\u1ed9t port \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o Subnet pool : enduser c\u00f3 th\u1ec3 t\u1ea1o c\u00e1c subnet v\u00e0 c\u00e1c \u0111\u1ecba ch\u1ec9 IP h\u1ee3p l\u00fd trong subnet \u0111\u00f3. Tuy nhi\u00ean, m\u1ea1ng tenant n\u00ean \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh c\u00e1c subnet tr\u01b0\u1edbc m\u00e0 t\u1ef1 g\u1eafn v\u00e0o c\u00e1c port S\u1eed d\u1ee5ng subnet pools s\u1ebd h\u1ea1n ch\u1ebf nh\u1eefng \u0111\u1ecba ch\u1ec9 n\u00e0o c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng b\u1eb1ng c\u00e1ch y\u00eau c\u1ea7u m\u1ecdi subnet ph\u1ea3i n\u1eb1m trong pool \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh. S\u1eed d\u1ee5ng nhi\u1ec1u subnet pool tr\u00ean m\u1ed9t subnet Ports : l\u00e0 m\u1ed9t \u0111i\u1ec3m k\u1ebft n\u1ed1i \u0111\u1ec3 g\u1eafn v\u00e0o m\u1ed9t thi\u1ebft b\u1ecb, ch\u1eb3ng h\u1ea1n t\u1eeb m\u1ed9t Virtual NIC \u0111\u1ebfn m\u1ed9t virtual network. Port c\u0169ng m\u00f4 t\u1ea3 c\u00e1c c\u1ea5u h\u00ecnh li\u00ean quan nh\u01b0 MAC v\u00e0 IP s\u1eed d\u1ee5ng tr\u00ean node \u0111\u00f3 Router : cung c\u1ea5p m\u1ed9t thi\u1ebft b\u1ecb layer-3 gi\u1ed1ng nh\u01b0 thi\u1ebft b\u1ecb \u0111\u1ecbnh tuy\u1ebfn s\u1eed d\u1ee5ng NAT gi\u1eefa sefl-service v\u00e0 provider network ho\u1eb7c gi\u1eefa c\u00e1c sefl-service network tr\u00ean nhi\u1ec1u project . Networking service s\u1eed d\u1ee5ng layer-3 agent \u0111\u1ec3 qu\u1ea3n l\u00fd router th\u00f4ng qua namespace Security Group : - Security groups cung c\u1ea5p v\u00f9ng l\u01b0u tr\u1eef cho virtual firewall rules \u0111\u1ec3 ki\u1ec3m so\u00e1t l\u01b0u l\u01b0\u1ee3ng truy c\u1eadp ingress (inbound to instance) v\u00e0 egress (outbound from instance) m\u1ea1ng \u1edf m\u1ee9c port. Security groups s\u1eed d\u1ee5ng default deny policy v\u00e0 ch\u1ec9 ch\u1ee9a c\u00e1c rules \u0111\u1ed3ng \u00fd ph\u00e9p l\u01b0u l\u01b0\u1ee3ng c\u1ee5 th\u1ec3. Firewall driver chuy\u1ec3n c\u00e1c group rule \u0111\u1ebfn c\u1ea5u h\u00ecnh c\u00f9ng c\u01a1 ch\u1ebf l\u1ecdc g\u00f3i tin nh\u01b0 iptables . - M\u1ed7i project c\u00f3 ch\u1ee9a 1 default security group m\u00e0 cho ph\u00e9p t\u00e1t c\u1ea3 l\u01b0u l\u01b0\u1ee3ng egress v\u00e0 t\u1eeb ch\u1ed1i t\u1ea5t c\u1ea3 c\u00e1c l\u01b0u l\u01b0\u1ee3ng ingress. B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i rules trong default security group. N\u00f3 b\u1ea1n launch instance m\u00e0 kh\u00f4ng c\u00f3 security group ch\u1ec9 \u0111\u1ecbnh, default security group s\u1ebd t\u1ef1 \u0111\u1ed9ng \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng cho instance \u0111\u00f3. T\u01b0\u01a1ng t\u1ef1, n\u1ebfu b\u1ea1n t\u1ea1o 1 port m\u00e0 kh\u00f4ng ch\u1ec9 \u0111\u1ecbnh security group, default security group t\u1ef1 \u0111\u1ed9ng \u0111\u01b0\u1ee3c \u00e1p cho port \u0111\u00f3. - M\u1eb7c \u0111\u1ecbnh khi m\u1ed9t g\u00f3i tin g\u1eedi \u0111\u1ebfn kh\u00f4ng g\u1ed3m tr\u01b0\u1eddng IP nh\u01b0ng default group s\u1ebd ng\u0103n ch\u1ea1n c\u00e1c b\u1ea3n tin ARP - M\u1eb7c \u0111\u1ecbnh, m\u1ecdi security groups ch\u1ee9a c\u00e1c rules th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 h\u00e0nh \u0111\u1ed9ng sau: - Cho ph\u00e9p traffic ra b\u00ean ngo\u00e0i ch\u1ec9 khi n\u00f3 s\u1eed d\u1ee5ng \u0111\u1ecba ch\u1ec9 MAC v\u00e0 IP c\u1ee7a port m\u00e1y \u1ea3o, c\u1ea3 hai \u0111\u1ecba ch\u1ec9 n\u00e0y \u0111\u01b0\u1ee3c k\u1ebft h\u1ee3p t\u1ea1i allowed-address-pairs - Cho ph\u00e9p t\u00edn hi\u1ec7u t\u00ecm ki\u1ebfm DHCP v\u00e0 g\u1eedi message request s\u1eed d\u1ee5ng MAC c\u1ee7a port cho m\u00e1y \u1ea3o v\u00e0 \u0111\u1ecba ch\u1ec9 IP ch\u01b0a x\u00e1c \u0111\u1ecbnh. - Cho ph\u00e9p tr\u1ea3 l\u1eddi c\u00e1c t\u00edn hi\u1ec7u DHCP v\u00e0 DHCPv6 t\u1eeb DHCP server \u0111\u1ec3 c\u00e1c m\u00e1y \u1ea3o c\u00f3 th\u1ec3 l\u1ea5y IP - T\u1eeb ch\u1ed1i vi\u1ec7c tr\u1ea3 l\u1eddi c\u00e1c t\u00edn hi\u1ec7u DHCP request t\u1eeb b\u00ean ngo\u00e0i \u0111\u1ec3 tr\u00e1nh vi\u1ec7c m\u00e1y \u1ea3o tr\u1edf th\u00e0nh DHCP server - Cho ph\u00e9p c\u00e1c t\u00edn hi\u1ec7u inbound/outbound ICMPv6 MLD, t\u00ecm ki\u1ebfm neighbors, c\u00e1c m\u00e1y \u1ea3o nh\u1edd v\u1eady c\u00f3 th\u1ec3 t\u00ecm ki\u1ebfm v\u00e0 gia nh\u1eadp c\u00e1c multicast group. - T\u1eeb ch\u1ed1i c\u00e1c t\u00edn hi\u1ec7u outbound ICMPv6 \u0111\u1ec3 ng\u0103n vi\u1ec7c m\u00e1y \u1ea3o tr\u1edf th\u00e0nh IPv6 router v\u00e0 forward c\u00e1c t\u00edn hi\u1ec7u cho m\u00e1y \u1ea3o kh\u00e1c. - Cho ph\u00e9p t\u00edn hi\u1ec7u outbound non-IP t\u1eeb \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a c\u00e1c port tr\u00ean m\u00e1y \u1ea3o . DHCP : - qu\u1ea3n l\u00fd c\u00e1c \u0111\u1ecba ch\u1ec9 IP cho provider v\u00e0 sefl-service network . Networking service s\u1eed d\u1ee5ng manages qdhcp namespaces v\u00e0 dnsmasq service. L3 Agent L3 agent l\u00e0 m\u1ed9t ph\u1ea7n c\u1ee7a package openstack-neutron. N\u00f3 \u0111\u01b0\u1ee3c xem nh\u01b0 router layer-3 chuy\u1ec3n h\u01b0\u1edbng l\u01b0u l\u01b0\u1ee3ng v\u00e0 cung c\u1ea5p d\u1ecbch v\u1ee5 gateway cho network l\u1edbp 2. C\u00e1c nodes ch\u1ea1y L3 agent kh\u00f4ng \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh IP tr\u1ef1c ti\u1ebfp tr\u00ean m\u1ed9t card m\u1ea1ng. Thay v\u00ec th\u1ebf, s\u1ebd c\u00f3 m\u1ed9t d\u1ea3i \u0111\u1ecba ch\u1ec9 IP t\u1eeb m\u1ea1ng ngo\u00e0i \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho OpenStack networking. C\u00e1c \u0111\u1ecba ch\u1ec9 n\u00e0y \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c routers m\u00e0 cung c\u1ea5p li\u00ean k\u1ebft gi\u1eefa m\u1ea1ng trong v\u00e0 m\u1ea1ng ngo\u00e0i. Mi\u1ec1n \u0111\u1ecba ch\u1ec9 \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn ph\u1ea3i \u0111\u1ee7 l\u1edbn \u0111\u1ec3 cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP duy nh\u1ea5t cho m\u1ed7i router khi tri\u1ec3n khai c\u0169ng nh\u01b0 m\u1ed7i floating IP g\u00e1n cho c\u00e1c m\u00e1y \u1ea3o. DHCP Agent: OpenStack Networking DHCP agent ch\u1ecbu tr\u00e1ch nhi\u1ec7m c\u1ea5p ph\u00e1t c\u00e1c \u0111\u1ecba ch\u1ec9 IP cho c\u00e1c m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean network. N\u1ebfu agent \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t v\u00e0 \u0111ang ho\u1ea1t \u0111\u1ed9ng khi m\u1ed9t subnet \u0111\u01b0\u1ee3c t\u1ea1o, subnet \u0111\u00f3 m\u1eb7c \u0111\u1ecbnh s\u1ebd \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t DHCP. Plugin Agent: Nhi\u1ec1u networking plug-ins \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho agent c\u1ee7a ch\u00fang, bao g\u1ed3m OVS v\u00e0 Linux bridge. C\u00e1c plug-in ch\u1ec9 \u0111\u1ecbnh agent ch\u1ea1y tr\u00ean c\u00e1c node \u0111ang qu\u1ea3n l\u00fd l\u01b0u l\u01b0\u1ee3ng m\u1ea1ng, bao g\u1ed3m c\u00e1c compute node, c\u0169ng nh\u01b0 c\u00e1c nodes ch\u1ea1y c\u00e1c agent","title":"2.3 . M\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m b\u1ed5 sung"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#3_cau_truc_thanh_phan_va_dich_vu","text":"","title":"3. C\u1ea5u tr\u00fac th\u00e0nh ph\u1ea7n v\u00e0 d\u1ecbch v\u1ee5"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#31_server","text":"Cung c\u1ea5p API, qu\u1ea3n l\u00ed database,...","title":"3.1 Server"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#32_plug-ins","text":"Qu\u1ea3n l\u00ed agents","title":"3.2 Plug-ins"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#33_agents","text":"Cung c\u1ea5p k\u1ebft n\u1ed1i layer 2/3 t\u1edbi m\u00e1y \u1ea3o X\u1eed l\u00fd truy\u1ec1n th\u00f4ng gi\u1eefa m\u1ea1ng \u1ea3o v\u00e0 m\u1ea1ng v\u1eadt l\u00fd. X\u1eed l\u00fd metadata, etc.","title":"3.3 Agents"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#layer_2_ethernet_and_switching","text":"Linux Bridge OVS","title":"Layer 2 (Ethernet and Switching)"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#layer_3_ip_and_routing","text":"L3 DHCP","title":"Layer 3 (IP and Routing)"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#miscellaneous","text":"Metadata","title":"Miscellaneous"},{"location":"Openstack_Research/Neutron/1. Introduction-neutron/#services","text":"C\u00e1c d\u1ecbch v\u1ee5 Routing VPNaaS: Virtual Private Network-as-a-Service (VPNaaS), extension c\u1ee7a neutron cho VPN LBaaS: Load-Balancer-as-a-Service (LBaaS), API quy \u0111\u1ecbnh v\u00e0 c\u1ea5u h\u00ecnh n\u00ean c\u00e1c load balancers, \u0111\u01b0\u1ee3c tri\u1ec3n khai d\u1ef1a tr\u00ean HAProxy software load balancer. FWaaS: Firewall-as-a-Service (FWaaS), API th\u1eed nghi\u1ec7m cho ph\u00e9p c\u00e1c nh\u00e0 cung c\u1ea5p ki\u1ec3m th\u1eed tr\u00ean networking c\u1ee7a h\u1ecd.","title":"Services"},{"location":"Openstack_Research/Neutron/10. OPS-Packet-Provider/","text":"3. M\u00f4 h\u00ecnh Provider \u00b6 3.1. B\u1eafc Nam \u00b6 Tr\u00ean Compute 1 : B1 : instance interface ( 1 ) forward packet \u0111\u1ebfn Linux Bridge port ( 2 ) nh\u1edd veth pair B2 : Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet B3 : Security group OVS bridge port ( 4 ) forward packet t\u1edbi OVS integration bridge port ( 5 ) nh\u1edd veth pair B4 : OVS integration bridge tag VLAN ID t\u1edbi packet B5 : OVS integration bridge patch port ( 6 ) forward packet \u0111\u1ebfn OVS provider bridge patch port ( 7 ) B6 : OVS provider bridge Tag VLAN external cho packet B7 : OVS provider bridge port ( 8 ) forward packet t\u1edbi physcal interface B8 : Physical interface ( 9) forward packet t\u1edbi h\u1ea1 t\u1ea7ng m\u1ea1ng ( 10 ) H\u1ea1 t\u1ea7ng m\u1ea1ng ngo\u00e0i : B1 : Switch b\u1ecf VLAN ID v\u00e0 forward packet l\u00ean Router ( 11 ) B2 : Router forward forward data ra c\u00e1c m\u1ea1ng ngo\u00e0i ( 12 ) v\u00e0 forward \u0111\u1ebfn switch ( 13 ) 3.2 : \u0110\u00f4ng - T\u00e2y : c\u00f9ng m\u1ea1ng \u00b6 Tr\u00ean Compute 1 : instance interface ( 1 ) forward data sang bridge instance port ( 2 )th\u00f4ng qua veth pair Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet Linux bridge port ( 4 ) forward packet sang OVS integration bridge port ( 5 ) s\u1eed d\u1ee5ng veth pair OVS integration tag internal VLAN_ID v\u00e0o c\u00e1c packet OVS integration bridge patch port ( 6 ) forward packet sang OVS integration bridge patch port ( 7 ) OVS provider bridge s\u1eed d\u1ee5ng VLAN_ID external thay th\u1ebf cho internal VLAN_ID OVS provider bridge port ( 8 )forward packet sang physical interface ( 9 ) Physical interface forward packet \u0111\u1ebfn switch v\u1eadt l\u00fd ( 10 ) Tr\u00ean Switch Forward packet t\u1eeb compute node 1 sang compute node 2 Tr\u00ean Compute 2 : Physical interface network interface ( 12 ) forward packet t\u1edbi OVS provider port ( 13 ) OVS provider bridge patch port ( 14 ) forward packet t\u1edbi OVS intergration bridge patch port ( 15 ) OVS integration bridge \u0111\u1ecbnh ngh\u0129a VLAN_ID OVS integration bridge port ( 16 ) forward packet \u0111\u1ebfn Linux Bridge port ( 17 ) s\u1eed d\u1ee5ng veth pair Securtiy group ( 18 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet Linux brige veth port ( 19 ) forward c\u00e1c packet sang instance interface ( 20 ) s\u1eed d\u1ee5ng veth pair 3.3: \u0110\u00f4ng - T\u00e2y : kh\u00e1c m\u1ea1ng \u00b6 Tr\u00ean Compute Node B1 : Instance 1 interface ( 1 ) forward packet sang Linux Bridge veth port ( 2 ) B2 : Securtiy group rule ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter package B3 : Linux Bridge port ( 4) forward packet \u0111\u1ebfn OVS integration bridge veth port ( 5 ) B4 : OVS integration bridge th\u00eam VLAN v\u00e0o c\u00e1c packet 2 B5 : OVS integration bridge B6 : OVS provider bridge s\u1eed d\u1ee5ng VLAN_ID external thay th\u1ebf cho local VLAN_ID B7 : OVS provider patch port ( 6 ) forward packet sang OVS provider bridge patch port ( 7 ) B8 : OVS provider bridge port ( 8 ) forward packet t\u1edbi physical interface ( 9 ) B9 : Physical interface forward packet t\u1edbi switch v\u1eadt l\u00fd ( 10 ) Tr\u00ean Switch B1 : Switch b\u1ecf c\u00e1c VLAN_ID kh\u1ecfi packet v\u00e0 forward t\u1edbi router ( 11 ) B2 : Router s\u1ebd forward t\u1edbi c\u00e1c c\u1ed5ng ( 12) \u0111\u1ec3 forward packet sang m\u1ea1ng 2 ( 13 ) B3 : Router forward c\u00e1c packet t\u1edbi switch ( 14 ) B4 : Switch tag VLAN v\u00e0o packet v\u00e0 forward t\u1edbi Compute Node ( 15 ) Tr\u00ean Compute Node B1 : Physical interface ( 16 ) forward packet t\u1edbi OVS provider bridge port ( 17 ) B2 : OVS provider bridge patch port ( 18 ) forward packet t\u1edbi OVS integration bridge port ( 19 ) B3 : OVS integration b\u1ecf VLAN_ID v\u00e0 tag local VLAN_ID B4 : OVS integration port ( 20 ) b\u1ecf VLAN v\u00e0 forward \u0111\u1ebfn Linux Bridge ( 21 ) B5 : Linux bridge s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter packet ( 22 ) B6 : Linux bridge veth port ( 23 ) foreward packet t\u1edbi instance 2 interface ( 24 End.","title":"10. OPS Packet Provider"},{"location":"Openstack_Research/Neutron/10. OPS-Packet-Provider/#3_mo_hinh_provider","text":"","title":"3. M\u00f4 h\u00ecnh Provider"},{"location":"Openstack_Research/Neutron/10. OPS-Packet-Provider/#31_bac_nam","text":"Tr\u00ean Compute 1 : B1 : instance interface ( 1 ) forward packet \u0111\u1ebfn Linux Bridge port ( 2 ) nh\u1edd veth pair B2 : Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet B3 : Security group OVS bridge port ( 4 ) forward packet t\u1edbi OVS integration bridge port ( 5 ) nh\u1edd veth pair B4 : OVS integration bridge tag VLAN ID t\u1edbi packet B5 : OVS integration bridge patch port ( 6 ) forward packet \u0111\u1ebfn OVS provider bridge patch port ( 7 ) B6 : OVS provider bridge Tag VLAN external cho packet B7 : OVS provider bridge port ( 8 ) forward packet t\u1edbi physcal interface B8 : Physical interface ( 9) forward packet t\u1edbi h\u1ea1 t\u1ea7ng m\u1ea1ng ( 10 ) H\u1ea1 t\u1ea7ng m\u1ea1ng ngo\u00e0i : B1 : Switch b\u1ecf VLAN ID v\u00e0 forward packet l\u00ean Router ( 11 ) B2 : Router forward forward data ra c\u00e1c m\u1ea1ng ngo\u00e0i ( 12 ) v\u00e0 forward \u0111\u1ebfn switch ( 13 )","title":"3.1. B\u1eafc Nam"},{"location":"Openstack_Research/Neutron/10. OPS-Packet-Provider/#32_ong_-_tay_cung_mang","text":"Tr\u00ean Compute 1 : instance interface ( 1 ) forward data sang bridge instance port ( 2 )th\u00f4ng qua veth pair Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet Linux bridge port ( 4 ) forward packet sang OVS integration bridge port ( 5 ) s\u1eed d\u1ee5ng veth pair OVS integration tag internal VLAN_ID v\u00e0o c\u00e1c packet OVS integration bridge patch port ( 6 ) forward packet sang OVS integration bridge patch port ( 7 ) OVS provider bridge s\u1eed d\u1ee5ng VLAN_ID external thay th\u1ebf cho internal VLAN_ID OVS provider bridge port ( 8 )forward packet sang physical interface ( 9 ) Physical interface forward packet \u0111\u1ebfn switch v\u1eadt l\u00fd ( 10 ) Tr\u00ean Switch Forward packet t\u1eeb compute node 1 sang compute node 2 Tr\u00ean Compute 2 : Physical interface network interface ( 12 ) forward packet t\u1edbi OVS provider port ( 13 ) OVS provider bridge patch port ( 14 ) forward packet t\u1edbi OVS intergration bridge patch port ( 15 ) OVS integration bridge \u0111\u1ecbnh ngh\u0129a VLAN_ID OVS integration bridge port ( 16 ) forward packet \u0111\u1ebfn Linux Bridge port ( 17 ) s\u1eed d\u1ee5ng veth pair Securtiy group ( 18 ) \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet Linux brige veth port ( 19 ) forward c\u00e1c packet sang instance interface ( 20 ) s\u1eed d\u1ee5ng veth pair","title":"3.2 : \u0110\u00f4ng - T\u00e2y : c\u00f9ng m\u1ea1ng"},{"location":"Openstack_Research/Neutron/10. OPS-Packet-Provider/#33_ong_-_tay_khac_mang","text":"Tr\u00ean Compute Node B1 : Instance 1 interface ( 1 ) forward packet sang Linux Bridge veth port ( 2 ) B2 : Securtiy group rule ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter package B3 : Linux Bridge port ( 4) forward packet \u0111\u1ebfn OVS integration bridge veth port ( 5 ) B4 : OVS integration bridge th\u00eam VLAN v\u00e0o c\u00e1c packet 2 B5 : OVS integration bridge B6 : OVS provider bridge s\u1eed d\u1ee5ng VLAN_ID external thay th\u1ebf cho local VLAN_ID B7 : OVS provider patch port ( 6 ) forward packet sang OVS provider bridge patch port ( 7 ) B8 : OVS provider bridge port ( 8 ) forward packet t\u1edbi physical interface ( 9 ) B9 : Physical interface forward packet t\u1edbi switch v\u1eadt l\u00fd ( 10 ) Tr\u00ean Switch B1 : Switch b\u1ecf c\u00e1c VLAN_ID kh\u1ecfi packet v\u00e0 forward t\u1edbi router ( 11 ) B2 : Router s\u1ebd forward t\u1edbi c\u00e1c c\u1ed5ng ( 12) \u0111\u1ec3 forward packet sang m\u1ea1ng 2 ( 13 ) B3 : Router forward c\u00e1c packet t\u1edbi switch ( 14 ) B4 : Switch tag VLAN v\u00e0o packet v\u00e0 forward t\u1edbi Compute Node ( 15 ) Tr\u00ean Compute Node B1 : Physical interface ( 16 ) forward packet t\u1edbi OVS provider bridge port ( 17 ) B2 : OVS provider bridge patch port ( 18 ) forward packet t\u1edbi OVS integration bridge port ( 19 ) B3 : OVS integration b\u1ecf VLAN_ID v\u00e0 tag local VLAN_ID B4 : OVS integration port ( 20 ) b\u1ecf VLAN v\u00e0 forward \u0111\u1ebfn Linux Bridge ( 21 ) B5 : Linux bridge s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter packet ( 22 ) B6 : Linux bridge veth port ( 23 ) foreward packet t\u1edbi instance 2 interface ( 24 End.","title":"3.3: \u0110\u00f4ng -  T\u00e2y : kh\u00e1c m\u1ea1ng"},{"location":"Openstack_Research/Neutron/11. VXLAN-Tunnel/","text":"LAB VXLAN tr\u00ean 2 host s\u1eed d\u1ee5ng OpenvSwitch \u00b6 1. M\u00f4 h\u00ecnh \u00b6 2. C\u1ea5u h\u00ecnh Host 1 \u00b6 C\u00e0i \u0111\u1eb7t OpenvSwitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit yum install -y /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm C\u1ea5u h\u00ecnh IP V4 Fowarding cat <<EOF > /etc/sysctl.conf net.ipv4.ip_forward = 1 EOF sysctl -p /etc/sysctl.conf C\u1ea5u h\u00ecnh VXLAN Tunnel Endpoint ovs-vsctl add-br br-extun ovs-vsctl add-port br-extun tun-vxlan0 -- set interface tun-vxlan0 type=vxlan options:local_ip=192.168.69.135 options:remote_ip=192.168.69.132 C\u1ea5u h\u00ecnh IP cho internal interface (VETP )( nh\u01b0 m\u1ed9t c\u1ed5ng layer 3 ) cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-extun DEVICE=br-extun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=192.168.199.1 EOF systemctl restart network Kh\u1edfi t\u1ea1o m\u1ed9t network m\u1edbi trong libvirt cat <<EOF > /etc/libvirt/qemu/networks/br-tun.xml <network> <name>ovs-tun</name> <forward mode='bridge'/> <bridge name='br-extun'/> <virtualport type='openvswitch'/> </network> EOF virsh net-define br-tun.xml virsh net-start ovs-tun virsh net-autostart ovs-tun C\u1ea5u h\u00ecnh network interface cho m\u00e1y \u1ea3o C\u1ea5u h\u00ecnh IP v\u00e0 Gateway cho m\u00e1y \u1ea3o 3. C\u1ea5u h\u00ecnh Host 2 \u00b6 C\u00e0i \u0111\u1eb7t OpenvSwitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit yum install -y /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm C\u1ea5u h\u00ecnh IP V4 Fowarding cat <<EOF > /etc/sysctl.conf net.ipv4.ip_forward = 1 EOF sysctl -p /etc/sysctl.conf C\u1ea5u h\u00ecnh VXLAN Tunnel Endpoint ovs-vsctl add-br br-extun ovs-vsctl add-port br-extun tun-vxlan0 -- set interface tun-vxlan0 type=vxlan options:local_ip=192.168.69.132 options:remote_ip=192.168.69.135 C\u1ea5u h\u00ecnh IP cho internal interface - VETP ( nh\u01b0 m\u1ed9t c\u1ed5ng layer 3 ) cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-extun DEVICE=br-extun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=192.168.199.2 EOF systemctl restart network Test Ping Tunnel Host 1 [root@compute2 ~]# ping 192.168.199.1 PING 192.168.199.1 (192.168.199.1) 56(84) bytes of data. 64 bytes from 192.168.199.1: icmp_seq=1 ttl=64 time=1.93 ms 64 bytes from 192.168.199.1: icmp_seq=2 ttl=64 time=0.585 ms 64 bytes from 192.168.199.1: icmp_seq=3 ttl=64 time=0.573 ms 64 bytes from 192.168.199.1: icmp_seq=4 ttl=64 time=0.524 ms ^C --- 192.168.199.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3001ms rtt min/avg/max/mdev = 0.524/0.904/1.936/0.596 ms Test Ping v\u1ec1 m\u00e1y \u1ea3o [root@compute2 ~]# ping 192.168.199.10 PING 192.168.199.10 (192.168.199.10) 56(84) bytes of data. 64 bytes from 192.168.199.10: icmp_seq=1 ttl=64 time=2.81 ms 64 bytes from 192.168.199.10: icmp_seq=2 ttl=64 time=1.59 ms 64 bytes from 192.168.199.10: icmp_seq=3 ttl=64 time=1.54 ms 64 bytes from 192.168.199.10: icmp_seq=4 ttl=64 time=1.42 ms 64 bytes from 192.168.199.10: icmp_seq=5 ttl=64 time=1.49 ms 64 bytes from 192.168.199.10: icmp_seq=6 ttl=64 time=0.834 ms 64 bytes from 192.168.199.10: icmp_seq=7 ttl=64 time=1.50 ms 64 bytes from 192.168.199.10: icmp_seq=8 ttl=64 time=1.50 ms ^C --- 192.168.199.10 ping statistics --- 8 packets transmitted, 8 received, 0% packet loss, time 7008ms rtt min/avg/max/mdev = 0.834/1.590/2.819/0.518 ms","title":"11. VXLAN Tunnel"},{"location":"Openstack_Research/Neutron/11. VXLAN-Tunnel/#lab_vxlan_tren_2_host_su_dung_openvswitch","text":"","title":"LAB VXLAN tr\u00ean 2 host  s\u1eed d\u1ee5ng OpenvSwitch"},{"location":"Openstack_Research/Neutron/11. VXLAN-Tunnel/#1_mo_hinh","text":"","title":"1. M\u00f4 h\u00ecnh"},{"location":"Openstack_Research/Neutron/11. VXLAN-Tunnel/#2_cau_hinh_host_1","text":"C\u00e0i \u0111\u1eb7t OpenvSwitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit yum install -y /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm C\u1ea5u h\u00ecnh IP V4 Fowarding cat <<EOF > /etc/sysctl.conf net.ipv4.ip_forward = 1 EOF sysctl -p /etc/sysctl.conf C\u1ea5u h\u00ecnh VXLAN Tunnel Endpoint ovs-vsctl add-br br-extun ovs-vsctl add-port br-extun tun-vxlan0 -- set interface tun-vxlan0 type=vxlan options:local_ip=192.168.69.135 options:remote_ip=192.168.69.132 C\u1ea5u h\u00ecnh IP cho internal interface (VETP )( nh\u01b0 m\u1ed9t c\u1ed5ng layer 3 ) cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-extun DEVICE=br-extun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=192.168.199.1 EOF systemctl restart network Kh\u1edfi t\u1ea1o m\u1ed9t network m\u1edbi trong libvirt cat <<EOF > /etc/libvirt/qemu/networks/br-tun.xml <network> <name>ovs-tun</name> <forward mode='bridge'/> <bridge name='br-extun'/> <virtualport type='openvswitch'/> </network> EOF virsh net-define br-tun.xml virsh net-start ovs-tun virsh net-autostart ovs-tun C\u1ea5u h\u00ecnh network interface cho m\u00e1y \u1ea3o C\u1ea5u h\u00ecnh IP v\u00e0 Gateway cho m\u00e1y \u1ea3o","title":"2. C\u1ea5u h\u00ecnh Host 1"},{"location":"Openstack_Research/Neutron/11. VXLAN-Tunnel/#3_cau_hinh_host_2","text":"C\u00e0i \u0111\u1eb7t OpenvSwitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit yum install -y /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm C\u1ea5u h\u00ecnh IP V4 Fowarding cat <<EOF > /etc/sysctl.conf net.ipv4.ip_forward = 1 EOF sysctl -p /etc/sysctl.conf C\u1ea5u h\u00ecnh VXLAN Tunnel Endpoint ovs-vsctl add-br br-extun ovs-vsctl add-port br-extun tun-vxlan0 -- set interface tun-vxlan0 type=vxlan options:local_ip=192.168.69.132 options:remote_ip=192.168.69.135 C\u1ea5u h\u00ecnh IP cho internal interface - VETP ( nh\u01b0 m\u1ed9t c\u1ed5ng layer 3 ) cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-extun DEVICE=br-extun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=192.168.199.2 EOF systemctl restart network Test Ping Tunnel Host 1 [root@compute2 ~]# ping 192.168.199.1 PING 192.168.199.1 (192.168.199.1) 56(84) bytes of data. 64 bytes from 192.168.199.1: icmp_seq=1 ttl=64 time=1.93 ms 64 bytes from 192.168.199.1: icmp_seq=2 ttl=64 time=0.585 ms 64 bytes from 192.168.199.1: icmp_seq=3 ttl=64 time=0.573 ms 64 bytes from 192.168.199.1: icmp_seq=4 ttl=64 time=0.524 ms ^C --- 192.168.199.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3001ms rtt min/avg/max/mdev = 0.524/0.904/1.936/0.596 ms Test Ping v\u1ec1 m\u00e1y \u1ea3o [root@compute2 ~]# ping 192.168.199.10 PING 192.168.199.10 (192.168.199.10) 56(84) bytes of data. 64 bytes from 192.168.199.10: icmp_seq=1 ttl=64 time=2.81 ms 64 bytes from 192.168.199.10: icmp_seq=2 ttl=64 time=1.59 ms 64 bytes from 192.168.199.10: icmp_seq=3 ttl=64 time=1.54 ms 64 bytes from 192.168.199.10: icmp_seq=4 ttl=64 time=1.42 ms 64 bytes from 192.168.199.10: icmp_seq=5 ttl=64 time=1.49 ms 64 bytes from 192.168.199.10: icmp_seq=6 ttl=64 time=0.834 ms 64 bytes from 192.168.199.10: icmp_seq=7 ttl=64 time=1.50 ms 64 bytes from 192.168.199.10: icmp_seq=8 ttl=64 time=1.50 ms ^C --- 192.168.199.10 ping statistics --- 8 packets transmitted, 8 received, 0% packet loss, time 7008ms rtt min/avg/max/mdev = 0.834/1.590/2.819/0.518 ms","title":"3. C\u1ea5u h\u00ecnh Host 2"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/","text":"C\u1ea5u h\u00ecnh VLAN Tunnel. C\u00e1c Physical Host l\u00e0m vi\u1ec7c v\u1edbi VM trong OPS \u00b6 1. M\u00f4 h\u00ecnh \u00b6 M\u00f4 h\u00ecnh k\u1ebft n\u1ed1i M\u00f4 h\u00ecnh network OVS tr\u00ean Compute Node M\u00f4 h\u00ecnh 2. T\u00ecm VLAN c\u1ee7a QVO interface tr\u00ean c\u00e1c br-int \u00b6 Tr\u00ean Controller \u00b6 get_id=`openstack server list | grep 10.20.30.101 | awk '{print $2}'` get_virsh_name=`openstack server show ${get_id} | awk '/OS-EXT-SRV-ATTR:instance_name/ {print $4}'` get_host=`openstack server show ${get_id} | awk '/OS-EXT-SRV-ATTR:host/ {print $4}'` echo \"ID VM :${get_virsh_name} , Compute Host : ${get_host} \" Tr\u00ean Compute Host \u00b6 S\u1eed d\u1ee5ng ID VM v\u00e0 Compute Host \u0111\u01b0\u1ee3c cung c\u1ea5p tr\u00ean Controller qbr=`virsh domiflist ${id_domain} | grep \"qbr.{0,12}\" -o -P | tail -c 13` get_vlan=`ovs-vsctl show | grep $qbr -b1 | awk '/tag:/ {print $3}'` echo \"VLAN = ${get_vlan}\" 3. C\u1ea5u h\u00ecnh VXAN Tunnel \u00b6 3.1 : Tr\u00ean Compute Host \u00b6 ## C\u1ea5u h\u00ecnh VXLAN END POINT ovs-vsctl add-br br-ex ovs-vsctl add-port br-ex pair_compute4 -- set interface pair_compute4 type=vxlan options:local_ip=192.168.69.132 options:remote_ip=192.168.69.135 options:in_key=flow options:out_key=flow ip link set up br-ex ## C\u1ea5u h\u00ecnh VETH Pair br-int v\u00e0 br-ex ip link add veth0 type veth peer name veth1 ip link set up veth0 ip link set up veth1 ovs-vsctl add-port br-ex veth0 ovs-vsctl add-port br-int veth1 ## C\u1ea5u h\u00ecnh VLAN tr\u00ean interface OVS - s\u1eed d\u1ee5ng VLAN trong b\u01b0\u1edbc tr\u01b0\u1edbc ovs-vsctl set port br-ex tag=1 3.2 : Tr\u00ean Host 4 \u00b6 # C\u1ea5u h\u00ecnh VXLAN END POINT ovs-vsctl add-br br-tun ovs-vsctl add-port br-tun pair_compute3 -- set interface pair_compute3 type=vxlan options:local_ip=192.168.69.135 options:remote_ip=192.168.69.132 options:in_key=flow options:out_key=flow ip link set up br-tun # C\u1ea5u h\u00ecnh br-tun interface cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-br-tun DEVICE=br-tun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=10.20.20.9 EOF systemctl restart network ## C\u1ea5u h\u00ecnh VLAN tr\u00ean interface OVS - s\u1eed d\u1ee5ng VLAN trong b\u01b0\u1edbc tr\u01b0\u1edbc ovs-vsctl set port br-tun tag=1 4. Ki\u1ec3m th\u1eed \u00b6 Ping t\u1eeb Host 4 v\u1ec1 m\u00e1y \u1ea3o Ping t\u1eeb m\u00e1y \u1ea3o v\u1ec1 Host 4","title":"12. VXLAN Tunnel Host pair OPS"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#cau_hinh_vlan_tunnel_cac_physical_host_lam_viec_voi_vm_trong_ops","text":"","title":"C\u1ea5u h\u00ecnh VLAN Tunnel. C\u00e1c Physical Host l\u00e0m vi\u1ec7c v\u1edbi VM trong OPS"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#1_mo_hinh","text":"M\u00f4 h\u00ecnh k\u1ebft n\u1ed1i M\u00f4 h\u00ecnh network OVS tr\u00ean Compute Node M\u00f4 h\u00ecnh","title":"1. M\u00f4 h\u00ecnh"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#2_tim_vlan_cua_qvo_interface_tren_cac_br-int","text":"","title":"2. T\u00ecm VLAN c\u1ee7a QVO interface tr\u00ean c\u00e1c br-int"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#tren_controller","text":"get_id=`openstack server list | grep 10.20.30.101 | awk '{print $2}'` get_virsh_name=`openstack server show ${get_id} | awk '/OS-EXT-SRV-ATTR:instance_name/ {print $4}'` get_host=`openstack server show ${get_id} | awk '/OS-EXT-SRV-ATTR:host/ {print $4}'` echo \"ID VM :${get_virsh_name} , Compute Host : ${get_host} \"","title":"Tr\u00ean Controller"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#tren_compute_host","text":"S\u1eed d\u1ee5ng ID VM v\u00e0 Compute Host \u0111\u01b0\u1ee3c cung c\u1ea5p tr\u00ean Controller qbr=`virsh domiflist ${id_domain} | grep \"qbr.{0,12}\" -o -P | tail -c 13` get_vlan=`ovs-vsctl show | grep $qbr -b1 | awk '/tag:/ {print $3}'` echo \"VLAN = ${get_vlan}\"","title":"Tr\u00ean Compute Host"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#3_cau_hinh_vxan_tunnel","text":"","title":"3. C\u1ea5u h\u00ecnh VXAN Tunnel"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#31_tren_compute_host","text":"## C\u1ea5u h\u00ecnh VXLAN END POINT ovs-vsctl add-br br-ex ovs-vsctl add-port br-ex pair_compute4 -- set interface pair_compute4 type=vxlan options:local_ip=192.168.69.132 options:remote_ip=192.168.69.135 options:in_key=flow options:out_key=flow ip link set up br-ex ## C\u1ea5u h\u00ecnh VETH Pair br-int v\u00e0 br-ex ip link add veth0 type veth peer name veth1 ip link set up veth0 ip link set up veth1 ovs-vsctl add-port br-ex veth0 ovs-vsctl add-port br-int veth1 ## C\u1ea5u h\u00ecnh VLAN tr\u00ean interface OVS - s\u1eed d\u1ee5ng VLAN trong b\u01b0\u1edbc tr\u01b0\u1edbc ovs-vsctl set port br-ex tag=1","title":"3.1 : Tr\u00ean Compute Host"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#32_tren_host_4","text":"# C\u1ea5u h\u00ecnh VXLAN END POINT ovs-vsctl add-br br-tun ovs-vsctl add-port br-tun pair_compute3 -- set interface pair_compute3 type=vxlan options:local_ip=192.168.69.135 options:remote_ip=192.168.69.132 options:in_key=flow options:out_key=flow ip link set up br-tun # C\u1ea5u h\u00ecnh br-tun interface cat <<EOF > /etc/sysconfig/network-scripts/ifcfg-br-tun DEVICE=br-tun BOOTPROTO=yes ONBOOT=yes PREFIX=24 IPADDR=10.20.20.9 EOF systemctl restart network ## C\u1ea5u h\u00ecnh VLAN tr\u00ean interface OVS - s\u1eed d\u1ee5ng VLAN trong b\u01b0\u1edbc tr\u01b0\u1edbc ovs-vsctl set port br-tun tag=1","title":"3.2 : Tr\u00ean Host 4"},{"location":"Openstack_Research/Neutron/12. VXLAN-Tunnel-Host-pair-OPS/#4_kiem_thu","text":"Ping t\u1eeb Host 4 v\u1ec1 m\u00e1y \u1ea3o Ping t\u1eeb m\u00e1y \u1ea3o v\u1ec1 Host 4","title":"4. Ki\u1ec3m th\u1eed"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/","text":"C\u00e0i \u0111\u1eb7t Neutron -- Linux Bridge \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean Controller Node \u00b6 C\u00e0i \u0111\u1eb7t etcd yum install etcd -y cat <<EOF > /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_NAME=\"controller\" #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_INITIAL_CLUSTER=\"controller=http://192.168.69.130:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster-01\" ETCD_INITIAL_CLUSTER_STATE=\"new\" EOF systemctl enable etcd systemctl start etcd Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE neutron; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'neutron_123'; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'neutron_123'; EOF Kh\u1edfi t\u1ea1o Neutron User v\u00e0 Neutron Service openstack user create --domain default --password=neutron_123 neutron openstack role add --project service --user neutron admin openstack service create --name neutron \\ --description \"OpenStack Networking\" network Kh\u1edfi t\u1ea1o endpoint openstack endpoint create --region RegionOne \\ network public http://controller:9696 openstack endpoint create --region RegionOne \\ network internal http://controller:9696 openstack endpoint create --region RegionOne \\ network admin http://controller:9696 C\u1ea5u h\u00ecnh m\u1ea1ng theo m\u00f4 h\u00ecnh Self-service \u00b6 C\u00e0i \u0111\u1eb7t package yum install openstack-neutron openstack-neutron-ml2 \\ openstack-neutron-linuxbridge ebtables C\u1ea5u h\u00ecnh neutron.conf cat <<EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router allow_overlapping_ips = true transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Layer 2 Plugin The ML2 plug-in uses the Linux bridge mechanism to build layer-2 (bridging and switching) virtual networking infrastructure for instances. cat <<EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan mechanism_drivers = linuxbridge,l2population extension_drivers = port_security [ml2_type_flat] flat_networks = provider [ml2_type_vxlan] vni_ranges = 1:1000 [securitygroup] enable_ipset = true EOF C\u1ea5u h\u00ecnh L2 Agent The Linux bridge agent builds layer-2 (bridging and switching) virtual networking infrastructure for instances and handles security groups. modprobe br_netfilter cat <<EOF > /etc/neutron/plugins/ml2/linuxbridge_agent.ini [linux_bridge] physical_interface_mappings = provider:ens192 [vxlan] enable_vxlan = true local_ip = 192.168.69.130 l2_population = true [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver EOF C\u1ea5u h\u00ecnh L3 Agent The Layer-3 (L3) agent provides routing and NAT services for self-service virtual networks. cat <<EOF > /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = linuxbridge EOF C\u1ea5u h\u00ecnh DHCP Agent The DHCP agent provides DHCP services for virtual networks. cat <<EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = linuxbridge dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true EOF C\u1ea5u h\u00ecnh Metadata Agent cat <<EOF >/etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh Nova s\u1eed d\u1ee5ng Neutron trong /etc/nova/nova.conf cat <<EOF >>/etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 service_metadata_proxy = true metadata_proxy_shared_secret = metadata_123 EOF Kh\u1edfi t\u1ea1o Database ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service systemctl enable neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl start neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl enable neutron-l3-agent.service systemctl start neutron-l3-agent.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload 2. C\u1ea5u h\u00ecnh tr\u00ean Compute Node \u00b6 C\u00e0i \u0111\u1eb7t package cho neutron yum install openstack-neutron-linuxbridge ebtables ipset C\u1ea5u h\u00ecnh file neutron.conf cat <<EOF > /etc/neutron/neutron.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh m\u1ea1ng theo m\u00f4 h\u00ecnh Self-service \u00b6 C\u1ea5u h\u00ecnh Linux Bridge Agent yum install openstack-selinux modprobe br_netfilter cat <<EOF > /etc/neutron/plugins/ml2/linuxbridge_agent.ini [linux_bridge] physical_interface_mappings = provider:ens192 [vxlan] enable_vxlan = true local_ip = 192.168.69.131 l2_population = true [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver EOF C\u1ea5u h\u00ecnh d\u1ecbch v\u1ee5 Neutron cho Nova /etc/nova/nova.conf cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-nova-compute.service systemctl restart openstack-nova-compute.service systemctl enable neutron-linuxbridge-agent.service systemctl start neutron-linuxbridge-agent.service Tr\u1edf l\u1ea1i Controller Node , ki\u1ec3m tra c\u00e1c agent [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | b68cd06e-384f-47d7-88e4-dd5a6a85796c | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | c4eb82a1-d86a-4eb8-a230-f62b567d4df8 | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | ce13fbcc-e0e6-4b55-87cd-7bdfe58ce357 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e2279058-9cad-4e05-801d-51a8f16b6850 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | f7fc3ab5-35c5-4968-a349-79ba6820d25a | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"C\u00e0i \u0111\u1eb7t Neutron  -- Linux Bridge"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/#cai_at_neutron_--_linux_bridge","text":"","title":"C\u00e0i \u0111\u1eb7t Neutron  -- Linux Bridge"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/#1_cau_hinh_tren_controller_node","text":"C\u00e0i \u0111\u1eb7t etcd yum install etcd -y cat <<EOF > /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_NAME=\"controller\" #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_INITIAL_CLUSTER=\"controller=http://192.168.69.130:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster-01\" ETCD_INITIAL_CLUSTER_STATE=\"new\" EOF systemctl enable etcd systemctl start etcd Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE neutron; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'neutron_123'; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'neutron_123'; EOF Kh\u1edfi t\u1ea1o Neutron User v\u00e0 Neutron Service openstack user create --domain default --password=neutron_123 neutron openstack role add --project service --user neutron admin openstack service create --name neutron \\ --description \"OpenStack Networking\" network Kh\u1edfi t\u1ea1o endpoint openstack endpoint create --region RegionOne \\ network public http://controller:9696 openstack endpoint create --region RegionOne \\ network internal http://controller:9696 openstack endpoint create --region RegionOne \\ network admin http://controller:9696","title":"1. C\u1ea5u h\u00ecnh tr\u00ean Controller Node"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/#cau_hinh_mang_theo_mo_hinh_self-service","text":"C\u00e0i \u0111\u1eb7t package yum install openstack-neutron openstack-neutron-ml2 \\ openstack-neutron-linuxbridge ebtables C\u1ea5u h\u00ecnh neutron.conf cat <<EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router allow_overlapping_ips = true transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Layer 2 Plugin The ML2 plug-in uses the Linux bridge mechanism to build layer-2 (bridging and switching) virtual networking infrastructure for instances. cat <<EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan mechanism_drivers = linuxbridge,l2population extension_drivers = port_security [ml2_type_flat] flat_networks = provider [ml2_type_vxlan] vni_ranges = 1:1000 [securitygroup] enable_ipset = true EOF C\u1ea5u h\u00ecnh L2 Agent The Linux bridge agent builds layer-2 (bridging and switching) virtual networking infrastructure for instances and handles security groups. modprobe br_netfilter cat <<EOF > /etc/neutron/plugins/ml2/linuxbridge_agent.ini [linux_bridge] physical_interface_mappings = provider:ens192 [vxlan] enable_vxlan = true local_ip = 192.168.69.130 l2_population = true [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver EOF C\u1ea5u h\u00ecnh L3 Agent The Layer-3 (L3) agent provides routing and NAT services for self-service virtual networks. cat <<EOF > /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = linuxbridge EOF C\u1ea5u h\u00ecnh DHCP Agent The DHCP agent provides DHCP services for virtual networks. cat <<EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = linuxbridge dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true EOF C\u1ea5u h\u00ecnh Metadata Agent cat <<EOF >/etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh Nova s\u1eed d\u1ee5ng Neutron trong /etc/nova/nova.conf cat <<EOF >>/etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 service_metadata_proxy = true metadata_proxy_shared_secret = metadata_123 EOF Kh\u1edfi t\u1ea1o Database ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl restart openstack-nova-api.service systemctl enable neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl start neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl enable neutron-l3-agent.service systemctl start neutron-l3-agent.service C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload","title":"C\u1ea5u h\u00ecnh m\u1ea1ng theo m\u00f4 h\u00ecnh  Self-service"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/#2_cau_hinh_tren_compute_node","text":"C\u00e0i \u0111\u1eb7t package cho neutron yum install openstack-neutron-linuxbridge ebtables ipset C\u1ea5u h\u00ecnh file neutron.conf cat <<EOF > /etc/neutron/neutron.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Compute Node"},{"location":"Openstack_Research/Neutron/2. Install Neutron Linux Bridge/#cau_hinh_mang_theo_mo_hinh_self-service_1","text":"C\u1ea5u h\u00ecnh Linux Bridge Agent yum install openstack-selinux modprobe br_netfilter cat <<EOF > /etc/neutron/plugins/ml2/linuxbridge_agent.ini [linux_bridge] physical_interface_mappings = provider:ens192 [vxlan] enable_vxlan = true local_ip = 192.168.69.131 l2_population = true [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver EOF C\u1ea5u h\u00ecnh d\u1ecbch v\u1ee5 Neutron cho Nova /etc/nova/nova.conf cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-nova-compute.service systemctl restart openstack-nova-compute.service systemctl enable neutron-linuxbridge-agent.service systemctl start neutron-linuxbridge-agent.service Tr\u1edf l\u1ea1i Controller Node , ki\u1ec3m tra c\u00e1c agent [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | b68cd06e-384f-47d7-88e4-dd5a6a85796c | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | c4eb82a1-d86a-4eb8-a230-f62b567d4df8 | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | ce13fbcc-e0e6-4b55-87cd-7bdfe58ce357 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e2279058-9cad-4e05-801d-51a8f16b6850 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | f7fc3ab5-35c5-4968-a349-79ba6820d25a | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"C\u1ea5u h\u00ecnh m\u1ea1ng theo m\u00f4 h\u00ecnh  Self-service"},{"location":"Openstack_Research/Neutron/2.1 . OVS-Self-Services/","text":"C\u00e0i \u0111\u1eb7t Neutron - OpenvSwitch - Self Service \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean Controller Node \u00b6 T\u1eaft c\u00e1c Agent systemctl stop neutron-linuxbridge-agent neutron-server neutron-dhcp-agent neutron-l3-agent neutron-metadata-agent X\u00f3a Bridge Provider c\u1ee7a Linux Bridge brctl del-if br19feqwe-eq ens192 ip link set down br19feqwe-eq brctl del-br br19feqwe-eq C\u00e0i \u0111\u1eb7t etcd yum install etcd -y cat <<EOF > /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_NAME=\"controller\" #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_INITIAL_CLUSTER=\"controller=http://192.168.69.130:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster-01\" ETCD_INITIAL_CLUSTER_STATE=\"new\" EOF systemctl enable etcd systemctl start etcd Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE neutron; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'neutron_123'; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'neutron_123'; EOF Kh\u1edfi t\u1ea1o Neutron User v\u00e0 Neutron Service openstack user create --domain default --password=neutron_123 neutron openstack role add --project service --user neutron admin openstack service create --name neutron \\ --description \"OpenStack Networking\" network Kh\u1edfi t\u1ea1o endpoint openstack endpoint create --region RegionOne \\ network public http://controller:9696 openstack endpoint create --region RegionOne \\ network internal http://controller:9696 openstack endpoint create --region RegionOne \\ network admin http://controller:9696 C\u00e0i \u0111\u1eb7t package yum --enablerepo=centos-openstack-queens,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch C\u00e0i \u0111\u1eb7t OpenVswitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit rpm -i /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm systemctl start openvswitch.service systemctl enable openvswitch.service systemctl status openvswitch.service ovs-vsctl -V C\u1ea5u h\u00ecnh neutron.conf cat << EOF > /etc/neutron/neutron.conf [DEFAULT] service_plugins = router allow_overlapping_ips = True core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh L2 Agent cat << EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch,l2population [ml2_type_vxlan] vni_ranges = 1:300 EOF C\u1ea5u h\u00ecnh Openvswitch Agent ( provider ) cat << EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider local_ip = 192.168.69.130 [agent] tunnel_types = vxlan l2_population = True [securitygroup] firewall_driver = iptables_hybrid EOF C\u1ea5u h\u00ecnh L3 Agent cat << EOF > /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = openvswitch external_network_bridge = EOF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh DHCP Agent The DHCP agent provides DHCP services for virtual networks. cat <<EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true EOF C\u1ea5u h\u00ecnh Metadata Agent cat <<EOF > /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh Nova s\u1eed d\u1ee5ng Neutron trong /etc/nova/nova.conf cat <<EOF >>/etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 service_metadata_proxy = true metadata_proxy_shared_secret = metadata_123 EOF Kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh network cho interface provider v\u00e0 bridge cat << EOF > /etc/sysconfig/network-scripts/ifcfg-provider DEVICE=\"br-provider\" TYPE=\"OVSBridge\" SLAVE=\"yes\" BOOTPROTO=\"static\" IPADDR=192.168.30.130 NETMASK=255.255.255.0 GATEWAY=192.168.30.1 DNS1=1.1.1.1 IPV6INIT=\"no\" NM_CONTROLLED=\"yes\" ONBOOT=\"yes\" DEFROUTE=\"yes\" PEERDNS=\"yes\" PEERROUTES=\"yes\" IPV4_FAILURE_FATAL=\"yes\" EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens192 DEVICE=\"ens192\" ONBOOT=\"yes\" TYPE=\"OVSPort\" DEVICETYPE=\"ovs\" OVS_BRIDGE=\"br-provider\" EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-compute Kh\u1edfi t\u1ea1o switch cho L2 Agent ( Provider ) - bridge_mappings = provider:br-provider systemctl start openvswitch systemctl enable openvswitch ovs-vsctl add-br br-provider ovs-vsctl add-port br-provider ens192 systemctl restart network Kh\u1edfi t\u1ea1o Database ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng c\u00e1c agent v\u00e0 service for service in server dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl start neutron-$service systemctl enable neutron-$service done systemctl restart openstack-nova-** C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload Ki\u1ec3m tra c\u00e1c Agent [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 4e897eae-29fc-4e55-bd7d-783f9907e627 | Linux bridge agent | controller | None | XXX | UP | neutron-linuxbridge-agent | | 96b049a4-ca30-4a46-bd0a-c1a062d766c1 | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ C\u00e1c m\u00e1y \u1ea3o \u0111ang s\u1eed d\u1ee5ng \u0111\u01b0\u1eddng provider tr\u00ean compute ra ngo\u00e0i b\u00ecnh th\u01b0\u1eddng [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 4e897eae-29fc-4e55-bd7d-783f9907e627 | Linux bridge agent | controller | None | XXX | UP | neutron-linuxbridge-agent | | 96b049a4-ca30-4a46-bd0a-c1a062d766c1 | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ 2. Tr\u00ean Compute Node \u00b6 C\u00e0i \u0111\u1eb7t package yum install -y openstack-neutron-openvswitch yum remove openstack-neutron-linuxbridge C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh OVS Agent cat << EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] local_ip = 192.168.69.132 [agent] tunnel_types = vxlan l2_population = True EOF T\u1eaft Linux Bridge Agent v\u00e0 kh\u1edfi \u0111\u1ed9ng OVS agent systemctl restart openvswitch.service systemctl restart neutron-openvswitch-agent.service systemctl enable openvswitch.service neutron-openvswitch-agent.service Tr\u1edf v\u1ec1 controller Linux bridge agent v\u00e0 ki\u1ec3m tra danh s\u00e1ch c\u00e1c Agent hi\u1ec7n t\u1ea1i [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 92510ebb-ce51-46a1-aba5-2e83dc05012a | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | c7383988-54af-4342-90f8-5f71073718ec | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +---------------------------","title":"2.1 . OVS Self Services"},{"location":"Openstack_Research/Neutron/2.1 . OVS-Self-Services/#cai_at_neutron_-_openvswitch_-_self_service","text":"","title":"C\u00e0i \u0111\u1eb7t Neutron - OpenvSwitch - Self Service"},{"location":"Openstack_Research/Neutron/2.1 . OVS-Self-Services/#1_cau_hinh_tren_controller_node","text":"T\u1eaft c\u00e1c Agent systemctl stop neutron-linuxbridge-agent neutron-server neutron-dhcp-agent neutron-l3-agent neutron-metadata-agent X\u00f3a Bridge Provider c\u1ee7a Linux Bridge brctl del-if br19feqwe-eq ens192 ip link set down br19feqwe-eq brctl del-br br19feqwe-eq C\u00e0i \u0111\u1eb7t etcd yum install etcd -y cat <<EOF > /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_NAME=\"controller\" #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.69.130:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.69.130:2379\" ETCD_INITIAL_CLUSTER=\"controller=http://192.168.69.130:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster-01\" ETCD_INITIAL_CLUSTER_STATE=\"new\" EOF systemctl enable etcd systemctl start etcd Kh\u1edfi t\u1ea1o Database mysql -u root --password=123@123Aa <<EOF CREATE DATABASE neutron; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'neutron_123'; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'neutron_123'; EOF Kh\u1edfi t\u1ea1o Neutron User v\u00e0 Neutron Service openstack user create --domain default --password=neutron_123 neutron openstack role add --project service --user neutron admin openstack service create --name neutron \\ --description \"OpenStack Networking\" network Kh\u1edfi t\u1ea1o endpoint openstack endpoint create --region RegionOne \\ network public http://controller:9696 openstack endpoint create --region RegionOne \\ network internal http://controller:9696 openstack endpoint create --region RegionOne \\ network admin http://controller:9696 C\u00e0i \u0111\u1eb7t package yum --enablerepo=centos-openstack-queens,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch C\u00e0i \u0111\u1eb7t OpenVswitch yum install wget openssl-devel python-sphinx gcc make python-devel openssl-devel kernel-devel graphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool python-twisted-core python-zope-interface PyQt4 desktop-file-utils libcap-ng-devel groff checkpolicy selinux-policy-devel python-six -y useradd ovs su - ovs mkdir -p ~/rpmbuild/SOURCES wget http://openvswitch.org/releases/openvswitch-2.9.2.tar.gz cp openvswitch-2.9.2.tar.gz ~/rpmbuild/SOURCES/ tar xfz openvswitch-2.9.2.tar.gz rpmbuild -bb --nocheck openvswitch-2.9.2/rhel/openvswitch-fedora.spec exit rpm -i /home/ovs/rpmbuild/RPMS/x86_64/openvswitch-2.9.2-1.el7.x86_64.rpm systemctl start openvswitch.service systemctl enable openvswitch.service systemctl status openvswitch.service ovs-vsctl -V C\u1ea5u h\u00ecnh neutron.conf cat << EOF > /etc/neutron/neutron.conf [DEFAULT] service_plugins = router allow_overlapping_ips = True core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh L2 Agent cat << EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch,l2population [ml2_type_vxlan] vni_ranges = 1:300 EOF C\u1ea5u h\u00ecnh Openvswitch Agent ( provider ) cat << EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider local_ip = 192.168.69.130 [agent] tunnel_types = vxlan l2_population = True [securitygroup] firewall_driver = iptables_hybrid EOF C\u1ea5u h\u00ecnh L3 Agent cat << EOF > /etc/neutron/l3_agent.ini [DEFAULT] interface_driver = openvswitch external_network_bridge = EOF C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload C\u1ea5u h\u00ecnh DHCP Agent The DHCP agent provides DHCP services for virtual networks. cat <<EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true EOF C\u1ea5u h\u00ecnh Metadata Agent cat <<EOF > /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh Nova s\u1eed d\u1ee5ng Neutron trong /etc/nova/nova.conf cat <<EOF >>/etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 service_metadata_proxy = true metadata_proxy_shared_secret = metadata_123 EOF Kh\u1edfi t\u1ea1o file c\u1ea5u h\u00ecnh network cho interface provider v\u00e0 bridge cat << EOF > /etc/sysconfig/network-scripts/ifcfg-provider DEVICE=\"br-provider\" TYPE=\"OVSBridge\" SLAVE=\"yes\" BOOTPROTO=\"static\" IPADDR=192.168.30.130 NETMASK=255.255.255.0 GATEWAY=192.168.30.1 DNS1=1.1.1.1 IPV6INIT=\"no\" NM_CONTROLLED=\"yes\" ONBOOT=\"yes\" DEFROUTE=\"yes\" PEERDNS=\"yes\" PEERROUTES=\"yes\" IPV4_FAILURE_FATAL=\"yes\" EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens192 DEVICE=\"ens192\" ONBOOT=\"yes\" TYPE=\"OVSPort\" DEVICETYPE=\"ovs\" OVS_BRIDGE=\"br-provider\" EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-compute Kh\u1edfi t\u1ea1o switch cho L2 Agent ( Provider ) - bridge_mappings = provider:br-provider systemctl start openvswitch systemctl enable openvswitch ovs-vsctl add-br br-provider ovs-vsctl add-port br-provider ens192 systemctl restart network Kh\u1edfi t\u1ea1o Database ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng c\u00e1c agent v\u00e0 service for service in server dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl start neutron-$service systemctl enable neutron-$service done systemctl restart openstack-nova-** C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload Ki\u1ec3m tra c\u00e1c Agent [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 4e897eae-29fc-4e55-bd7d-783f9907e627 | Linux bridge agent | controller | None | XXX | UP | neutron-linuxbridge-agent | | 96b049a4-ca30-4a46-bd0a-c1a062d766c1 | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ C\u00e1c m\u00e1y \u1ea3o \u0111ang s\u1eed d\u1ee5ng \u0111\u01b0\u1eddng provider tr\u00ean compute ra ngo\u00e0i b\u00ecnh th\u01b0\u1eddng [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 4e897eae-29fc-4e55-bd7d-783f9907e627 | Linux bridge agent | controller | None | XXX | UP | neutron-linuxbridge-agent | | 96b049a4-ca30-4a46-bd0a-c1a062d766c1 | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"1. C\u1ea5u h\u00ecnh tr\u00ean Controller Node"},{"location":"Openstack_Research/Neutron/2.1 . OVS-Self-Services/#2_tren_compute_node","text":"C\u00e0i \u0111\u1eb7t package yum install -y openstack-neutron-openvswitch yum remove openstack-neutron-linuxbridge C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh OVS Agent cat << EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] local_ip = 192.168.69.132 [agent] tunnel_types = vxlan l2_population = True EOF T\u1eaft Linux Bridge Agent v\u00e0 kh\u1edfi \u0111\u1ed9ng OVS agent systemctl restart openvswitch.service systemctl restart neutron-openvswitch-agent.service systemctl enable openvswitch.service neutron-openvswitch-agent.service Tr\u1edf v\u1ec1 controller Linux bridge agent v\u00e0 ki\u1ec3m tra danh s\u00e1ch c\u00e1c Agent hi\u1ec7n t\u1ea1i [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 92510ebb-ce51-46a1-aba5-2e83dc05012a | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | c7383988-54af-4342-90f8-5f71073718ec | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +---------------------------","title":"2. Tr\u00ean Compute Node"},{"location":"Openstack_Research/Neutron/2.2. OVS Self-Service-&-Provider/","text":"C\u1ea5u h\u00ecnh b\u1ed5 sung Provider \u00b6 1. C\u1ea5u h\u00ecnh tr\u00ean Controller \u00b6 C\u00e0i \u0111\u1eb7t package yum install -y openstack-neutron openstack-neutron-ml2 C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone dhcp_agents_per_network = 2 ## dhcp_agents_per_network : cho phep cac dhcp agent chay tren cac compute node cung dam nhien cap ip cho mot network C\u1ea5u h\u00ecnh Neutron \u0111\u1ea7y \u0111\u1ee7 cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = auth_strategy = keystone dhcp_agents_per_network = 2 transport_url = rabbit://openstack:rabbitmq_123@controller notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-** C\u1ea5u h\u00ecnh Agent L2 /etc/neutron/plugins/ml2/ml2_conf.ini cat <<EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = provider [ml2_type_vlan] network_vlan_ranges = provider EOF Update Database su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server openstack-nova-api systemctl enable neutron-server openstack-nova-api 2. C\u1ea5u h\u00ecnh tr\u00ean Compute \u00b6 C\u00e0i \u0111\u1eb7t package yum -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone C\u1ea5u h\u00ecnh Neutron \u0111\u1ea7y \u0111\u1ee7 cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-compute C\u1ea5u h\u00ecnh OVS Agent /etc/neutron/plugins/ml2/openvswitch_agent.ini cat <<EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider [securitygroup] firewall_driver = iptables_hybrid EOF C\u1ea5u h\u00ecnh Metadata Agent /etc/neutron/metadata_agent.ini cat << EOF > /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh DHCP Agent cat << EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch enable_isolated_metadata = True force_metadata = True EOF Kh\u1edfi t\u1ea1o br_provider systemctl start openvswitch ovs-vsctl add-br br-provider cat << EOF > /etc/sysconfig/network-scripts/ifcfg-provider DEVICE=\"br-provider\" TYPE=\"OVSBridge\" SLAVE=\"yes\" BOOTPROTO=\"static\" IPADDR=192.168.30.132 NETMASK=255.255.255.0 GATEWAY=192.168.30.1 DNS1=1.1.1.1 IPV6INIT=\"no\" NM_CONTROLLED=\"yes\" ONBOOT=\"yes\" DEFROUTE=\"yes\" PEERDNS=\"yes\" PEERROUTES=\"yes\" IPV4_FAILURE_FATAL=\"yes\" EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens192 DEVICE=\"ens192\" ONBOOT=\"yes\" TYPE=\"OVSPort\" DEVICETYPE=\"ovs\" OVS_BRIDGE=\"br-provider\" EOF ovs-vsctl add-port br-provider ens192 && systemctl restart network Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 for service in metadata-agent dhcp-agent openvswitch-agent do systemctl restart neutron-$service systemctl enable neutron-$service done C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload Ki\u1ec3m tra c\u00e1c agent tr\u00ean controller node [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 2cee612d-aaae-49e3-87ed-4ad6ea0ac3a9 | DHCP agent | compute1 | nova | :-) | UP | neutron-dhcp-agent | | 873b5acb-7c26-495c-be77-a16003322fa9 | DHCP agent | compute2 | nova | :-) | UP | neutron-dhcp-agent | | 92510ebb-ce51-46a1-aba5-2e83dc05012a | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | 95218dcd-eb5e-4fe1-9678-8059882aac31 | Metadata agent | compute1 | None | :-) | UP | neutron-metadata-agent | | a26424d4-9084-42b1-b34a-29d63eb2c5cf | Metadata agent | compute2 | None | :-) | UP | neutron-metadata-agent | | c7383988-54af-4342-90f8-5f71073718ec | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"2.2. OVS Self Service & Provider"},{"location":"Openstack_Research/Neutron/2.2. OVS Self-Service-&-Provider/#cau_hinh_bo_sung_provider","text":"","title":"C\u1ea5u h\u00ecnh b\u1ed5 sung Provider"},{"location":"Openstack_Research/Neutron/2.2. OVS Self-Service-&-Provider/#1_cau_hinh_tren_controller","text":"C\u00e0i \u0111\u1eb7t package yum install -y openstack-neutron openstack-neutron-ml2 C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone dhcp_agents_per_network = 2 ## dhcp_agents_per_network : cho phep cac dhcp agent chay tren cac compute node cung dam nhien cap ip cho mot network C\u1ea5u h\u00ecnh Neutron \u0111\u1ea7y \u0111\u1ee7 cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = auth_strategy = keystone dhcp_agents_per_network = 2 transport_url = rabbit://openstack:rabbitmq_123@controller notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [database] connection = mysql+pymysql://neutron:neutron_123@controller/neutron [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [nova] auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = nova_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-** C\u1ea5u h\u00ecnh Agent L2 /etc/neutron/plugins/ml2/ml2_conf.ini cat <<EOF > /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = provider [ml2_type_vlan] network_vlan_ranges = provider EOF Update Database su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 systemctl restart neutron-server openstack-nova-api systemctl enable neutron-server openstack-nova-api","title":"1. C\u1ea5u h\u00ecnh tr\u00ean Controller"},{"location":"Openstack_Research/Neutron/2.2. OVS Self-Service-&-Provider/#2_cau_hinh_tren_compute","text":"C\u00e0i \u0111\u1eb7t package yum -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch C\u1ea5u h\u00ecnh /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone C\u1ea5u h\u00ecnh Neutron \u0111\u1ea7y \u0111\u1ee7 cat << EOF > /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:rabbitmq_123@controller auth_strategy = keystone [keystone_authtoken] auth_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = neutron_123 [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF C\u1ea5u h\u00ecnh Nova cat <<EOF >> /etc/nova/nova.conf [neutron] url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron_123 EOF systemctl restart openstack-nova-compute C\u1ea5u h\u00ecnh OVS Agent /etc/neutron/plugins/ml2/openvswitch_agent.ini cat <<EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs] bridge_mappings = provider:br-provider [securitygroup] firewall_driver = iptables_hybrid EOF C\u1ea5u h\u00ecnh Metadata Agent /etc/neutron/metadata_agent.ini cat << EOF > /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_123 EOF C\u1ea5u h\u00ecnh DHCP Agent cat << EOF > /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch enable_isolated_metadata = True force_metadata = True EOF Kh\u1edfi t\u1ea1o br_provider systemctl start openvswitch ovs-vsctl add-br br-provider cat << EOF > /etc/sysconfig/network-scripts/ifcfg-provider DEVICE=\"br-provider\" TYPE=\"OVSBridge\" SLAVE=\"yes\" BOOTPROTO=\"static\" IPADDR=192.168.30.132 NETMASK=255.255.255.0 GATEWAY=192.168.30.1 DNS1=1.1.1.1 IPV6INIT=\"no\" NM_CONTROLLED=\"yes\" ONBOOT=\"yes\" DEFROUTE=\"yes\" PEERDNS=\"yes\" PEERROUTES=\"yes\" IPV4_FAILURE_FATAL=\"yes\" EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens192 DEVICE=\"ens192\" ONBOOT=\"yes\" TYPE=\"OVSPort\" DEVICETYPE=\"ovs\" OVS_BRIDGE=\"br-provider\" EOF ovs-vsctl add-port br-provider ens192 && systemctl restart network Kh\u1edfi \u0111\u1ed9ng l\u1ea1i d\u1ecbch v\u1ee5 for service in metadata-agent dhcp-agent openvswitch-agent do systemctl restart neutron-$service systemctl enable neutron-$service done C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=9696/tcp --permanent firewall-cmd --reload Ki\u1ec3m tra c\u00e1c agent tr\u00ean controller node [root@controller ~]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 1330a4b7-6142-4960-8a9a-3e2e92c2cce1 | Open vSwitch agent | controller | None | :-) | UP | neutron-openvswitch-agent | | 13817d05-5a3a-4ccf-8beb-eba92d01fc1c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 2cee612d-aaae-49e3-87ed-4ad6ea0ac3a9 | DHCP agent | compute1 | nova | :-) | UP | neutron-dhcp-agent | | 873b5acb-7c26-495c-be77-a16003322fa9 | DHCP agent | compute2 | nova | :-) | UP | neutron-dhcp-agent | | 92510ebb-ce51-46a1-aba5-2e83dc05012a | Open vSwitch agent | compute1 | None | :-) | UP | neutron-openvswitch-agent | | 95218dcd-eb5e-4fe1-9678-8059882aac31 | Metadata agent | compute1 | None | :-) | UP | neutron-metadata-agent | | a26424d4-9084-42b1-b34a-29d63eb2c5cf | Metadata agent | compute2 | None | :-) | UP | neutron-metadata-agent | | c7383988-54af-4342-90f8-5f71073718ec | Open vSwitch agent | compute2 | None | :-) | UP | neutron-openvswitch-agent | | e05b5756-b54a-48a7-8cb8-384f31ed56b8 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e20dc1c0-85da-427a-987b-a65984d9af42 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"2. C\u1ea5u h\u00ecnh tr\u00ean Compute"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/","text":"L\u00e0m vi\u1ec7c v\u1edbi Neutron \u00b6 1. Kh\u1edfi t\u1ea1o Network , Router, Port, Floating IP \u00b6 Kh\u1edfi t\u1ea1o external network [root@controller ~]# openstack network create --share --provider-network-type flat --provider-physical-network provider net_ex +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:30:54Z | | description | | | dns_domain | None | | id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | net_ex | | port_security_enabled | True | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | True | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2018-11-12T01:30:54Z | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Subnet cho external network [root@controller ~]# openstack subnet create --subnet-range 192.168.30.0/24 --dhcp --gateway 192.168.30.1 --network net_ex --allocation-pool start=192.168.30.140,end=192.168.30.160 --dns-nameserver 1.1.1.1 subnet1_ex_net +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | allocation_pools | 192.168.30.140-192.168.30.160 | | cidr | 192.168.30.0/24 | | created_at | 2018-11-12T01:35:51Z | | description | | | dns_nameservers | 1.1.1.1 | | enable_dhcp | True | | gateway_ip | 192.168.30.1 | | host_routes | | | id | a8dea47b-2ba5-492b-94ce-263d0a197b4a | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | subnet1_ex_net | | network_id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2018-11-12T01:35:51Z | +-------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t Sefl-Service Network [root@controller ~]# openstack network create self_net +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:41:33Z | | description | | | dns_domain | None | | id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1450 | | name | self_net | | port_security_enabled | True | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | provider:network_type | vxlan | | provider:physical_network | None | | provider:segmentation_id | 78 | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2018-11-12T01:41:33Z | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o subnet cho self-service network [root@controller neutron]# openstack subnet create --subnet-range 172.16.1.0/24 --gateway 172.16.1.1 --dns-nameserver 1.1.1.1 --network self_net subnet_self_net +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | allocation_pools | 172.16.1.2-172.16.1.254 | | cidr | 172.16.1.0/24 | | created_at | 2018-11-12T02:24:11Z | | description | | | dns_nameservers | 1.1.1.1 | | enable_dhcp | True | | gateway_ip | 172.16.1.1 | | host_routes | | | id | 5255ad53-bd97-49fa-8bdc-279ff971ca10 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | subnet_self_net | | network_id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2018-11-12T02:24:11Z | +-------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t router [root@controller ~]# openstack router create router1 +-------------------------+--------------------------------------+ | Field | Value | +-------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:56:30Z | | description | | | distributed | False | | external_gateway_info | None | | flavor_id | None | | ha | False | | id | 89b1fb9f-0347-46f3-bf08-c5c561a6c7a4 | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T01:56:30Z | +-------------------------+--------------------------------------+ G\u1eafn external network l\u00e0m gateway \u0111\u1ec3 truy c\u1eadp internet , c\u00f2n c\u00e1c m\u1ea1ng self-service c\u1eafm v\u00e0o c\u00e1c interface \u0111\u1ec3 tham gia \u0111\u1ecbnh tuy\u1ebfn openstack network set --external net_ex openstack router set router1 --external-gateway net_ex openstack router add subnet router1 subnet_self_net Xem th\u00f4ng tin router v\u1eeba kh\u1edfi t\u1ea1o [root@controller neutron]# openstack router show router1 +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-11-12T02:04:13Z | | description | | | distributed | False | | external_gateway_info | {\"network_id\": \"355f6ca6-15f7-4121-a82b-6ee6f4d5fea3\", \"enable_snat\": true, \"external_fixed_ips\": [{\"subnet_id\": \"a8dea47b-2ba5-492b-94ce-263d0a197b4a\", \"ip_address\": \"192.168.30.145\"}]} | | flavor_id | None | | ha | False | | id | 32fe6f32-5bb6-4a89-a24f-df34124e8c76 | | interfaces_info | [{\"subnet_id\": \"5255ad53-bd97-49fa-8bdc-279ff971ca10\", \"ip_address\": \"172.16.1.1\", \"port_id\": \"94e669bc-adde-47d2-9b49-6dd57b1ec189\"}] | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 13 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T02:24:39Z | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Li\u1ec7t k\u00ea c\u00e1c port [root@controller neutron]# openstack port list +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ | ID | Name | MAC Address | Fixed IP Addresses | Status | +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ | 9175a03d-7d47-4b57-966c-30bbf1cfa845 | | fa:16:3e:65:f7:8c | ip_address='172.16.1.2', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | ACTIVE | | 94e669bc-adde-47d2-9b49-6dd57b1ec189 | | fa:16:3e:12:2d:c7 | ip_address='172.16.1.1', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | ACTIVE | | ab735c5b-426f-4d69-977b-7c305f772980 | | fa:16:3e:2d:ea:66 | ip_address='192.168.30.145', subnet_id='a8dea47b-2ba5-492b-94ce-263d0a197b4a' | ACTIVE | | fc83c1c9-13e9-483a-a39f-d98872648c82 | | fa:16:3e:ae:ea:40 | ip_address='192.168.30.140', subnet_id='a8dea47b-2ba5-492b-94ce-263d0a197b4a' | ACTIVE | +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ Xem th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t Port [root@controller neutron]# openstack port show 9175a03d-7d47-4b57-966c-30bbf1cfa845 +-----------------------+-------------------------------------------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | | | binding_host_id | controller | | binding_profile | | | binding_vif_details | port_filter='True' | | binding_vif_type | bridge | | binding_vnic_type | normal | | created_at | 2018-11-12T02:24:12Z | | data_plane_status | None | | description | | | device_id | dhcpd3377d3c-a0d1-5d71-9947-f17125c357bb-7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | device_owner | network:dhcp | | dns_assignment | None | | dns_name | None | | extra_dhcp_opts | | | fixed_ips | ip_address='172.16.1.2', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | | id | 9175a03d-7d47-4b57-966c-30bbf1cfa845 | | ip_address | None | | mac_address | fa:16:3e:65:f7:8c | | name | | | network_id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | option_name | None | | option_value | None | | port_security_enabled | False | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | qos_policy_id | None | | revision_number | 7 | | security_group_ids | | | status | ACTIVE | | subnet_id | None | | tags | | | trunk_details | None | | updated_at | 2018-11-12T02:24:17Z | +-----------------------+-------------------------------------------------------------------------------+ Kh\u1edfi t\u1ea1o Floating IP , g\u1eafn Floating IP \u0111\u1ebfn cho c\u00e1c instance v\u1edbi c\u00e1c IP t\u1eeb ISP \u0111\u1ec3 c\u00f3 th\u1ec3 truy c\u1eadp t\u1eeb ngo\u00e0i internet s\u1eed d\u1ee5ng DNAT [root@controller neutron]# openstack floating ip create net_ex +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | created_at | 2018-11-12T02:33:25Z | | description | | | fixed_ip_address | None | | floating_ip_address | 192.168.30.142 | | floating_network_id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | id | 78f10521-fc1d-4f0f-af0e-49b209073261 | | name | 192.168.30.142 | | port_id | None | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | updated_at | 2018-11-12T02:33:25Z | +---------------------+--------------------------------------+ 2. X\u00f3a Router, Subnet, Network \u00b6 2.1. X\u00f3a Self-Service Subnet \u0111ang Binding Router \u00b6 \u0110\u1ec3 x\u00f3a m\u1ed9t subnet \u0111ang g\u1eafn v\u00e0o m\u1ed9t router c\u1ea7n x\u00f3a subnet \u0111\u00f3 kh\u1ecfi router \u0111\u1ec3 x\u00f3a c\u00e1c port \u0111ang \u0111c binding Xem router n\u00e0o \u0111ang ch\u1ee9a subnet [root@controller neutron]# openstack router show router1 +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-11-12T02:04:13Z | | description | | | distributed | False | | external_gateway_info | {\"network_id\": \"355f6ca6-15f7-4121-a82b-6ee6f4d5fea3\", \"enable_snat\": true, \"external_fixed_ips\": [{\"subnet_id\": \"a8dea47b-2ba5-492b-94ce-263d0a197b4a\", \"ip_address\": \"192.168.30.145\"}]} | | flavor_id | None | | ha | False | | id | 32fe6f32-5bb6-4a89-a24f-df34124e8c76 | | interfaces_info | [{\"subnet_id\": \"5255ad53-bd97-49fa-8bdc-279ff971ca10\", \"ip_address\": \"172.16.1.1\", \"port_id\": \"94e669bc-adde-47d2-9b49-6dd57b1ec189\"}] | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 13 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T02:24:39Z | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ X\u00f3a Subnet ra kh\u1edfi router [root@controller]# openstack router remove subnet router1 5255ad53-bd97-49fa-8bdc-279ff971ca10 X\u00f3a Subnet [root@controller neutron]# openstack subnet delete 5255ad53-bd97-49fa-8bdc-279ff971ca10 2.2. X\u00f3a Self-service Network \u00b6 Khi x\u00f3a m\u1ed9t Network th\u00ec s\u1ebd x\u00f3a c\u00e1c Subnet \u0111ang binding v\u00e0o [root@controller]# openstack network list +--------------------------------------+----------+----------------------------------------------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------+----------------------------------------------------------------------------+ | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | net_ex | a8dea47b-2ba5-492b-94ce-263d0a197b4a | | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | self_net | 06dd5897-280a-496c-90ad-0608e2d663ac, d73d8c19-290f-4e59-bb8d-38284136c3ca | +--------------------------------------+----------+----------------------------------------------------------------------------+ [root@controller]# openstack network delete 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 [root@controller neutron]# 3. Qu\u1ea3n l\u00fd Security Group \u00b6 Security Group \u0111\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 filter nh\u01b0 iptables [root@controller neutron]# openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 9373ec3c823343de87ae613b972aa4d3 | admin | | e66cc62b00304934a61f929704ea5320 | service | +----------------------------------+---------+ [root@controller neutron]# openstack security group list +--------------------------------------+---------+------------------------+----------------------------------+ | ID | Name | Description | Project | +--------------------------------------+---------+------------------------+----------------------------------+ | 3e5cf3f1-1a13-4427-8b5a-d5fcc7d30690 | default | Default security group | | | 9b14072f-0061-4805-8b18-e87c7c22cb38 | default | Default security group | 9373ec3c823343de87ae613b972aa4d3 | +--------------------------------------+---------+------------------------+----------------------------------+ Xem th\u00f4ng tin c\u1ee7a m\u1ed9t security group [root@controller neutron]# openstack security group show 9b14072f-0061-4805-8b18-e87c7c22cb38 +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2018-11-12T01:30:53Z | | description | Default security group | | id | 9b14072f-0061-4805-8b18-e87c7c22cb38 | | name | default | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 4 | | rules | created_at='2018-11-12T01:30:53Z', direction='ingress', ethertype='IPv6', id='1d324537-0b8c-4ef4-952d-64f0e698a54f', remote_group_id='9b14072f-0061-4805-8b18-e87c7c22cb38', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='egress', ethertype='IPv4', id='4a823012-a991-49bc-a5d9-a0adb4ae524d', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='egress', ethertype='IPv6', id='70cfc983-dac3-4113-b0b8-c0e522532e91', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='ingress', ethertype='IPv4', id='a421e093-d749-4c10-9cca-12744887bc21', remote_group_id='9b14072f-0061-4805-8b18-e87c7c22cb38', updated_at='2018-11-12T01:30:53Z' | | updated_at | 2018-11-12T01:30:53Z | +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Nh\u01b0 v\u1eady \u0111\u00e3 c\u00f3 m\u1ed9t sececurity \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean project admin Kh\u1edfi t\u1ea1o m\u1ed9t rule m\u1edbi [root@controller neutron]# openstack security group rule create --protocol tcp --dst-port 22 --project admin 9b14072f-0061-4805-8b18-e87c7c22cb38 +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | created_at | 2018-11-12T03:08:10Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | a4708c13-7e9e-44fa-904e-4c6a0a9f97f0 | | name | None | | port_range_max | 22 | | port_range_min | 22 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | protocol | tcp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 9b14072f-0061-4805-8b18-e87c7c22cb38 | | updated_at | 2018-11-12T03:08:10Z | +-------------------+--------------------------------------+","title":"L\u00e0m vi\u1ec7c v\u1edbi Neutron"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#lam_viec_voi_neutron","text":"","title":"L\u00e0m vi\u1ec7c v\u1edbi Neutron"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#1_khoi_tao_network_router_port_floating_ip","text":"Kh\u1edfi t\u1ea1o external network [root@controller ~]# openstack network create --share --provider-network-type flat --provider-physical-network provider net_ex +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:30:54Z | | description | | | dns_domain | None | | id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | net_ex | | port_security_enabled | True | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | True | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2018-11-12T01:30:54Z | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o Subnet cho external network [root@controller ~]# openstack subnet create --subnet-range 192.168.30.0/24 --dhcp --gateway 192.168.30.1 --network net_ex --allocation-pool start=192.168.30.140,end=192.168.30.160 --dns-nameserver 1.1.1.1 subnet1_ex_net +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | allocation_pools | 192.168.30.140-192.168.30.160 | | cidr | 192.168.30.0/24 | | created_at | 2018-11-12T01:35:51Z | | description | | | dns_nameservers | 1.1.1.1 | | enable_dhcp | True | | gateway_ip | 192.168.30.1 | | host_routes | | | id | a8dea47b-2ba5-492b-94ce-263d0a197b4a | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | subnet1_ex_net | | network_id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2018-11-12T01:35:51Z | +-------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t Sefl-Service Network [root@controller ~]# openstack network create self_net +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:41:33Z | | description | | | dns_domain | None | | id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1450 | | name | self_net | | port_security_enabled | True | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | provider:network_type | vxlan | | provider:physical_network | None | | provider:segmentation_id | 78 | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2018-11-12T01:41:33Z | +---------------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o subnet cho self-service network [root@controller neutron]# openstack subnet create --subnet-range 172.16.1.0/24 --gateway 172.16.1.1 --dns-nameserver 1.1.1.1 --network self_net subnet_self_net +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | allocation_pools | 172.16.1.2-172.16.1.254 | | cidr | 172.16.1.0/24 | | created_at | 2018-11-12T02:24:11Z | | description | | | dns_nameservers | 1.1.1.1 | | enable_dhcp | True | | gateway_ip | 172.16.1.1 | | host_routes | | | id | 5255ad53-bd97-49fa-8bdc-279ff971ca10 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | subnet_self_net | | network_id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2018-11-12T02:24:11Z | +-------------------+--------------------------------------+ Kh\u1edfi t\u1ea1o m\u1ed9t router [root@controller ~]# openstack router create router1 +-------------------------+--------------------------------------+ | Field | Value | +-------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2018-11-12T01:56:30Z | | description | | | distributed | False | | external_gateway_info | None | | flavor_id | None | | ha | False | | id | 89b1fb9f-0347-46f3-bf08-c5c561a6c7a4 | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T01:56:30Z | +-------------------------+--------------------------------------+ G\u1eafn external network l\u00e0m gateway \u0111\u1ec3 truy c\u1eadp internet , c\u00f2n c\u00e1c m\u1ea1ng self-service c\u1eafm v\u00e0o c\u00e1c interface \u0111\u1ec3 tham gia \u0111\u1ecbnh tuy\u1ebfn openstack network set --external net_ex openstack router set router1 --external-gateway net_ex openstack router add subnet router1 subnet_self_net Xem th\u00f4ng tin router v\u1eeba kh\u1edfi t\u1ea1o [root@controller neutron]# openstack router show router1 +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-11-12T02:04:13Z | | description | | | distributed | False | | external_gateway_info | {\"network_id\": \"355f6ca6-15f7-4121-a82b-6ee6f4d5fea3\", \"enable_snat\": true, \"external_fixed_ips\": [{\"subnet_id\": \"a8dea47b-2ba5-492b-94ce-263d0a197b4a\", \"ip_address\": \"192.168.30.145\"}]} | | flavor_id | None | | ha | False | | id | 32fe6f32-5bb6-4a89-a24f-df34124e8c76 | | interfaces_info | [{\"subnet_id\": \"5255ad53-bd97-49fa-8bdc-279ff971ca10\", \"ip_address\": \"172.16.1.1\", \"port_id\": \"94e669bc-adde-47d2-9b49-6dd57b1ec189\"}] | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 13 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T02:24:39Z | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Li\u1ec7t k\u00ea c\u00e1c port [root@controller neutron]# openstack port list +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ | ID | Name | MAC Address | Fixed IP Addresses | Status | +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ | 9175a03d-7d47-4b57-966c-30bbf1cfa845 | | fa:16:3e:65:f7:8c | ip_address='172.16.1.2', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | ACTIVE | | 94e669bc-adde-47d2-9b49-6dd57b1ec189 | | fa:16:3e:12:2d:c7 | ip_address='172.16.1.1', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | ACTIVE | | ab735c5b-426f-4d69-977b-7c305f772980 | | fa:16:3e:2d:ea:66 | ip_address='192.168.30.145', subnet_id='a8dea47b-2ba5-492b-94ce-263d0a197b4a' | ACTIVE | | fc83c1c9-13e9-483a-a39f-d98872648c82 | | fa:16:3e:ae:ea:40 | ip_address='192.168.30.140', subnet_id='a8dea47b-2ba5-492b-94ce-263d0a197b4a' | ACTIVE | +--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+ Xem th\u00f4ng tin c\u1ee5 th\u1ec3 c\u1ee7a m\u1ed9t Port [root@controller neutron]# openstack port show 9175a03d-7d47-4b57-966c-30bbf1cfa845 +-----------------------+-------------------------------------------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | | | binding_host_id | controller | | binding_profile | | | binding_vif_details | port_filter='True' | | binding_vif_type | bridge | | binding_vnic_type | normal | | created_at | 2018-11-12T02:24:12Z | | data_plane_status | None | | description | | | device_id | dhcpd3377d3c-a0d1-5d71-9947-f17125c357bb-7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | device_owner | network:dhcp | | dns_assignment | None | | dns_name | None | | extra_dhcp_opts | | | fixed_ips | ip_address='172.16.1.2', subnet_id='5255ad53-bd97-49fa-8bdc-279ff971ca10' | | id | 9175a03d-7d47-4b57-966c-30bbf1cfa845 | | ip_address | None | | mac_address | fa:16:3e:65:f7:8c | | name | | | network_id | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | | option_name | None | | option_value | None | | port_security_enabled | False | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | qos_policy_id | None | | revision_number | 7 | | security_group_ids | | | status | ACTIVE | | subnet_id | None | | tags | | | trunk_details | None | | updated_at | 2018-11-12T02:24:17Z | +-----------------------+-------------------------------------------------------------------------------+ Kh\u1edfi t\u1ea1o Floating IP , g\u1eafn Floating IP \u0111\u1ebfn cho c\u00e1c instance v\u1edbi c\u00e1c IP t\u1eeb ISP \u0111\u1ec3 c\u00f3 th\u1ec3 truy c\u1eadp t\u1eeb ngo\u00e0i internet s\u1eed d\u1ee5ng DNAT [root@controller neutron]# openstack floating ip create net_ex +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | created_at | 2018-11-12T02:33:25Z | | description | | | fixed_ip_address | None | | floating_ip_address | 192.168.30.142 | | floating_network_id | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | | id | 78f10521-fc1d-4f0f-af0e-49b209073261 | | name | 192.168.30.142 | | port_id | None | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | updated_at | 2018-11-12T02:33:25Z | +---------------------+--------------------------------------+","title":"1. Kh\u1edfi t\u1ea1o Network , Router, Port, Floating IP"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#2_xoa_router_subnet_network","text":"","title":"2. X\u00f3a Router, Subnet, Network"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#21_xoa_self-service_subnet_ang_binding_router","text":"\u0110\u1ec3 x\u00f3a m\u1ed9t subnet \u0111ang g\u1eafn v\u00e0o m\u1ed9t router c\u1ea7n x\u00f3a subnet \u0111\u00f3 kh\u1ecfi router \u0111\u1ec3 x\u00f3a c\u00e1c port \u0111ang \u0111c binding Xem router n\u00e0o \u0111ang ch\u1ee9a subnet [root@controller neutron]# openstack router show router1 +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2018-11-12T02:04:13Z | | description | | | distributed | False | | external_gateway_info | {\"network_id\": \"355f6ca6-15f7-4121-a82b-6ee6f4d5fea3\", \"enable_snat\": true, \"external_fixed_ips\": [{\"subnet_id\": \"a8dea47b-2ba5-492b-94ce-263d0a197b4a\", \"ip_address\": \"192.168.30.145\"}]} | | flavor_id | None | | ha | False | | id | 32fe6f32-5bb6-4a89-a24f-df34124e8c76 | | interfaces_info | [{\"subnet_id\": \"5255ad53-bd97-49fa-8bdc-279ff971ca10\", \"ip_address\": \"172.16.1.1\", \"port_id\": \"94e669bc-adde-47d2-9b49-6dd57b1ec189\"}] | | name | router1 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 13 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2018-11-12T02:24:39Z | +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ X\u00f3a Subnet ra kh\u1edfi router [root@controller]# openstack router remove subnet router1 5255ad53-bd97-49fa-8bdc-279ff971ca10 X\u00f3a Subnet [root@controller neutron]# openstack subnet delete 5255ad53-bd97-49fa-8bdc-279ff971ca10","title":"2.1. X\u00f3a Self-Service Subnet \u0111ang Binding Router"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#22_xoa_self-service_network","text":"Khi x\u00f3a m\u1ed9t Network th\u00ec s\u1ebd x\u00f3a c\u00e1c Subnet \u0111ang binding v\u00e0o [root@controller]# openstack network list +--------------------------------------+----------+----------------------------------------------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------+----------------------------------------------------------------------------+ | 355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 | net_ex | a8dea47b-2ba5-492b-94ce-263d0a197b4a | | 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 | self_net | 06dd5897-280a-496c-90ad-0608e2d663ac, d73d8c19-290f-4e59-bb8d-38284136c3ca | +--------------------------------------+----------+----------------------------------------------------------------------------+ [root@controller]# openstack network delete 7aeda55f-6845-4dd1-a9c6-436d4ea5ab09 [root@controller neutron]#","title":"2.2. X\u00f3a  Self-service Network"},{"location":"Openstack_Research/Neutron/3. Neutron-CLI/#3_quan_ly_security_group","text":"Security Group \u0111\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 filter nh\u01b0 iptables [root@controller neutron]# openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 9373ec3c823343de87ae613b972aa4d3 | admin | | e66cc62b00304934a61f929704ea5320 | service | +----------------------------------+---------+ [root@controller neutron]# openstack security group list +--------------------------------------+---------+------------------------+----------------------------------+ | ID | Name | Description | Project | +--------------------------------------+---------+------------------------+----------------------------------+ | 3e5cf3f1-1a13-4427-8b5a-d5fcc7d30690 | default | Default security group | | | 9b14072f-0061-4805-8b18-e87c7c22cb38 | default | Default security group | 9373ec3c823343de87ae613b972aa4d3 | +--------------------------------------+---------+------------------------+----------------------------------+ Xem th\u00f4ng tin c\u1ee7a m\u1ed9t security group [root@controller neutron]# openstack security group show 9b14072f-0061-4805-8b18-e87c7c22cb38 +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2018-11-12T01:30:53Z | | description | Default security group | | id | 9b14072f-0061-4805-8b18-e87c7c22cb38 | | name | default | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | revision_number | 4 | | rules | created_at='2018-11-12T01:30:53Z', direction='ingress', ethertype='IPv6', id='1d324537-0b8c-4ef4-952d-64f0e698a54f', remote_group_id='9b14072f-0061-4805-8b18-e87c7c22cb38', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='egress', ethertype='IPv4', id='4a823012-a991-49bc-a5d9-a0adb4ae524d', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='egress', ethertype='IPv6', id='70cfc983-dac3-4113-b0b8-c0e522532e91', updated_at='2018-11-12T01:30:53Z' | | | created_at='2018-11-12T01:30:53Z', direction='ingress', ethertype='IPv4', id='a421e093-d749-4c10-9cca-12744887bc21', remote_group_id='9b14072f-0061-4805-8b18-e87c7c22cb38', updated_at='2018-11-12T01:30:53Z' | | updated_at | 2018-11-12T01:30:53Z | +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Nh\u01b0 v\u1eady \u0111\u00e3 c\u00f3 m\u1ed9t sececurity \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean project admin Kh\u1edfi t\u1ea1o m\u1ed9t rule m\u1edbi [root@controller neutron]# openstack security group rule create --protocol tcp --dst-port 22 --project admin 9b14072f-0061-4805-8b18-e87c7c22cb38 +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | created_at | 2018-11-12T03:08:10Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | a4708c13-7e9e-44fa-904e-4c6a0a9f97f0 | | name | None | | port_range_max | 22 | | port_range_min | 22 | | project_id | 9373ec3c823343de87ae613b972aa4d3 | | protocol | tcp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 9b14072f-0061-4805-8b18-e87c7c22cb38 | | updated_at | 2018-11-12T03:08:10Z | +-------------------+--------------------------------------+","title":"3. Qu\u1ea3n l\u00fd Security Group"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/","text":"T\u00ccm hi\u1ec3u Namepsace , DHCP, Agent trong OPS \u00b6 1. Overlapping network trong OPS \u00b6 Overlapping \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t m\u1ea1ng m\u00e1y t\u00ednh \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng tr\u00ean m\u1ed9t n\u1ec1n t\u1ea3ng network m\u1ea1ng s\u1eb5n Openstack cung c\u1ea5p m\u00f4i tr\u01b0\u1eddng Multi Tenant . M\u1ed7i tenant cung c\u1ea5p m\u1ed9t m\u1ea1ng prviate , router, firewall , loadblancer ri\u00eang . Nh\u1edd namepsace cung c\u1ea5p kh\u1ea3 n\u0103ng t\u00e1ch bi\u1ebft c\u00e1c t\u00e0i nguy\u00ean m\u1ea1ng gi\u1eefa c\u00e1c tenant - network namespace \u0110\u1ec3 xem \u0111\u01b0\u1ee3c namepsace c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng [root@controller nova]# ip netns list qrouter-32fe6f32-5bb6-4a89-a24f-df34124e8c76 (id: 2) qdhcp-355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 (id: 0) [root@controller nova]# C\u00e1c namespace hi\u1ec3n th\u1ecb d\u01b0\u1edbi d\u1ea1ng qdhcp-* qrouter-* qlbaas-* \u0110\u1ec3 th\u1ef1c hi\u1ec7n m\u1ed9t comman tr\u00ean m\u1ed9t namespace c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng [root@controller nova]# ip netns exec qrouter-32fe6f32-5bb6-4a89-a24f-df34124e8c76 ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. 64 bytes from 1.1.1.1: icmp_seq=1 ttl=57 time=37.3 ms 64 bytes from 1.1.1.1: icmp_seq=2 ttl=57 time=37.7 ms 64 bytes from 1.1.1.1: icmp_seq=3 ttl=57 time=38.3 ms 64 bytes from 1.1.1.1: icmp_seq=4 ttl=57 time=38.8 ms 64 bytes from 1.1.1.1: icmp_seq=5 ttl=57 time=37.4 ms ^C --- 1.1.1.1 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4001ms rtt min/avg/max/mdev = 37.317/37.923/38.822/0.601 ms Nh\u01b0 v\u1eady router \u0111\u00e3 t\u1ea1o t\u1eeb tr\u01b0\u1edbc, g\u1eafn network net_ex \u0111\u00e3 c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi internet Khi m\u1ed9t namespace kh\u1edfi t\u1ea1o , neutron c\u0169ng kh\u1edfi t\u1ea1o \u0111\u1ed3ng th\u1eddi m\u1ed9t DHCP and routing service cho t\u1eebng network ri\u00eang bi\u1ec7t. Namespace qdhcp ch\u1ee9a DHCP Service cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP cho c\u00e1c instance s\u1eed d\u1ee5ng DHCP Protocol . Trong qu\u00e1 th\u1ef1c hi\u1ec7n, dnsmasq \u0111\u1ea3m nhi\u1ec7m x\u1eed l\u00fd c\u00e1c DHCP Request . qdhcp namespace nh\u01b0 m\u1ed9t host \u1ea3o, \u0111\u01b0\u1ee3c c\u1eafm v\u00e0o m\u1ed9t interface trong virtual switch, do \u0111\u00f3 s\u1ebd c\u00f3 kh\u1ea3 n\u0103ng k\u1ebft n\u1ed1i v\u1edbi c\u00e1c instance \u0111\u00e3 \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o network n\u00e0o \u0111\u00f3. Namesapce qrouter nh\u01b0 m\u1ed9t router \u1ea3o , v\u00e0 \u0111\u1ea3m nhi\u1ec7m routing t\u1eeb c\u00e1c instance \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o network . Router \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c network kh\u00e1c nhau c\u00f3 th\u1ec3 routing gi\u1eefa c\u00e1c m\u1ea1ng2 2. Neutron Agent \u00b6 M\u1ed9t agent trong neutron \u0111\u1ea3m nhi\u1ec7m c\u00e1c nhi\u1ec7m v\u1ee5 kh\u00e1c nhau \u0111\u1ec3 t\u00e1c \u0111\u1ed9ng t\u1edbi c\u00e1c m\u1ea1ng \u1ea3o . Trong neutron g\u1ed3m c\u00e1c agent c\u01a1 b\u1ea3n sau : neutron-dhcp-agent, neutron-l3-agent, neutron-metering-agent, and neutron-lbaas-agent, C\u00e1c agent c\u01a1 b\u1ea3n khi khi tri\u1ec3n khai self-service network [root@controller nova]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | b68cd06e-384f-47d7-88e4-dd5a6a85796c | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | c4eb82a1-d86a-4eb8-a230-f62b567d4df8 | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | ce13fbcc-e0e6-4b55-87cd-7bdfe58ce357 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e2279058-9cad-4e05-801d-51a8f16b6850 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | f7fc3ab5-35c5-4968-a349-79ba6820d25a | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ 2.1 : ML2 plugin , agent \u00b6 Modular Layer 2 (ml2) cung c\u1ea5p m\u1ed9t framework cho ph\u00e9p neutron t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c h\u1ea1 t\u1ea7ng Layer 2 hi\u1ec7n \u0111ang c\u00f3 trong c\u00e1c DC. Ml2 framework g\u1ed3m c\u00f3 2 driver ri\u00eang bi\u1ec7t Type driver : gi\u00fap neutron x\u00e1c \u0111inh \u0111\u01b0\u1ee3c c\u00f4ng ngh\u1ec7 s\u1eed d\u1ee5ng : V\u00ed d\u1ee5 nh\u01b0 VLAN . V\u1edbi m\u1ed7i ki\u1ec3u network \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi ML2 Type Driver , x\u00e1c \u0111\u1ecbnh tr\u1ea1ng th\u00e1i m\u1ea1ng c\u1ee5 th\u1ec3 v\u00e0 ch\u1ecbu tr\u00e1ch nhi\u1ec7m cho c\u00e1c segment layer 2 Mechanism drivers : gi\u00fap neutron x\u00e1c \u0111\u1ecbnh r\u00f5 r\u00e0ng c\u00e1c l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t lo\u1ea1i m\u1ea1ng c\u1ee5 th\u1ec3 . Type driver cung c\u1ea5p m\u1ea1ng qu\u1ea3n l\u00fd sau \u0111\u00f3 Mechanism driver s\u1ebd \u0111\u1ebfn c\u00e1c device \u1edf ngo\u00e0i \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t m\u1ea1ng n\u00e0o \u0111\u00f3 . L2 agent serves ph\u1ee5c v\u1ee5 kh\u1ea3 n\u0103ng l\u00e0m vi\u1ec7c v\u1edbi Layer 2. Th\u01b0\u1eddng n\u0103m tr\u00ean Network Node v\u00e0 tr\u00ean m\u1ed7i Compute Node 2.2 : L3 Agent \u00b6 Cung c\u1ea5p kh\u1ea3 n\u0103ng l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c d\u1ecbch v\u1ee5 Layer 3 : virtual Routers v\u00e0 Floating IP Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent 2.3. DHCP agent \u00b6 \u0110\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 DHCP . Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent 2.4. Meta Data agent \u00b6 Cung c\u1ea5p kh\u1ea3 g\u1eedi c\u00e1c cloud init data t\u1edbi c\u00e1c instance th\u00f4ng tin network Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent 3. Tham kh\u1ea3o th\u00eam \u00b6 T\u00ccm hi\u1ec3u th\u00eam t\u1ea1i : [1] : https://objects-east.cloud.ca/v1/5ef827605f884961b94881e928e7a250/crivera/AYCE%20Neutron.pdf [2] : https://dischord.org/2015/03/09/troubleshooting-openstack-neutron-networking-part-one/","title":"T\u00ccm hi\u1ec3u Namepsace , DHCP, Agent trong OPS"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#tim_hieu_namepsace_dhcp_agent_trong_ops","text":"","title":"T\u00ccm hi\u1ec3u Namepsace , DHCP, Agent trong OPS"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#1_overlapping_network_trong_ops","text":"Overlapping \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t m\u1ea1ng m\u00e1y t\u00ednh \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng tr\u00ean m\u1ed9t n\u1ec1n t\u1ea3ng network m\u1ea1ng s\u1eb5n Openstack cung c\u1ea5p m\u00f4i tr\u01b0\u1eddng Multi Tenant . M\u1ed7i tenant cung c\u1ea5p m\u1ed9t m\u1ea1ng prviate , router, firewall , loadblancer ri\u00eang . Nh\u1edd namepsace cung c\u1ea5p kh\u1ea3 n\u0103ng t\u00e1ch bi\u1ebft c\u00e1c t\u00e0i nguy\u00ean m\u1ea1ng gi\u1eefa c\u00e1c tenant - network namespace \u0110\u1ec3 xem \u0111\u01b0\u1ee3c namepsace c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng [root@controller nova]# ip netns list qrouter-32fe6f32-5bb6-4a89-a24f-df34124e8c76 (id: 2) qdhcp-355f6ca6-15f7-4121-a82b-6ee6f4d5fea3 (id: 0) [root@controller nova]# C\u00e1c namespace hi\u1ec3n th\u1ecb d\u01b0\u1edbi d\u1ea1ng qdhcp-* qrouter-* qlbaas-* \u0110\u1ec3 th\u1ef1c hi\u1ec7n m\u1ed9t comman tr\u00ean m\u1ed9t namespace c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng [root@controller nova]# ip netns exec qrouter-32fe6f32-5bb6-4a89-a24f-df34124e8c76 ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. 64 bytes from 1.1.1.1: icmp_seq=1 ttl=57 time=37.3 ms 64 bytes from 1.1.1.1: icmp_seq=2 ttl=57 time=37.7 ms 64 bytes from 1.1.1.1: icmp_seq=3 ttl=57 time=38.3 ms 64 bytes from 1.1.1.1: icmp_seq=4 ttl=57 time=38.8 ms 64 bytes from 1.1.1.1: icmp_seq=5 ttl=57 time=37.4 ms ^C --- 1.1.1.1 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4001ms rtt min/avg/max/mdev = 37.317/37.923/38.822/0.601 ms Nh\u01b0 v\u1eady router \u0111\u00e3 t\u1ea1o t\u1eeb tr\u01b0\u1edbc, g\u1eafn network net_ex \u0111\u00e3 c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi internet Khi m\u1ed9t namespace kh\u1edfi t\u1ea1o , neutron c\u0169ng kh\u1edfi t\u1ea1o \u0111\u1ed3ng th\u1eddi m\u1ed9t DHCP and routing service cho t\u1eebng network ri\u00eang bi\u1ec7t. Namespace qdhcp ch\u1ee9a DHCP Service cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP cho c\u00e1c instance s\u1eed d\u1ee5ng DHCP Protocol . Trong qu\u00e1 th\u1ef1c hi\u1ec7n, dnsmasq \u0111\u1ea3m nhi\u1ec7m x\u1eed l\u00fd c\u00e1c DHCP Request . qdhcp namespace nh\u01b0 m\u1ed9t host \u1ea3o, \u0111\u01b0\u1ee3c c\u1eafm v\u00e0o m\u1ed9t interface trong virtual switch, do \u0111\u00f3 s\u1ebd c\u00f3 kh\u1ea3 n\u0103ng k\u1ebft n\u1ed1i v\u1edbi c\u00e1c instance \u0111\u00e3 \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o network n\u00e0o \u0111\u00f3. Namesapce qrouter nh\u01b0 m\u1ed9t router \u1ea3o , v\u00e0 \u0111\u1ea3m nhi\u1ec7m routing t\u1eeb c\u00e1c instance \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o network . Router \u0111\u01b0\u1ee3c g\u1eafn v\u00e0o c\u00e1c network kh\u00e1c nhau c\u00f3 th\u1ec3 routing gi\u1eefa c\u00e1c m\u1ea1ng2","title":"1. Overlapping network trong OPS"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#2_neutron_agent","text":"M\u1ed9t agent trong neutron \u0111\u1ea3m nhi\u1ec7m c\u00e1c nhi\u1ec7m v\u1ee5 kh\u00e1c nhau \u0111\u1ec3 t\u00e1c \u0111\u1ed9ng t\u1edbi c\u00e1c m\u1ea1ng \u1ea3o . Trong neutron g\u1ed3m c\u00e1c agent c\u01a1 b\u1ea3n sau : neutron-dhcp-agent, neutron-l3-agent, neutron-metering-agent, and neutron-lbaas-agent, C\u00e1c agent c\u01a1 b\u1ea3n khi khi tri\u1ec3n khai self-service network [root@controller nova]# openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | b68cd06e-384f-47d7-88e4-dd5a6a85796c | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | c4eb82a1-d86a-4eb8-a230-f62b567d4df8 | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | ce13fbcc-e0e6-4b55-87cd-7bdfe58ce357 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent | | e2279058-9cad-4e05-801d-51a8f16b6850 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | f7fc3ab5-35c5-4968-a349-79ba6820d25a | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+","title":"2. Neutron Agent"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#21_ml2_plugin_agent","text":"Modular Layer 2 (ml2) cung c\u1ea5p m\u1ed9t framework cho ph\u00e9p neutron t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c h\u1ea1 t\u1ea7ng Layer 2 hi\u1ec7n \u0111ang c\u00f3 trong c\u00e1c DC. Ml2 framework g\u1ed3m c\u00f3 2 driver ri\u00eang bi\u1ec7t Type driver : gi\u00fap neutron x\u00e1c \u0111inh \u0111\u01b0\u1ee3c c\u00f4ng ngh\u1ec7 s\u1eed d\u1ee5ng : V\u00ed d\u1ee5 nh\u01b0 VLAN . V\u1edbi m\u1ed7i ki\u1ec3u network \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd b\u1edfi ML2 Type Driver , x\u00e1c \u0111\u1ecbnh tr\u1ea1ng th\u00e1i m\u1ea1ng c\u1ee5 th\u1ec3 v\u00e0 ch\u1ecbu tr\u00e1ch nhi\u1ec7m cho c\u00e1c segment layer 2 Mechanism drivers : gi\u00fap neutron x\u00e1c \u0111\u1ecbnh r\u00f5 r\u00e0ng c\u00e1c l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t lo\u1ea1i m\u1ea1ng c\u1ee5 th\u1ec3 . Type driver cung c\u1ea5p m\u1ea1ng qu\u1ea3n l\u00fd sau \u0111\u00f3 Mechanism driver s\u1ebd \u0111\u1ebfn c\u00e1c device \u1edf ngo\u00e0i \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi m\u1ed9t m\u1ea1ng n\u00e0o \u0111\u00f3 . L2 agent serves ph\u1ee5c v\u1ee5 kh\u1ea3 n\u0103ng l\u00e0m vi\u1ec7c v\u1edbi Layer 2. Th\u01b0\u1eddng n\u0103m tr\u00ean Network Node v\u00e0 tr\u00ean m\u1ed7i Compute Node","title":"2.1 : ML2 plugin , agent"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#22_l3_agent","text":"Cung c\u1ea5p kh\u1ea3 n\u0103ng l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c d\u1ecbch v\u1ee5 Layer 3 : virtual Routers v\u00e0 Floating IP Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent","title":"2.2 : L3 Agent"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#23_dhcp_agent","text":"\u0110\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 DHCP . Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent","title":"2.3. DHCP agent"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#24_meta_data_agent","text":"Cung c\u1ea5p kh\u1ea3 g\u1eedi c\u00e1c cloud init data t\u1edbi c\u00e1c instance th\u00f4ng tin network Y\u00eau c\u1ea7u c\u00f3 s\u1eb5n m\u1ed9t L2 Agent","title":"2.4. Meta Data agent"},{"location":"Openstack_Research/Neutron/4. Neutron-Namespace-Agent/#3_tham_khao_them","text":"T\u00ccm hi\u1ec3u th\u00eam t\u1ea1i : [1] : https://objects-east.cloud.ca/v1/5ef827605f884961b94881e928e7a250/crivera/AYCE%20Neutron.pdf [2] : https://dischord.org/2015/03/09/troubleshooting-openstack-neutron-networking-part-one/","title":"3. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/","text":"Neutron Traffic Flow trong Linux Bridge \u00b6 1. Provider network \u00b6 1.1 . North - South : instance with IP Floating \u00b6 Qu\u00e1 tr\u00ecnh truy\u1ec1n t\u1ea3i tr\u00ean compute node : B1 : Instance interface s\u1ebd g\u1eedi packet \u0111\u1ebfn c\u1ed5ng t\u01b0\u01a1ng \u1ee9ng c\u1ee7a instance tr\u00ean provider bridge (1) th\u00f4ng qua k\u1ebft n\u1ed1i veth ( 2 ) B2 : Security group tr\u00ean LB s\u1ebd ki\u1ec3m so\u00e1t traffic (3) B3 : C\u00e1c sub-interface tr\u00ean provider bridge s\u1ebd chuy\u1ec3n c\u00e1c frame \u0111\u1ebfn physical interface ( c\u00f3 th\u1ec3 l\u00e0 VLAN subport ho\u1eb7c flat ) (4 ) B4 : Physical interface s\u1ebd (5 ) chuy\u1ec3n ti\u1ebfp c\u00e1c traffic ra ngo\u00e0i switch ngo\u00e0i h\u1ea1 t\u1ea7ng ( c\u00f3 th\u1ec3 g\u1eafn VLAN_ID ho\u1eb7c no_tag ) (6 ) B5.: Khi \u0111\u1ebfn swtich v\u1eadt l\u00fd ( 6 ) c\u00e1c frame s\u1ebd \u0111\u01b0\u1ee3c b\u1ecf VLAN v\u00e0 chuy\u1ec3n \u0111\u1ebfn router ( 7 ) B6. Router nh\u1eadn packet t\u1eeb provider network sau \u0111\u00f3 s\u1ebd g\u1eedi ra m\u1ea1ng ngo\u00e0i ( 8 ) 1.2. East - West - same network \u00b6 C\u00e1c instance thu\u1ed9c c\u00e1c compute node kh\u00e1c nhau li\u00ean h\u1ec7 v\u1edbi nhau tr\u00ean c\u00f9ng m\u1ed9t network \u0110\u01b0\u1eddng \u0111i c\u1ee7a c\u1ee7a c\u00e1c instance - B1 : instance interface (1 ) s\u1ebd g\u1eedi c\u00e1c packet \u0111\u1ebfn tun port t\u01b0\u01a1ng \u1ee9ng tr\u00ean provider bridge (2) nh\u1edd v\u00e0o veth pair - B2 : Security group (3 s\u1ebd l\u00e0m vi\u1ec7c ki\u1ec3m so\u00e1t c\u00e1c packet - B3. C\u00e1c sub_interface (4 ) tr\u00ean bridge s\u1ebd g\u1eedi c\u00e1c packet t\u1edbi physical interface ( 5 ) - c\u00f3 th\u1ec3 VLAN_port ho\u1eb7c no_tag - B4. Physical interface ( 5 ) s\u1ebd g\u1eafn VLAN_ID t\u01b0\u01a1ng \u1ee9ng v\u1edbi VLAN_PORT ho\u1eb7c no_tag sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn swtich ( 6 ) - B5. Switch s\u1ebd g\u1eedi frame t\u1eeb compute 1 \u0111\u1ebfn compute 2 ( 7 ) - B6. Physical interface ( 8 ) tr\u00ean Compute s\u1ebd b\u1ecf VLAN_ID ( ho\u1eb7c kh\u00f4ng ) sau \u0111\u00f3 g\u1eedi \u0111\u1ebfn VLAN_sub interface t\u01b0\u01a1ng \u1ee9ng ( 9 ) tr\u00ean provider bridge - B7. Security group s\u1ebd ki\u1ec3m so\u00e1t packet ( 10 ) - B8. Provider bridge g\u1eedi packet \u0111\u1ebfn instance interface 1.3 . East-west - different network \u00b6 C\u00e1c instance thu\u1ed9c c\u00e1c compute node kh\u00e1c nhau li\u00ean h\u1ec7 v\u1edbi nhau kh\u00e1c network - Tr\u00ean Compute 1 - B1. instance interface ( 1 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn \u0111\u1ebfn port tr\u00ean provider bridge nh\u1edd veth pair ( 2 ) - B2. Security group ( 3 ) s\u1ebd ki\u1ec3m so\u00e1t traffic - B3. VLAN sub_interface ho\u1eb7c no_vlan (4 ) tr\u00ean provider bridge packet \u0111\u1ebfn physical interface - B4. Physical interface ( 5 ) s\u1ebd th\u00eam VLAN_ID v\u00e0o frame sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn switch v\u1eadt l\u00fd ( 6 ) Tr\u00ean m\u1ea1ng v\u1eadt l\u00fd B1. Switch s\u1ebd b\u1ecf VLAN_ID tr\u00ean sau \u0111\u00f3 g\u1eedi packet \u0111\u1ebfn router ( 7 ) B2. Router g\u1eedi packet t\u1eeb provider network 1 ( 8 ) sang provider network 2 ( 9 ) B3. Router s\u1ebd g\u1eedi packet \u0111\u1ebfn swtich ( 10 ) B4. Swtich th\u00eam VLAN_ID ho\u1eb7c no_tag sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn compute 2 ( 11 ) Tr\u00ean Compute 2 : B1. Tr\u00ean physical interface ( 12 )s\u1ebd b\u1ecf VLAN_ID v\u00e0 g\u1eedi packet \u0111\u1ebfn sub_port tr\u00ean provider bridge ( 13 B2. Security group s\u1ebd ki\u1ec3m so\u00e1t traffic ( 14 ) B3. Provider bridge (15 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn port c\u1ee7a instance 2 ( 16 ) 2. Self-service Network \u00b6 Trong self-service c\u00e1c instance s\u1ebd s\u1eed d\u1ee5ng IPv4 Private . \u0110\u1ec3 truy c\u1eadp \u0111\u01b0\u1ee3c interface , networking service s\u1ebd l\u00e0m nhi\u1ec7m v\u1ee5 SNAT ( Source Network Addresss Translation ) \u0111\u1ec3 truy c\u1eadp ra m\u1ea1ng external . . \u0110\u1ec3 t\u1eeb c\u00e1c m\u1ea1ng c\u00f3 th\u1ec3 truy c\u1eadp , c\u00e1c instance y\u00eau c\u1ea7u c\u00f3 m\u1ed9t floating IP . Networking service th\u1ef1c hi\u1ec7n DNAT ( desnation network address translation ) t\u1eeb IP Floating sang IP self-service 2.1. North-south - instance with Fixed IP V4 \u00b6 V\u1edbi c\u00e1c instance k\u00e8m IP v4 Floating, tr\u00ean network node s\u1ebd th\u1ef1c hi\u1ec7n SNAT \u0111\u1ec3 self-service c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi m\u1ea1ng ngo\u00e0i \u0110\u01b0\u1eddng \u0111i c\u1ee7a instance \u0111i ra internet : - Tr\u00ean compute node : - B1 : instance interface ( 1 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn port t\u01b0\u01a1ng \u1ee9ng \u0111\u1ebfn bridge s\u1eed d\u1ee5ng veth pair ( 2 ) - B2 : Security group ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter traffic (3 ) - B3 : Self-service bridge s\u1ebd chuy\u1ec3n packet t\u1edbi VXLAN interface tr\u00ean bridge ( 4 ) k\u00e8m VNI - B4 : Physical interface ( 5 ) cho ph\u00e9p m\u1ea1ng Overlay XVLAN chuy\u1ec3n packet l\u00ean network node ( 6 ) Tr\u00ean network node : B1 : Physical network ( 7 ) nh\u1eadn packet t\u1eeb Overlay VXLAN Interface sau \u0111\u00f3 chuy\u1ec3n l\u00ean Self-service bridge port ( 8 ) B2 : Self-service bridge( 9 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn router namespace .( 10 ) V\u1edbi IPv4. router namespace s\u1ebd th\u1ef1c hi\u1ec7n SNAT, thay \u0111\u1ed5i IP ngu\u1ed3n th\u00e0nh Router IP c\u1ee7a Provider Network ( 11 ) . B3 : Router g\u1eedi packet \u0111\u1ebfn provider bridge ( 12 ) B4 : VLAN sub_interface tr\u00ean provider bridge s\u1ebd g\u1eedi packet \u0111\u1ebfn provider physical network interface . B5 : Provider physical network th\u00eam VLAN Tag v\u00e0 \u0111i ra internet 2.2. North-South : instance with floating IP \u00b6 Qu\u00e1 tr\u00ecnh m\u1ed9t host t\u1eeb internet g\u1eedi packet cho instance Tr\u00ean network node : B1: T\u1eeb m\u1ea1ng v\u1eadt l\u00fd ( 1 ) g\u1eedi packet v\u00e0o provider physical interface ( 2 ) B2: Provider physical interface ( 3 ) s\u1ebd b\u1ecf c\u00e1c VLAN_TAG v\u00e0 s\u1ebd g\u1eedi c\u00e1c packet v\u00e0o VLAN Sub_interface t\u01b0\u01a1ng \u1ee9ng tr\u00ean provider bridge ( 4 ) B3 : Provider bridge s\u1ebd chuy\u1ec3n packet sang self-service router gateway port ( 5 ) V\u1edbi IPv4, router \u0111\u1ea3m nhi\u1ec7m th\u1ef1c hi\u1ec7n DNAT \u0111\u1ec3 thay \u0111\u1ed5i \u0111\u1ecba ch\u1ec9 \u0111\u00edch IP th\u00e0nh IP Floating c\u1ee7a instance tr\u00ean self-service network . ( 6 ) B4 : Router chuy\u1ec3n g\u00f3i tin \u0111\u1ebfn tin \u0111\u1ebfn self-service bridge port ( 7 ) B5 : Self-service bridge g\u1eedi packet \u0111\u1ebfn VXLAN Interface k\u00e8m theo VNI ( 8 ) B6 : Physical network interface( 9 ) g\u1eedi packet \u0111\u1ebfn compute node th\u00f4ng qua Overlay network ( 10 ) Tr\u00ean compute node: - B1 : Physical interface ( 11 ) send packet t\u1edbi VXLAN interface \u1edf self-server bridge ( 12 ) - B2 : Security group \u0111\u1ea3m nhi\u1ec7m filter packet ( 13 ) - B3 : Self-service bridge chuy\u1ec3n packet \u0111\u1ebfn instance port 2.3 East-west - same network \u00b6 Tr\u00ean Compute 1 : - B1 : Instance interface ( 1 ) chuy\u1ec3n packet \u0111\u1ebfn self-service port t\u01b0\u01a1ng \u1ee9ng ( 2 ) - B2 : Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter data - B3 : Self-service bridge ( 4 ) chuy\u1ec3n ti\u1ebfp packet t\u1edbi VXLAN Interface k\u00e8m theo VNI - B4 : Physical interface ( 5 ) chuy\u1ec3n ti\u1ebfp packet t\u1edbi compute 2 nh\u1edd overlay network ( 6 ) Tr\u00ean Compute 2 : - B1 : Tr\u00ean physical ( 7 ) interface cho ph\u00e9p XVLAN interface chuy\u1ec3n ti\u1ebfp packet t\u1edbi XVLAN interface ( 8 ) - B2 : Security group ( 9 ) \u0111\u1ea3m nhi\u1ec7m filter data - B3 : Self-service bridge ( 10 ) chuy\u1ec3n data t\u1edbi instance interface ( 11 ) 2.3 East-west - different network \u00b6 3. M\u1ed9t s\u1ed1 quy \u01b0\u1edbc trong Neutron OVS \u00b6 Tr\u00ean compute node - Linux bridge: qbr-ID - Linux bridge n\u1eb1m gi\u1eefa VM v\u00e0 br-int, g\u1ed3m 2 port: - port tap g\u1eafn v\u1edbi VM: tap-ID - port veth pair g\u1eafn v\u1edbi br-int: qvb-ID - Br-int : - port veth pair g\u1eafn v\u1edbi linux bridge: qvo-ID - port patch g\u1eafn v\u1edbi br-tun Tr\u00ean 1 network th\u00ec c\u00e1c port c\u1ee7a c\u00e1c thi\u1ebft b\u1ecb n\u00e0y c\u00f3 chung ID l\u00e0 ID c\u1ee7a network \u0111\u00f3. Tr\u00ean network node - Br-int: cung c\u1ea5p router \u1ea3o v\u00e0 DHCP cho instance. g\u1ed3m c\u00e1c port: - port tap g\u1eafn v\u1edbi DHCP namespace: tap-ID - port qr g\u1eafn v\u1edbi router namespace: qr-ID - Br-ex: cung c\u1ea5p external connection. G\u1ed3m port qg g\u1eafn v\u1edbi router namespace: qg-ID 4. Tham kh\u1ea3o th\u00eam \u00b6 [1] : https://docs.openstack.org/neutron/pike/admin/deploy-lb-provider.html","title":"Neutron Traffic Flow trong Linux Bridge"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#neutron_traffic_flow_trong_linux_bridge","text":"","title":"Neutron Traffic Flow trong Linux Bridge"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#1_provider_network","text":"","title":"1. Provider network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#11_north_-_south_instance_with_ip_floating","text":"Qu\u00e1 tr\u00ecnh truy\u1ec1n t\u1ea3i tr\u00ean compute node : B1 : Instance interface s\u1ebd g\u1eedi packet \u0111\u1ebfn c\u1ed5ng t\u01b0\u01a1ng \u1ee9ng c\u1ee7a instance tr\u00ean provider bridge (1) th\u00f4ng qua k\u1ebft n\u1ed1i veth ( 2 ) B2 : Security group tr\u00ean LB s\u1ebd ki\u1ec3m so\u00e1t traffic (3) B3 : C\u00e1c sub-interface tr\u00ean provider bridge s\u1ebd chuy\u1ec3n c\u00e1c frame \u0111\u1ebfn physical interface ( c\u00f3 th\u1ec3 l\u00e0 VLAN subport ho\u1eb7c flat ) (4 ) B4 : Physical interface s\u1ebd (5 ) chuy\u1ec3n ti\u1ebfp c\u00e1c traffic ra ngo\u00e0i switch ngo\u00e0i h\u1ea1 t\u1ea7ng ( c\u00f3 th\u1ec3 g\u1eafn VLAN_ID ho\u1eb7c no_tag ) (6 ) B5.: Khi \u0111\u1ebfn swtich v\u1eadt l\u00fd ( 6 ) c\u00e1c frame s\u1ebd \u0111\u01b0\u1ee3c b\u1ecf VLAN v\u00e0 chuy\u1ec3n \u0111\u1ebfn router ( 7 ) B6. Router nh\u1eadn packet t\u1eeb provider network sau \u0111\u00f3 s\u1ebd g\u1eedi ra m\u1ea1ng ngo\u00e0i ( 8 )","title":"1.1 . North - South : instance with IP Floating"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#12_east_-_west_-_same_network","text":"C\u00e1c instance thu\u1ed9c c\u00e1c compute node kh\u00e1c nhau li\u00ean h\u1ec7 v\u1edbi nhau tr\u00ean c\u00f9ng m\u1ed9t network \u0110\u01b0\u1eddng \u0111i c\u1ee7a c\u1ee7a c\u00e1c instance - B1 : instance interface (1 ) s\u1ebd g\u1eedi c\u00e1c packet \u0111\u1ebfn tun port t\u01b0\u01a1ng \u1ee9ng tr\u00ean provider bridge (2) nh\u1edd v\u00e0o veth pair - B2 : Security group (3 s\u1ebd l\u00e0m vi\u1ec7c ki\u1ec3m so\u00e1t c\u00e1c packet - B3. C\u00e1c sub_interface (4 ) tr\u00ean bridge s\u1ebd g\u1eedi c\u00e1c packet t\u1edbi physical interface ( 5 ) - c\u00f3 th\u1ec3 VLAN_port ho\u1eb7c no_tag - B4. Physical interface ( 5 ) s\u1ebd g\u1eafn VLAN_ID t\u01b0\u01a1ng \u1ee9ng v\u1edbi VLAN_PORT ho\u1eb7c no_tag sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn swtich ( 6 ) - B5. Switch s\u1ebd g\u1eedi frame t\u1eeb compute 1 \u0111\u1ebfn compute 2 ( 7 ) - B6. Physical interface ( 8 ) tr\u00ean Compute s\u1ebd b\u1ecf VLAN_ID ( ho\u1eb7c kh\u00f4ng ) sau \u0111\u00f3 g\u1eedi \u0111\u1ebfn VLAN_sub interface t\u01b0\u01a1ng \u1ee9ng ( 9 ) tr\u00ean provider bridge - B7. Security group s\u1ebd ki\u1ec3m so\u00e1t packet ( 10 ) - B8. Provider bridge g\u1eedi packet \u0111\u1ebfn instance interface","title":"1.2. East - West - same network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#13_east-west_-_different_network","text":"C\u00e1c instance thu\u1ed9c c\u00e1c compute node kh\u00e1c nhau li\u00ean h\u1ec7 v\u1edbi nhau kh\u00e1c network - Tr\u00ean Compute 1 - B1. instance interface ( 1 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn \u0111\u1ebfn port tr\u00ean provider bridge nh\u1edd veth pair ( 2 ) - B2. Security group ( 3 ) s\u1ebd ki\u1ec3m so\u00e1t traffic - B3. VLAN sub_interface ho\u1eb7c no_vlan (4 ) tr\u00ean provider bridge packet \u0111\u1ebfn physical interface - B4. Physical interface ( 5 ) s\u1ebd th\u00eam VLAN_ID v\u00e0o frame sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn switch v\u1eadt l\u00fd ( 6 ) Tr\u00ean m\u1ea1ng v\u1eadt l\u00fd B1. Switch s\u1ebd b\u1ecf VLAN_ID tr\u00ean sau \u0111\u00f3 g\u1eedi packet \u0111\u1ebfn router ( 7 ) B2. Router g\u1eedi packet t\u1eeb provider network 1 ( 8 ) sang provider network 2 ( 9 ) B3. Router s\u1ebd g\u1eedi packet \u0111\u1ebfn swtich ( 10 ) B4. Swtich th\u00eam VLAN_ID ho\u1eb7c no_tag sau \u0111\u00f3 g\u1eedi frame \u0111\u1ebfn compute 2 ( 11 ) Tr\u00ean Compute 2 : B1. Tr\u00ean physical interface ( 12 )s\u1ebd b\u1ecf VLAN_ID v\u00e0 g\u1eedi packet \u0111\u1ebfn sub_port tr\u00ean provider bridge ( 13 B2. Security group s\u1ebd ki\u1ec3m so\u00e1t traffic ( 14 ) B3. Provider bridge (15 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn port c\u1ee7a instance 2 ( 16 )","title":"1.3 . East-west - different network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#2_self-service_network","text":"Trong self-service c\u00e1c instance s\u1ebd s\u1eed d\u1ee5ng IPv4 Private . \u0110\u1ec3 truy c\u1eadp \u0111\u01b0\u1ee3c interface , networking service s\u1ebd l\u00e0m nhi\u1ec7m v\u1ee5 SNAT ( Source Network Addresss Translation ) \u0111\u1ec3 truy c\u1eadp ra m\u1ea1ng external . . \u0110\u1ec3 t\u1eeb c\u00e1c m\u1ea1ng c\u00f3 th\u1ec3 truy c\u1eadp , c\u00e1c instance y\u00eau c\u1ea7u c\u00f3 m\u1ed9t floating IP . Networking service th\u1ef1c hi\u1ec7n DNAT ( desnation network address translation ) t\u1eeb IP Floating sang IP self-service","title":"2. Self-service Network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#21_north-south_-_instance_with_fixed_ip_v4","text":"V\u1edbi c\u00e1c instance k\u00e8m IP v4 Floating, tr\u00ean network node s\u1ebd th\u1ef1c hi\u1ec7n SNAT \u0111\u1ec3 self-service c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi m\u1ea1ng ngo\u00e0i \u0110\u01b0\u1eddng \u0111i c\u1ee7a instance \u0111i ra internet : - Tr\u00ean compute node : - B1 : instance interface ( 1 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn port t\u01b0\u01a1ng \u1ee9ng \u0111\u1ebfn bridge s\u1eed d\u1ee5ng veth pair ( 2 ) - B2 : Security group ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter traffic (3 ) - B3 : Self-service bridge s\u1ebd chuy\u1ec3n packet t\u1edbi VXLAN interface tr\u00ean bridge ( 4 ) k\u00e8m VNI - B4 : Physical interface ( 5 ) cho ph\u00e9p m\u1ea1ng Overlay XVLAN chuy\u1ec3n packet l\u00ean network node ( 6 ) Tr\u00ean network node : B1 : Physical network ( 7 ) nh\u1eadn packet t\u1eeb Overlay VXLAN Interface sau \u0111\u00f3 chuy\u1ec3n l\u00ean Self-service bridge port ( 8 ) B2 : Self-service bridge( 9 ) s\u1ebd g\u1eedi packet \u0111\u1ebfn router namespace .( 10 ) V\u1edbi IPv4. router namespace s\u1ebd th\u1ef1c hi\u1ec7n SNAT, thay \u0111\u1ed5i IP ngu\u1ed3n th\u00e0nh Router IP c\u1ee7a Provider Network ( 11 ) . B3 : Router g\u1eedi packet \u0111\u1ebfn provider bridge ( 12 ) B4 : VLAN sub_interface tr\u00ean provider bridge s\u1ebd g\u1eedi packet \u0111\u1ebfn provider physical network interface . B5 : Provider physical network th\u00eam VLAN Tag v\u00e0 \u0111i ra internet","title":"2.1. North-south - instance with Fixed IP V4"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#22_north-south_instance_with_floating_ip","text":"Qu\u00e1 tr\u00ecnh m\u1ed9t host t\u1eeb internet g\u1eedi packet cho instance Tr\u00ean network node : B1: T\u1eeb m\u1ea1ng v\u1eadt l\u00fd ( 1 ) g\u1eedi packet v\u00e0o provider physical interface ( 2 ) B2: Provider physical interface ( 3 ) s\u1ebd b\u1ecf c\u00e1c VLAN_TAG v\u00e0 s\u1ebd g\u1eedi c\u00e1c packet v\u00e0o VLAN Sub_interface t\u01b0\u01a1ng \u1ee9ng tr\u00ean provider bridge ( 4 ) B3 : Provider bridge s\u1ebd chuy\u1ec3n packet sang self-service router gateway port ( 5 ) V\u1edbi IPv4, router \u0111\u1ea3m nhi\u1ec7m th\u1ef1c hi\u1ec7n DNAT \u0111\u1ec3 thay \u0111\u1ed5i \u0111\u1ecba ch\u1ec9 \u0111\u00edch IP th\u00e0nh IP Floating c\u1ee7a instance tr\u00ean self-service network . ( 6 ) B4 : Router chuy\u1ec3n g\u00f3i tin \u0111\u1ebfn tin \u0111\u1ebfn self-service bridge port ( 7 ) B5 : Self-service bridge g\u1eedi packet \u0111\u1ebfn VXLAN Interface k\u00e8m theo VNI ( 8 ) B6 : Physical network interface( 9 ) g\u1eedi packet \u0111\u1ebfn compute node th\u00f4ng qua Overlay network ( 10 ) Tr\u00ean compute node: - B1 : Physical interface ( 11 ) send packet t\u1edbi VXLAN interface \u1edf self-server bridge ( 12 ) - B2 : Security group \u0111\u1ea3m nhi\u1ec7m filter packet ( 13 ) - B3 : Self-service bridge chuy\u1ec3n packet \u0111\u1ebfn instance port","title":"2.2. North-South : instance with floating IP"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#23_east-west_-_same_network","text":"Tr\u00ean Compute 1 : - B1 : Instance interface ( 1 ) chuy\u1ec3n packet \u0111\u1ebfn self-service port t\u01b0\u01a1ng \u1ee9ng ( 2 ) - B2 : Security group ( 3 ) \u0111\u1ea3m nhi\u1ec7m filter data - B3 : Self-service bridge ( 4 ) chuy\u1ec3n ti\u1ebfp packet t\u1edbi VXLAN Interface k\u00e8m theo VNI - B4 : Physical interface ( 5 ) chuy\u1ec3n ti\u1ebfp packet t\u1edbi compute 2 nh\u1edd overlay network ( 6 ) Tr\u00ean Compute 2 : - B1 : Tr\u00ean physical ( 7 ) interface cho ph\u00e9p XVLAN interface chuy\u1ec3n ti\u1ebfp packet t\u1edbi XVLAN interface ( 8 ) - B2 : Security group ( 9 ) \u0111\u1ea3m nhi\u1ec7m filter data - B3 : Self-service bridge ( 10 ) chuy\u1ec3n data t\u1edbi instance interface ( 11 )","title":"2.3 East-west - same network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#23_east-west_-_different_network","text":"","title":"2.3 East-west - different network"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#3_mot_so_quy_uoc_trong_neutron_ovs","text":"Tr\u00ean compute node - Linux bridge: qbr-ID - Linux bridge n\u1eb1m gi\u1eefa VM v\u00e0 br-int, g\u1ed3m 2 port: - port tap g\u1eafn v\u1edbi VM: tap-ID - port veth pair g\u1eafn v\u1edbi br-int: qvb-ID - Br-int : - port veth pair g\u1eafn v\u1edbi linux bridge: qvo-ID - port patch g\u1eafn v\u1edbi br-tun Tr\u00ean 1 network th\u00ec c\u00e1c port c\u1ee7a c\u00e1c thi\u1ebft b\u1ecb n\u00e0y c\u00f3 chung ID l\u00e0 ID c\u1ee7a network \u0111\u00f3. Tr\u00ean network node - Br-int: cung c\u1ea5p router \u1ea3o v\u00e0 DHCP cho instance. g\u1ed3m c\u00e1c port: - port tap g\u1eafn v\u1edbi DHCP namespace: tap-ID - port qr g\u1eafn v\u1edbi router namespace: qr-ID - Br-ex: cung c\u1ea5p external connection. G\u1ed3m port qg g\u1eafn v\u1edbi router namespace: qg-ID","title":"3. M\u1ed9t s\u1ed1 quy \u01b0\u1edbc trong Neutron OVS"},{"location":"Openstack_Research/Neutron/5.  Packet-Walkthrough-Linux-Bridge/#4_tham_khao_them","text":"[1] : https://docs.openstack.org/neutron/pike/admin/deploy-lb-provider.html","title":"4. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Neutron/6. Bonding/","text":"T\u00ecm hi\u1ec3u bonding trong Centos \u00b6 1. Linux Bonding \u00b6 1. Kh\u00e1i ni\u1ec7m \u00b6 Linux cho ph\u00e9p qu\u1ea3n tr\u1ecb vi\u00ean bonnding interface t\u1eeb 2 ho\u1eb7c nhi\u1ec1u interface k\u1ebft h\u1ee3p th\u00e0nh 1 interface \u1ea3o c\u00f3 t\u00ean bonding interface b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng module kernel \"bonding \" tr\u00ean Linux . B\u1eb1ng c\u00e1ch n\u00e0y gi\u00fap nhi\u1ec1u interface v\u1eadt l\u00fd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t network interface nh\u1eb1m : t\u0103ng bandwidth, t\u0103ng t\u00ednh d\u1ef1 ph\u00f2ng n\u1ebfu 1 card v\u1eadt l\u00fd ch\u1ebft th\u00ec s\u1ebd c\u00f2n card c\u00f2n l\u1ea1i 2. C\u00e1c mode bonding \u00b6 Mode Ch\u00ednh s\u00e1ch Ho\u1ea1t \u0111\u1ed9ng Kh\u1ea3 n\u0103ng ch\u1ecbu l\u1ed7i C\u00e2n b\u1eb1ng t\u1ea3i 0 Round Rubin C\u00e1c packet \u0111\u01b0\u1ee3c truy\u1ec1n / nh\u1eadn tu\u1ea7n t\u1ef1 tr\u00ean t\u1eebng giao di\u1ec7n Kh\u00f4ng C\u00f3 1 Active Backup khi m\u1ed9t NIC active th\u00ec NIC khi s\u1ebd \u1edf tr\u1ea1ng th\u00e1i sleep v\u00e0 ng\u01b0\u1ee3c l\u1ea1i , ch\u1ec9 h\u1ed7 tr\u1ee3 tr\u00ean x86 C\u00f3 Kh\u00f4ng 2 XOR Truy\u1ec1n t\u1ea3i d\u1ef1a tr\u00ean \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n m\u00e0 MAC \u0111\u00edch C\u00f3 C\u00f3 3 Broadcast Truy\u1ec1n packet tr\u00ean t\u1ea5t c\u1ea3 slave interface C\u00f3 Kh\u00f4ng 4 Dynamic Link Aggregation 802.3ad T\u1ea1o m\u1ed9t nh\u00f3m c\u00e1c interface c\u00f9ng t\u1ed1c \u0111\u1ed9 v\u00e0 duplex . Y\u00eau c\u1ea7u swtich h\u1ed7 tr\u1ee3 IEEE 802.3ad Yes Yes 5 Transmit Load Balancing (TLB) c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean qu\u00e1 tr\u00ecnh truy\u1ec1n d\u1eef li\u1ec7u ra ngo\u00e0i : l\u01b0u l\u01b0\u1ee3ng packet ra ngo\u00e0i s\u1ebd ph\u00e2n ph\u1ed1i t\u00f9y thu\u1ed9c v\u00e0o % ch\u1ecbu t\u1ea3i c\u00f2n r\u1ea3nh l\u00ean c\u00e1c slave interface . L\u01b0u l\u01b0\u1ee3ng \u0111\u1ebfn s\u1ebd g\u1eedi \u0111\u1ebfn m\u1ed9t slave , n\u1ed1i b\u1ecb l\u1ed7i s\u1ebd chi\u1ebfm \u0111\u1ecba ch\u1ec9 MAC v\u00e0 \u0111\u1ea3m nhi\u1ec7m nh\u1eadn packet 6 Adaptive Load Balancing (ALB) C\u00e2n b\u1eb1ng t\u1ea3i th\u00edch \u1ee9ng: bao g\u1ed3m c\u1ea3 c\u00e2n b\u1eb1ng t\u1ea3i truy\u1ec1n (balance-tlb) v\u00e0 c\u00e2n b\u1eb1ng t\u1ea3i nh\u1eadn (rlb - receive load balancing) \u0111\u1ed1i v\u1edbi l\u01b0u l\u01b0\u1ee3ng IPv4 Bonding driver s\u1ebd ch\u1eb7n c\u00e1c b\u1ea3n tin ph\u1ea3n h\u1ed3i ARP g\u1eedi b\u1edfi h\u1ec7 th\u1ed1ng c\u1ee5c b\u1ed9 tr\u00ean \u0111\u01b0\u1eddng ra v\u00e0 ghi \u0111\u00e8 \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n b\u1eb1ng \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u1ed9t trong c\u00e1c slaves tr\u00ean \u0111\u01b0\u1eddng bond.. Ch\u1ec9 h\u1ed7 tr\u1ee3 tr\u00ean x86 C\u00f3 C\u00f3 3. C\u00e1c parameter trong bonding \u00b6 max_bonds : s\u1ed1 l\u01b0\u1ee3ng bond driver t\u1ea1o ra tx_queues : s\u1ed1 l\u01b0\u1ee3ng packet \u1edf h\u00e0ng \u0111\u1ee3i truy\u1ec1n t\u1ea3i num_grat_arp : s\u1ed1 th\u00f4ng b\u00e1o ngang h\u00e0ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh failover ovent miimon : milliseconds \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh failover updelay : s\u1ed1 milliseconds tr\u00ec ho\u00e3n tr\u01b0\u1edbc khi cho 1 slave th\u00e0nh th\u1ea1ng th\u00e1o up downdelay : s\u1ed1 milliseconds tr\u00ec ho\u00e3n tr\u01b0\u1edbc khi h\u1ee7y 1 slave khi b\u1ecb down arp_interval : ARP monitor l\u00e0m vi\u1ec7c theo chu k\u00ec \u0111\u1ec3 check slave xem n\u00f3 g\u1eedi hay nh\u1eadn nh\u01b0ng traffic g\u1ea7n nh\u1ea5t. T\u00f9y ch\u1ecdn n\u00e0y cho ph\u00e9p k\u00edch ho\u1ea1t ARP monitoring, m\u1eb7c \u0111\u1ecbnh n\u00f3 s\u1ebd b\u1ecb disabled, gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh c\u0169ng l\u00e0 0. arp_ip_target : Ch\u1ec9 ra \u0111\u1ecba ch\u1ec9 IP s\u1ebd d\u01b0\u1ee3c d\u00f9ng l\u00e0m ARP monitoring khi m\u00e0 gi\u00e1 tr\u1ecb arp_interval > 0. primary : C\u00e1c card m\u1ea1ng s\u1ebd \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn \u0111\u1ec3 l\u00e0m primary device. Card m\u1ea1ng n\u00e0o \u0111\u01b0\u1ee3c ch\u1ecdn th\u00ec n\u00f3 s\u1ebd lu\u00f4n l\u00e0 active slave n\u1ebfu th\u1eddi \u0111i\u1ec3m \u0111\u00f3 n\u00f3 available. T\u00f9y ch\u1ecdn n\u00e0y ch\u1ec9 c\u00f3 t\u00e1c d\u1ee5ng \u1edf mode 1, 5, v\u00e0 6. 4. Lab Bonding Centos 7 \u00b6 Load module boding modprobe bonding Kh\u1edfi t\u1ea1o m\u1ed9t bond interface m\u1edbi cat << EOF > /etc/sysconfig/network-scripts/ifcfg-bond0 DEVICE=bond0 NAME=bond0 TYPE=Bond BONDING_MASTER=yes IPADDR=192.168.30.131 PREFIX=24 GATEWAY=192.168.30.1 ONBOOT=yes BOOTPROTO=none BONDING_OPTS=\"mode=1 miimon=100\" EOF S\u1eeda c\u1ea5u h\u00ecnh tr\u00ean 2 interface slave ens224 , ens256 cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens224 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=ens224 DEVICE=ens224 ONBOOT=yes DNS1=8.8.8.8 DNS2=8.8.4.4 MASTER=bond0 SLAVE=yes EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens256 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=ens256 DEVICE=ens256 ONBOOT=yes DNS1=8.8.8.8 DNS2=8.8.4.4 MASTER=bond0 SLAVE=yes EOF Kh\u1edfi \u0111\u1ed9ng l\u1ea1i network service systemctl restart network Ki\u1ec3m tra IP tr\u00ean c\u1ed5ng interface bond [root@compute1 network-scripts]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:0a:98:b6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.131/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet6 fe80::c787:c683:5333:de24/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: ens224: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq master bond0 state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff 8: ens256: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq master bond0 state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff 9: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff inet 192.168.30.131/24 brd 192.168.30.255 scope global noprefixroute bond0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe0a:98c0/64 scope link valid_lft forever preferred_lft forever Ki\u1ec3m tra th\u00f4ng tin bond interface [root@compute1 network-scripts]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: ens224 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: ens224 MII Status: up Speed: 10000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:0a:98:c0 Slave queue ID: 0 Slave Interface: ens256 MII Status: up Speed: 10000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:0a:98:ca Slave queue ID: 0 5. Tham kh\u1ea3o th\u00eam \u00b6 [1] : https://www.unixmen.com/linux-basics-create-network-bonding-on-centos-76-5/","title":"T\u00ecm hi\u1ec3u bonding trong Centos"},{"location":"Openstack_Research/Neutron/6. Bonding/#tim_hieu_bonding_trong_centos","text":"","title":"T\u00ecm hi\u1ec3u bonding trong Centos"},{"location":"Openstack_Research/Neutron/6. Bonding/#1_linux_bonding","text":"","title":"1. Linux Bonding"},{"location":"Openstack_Research/Neutron/6. Bonding/#1_khai_niem","text":"Linux cho ph\u00e9p qu\u1ea3n tr\u1ecb vi\u00ean bonnding interface t\u1eeb 2 ho\u1eb7c nhi\u1ec1u interface k\u1ebft h\u1ee3p th\u00e0nh 1 interface \u1ea3o c\u00f3 t\u00ean bonding interface b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng module kernel \"bonding \" tr\u00ean Linux . B\u1eb1ng c\u00e1ch n\u00e0y gi\u00fap nhi\u1ec1u interface v\u1eadt l\u00fd ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t network interface nh\u1eb1m : t\u0103ng bandwidth, t\u0103ng t\u00ednh d\u1ef1 ph\u00f2ng n\u1ebfu 1 card v\u1eadt l\u00fd ch\u1ebft th\u00ec s\u1ebd c\u00f2n card c\u00f2n l\u1ea1i","title":"1. Kh\u00e1i ni\u1ec7m"},{"location":"Openstack_Research/Neutron/6. Bonding/#2_cac_mode_bonding","text":"Mode Ch\u00ednh s\u00e1ch Ho\u1ea1t \u0111\u1ed9ng Kh\u1ea3 n\u0103ng ch\u1ecbu l\u1ed7i C\u00e2n b\u1eb1ng t\u1ea3i 0 Round Rubin C\u00e1c packet \u0111\u01b0\u1ee3c truy\u1ec1n / nh\u1eadn tu\u1ea7n t\u1ef1 tr\u00ean t\u1eebng giao di\u1ec7n Kh\u00f4ng C\u00f3 1 Active Backup khi m\u1ed9t NIC active th\u00ec NIC khi s\u1ebd \u1edf tr\u1ea1ng th\u00e1i sleep v\u00e0 ng\u01b0\u1ee3c l\u1ea1i , ch\u1ec9 h\u1ed7 tr\u1ee3 tr\u00ean x86 C\u00f3 Kh\u00f4ng 2 XOR Truy\u1ec1n t\u1ea3i d\u1ef1a tr\u00ean \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n m\u00e0 MAC \u0111\u00edch C\u00f3 C\u00f3 3 Broadcast Truy\u1ec1n packet tr\u00ean t\u1ea5t c\u1ea3 slave interface C\u00f3 Kh\u00f4ng 4 Dynamic Link Aggregation 802.3ad T\u1ea1o m\u1ed9t nh\u00f3m c\u00e1c interface c\u00f9ng t\u1ed1c \u0111\u1ed9 v\u00e0 duplex . Y\u00eau c\u1ea7u swtich h\u1ed7 tr\u1ee3 IEEE 802.3ad Yes Yes 5 Transmit Load Balancing (TLB) c\u00e2n b\u1eb1ng t\u1ea3i tr\u00ean qu\u00e1 tr\u00ecnh truy\u1ec1n d\u1eef li\u1ec7u ra ngo\u00e0i : l\u01b0u l\u01b0\u1ee3ng packet ra ngo\u00e0i s\u1ebd ph\u00e2n ph\u1ed1i t\u00f9y thu\u1ed9c v\u00e0o % ch\u1ecbu t\u1ea3i c\u00f2n r\u1ea3nh l\u00ean c\u00e1c slave interface . L\u01b0u l\u01b0\u1ee3ng \u0111\u1ebfn s\u1ebd g\u1eedi \u0111\u1ebfn m\u1ed9t slave , n\u1ed1i b\u1ecb l\u1ed7i s\u1ebd chi\u1ebfm \u0111\u1ecba ch\u1ec9 MAC v\u00e0 \u0111\u1ea3m nhi\u1ec7m nh\u1eadn packet 6 Adaptive Load Balancing (ALB) C\u00e2n b\u1eb1ng t\u1ea3i th\u00edch \u1ee9ng: bao g\u1ed3m c\u1ea3 c\u00e2n b\u1eb1ng t\u1ea3i truy\u1ec1n (balance-tlb) v\u00e0 c\u00e2n b\u1eb1ng t\u1ea3i nh\u1eadn (rlb - receive load balancing) \u0111\u1ed1i v\u1edbi l\u01b0u l\u01b0\u1ee3ng IPv4 Bonding driver s\u1ebd ch\u1eb7n c\u00e1c b\u1ea3n tin ph\u1ea3n h\u1ed3i ARP g\u1eedi b\u1edfi h\u1ec7 th\u1ed1ng c\u1ee5c b\u1ed9 tr\u00ean \u0111\u01b0\u1eddng ra v\u00e0 ghi \u0111\u00e8 \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n b\u1eb1ng \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u1ed9t trong c\u00e1c slaves tr\u00ean \u0111\u01b0\u1eddng bond.. Ch\u1ec9 h\u1ed7 tr\u1ee3 tr\u00ean x86 C\u00f3 C\u00f3","title":"2. C\u00e1c mode bonding"},{"location":"Openstack_Research/Neutron/6. Bonding/#3_cac_parameter_trong_bonding","text":"max_bonds : s\u1ed1 l\u01b0\u1ee3ng bond driver t\u1ea1o ra tx_queues : s\u1ed1 l\u01b0\u1ee3ng packet \u1edf h\u00e0ng \u0111\u1ee3i truy\u1ec1n t\u1ea3i num_grat_arp : s\u1ed1 th\u00f4ng b\u00e1o ngang h\u00e0ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh failover ovent miimon : milliseconds \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh failover updelay : s\u1ed1 milliseconds tr\u00ec ho\u00e3n tr\u01b0\u1edbc khi cho 1 slave th\u00e0nh th\u1ea1ng th\u00e1o up downdelay : s\u1ed1 milliseconds tr\u00ec ho\u00e3n tr\u01b0\u1edbc khi h\u1ee7y 1 slave khi b\u1ecb down arp_interval : ARP monitor l\u00e0m vi\u1ec7c theo chu k\u00ec \u0111\u1ec3 check slave xem n\u00f3 g\u1eedi hay nh\u1eadn nh\u01b0ng traffic g\u1ea7n nh\u1ea5t. T\u00f9y ch\u1ecdn n\u00e0y cho ph\u00e9p k\u00edch ho\u1ea1t ARP monitoring, m\u1eb7c \u0111\u1ecbnh n\u00f3 s\u1ebd b\u1ecb disabled, gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh c\u0169ng l\u00e0 0. arp_ip_target : Ch\u1ec9 ra \u0111\u1ecba ch\u1ec9 IP s\u1ebd d\u01b0\u1ee3c d\u00f9ng l\u00e0m ARP monitoring khi m\u00e0 gi\u00e1 tr\u1ecb arp_interval > 0. primary : C\u00e1c card m\u1ea1ng s\u1ebd \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn \u0111\u1ec3 l\u00e0m primary device. Card m\u1ea1ng n\u00e0o \u0111\u01b0\u1ee3c ch\u1ecdn th\u00ec n\u00f3 s\u1ebd lu\u00f4n l\u00e0 active slave n\u1ebfu th\u1eddi \u0111i\u1ec3m \u0111\u00f3 n\u00f3 available. T\u00f9y ch\u1ecdn n\u00e0y ch\u1ec9 c\u00f3 t\u00e1c d\u1ee5ng \u1edf mode 1, 5, v\u00e0 6.","title":"3. C\u00e1c parameter trong bonding"},{"location":"Openstack_Research/Neutron/6. Bonding/#4_lab_bonding_centos_7","text":"Load module boding modprobe bonding Kh\u1edfi t\u1ea1o m\u1ed9t bond interface m\u1edbi cat << EOF > /etc/sysconfig/network-scripts/ifcfg-bond0 DEVICE=bond0 NAME=bond0 TYPE=Bond BONDING_MASTER=yes IPADDR=192.168.30.131 PREFIX=24 GATEWAY=192.168.30.1 ONBOOT=yes BOOTPROTO=none BONDING_OPTS=\"mode=1 miimon=100\" EOF S\u1eeda c\u1ea5u h\u00ecnh tr\u00ean 2 interface slave ens224 , ens256 cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens224 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=ens224 DEVICE=ens224 ONBOOT=yes DNS1=8.8.8.8 DNS2=8.8.4.4 MASTER=bond0 SLAVE=yes EOF cat << EOF > /etc/sysconfig/network-scripts/ifcfg-ens256 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=ens256 DEVICE=ens256 ONBOOT=yes DNS1=8.8.8.8 DNS2=8.8.4.4 MASTER=bond0 SLAVE=yes EOF Kh\u1edfi \u0111\u1ed9ng l\u1ea1i network service systemctl restart network Ki\u1ec3m tra IP tr\u00ean c\u1ed5ng interface bond [root@compute1 network-scripts]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:0a:98:b6 brd ff:ff:ff:ff:ff:ff inet 192.168.30.131/24 brd 192.168.30.255 scope global noprefixroute ens192 valid_lft forever preferred_lft forever inet6 fe80::c787:c683:5333:de24/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: ens224: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq master bond0 state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff 8: ens256: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq master bond0 state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff 9: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:0c:29:0a:98:c0 brd ff:ff:ff:ff:ff:ff inet 192.168.30.131/24 brd 192.168.30.255 scope global noprefixroute bond0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe0a:98c0/64 scope link valid_lft forever preferred_lft forever Ki\u1ec3m tra th\u00f4ng tin bond interface [root@compute1 network-scripts]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: ens224 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: ens224 MII Status: up Speed: 10000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:0a:98:c0 Slave queue ID: 0 Slave Interface: ens256 MII Status: up Speed: 10000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:0a:98:ca Slave queue ID: 0","title":"4. Lab Bonding Centos 7"},{"location":"Openstack_Research/Neutron/6. Bonding/#5_tham_khao_them","text":"[1] : https://www.unixmen.com/linux-basics-create-network-bonding-on-centos-76-5/","title":"5. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Neutron/7. VXLAN/","text":"T\u00ecm hi\u1ec3u VXLAN \u00b6 1. V\u1ea5n \u0111\u1ec1 v\u1edbi VLAN \u00b6 VLAN \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng ch\u1ee7 y\u1ebfu \u0111\u1ec3 c\u00f4 l\u1eadp d\u1eef li\u1ec7u tr\u00ean layer 2. C\u00e1c m\u00f4i tr\u01b0\u1eddng m\u1ea1ng l\u1edbn y\u00eau c\u1ea7u m\u1edf r\u1ed9ng kh\u1ea3 n\u0103ng c\u00f4 l\u1eadp l\u1edbn h\u01a1n kh\u1ea3 n\u0103ng \u0111\u00e1p \u1ee9ng c\u1ee7a VLAN Hi\u1ec7n t\u1ea1i VLAN ch\u1ec9 h\u1ed7 tr\u1ee3 t\u1ed1i \u0111a t\u1ed1i \u0111a 12 bit VLAN_ID, b\u1ecb gi\u1edbi h\u1ea1n trong 4096 VLAN_ID S\u1eed d\u1ee5ng STP cung c\u1ea5p m\u1ed9t topology L2 ch\u1ed1ng loop v\u00e0 c\u1eaft b\u1ecf \u0111i h\u1ea7u h\u1ebft nh\u1eefng li\u00ean k\u1ebft d\u01b0 l\u1eeba. V\u1ea5n \u0111\u1ec1 l\u01b0u tr\u1eef MAC tr\u00ean c\u00e1c swtich khi s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o qu\u00e1 nhi\u1ec1u, c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn tr\u00f9ng MAC Adress 2. VXLAN l\u00e0 g\u00ec ? \u00b6 VXLAN (Virtual eXtensible LANs) : \u0111\u00e2y l\u00e0 c\u00f4ng ngh\u1ec7 cung c\u1ea5p d\u1ecbch v\u1ee5 \u0111\u1ec3 k\u1ebft n\u1ed1i Ethernet t\u1edbi c\u00e1c thi\u1ebft b\u1ecb cu\u1ed1i nh\u01b0 VLAN ng\u00e0y nay, nh\u01b0ng c\u00f3 nhi\u1ec1u t\u00ednh n\u0103ng m\u1edf r\u1ed9ng h\u01a1n. So s\u00e1nh v\u1edbi VLAN, VXLAN \u0111\u01b0\u1ee3c m\u1edf r\u1ed9ng h\u01a1n v\u1ec1 quy m\u00f4 v\u00e0 kh\u1ea3 n\u0103ng tri\u1ec3n khai ch\u00fang. Trong chu\u1ea9n \u0111\u1ecbnh ngh\u0129a cho VLAN 802.1q ch\u1ec9 d\u00e0nh ra 12 bit \u0111\u1ec3 \u0111\u00e1nh VLAN-ID. VXLAN s\u1eed d\u1ee5ng 24 bit \u0111\u1ec3 \u0111\u00e1nh \u0111\u1ecba ch\u1ec9 VLAN_ID. Ngh\u0129a l\u00e0 n\u00f3 s\u1ebd h\u1ed7 tr\u1ee3 kh\u00f4ng gian \u0111\u1ecba ch\u1ec9 VXLAN_ID l\u00ean t\u1edbi 4 l\u1ea7n so v\u1edbi VLAN, t\u1ee9c l\u00e0 kho\u1ea3ng h\u01a1n 16 tri\u1ec7u. \u0110i\u1ec1u n\u00e0y s\u1ebd cung c\u1ea5p \u0111\u1ee7 kh\u00f4ng gian \u0111\u1ec3 tri\u1ec3n khai c\u00e1c quy m\u00f4 m\u1ea1ng trong v\u00e0i n\u0103m t\u1edbi. VXLAN s\u1eed d\u1ee5ng IP (c\u1ea3 unicast v\u00e0 multicast) nh\u01b0 ph\u01b0\u01a1ng ti\u1ec7n truy\u1ec1n. S\u1ef1 ph\u1ed5 bi\u1ebfn c\u1ee7a m\u1ea1ng IP v\u00e0 c\u00e1c thi\u1ebft b\u1ecb cho ph\u00e9p \u0111\u1ea7u cu\u1ed1i s\u1ebd cho ph\u00e9p kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng v\u01b0\u1ee3t tr\u1ed9i ti\u1ebfn xa h\u01a1n r\u1ea5t nhi\u1ec1u so v\u1edbi VLAN s\u1eed d\u1ee5ng 802.1q hi\u1ec7n nay. Kh\u00f4ng g\u00ec c\u00f3 th\u1ec3 ph\u1ee7 nh\u1eadn r\u1eb1ng c\u00e1c c\u00f4ng ngh\u1ec7 kh\u00e1c c\u00f3 th\u1ec3 m\u1edf r\u1ed9ng \u0111\u01b0\u1ee3c ph\u1ea1m vi c\u1ee7a VLAN, nh\u01b0ng kh\u00f4ng c\u00f3 g\u00ec c\u00f3 th\u1ec3 tri\u1ec3n khai ph\u1ed5 bi\u1ebfn nh\u01b0 m\u1ea1ng IP. 3. C\u00e1c kh\u00e1i ni\u1ec7m trong VXLAN ? \u00b6 1.3.1. VNI \u00b6 VXLAN ho\u1ea1t \u0111\u1ed9ng tr\u00ean c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng m\u1ea1ng hi\u1ec7n c\u00f3 v\u00e0 cung c\u1ea5p m\u1ed9t ph\u01b0\u01a1ng ti\u1ec7n \u0111\u1ec3 \"k\u00e9o d\u00e0i\" m\u1ed9t m\u1ea1ng l\u1edbp 2. T\u00f3m l\u1ea1i, VXLAN l\u00e0 m\u1ed9t m\u1ea1ng l\u1edbp 2 overlay tr\u00ean m\u1ea1ng l\u1edbp 3. M\u1ed7i l\u1edbp m\u1ea1ng nh\u01b0 v\u1eady \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 VXLAN segment. Ch\u1ec9 c\u00e1c m\u00e1y \u1ea3o trong c\u00f9ng VXLAN segment m\u1edbi c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi nhau. M\u1ed7i VXLAN segment \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh th\u00f4ng qua ID k\u00edch th\u01b0\u1edbc 24 bit, g\u1ecdi l\u00e0 VXLAN Network Identifier (VNI) . \u0110i\u1ec1u n\u00e0y cho ph\u00e9p t\u1ed1i \u0111a 16 tri\u1ec7u c\u00e1c VXLAN segment c\u00f9ng t\u1ed3n t\u1ea1i trong c\u00f9ng m\u1ed9t domain. VNI x\u00e1c \u0111\u1ecbnh ph\u1ea1m vi c\u1ee7a inner MAC frame sinh ra b\u1edfi m\u00e1y \u1ea3o VM. Do \u0111\u00f3, b\u1ea1n c\u00f3 th\u1ec3 overlapping \u0111\u1ecba ch\u1ec9 MAC th\u00f4ng qua segment nh\u01b0 kh\u00f4ng b\u1ecb l\u1eabn l\u1ed9n c\u00e1c l\u01b0u l\u01b0\u1ee3ng b\u1edfi ch\u00fang \u0111\u00e3 b\u1ecb c\u00f4 l\u1eadp b\u1edfi VNI kh\u00e1c nhau. VNI n\u1eb1m trong header \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u1edbi innere MAC sinh ra b\u1edfi VM. 1.3.2. Encapsulation v\u00e0 VTEP \u00b6 VXLAN l\u00e0 c\u00f4ng ngh\u1ec7 overlay qua l\u1edbp m\u1ea1ng. Overlay Network c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a nh\u01b0 l\u00e0 m\u1ed9t m\u1ea1ng logic m\u00e0 \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean m\u1ed9t n\u1ec1n t\u1ea3ng m\u1ea1ng v\u1eadt l\u00fd \u0111\u00e3 c\u00f3 s\u1eb5n. VXLAN t\u1ea1o m\u1ed9t m\u1ea1ng v\u1eadt l\u00fd layer 2 tr\u00ean l\u1edbp m\u1ea1ng IP. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 2 t\u1eeb kh\u00f3a \u0111\u01b0\u1ee3c d\u00f9ng trong c\u00f4ng ngh\u1ec7 overlay network: Encapsulate : \u0110\u00f3ng g\u00f3i nh\u1eefng g\u00f3i tin ethernet th\u00f4ng th\u01b0\u1eddng trong m\u1ed9t header m\u1edbi. V\u00ed d\u1ee5: trong c\u00f4ng ngh\u1ec7 overlay IPSec VPN, \u0111\u00f3ng g\u00f3i g\u00f3i tin IP th\u00f4ng th\u01b0\u1eddng v\u00e0o m\u1ed9t IP header kh\u00e1c. VTEP : Vi\u1ec7c li\u00ean l\u1ea1c \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp gi\u1eefa 2 \u0111\u1ea7u tunnel end points (\u0111\u01b0\u1eddng \u1ed1ng). Khi b\u1ea1n \u00e1p d\u1ee5ng v\u00e0o v\u1edbi c\u00f4ng ngh\u1ec7 overlay trong VXLAN, b\u1ea1n s\u1ebd th\u1ea5y VXLAN s\u1ebd \u0111\u00f3ng g\u00f3i m\u1ed9t frame MAC th\u00f4ng th\u01b0\u1eddng v\u00e0o m\u1ed9t UDP header. V\u00e0 t\u1ea5t c\u1ea3 c\u00e1c host tham gia v\u00e0o VXLAN th\u00ec ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t tunnel end points. Ch\u00fang g\u1ecdi l\u00e0 Virtual Tunnel Endpoints (VTEPs) VTEPs l\u00e0 c\u00e1c node m\u00e0 cung c\u1ea5p c\u00e1c ch\u1ee9c n\u0103ng Encalsulation v\u00e0 De-encapsulation. Ch\u00fang bi\u1ebft r\u00f5 \u0111\u01b0\u1ee3c l\u00e0m th\u1ebf n\u00e0o m\u00e0 VTEPs encap v\u00e0 de-encap l\u01b0u l\u01b0\u1ee3ng t\u1eeb b\u1ea5t k\u00ec m\u00e1y \u1ea3o k\u1ebft n\u1ed1i v\u1edbi m\u1ed9t m\u1ea1ng VXLAN d\u1ef1a tr\u00ean m\u1ea1ng v\u1eadt l\u00fd layer 2. VXLAN h\u1ecdc t\u1ea5t c\u1ea3 c\u00e1c \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u00e1y \u1ea3o v\u00e0 vi\u1ec7c k\u1ebft n\u1ed1i n\u00f3 t\u1edbi VTEP IP th\u00ec \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n th\u00f4ng qua s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a m\u1ea1ng v\u1eadt l\u00fd. M\u1ed9t trong nh\u1eefng giao th\u1ee9c \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong m\u1ea1ng v\u1eadt l\u00fd l\u00e0 IP multicast. VXLAN s\u1eed d\u1ee5ng giao th\u1ee9c c\u1ee7a IP multicast \u0111\u1ec3 c\u01b0 tr\u00fa trong b\u1ea3ng forwarding trong VTEP. Do s\u1ef1 \u0111\u00f3ng g\u00f3i (encapsulation) n\u00e0y, VXLAN c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 thi\u1ebft l\u1eadp \u0111\u01b0\u1eddng h\u1ea7m (tunneling) \u0111\u1ec3 k\u00e9o d\u00e0i m\u1ea1ng l\u1edbp 2 th\u00f4ng qua l\u1edbp 3. \u0110i\u1ec3m cu\u1ed1i c\u00e1c tunnel n\u00e0y - (VXLAN Tunnel End Point ho\u1eb7c VTEP) n\u1eb1m trong hypervisor tr\u00ean server m\u00e1y ch\u1ee7 c\u1ee7a c\u00e1c VM. Do \u0111\u00f3, VNI v\u00e0 VXLAN li\u00ean quan t\u1edbi c\u00e1c kh\u00e1i ni\u1ec7m \u0111\u00f3ng g\u00f3i header tunnel \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi VTEP - v\u00e0 trong su\u1ed1t v\u1edbi VM. L\u01b0u \u00fd : VTEP c\u00f3 th\u1ec3 n\u1eb1m tr\u00ean switch ho\u1eb7c server v\u1eadt l\u00fd v\u00e0 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean ph\u1ea7n m\u1ec1m ho\u1eb7c ph\u1ea7n c\u1ee9ng. 1.3.3. VXLAN frame format \u00b6 Frame Ethernet th\u00f4ng th\u01b0\u1eddng bao g\u1ed3m \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n, MAC \u0111\u00edch, Ethernet type v\u00e0 th\u00eam ph\u1ea7n VLAN_ID (802.1q) n\u1ebfu c\u00f3. \u0110\u00e2y l\u00e0 frame \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i s\u1eed d\u1ee5ng VXLAN, th\u00eam c\u00e1c header sau: VXLAN header : 8 byte bao g\u1ed3m c\u00e1c tr\u01b0\u1eddng quan tr\u1ecdng sau: Flags : 8 but, trong \u0111\u00f3 bit th\u1ee9 5 (I flag) \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 1 \u0111\u1ec3 ch\u1ec9 ra r\u1eb1ng \u0111\u00f3 l\u00e0 m\u1ed9t frame c\u00f3 VNI c\u00f3 gi\u00e1 tr\u1ecb. 7 bit c\u00f2n l\u1ea1i d\u00f9ng d\u1eef tr\u1eef \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 0 h\u1ebft. VNI : 24 bit cung c\u1ea5p \u0111\u1ecbnh danh duy nh\u1ea5t cho VXLAN segment. C\u00e1c VM trong c\u00e1c VXLAN kh\u00e1c nhau kh\u00f4ng th\u1ec3 giao ti\u1ebfp v\u1edbi nhau. 24 bit VNI cung c\u1ea5p l\u00ean t\u1edbi h\u01a1n 16 tri\u1ec7u VXLAN segment trong m\u1ed9t v\u00f9ng qu\u1ea3n tr\u1ecb m\u1ea1ng. Outer UDP Header : port ngu\u1ed3n c\u1ee7a Outer UDP \u0111\u01b0\u1ee3c g\u00e1n t\u1ef1 \u0111\u1ed9ng v\u00e0 sinh ra b\u1edfi VTEP v\u00e0 port \u0111\u00edch th\u00f4ng th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0 port 4789 hay \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng (c\u00f3 th\u1ec3 ch\u1ecdn port kh\u00e1c). Outer IP Header : Cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP ngu\u1ed3n c\u1ee7a VTEP ngu\u1ed3n k\u1ebft n\u1ed1i v\u1edbi VM b\u00ean trong. \u0110\u1ecba ch\u1ec9 IP outer \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 IP c\u1ee7a VTEP nh\u1eadn frame. Outer Ethernet Header : cung c\u1ea5p \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n c\u1ee7a VTEP c\u00f3 khung frame ban \u0111\u1ea7u. \u0110\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 c\u1ee7a hop ti\u1ebfp theo \u0111\u01b0\u1ee3c \u0111\u1ecbnh tuy\u1ebfn b\u1edfi VTEP. Outer Ethernet header c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eafn tag theo chu\u1ea9n 802.1q trong qu\u00e1 tr\u00ecnh v\u1eadn chuy\u1ec3n trong m\u1ea1ng. 2. C\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a VXLAN \u00b6 VXLAN ho\u1ea1t \u0111\u1ed9ng d\u1ef1a tr\u00ean vi\u1ec7c g\u1eedi c\u00e1c frame th\u00f4ng qua giao th\u1ee9c IP Multicast. Trong qu\u00e1 tr\u00ecnh c\u1ea5u h\u00ecnh VXLAN, c\u1ea7n c\u1ea5p ph\u00e1t \u0111\u1ecba ch\u1ec9 IP multicast \u0111\u1ec3 g\u00e1n v\u1edbi VXLAN s\u1ebd t\u1ea1o. M\u1ed7i \u0111\u1ecba ch\u1ec9 IP multicast s\u1ebd \u0111\u1ea1i di\u1ec7n cho m\u1ed9t VXLAN. Sau \u0111\u00e2y s\u1ebd t\u00ecm hi\u1ec3u ho\u1ea1t \u0111\u1ed9ng chi ti\u1ebft c\u00e1ch frame \u0111i qua VTEP v\u00e0 \u0111i qua m\u1ea1ng v\u1eadt l\u00fd trong VXLAN tri\u1ec3n khai tr\u00ean m\u1ed9t m\u1ea1ng logic v\u1edbi m\u00f4 h\u00ecnh nh\u01b0 sau: 2.1. VM g\u1eedi request tham gia v\u00e0o group multicast \u00b6 Gi\u1ea3 s\u1eed m\u1ed9t m\u1ea1ng logic tr\u00ean 4 host nh\u01b0 h\u00ecnh. Topo m\u1ea1ng v\u1eadt l\u00fd cung c\u1ea5p m\u1ed9t VLAN 2000 \u0111\u1ec3 v\u1eadn chuy\u1ec3n c\u00e1c l\u01b0u l\u01b0\u1ee3ng VXLAN. Trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y, ch\u1ec9 IGMP snooping v\u00e0 IGMP querier \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh tr\u00ean m\u1ea1ng v\u1eadt l\u00fd. M\u1ed9t v\u00e0i b\u01b0\u1edbc s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u01b0\u1edbc khi c\u00e1c thi\u1ebft b\u1ecb tr\u00ean m\u1ea1ng v\u1eadt l\u00fd c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c g\u00f3i tin multicast. IGMP Packet flows: 1) M\u00e1y \u1ea3o VM (MAC1) tr\u00ean Host 1 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ed9t m\u1ea1ng logical layer 2 m\u00e0 c\u00f3 VXLAN 5001 \u1edf \u0111\u00f3. 2) VTEP tr\u00ean Host 1 g\u1eedi b\u1ea3n tin IGMP \u0111\u1ec3 join v\u00e0o m\u1ea1ng v\u00e0 join v\u00e0o nh\u00f3m multicast 239.1.1.100 \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. 3) T\u01b0\u01a1ng t\u1ef1, m\u00e1y \u1ea3o VM (MAC2) tr\u00ean Host 4 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ea1ng m\u00e0 c\u00f3 VXLAN 5001. 4) VTEP tr\u00ean Host 4 g\u1eedi b\u1ea3n tin IGMP join v\u00e0o m\u1ea1ng v\u00e0 join v\u00e0o nh\u00f3m multicast 239.1.1.100 \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. Host 2 v\u00e0 Host 3 VTEP kh\u00f4ng join nh\u00f3m multicast b\u1edfi v\u00ec ch\u00fang kh\u00f4ng c\u00f3 m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean n\u00f3 v\u00e0 c\u1ea7n k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. Ch\u1ec9 VTEP n\u00e0o c\u1ea7n tham gia v\u00e0o nh\u00f3m multicast m\u1edbi g\u1eedi request join v\u00e0o nh\u00f3m Multicast Packet flow: 1) M\u00e1y \u1ea3o VM (MAC1) tr\u00ean Host 1 sinh ra m\u1ed9t frame broadcast. 2) VTEP tr\u00ean Host 1 \u0111\u00f3ng g\u00f3i frame broadcast n\u00e0y v\u00e0o m\u1ed9t UDP header v\u1edbi IP \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 IP multicast 239.1.1.100 3) M\u1ea1ng v\u1eadt l\u00fd s\u1ebd chuy\u1ec3n c\u00e1c g\u00f3i tin n\u00e0y t\u1edbi Host 4 VTEP, v\u00ec n\u00f3 \u0111\u00e3 join v\u00e0o nh\u00f3m multicast 239.1.1.100. Host 2 v\u00e0 3 VTEP s\u1ebd kh\u00f4ng nh\u1eadn \u0111\u01b0\u1ee3c frame broadcast n\u00e0y. 4) VTEP tr\u00ean Host 4 \u0111\u1ea7u ti\u00ean \u0111\u1ed1i chi\u1ebfu header \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i, n\u1ebfu 24 bit VNI tr\u00f9ng v\u1edbi ID c\u1ee7a VXLAN. N\u00f3 s\u1ebd decapsulated l\u1edbp g\u00f3i \u0111\u01b0\u1ee3c VTEP host 1 \u0111\u00f3ng v\u00e0o v\u00e0 chuy\u1ec3n t\u1edbi m\u00e1y \u1ea3o VM \u0111\u00edch (MAC2). 2.2. VTEP h\u1ecdc v\u00e0 t\u1ea1o b\u1ea3ng forwarding \u00b6 Ban \u0111\u1ea7u, m\u1ed7i VTEP sau khi \u0111\u00e3 join v\u00e0o nh\u00f3m IP multicast \u0111\u1ec1u c\u00f3 m\u1ed9t b\u1ea3ng forwarding table nh\u01b0 sau: C\u00e1c b\u01b0\u1edbc sau s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 VTEP h\u1ecdc v\u00e0 ghi v\u00e0o b\u1ea3ng forwarding table: \u0110\u1ea7u ti\u00ean, m\u1ed9t b\u1ea3n tin ARP request \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb VM MAC1 \u0111\u1ec3 t\u00ecm \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u00e1y \u1ea3o \u0111\u00edch n\u00f3 c\u1ea7n g\u1eedi tin \u0111\u1ebfn VM MAC2 tr\u00ean Host 2. ARP request l\u00e0 b\u1ea3n tin broadcast. Host 2 VTEP \u2013 Forwarding table entry 1) VM tr\u00ean Host 1 g\u1eedi b\u1ea3n tin ARP request v\u1edbi \u0111\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u201cFFFFFFFFFFF\u201d 2) VTEP tr\u00ean Host 1 \u0111\u00f3ng g\u00f3i v\u00e0o frame Ethernet broadcast v\u00e0o m\u1ed9t UDP header v\u1edbi \u0111\u1ecba ch\u1ec9 IP \u0111\u00edch multicast v\u00e0 \u0111\u1ecba ch\u1ec9 IP ngu\u1ed3n 10.20.10.10 c\u1ee7a VTEP. 3) M\u1ea1ng v\u1eadt l\u00fd s\u1ebd chuy\u1ec3n g\u00f3i tin multicast t\u1edbi c\u00e1c host join v\u00e0o nh\u00f3m IP multicast \u201c239.1.1.10\u201d. 4) VTEP tr\u00ean Host 2 nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin \u0111\u00e3 \u0111\u00f3ng g\u00f3i. D\u1ef1a v\u00e0o outer v\u00e0 inner header, n\u00f3 s\u1ebd t\u1ea1o m\u1ed9t entry trong b\u1ea3ng forwarding ch\u1ec9 ra mapping gi\u1eefa MAC c\u1ee7a m\u00e1y VM MAC1 \u1ee9ng v\u1edbi VTEP ngu\u1ed3n v\u00e0 \u0111\u1ecba ch\u1ec9 IP c\u1ee7a n\u00f3. VTEP c\u0169ng ki\u1ec3m tra VNI c\u1ee7a g\u00f3i tin \u0111\u1ec3 quy\u1ebft \u0111\u1ecbnh s\u1ebd chuy\u1ec3n ti\u1ebfp g\u00f3i tin v\u00e0o trong cho m\u00e1y \u1ea3o VM b\u00ean trong n\u00f3 hay kh\u00f4ng. 5) G\u00f3i tin \u0111\u01b0\u1ee3c de-encapsulated v\u00e0 chuy\u1ec3n v\u00e0o t\u1edbi VM m\u00e0 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. H\u00ecnh sau minh h\u1ecda c\u00e1ch m\u00e0 VTEP t\u00ecm ki\u1ebfm th\u00f4ng tin trong forwarding table \u0111\u1ec3 g\u1eedi unicast tr\u1ea3 l\u1eddi l\u1ea1i t\u1eeb VM t\u1eeb VTEP 2: 1) M\u00e1y \u1ea3o VM MAC2 tr\u00ean Host 2 \u0111\u00e1p tr\u1ea3 l\u1ea1i b\u1ea3n tin ARP request b\u1eb1ng c\u00e1ch g\u1eedi unicast l\u1ea1i g\u00f3i tin v\u1edbi \u0111\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 MAC1 2) Sau khi nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin unicast \u0111\u00f3, VTEP tr\u00ean Host 2 th\u1ef1c hi\u1ec7n t\u00ecm ki\u1ebfm th\u00f4ng tin trong b\u1ea3ng forwarding table v\u00e0 l\u1ea5y \u0111\u01b0\u1ee3c th\u00f4ng tin \u1ee9ng v\u1edbi MAC \u0111\u00edch l\u00e0 MAC 1. VTEP s\u1ebd bi\u1ebft r\u1eb1ng ph\u1ea3i chuy\u1ec3n g\u00f3i tin t\u1edbi m\u00e1y \u1ea3o VM MAC 1 b\u1eb1ng c\u00e1ch g\u1eedi g\u00f3i tin t\u1edbi VTEP c\u00f3 \u0111\u1ecba ch\u1ec9 \u201c10.20.10.10\u201d. 3) VTEP t\u1ea1o b\u1ea3n tin unicast v\u1edbi \u0111\u1ecba ch\u1ec9 \u0111\u00edch l\u00e0 \u201c10.20.10.10\u201d v\u00e0 g\u1eedi n\u00f3 \u0111i. Tr\u00ean Host 1, VTEP s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin unicast v\u00e0 c\u0169ng h\u1ecdc \u0111\u01b0\u1ee3c v\u1ecb tr\u00ed c\u1ee7a VM MAC2 nh\u01b0 h\u00ecnh sau: Host 1 VTEP \u2013 Forwarding table entry 1) G\u00f3i tin \u0111\u01b0\u1ee3c chuy\u1ec3n t\u1edbi Host 1 2) VTEP tr\u00ean Host 1 nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin. D\u1ef1a tr\u00ean outer v\u00e0 inner header, n\u00f3 t\u1ea1o m\u1ed9t entry trong b\u1ea3ng forwarding \u00e1nh x\u1ea1 \u0111\u1ecba ch\u1ec9 MAC 2 v\u00e0 VTEP tr\u00ean Host 2. VTEP c\u0169ng check l\u1ea1i VNI v\u00e0 quy\u1ebft \u0111\u1ecbnh g\u1eedi frame v\u00e0o c\u00e1c VM b\u00ean trong. 3) G\u00f3i tin \u0111\u01b0\u1ee3c de-encapsulated v\u00e0 chuy\u1ec3n t\u1edbi ch\u00ednh x\u00e1c VM c\u00f3 MAC \u0111\u00edch tr\u00f9ng v\u00e0 n\u1eb1m trong VXLAN 5001. C\u00e1c b\u01b0\u1edbc tr\u00ean l\u00e0 qu\u00e1 tr\u00ecnh ho\u1ea1t \u0111\u1ed9ng trong VXLAN. Tham kh\u1ea3o th\u00eam m\u00f4 h\u00ecnh multiple VXLAN sau: https://blogs.vmware.com/vsphere/2013/05/vxlan-series-multiple-logical-networks-mapped-to-one-multicast-group-address-part-4.html 4. Tham kh\u1ea3o th\u00eam \u00b6 ovs-vsctl add-port br0 vxlan1 -- set interface vxlan1 type=vxlan options:remote_ip=192.168.30.139 options:key=flow options:dst_port=4789 ovs-appctl ofproto/trace br-tun in_port=vxlan-c0a84583 ip link add vxlan0 type vxlan id 38 group 239.30.1.2 dev ens224 dstport 4789 4.: https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Virtualization/docs/4.Tim_hieu_VXLAN.md","title":"7. VXLAN"},{"location":"Openstack_Research/Neutron/7. VXLAN/#tim_hieu_vxlan","text":"","title":"T\u00ecm hi\u1ec3u VXLAN"},{"location":"Openstack_Research/Neutron/7. VXLAN/#1_van_e_voi_vlan","text":"VLAN \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng ch\u1ee7 y\u1ebfu \u0111\u1ec3 c\u00f4 l\u1eadp d\u1eef li\u1ec7u tr\u00ean layer 2. C\u00e1c m\u00f4i tr\u01b0\u1eddng m\u1ea1ng l\u1edbn y\u00eau c\u1ea7u m\u1edf r\u1ed9ng kh\u1ea3 n\u0103ng c\u00f4 l\u1eadp l\u1edbn h\u01a1n kh\u1ea3 n\u0103ng \u0111\u00e1p \u1ee9ng c\u1ee7a VLAN Hi\u1ec7n t\u1ea1i VLAN ch\u1ec9 h\u1ed7 tr\u1ee3 t\u1ed1i \u0111a t\u1ed1i \u0111a 12 bit VLAN_ID, b\u1ecb gi\u1edbi h\u1ea1n trong 4096 VLAN_ID S\u1eed d\u1ee5ng STP cung c\u1ea5p m\u1ed9t topology L2 ch\u1ed1ng loop v\u00e0 c\u1eaft b\u1ecf \u0111i h\u1ea7u h\u1ebft nh\u1eefng li\u00ean k\u1ebft d\u01b0 l\u1eeba. V\u1ea5n \u0111\u1ec1 l\u01b0u tr\u1eef MAC tr\u00ean c\u00e1c swtich khi s\u1ed1 l\u01b0\u1ee3ng m\u00e1y \u1ea3o qu\u00e1 nhi\u1ec1u, c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn tr\u00f9ng MAC Adress","title":"1. V\u1ea5n \u0111\u1ec1 v\u1edbi VLAN"},{"location":"Openstack_Research/Neutron/7. VXLAN/#2_vxlan_la_gi","text":"VXLAN (Virtual eXtensible LANs) : \u0111\u00e2y l\u00e0 c\u00f4ng ngh\u1ec7 cung c\u1ea5p d\u1ecbch v\u1ee5 \u0111\u1ec3 k\u1ebft n\u1ed1i Ethernet t\u1edbi c\u00e1c thi\u1ebft b\u1ecb cu\u1ed1i nh\u01b0 VLAN ng\u00e0y nay, nh\u01b0ng c\u00f3 nhi\u1ec1u t\u00ednh n\u0103ng m\u1edf r\u1ed9ng h\u01a1n. So s\u00e1nh v\u1edbi VLAN, VXLAN \u0111\u01b0\u1ee3c m\u1edf r\u1ed9ng h\u01a1n v\u1ec1 quy m\u00f4 v\u00e0 kh\u1ea3 n\u0103ng tri\u1ec3n khai ch\u00fang. Trong chu\u1ea9n \u0111\u1ecbnh ngh\u0129a cho VLAN 802.1q ch\u1ec9 d\u00e0nh ra 12 bit \u0111\u1ec3 \u0111\u00e1nh VLAN-ID. VXLAN s\u1eed d\u1ee5ng 24 bit \u0111\u1ec3 \u0111\u00e1nh \u0111\u1ecba ch\u1ec9 VLAN_ID. Ngh\u0129a l\u00e0 n\u00f3 s\u1ebd h\u1ed7 tr\u1ee3 kh\u00f4ng gian \u0111\u1ecba ch\u1ec9 VXLAN_ID l\u00ean t\u1edbi 4 l\u1ea7n so v\u1edbi VLAN, t\u1ee9c l\u00e0 kho\u1ea3ng h\u01a1n 16 tri\u1ec7u. \u0110i\u1ec1u n\u00e0y s\u1ebd cung c\u1ea5p \u0111\u1ee7 kh\u00f4ng gian \u0111\u1ec3 tri\u1ec3n khai c\u00e1c quy m\u00f4 m\u1ea1ng trong v\u00e0i n\u0103m t\u1edbi. VXLAN s\u1eed d\u1ee5ng IP (c\u1ea3 unicast v\u00e0 multicast) nh\u01b0 ph\u01b0\u01a1ng ti\u1ec7n truy\u1ec1n. S\u1ef1 ph\u1ed5 bi\u1ebfn c\u1ee7a m\u1ea1ng IP v\u00e0 c\u00e1c thi\u1ebft b\u1ecb cho ph\u00e9p \u0111\u1ea7u cu\u1ed1i s\u1ebd cho ph\u00e9p kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng v\u01b0\u1ee3t tr\u1ed9i ti\u1ebfn xa h\u01a1n r\u1ea5t nhi\u1ec1u so v\u1edbi VLAN s\u1eed d\u1ee5ng 802.1q hi\u1ec7n nay. Kh\u00f4ng g\u00ec c\u00f3 th\u1ec3 ph\u1ee7 nh\u1eadn r\u1eb1ng c\u00e1c c\u00f4ng ngh\u1ec7 kh\u00e1c c\u00f3 th\u1ec3 m\u1edf r\u1ed9ng \u0111\u01b0\u1ee3c ph\u1ea1m vi c\u1ee7a VLAN, nh\u01b0ng kh\u00f4ng c\u00f3 g\u00ec c\u00f3 th\u1ec3 tri\u1ec3n khai ph\u1ed5 bi\u1ebfn nh\u01b0 m\u1ea1ng IP.","title":"2. VXLAN l\u00e0 g\u00ec ?"},{"location":"Openstack_Research/Neutron/7. VXLAN/#3_cac_khai_niem_trong_vxlan","text":"","title":"3. C\u00e1c kh\u00e1i ni\u1ec7m trong VXLAN ?"},{"location":"Openstack_Research/Neutron/7. VXLAN/#131_vni","text":"VXLAN ho\u1ea1t \u0111\u1ed9ng tr\u00ean c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng m\u1ea1ng hi\u1ec7n c\u00f3 v\u00e0 cung c\u1ea5p m\u1ed9t ph\u01b0\u01a1ng ti\u1ec7n \u0111\u1ec3 \"k\u00e9o d\u00e0i\" m\u1ed9t m\u1ea1ng l\u1edbp 2. T\u00f3m l\u1ea1i, VXLAN l\u00e0 m\u1ed9t m\u1ea1ng l\u1edbp 2 overlay tr\u00ean m\u1ea1ng l\u1edbp 3. M\u1ed7i l\u1edbp m\u1ea1ng nh\u01b0 v\u1eady \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 VXLAN segment. Ch\u1ec9 c\u00e1c m\u00e1y \u1ea3o trong c\u00f9ng VXLAN segment m\u1edbi c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi nhau. M\u1ed7i VXLAN segment \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh th\u00f4ng qua ID k\u00edch th\u01b0\u1edbc 24 bit, g\u1ecdi l\u00e0 VXLAN Network Identifier (VNI) . \u0110i\u1ec1u n\u00e0y cho ph\u00e9p t\u1ed1i \u0111a 16 tri\u1ec7u c\u00e1c VXLAN segment c\u00f9ng t\u1ed3n t\u1ea1i trong c\u00f9ng m\u1ed9t domain. VNI x\u00e1c \u0111\u1ecbnh ph\u1ea1m vi c\u1ee7a inner MAC frame sinh ra b\u1edfi m\u00e1y \u1ea3o VM. Do \u0111\u00f3, b\u1ea1n c\u00f3 th\u1ec3 overlapping \u0111\u1ecba ch\u1ec9 MAC th\u00f4ng qua segment nh\u01b0 kh\u00f4ng b\u1ecb l\u1eabn l\u1ed9n c\u00e1c l\u01b0u l\u01b0\u1ee3ng b\u1edfi ch\u00fang \u0111\u00e3 b\u1ecb c\u00f4 l\u1eadp b\u1edfi VNI kh\u00e1c nhau. VNI n\u1eb1m trong header \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u1edbi innere MAC sinh ra b\u1edfi VM.","title":"1.3.1.   VNI"},{"location":"Openstack_Research/Neutron/7. VXLAN/#132_encapsulation_va_vtep","text":"VXLAN l\u00e0 c\u00f4ng ngh\u1ec7 overlay qua l\u1edbp m\u1ea1ng. Overlay Network c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a nh\u01b0 l\u00e0 m\u1ed9t m\u1ea1ng logic m\u00e0 \u0111\u01b0\u1ee3c t\u1ea1o tr\u00ean m\u1ed9t n\u1ec1n t\u1ea3ng m\u1ea1ng v\u1eadt l\u00fd \u0111\u00e3 c\u00f3 s\u1eb5n. VXLAN t\u1ea1o m\u1ed9t m\u1ea1ng v\u1eadt l\u00fd layer 2 tr\u00ean l\u1edbp m\u1ea1ng IP. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 2 t\u1eeb kh\u00f3a \u0111\u01b0\u1ee3c d\u00f9ng trong c\u00f4ng ngh\u1ec7 overlay network: Encapsulate : \u0110\u00f3ng g\u00f3i nh\u1eefng g\u00f3i tin ethernet th\u00f4ng th\u01b0\u1eddng trong m\u1ed9t header m\u1edbi. V\u00ed d\u1ee5: trong c\u00f4ng ngh\u1ec7 overlay IPSec VPN, \u0111\u00f3ng g\u00f3i g\u00f3i tin IP th\u00f4ng th\u01b0\u1eddng v\u00e0o m\u1ed9t IP header kh\u00e1c. VTEP : Vi\u1ec7c li\u00ean l\u1ea1c \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp gi\u1eefa 2 \u0111\u1ea7u tunnel end points (\u0111\u01b0\u1eddng \u1ed1ng). Khi b\u1ea1n \u00e1p d\u1ee5ng v\u00e0o v\u1edbi c\u00f4ng ngh\u1ec7 overlay trong VXLAN, b\u1ea1n s\u1ebd th\u1ea5y VXLAN s\u1ebd \u0111\u00f3ng g\u00f3i m\u1ed9t frame MAC th\u00f4ng th\u01b0\u1eddng v\u00e0o m\u1ed9t UDP header. V\u00e0 t\u1ea5t c\u1ea3 c\u00e1c host tham gia v\u00e0o VXLAN th\u00ec ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u1ed9t tunnel end points. Ch\u00fang g\u1ecdi l\u00e0 Virtual Tunnel Endpoints (VTEPs) VTEPs l\u00e0 c\u00e1c node m\u00e0 cung c\u1ea5p c\u00e1c ch\u1ee9c n\u0103ng Encalsulation v\u00e0 De-encapsulation. Ch\u00fang bi\u1ebft r\u00f5 \u0111\u01b0\u1ee3c l\u00e0m th\u1ebf n\u00e0o m\u00e0 VTEPs encap v\u00e0 de-encap l\u01b0u l\u01b0\u1ee3ng t\u1eeb b\u1ea5t k\u00ec m\u00e1y \u1ea3o k\u1ebft n\u1ed1i v\u1edbi m\u1ed9t m\u1ea1ng VXLAN d\u1ef1a tr\u00ean m\u1ea1ng v\u1eadt l\u00fd layer 2. VXLAN h\u1ecdc t\u1ea5t c\u1ea3 c\u00e1c \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u00e1y \u1ea3o v\u00e0 vi\u1ec7c k\u1ebft n\u1ed1i n\u00f3 t\u1edbi VTEP IP th\u00ec \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n th\u00f4ng qua s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a m\u1ea1ng v\u1eadt l\u00fd. M\u1ed9t trong nh\u1eefng giao th\u1ee9c \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong m\u1ea1ng v\u1eadt l\u00fd l\u00e0 IP multicast. VXLAN s\u1eed d\u1ee5ng giao th\u1ee9c c\u1ee7a IP multicast \u0111\u1ec3 c\u01b0 tr\u00fa trong b\u1ea3ng forwarding trong VTEP. Do s\u1ef1 \u0111\u00f3ng g\u00f3i (encapsulation) n\u00e0y, VXLAN c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 thi\u1ebft l\u1eadp \u0111\u01b0\u1eddng h\u1ea7m (tunneling) \u0111\u1ec3 k\u00e9o d\u00e0i m\u1ea1ng l\u1edbp 2 th\u00f4ng qua l\u1edbp 3. \u0110i\u1ec3m cu\u1ed1i c\u00e1c tunnel n\u00e0y - (VXLAN Tunnel End Point ho\u1eb7c VTEP) n\u1eb1m trong hypervisor tr\u00ean server m\u00e1y ch\u1ee7 c\u1ee7a c\u00e1c VM. Do \u0111\u00f3, VNI v\u00e0 VXLAN li\u00ean quan t\u1edbi c\u00e1c kh\u00e1i ni\u1ec7m \u0111\u00f3ng g\u00f3i header tunnel \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi VTEP - v\u00e0 trong su\u1ed1t v\u1edbi VM. L\u01b0u \u00fd : VTEP c\u00f3 th\u1ec3 n\u1eb1m tr\u00ean switch ho\u1eb7c server v\u1eadt l\u00fd v\u00e0 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean ph\u1ea7n m\u1ec1m ho\u1eb7c ph\u1ea7n c\u1ee9ng.","title":"1.3.2.   Encapsulation v\u00e0 VTEP"},{"location":"Openstack_Research/Neutron/7. VXLAN/#133_vxlan_frame_format","text":"Frame Ethernet th\u00f4ng th\u01b0\u1eddng bao g\u1ed3m \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n, MAC \u0111\u00edch, Ethernet type v\u00e0 th\u00eam ph\u1ea7n VLAN_ID (802.1q) n\u1ebfu c\u00f3. \u0110\u00e2y l\u00e0 frame \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i s\u1eed d\u1ee5ng VXLAN, th\u00eam c\u00e1c header sau: VXLAN header : 8 byte bao g\u1ed3m c\u00e1c tr\u01b0\u1eddng quan tr\u1ecdng sau: Flags : 8 but, trong \u0111\u00f3 bit th\u1ee9 5 (I flag) \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 1 \u0111\u1ec3 ch\u1ec9 ra r\u1eb1ng \u0111\u00f3 l\u00e0 m\u1ed9t frame c\u00f3 VNI c\u00f3 gi\u00e1 tr\u1ecb. 7 bit c\u00f2n l\u1ea1i d\u00f9ng d\u1eef tr\u1eef \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp l\u00e0 0 h\u1ebft. VNI : 24 bit cung c\u1ea5p \u0111\u1ecbnh danh duy nh\u1ea5t cho VXLAN segment. C\u00e1c VM trong c\u00e1c VXLAN kh\u00e1c nhau kh\u00f4ng th\u1ec3 giao ti\u1ebfp v\u1edbi nhau. 24 bit VNI cung c\u1ea5p l\u00ean t\u1edbi h\u01a1n 16 tri\u1ec7u VXLAN segment trong m\u1ed9t v\u00f9ng qu\u1ea3n tr\u1ecb m\u1ea1ng. Outer UDP Header : port ngu\u1ed3n c\u1ee7a Outer UDP \u0111\u01b0\u1ee3c g\u00e1n t\u1ef1 \u0111\u1ed9ng v\u00e0 sinh ra b\u1edfi VTEP v\u00e0 port \u0111\u00edch th\u00f4ng th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0 port 4789 hay \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng (c\u00f3 th\u1ec3 ch\u1ecdn port kh\u00e1c). Outer IP Header : Cung c\u1ea5p \u0111\u1ecba ch\u1ec9 IP ngu\u1ed3n c\u1ee7a VTEP ngu\u1ed3n k\u1ebft n\u1ed1i v\u1edbi VM b\u00ean trong. \u0110\u1ecba ch\u1ec9 IP outer \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 IP c\u1ee7a VTEP nh\u1eadn frame. Outer Ethernet Header : cung c\u1ea5p \u0111\u1ecba ch\u1ec9 MAC ngu\u1ed3n c\u1ee7a VTEP c\u00f3 khung frame ban \u0111\u1ea7u. \u0110\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 c\u1ee7a hop ti\u1ebfp theo \u0111\u01b0\u1ee3c \u0111\u1ecbnh tuy\u1ebfn b\u1edfi VTEP. Outer Ethernet header c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1eafn tag theo chu\u1ea9n 802.1q trong qu\u00e1 tr\u00ecnh v\u1eadn chuy\u1ec3n trong m\u1ea1ng.","title":"1.3.3.   VXLAN frame format"},{"location":"Openstack_Research/Neutron/7. VXLAN/#2_cach_hoat_ong_cua_vxlan","text":"VXLAN ho\u1ea1t \u0111\u1ed9ng d\u1ef1a tr\u00ean vi\u1ec7c g\u1eedi c\u00e1c frame th\u00f4ng qua giao th\u1ee9c IP Multicast. Trong qu\u00e1 tr\u00ecnh c\u1ea5u h\u00ecnh VXLAN, c\u1ea7n c\u1ea5p ph\u00e1t \u0111\u1ecba ch\u1ec9 IP multicast \u0111\u1ec3 g\u00e1n v\u1edbi VXLAN s\u1ebd t\u1ea1o. M\u1ed7i \u0111\u1ecba ch\u1ec9 IP multicast s\u1ebd \u0111\u1ea1i di\u1ec7n cho m\u1ed9t VXLAN. Sau \u0111\u00e2y s\u1ebd t\u00ecm hi\u1ec3u ho\u1ea1t \u0111\u1ed9ng chi ti\u1ebft c\u00e1ch frame \u0111i qua VTEP v\u00e0 \u0111i qua m\u1ea1ng v\u1eadt l\u00fd trong VXLAN tri\u1ec3n khai tr\u00ean m\u1ed9t m\u1ea1ng logic v\u1edbi m\u00f4 h\u00ecnh nh\u01b0 sau:","title":"2. C\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a VXLAN"},{"location":"Openstack_Research/Neutron/7. VXLAN/#21_vm_gui_request_tham_gia_vao_group_multicast","text":"Gi\u1ea3 s\u1eed m\u1ed9t m\u1ea1ng logic tr\u00ean 4 host nh\u01b0 h\u00ecnh. Topo m\u1ea1ng v\u1eadt l\u00fd cung c\u1ea5p m\u1ed9t VLAN 2000 \u0111\u1ec3 v\u1eadn chuy\u1ec3n c\u00e1c l\u01b0u l\u01b0\u1ee3ng VXLAN. Trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y, ch\u1ec9 IGMP snooping v\u00e0 IGMP querier \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh tr\u00ean m\u1ea1ng v\u1eadt l\u00fd. M\u1ed9t v\u00e0i b\u01b0\u1edbc s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u01b0\u1edbc khi c\u00e1c thi\u1ebft b\u1ecb tr\u00ean m\u1ea1ng v\u1eadt l\u00fd c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c g\u00f3i tin multicast. IGMP Packet flows: 1) M\u00e1y \u1ea3o VM (MAC1) tr\u00ean Host 1 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ed9t m\u1ea1ng logical layer 2 m\u00e0 c\u00f3 VXLAN 5001 \u1edf \u0111\u00f3. 2) VTEP tr\u00ean Host 1 g\u1eedi b\u1ea3n tin IGMP \u0111\u1ec3 join v\u00e0o m\u1ea1ng v\u00e0 join v\u00e0o nh\u00f3m multicast 239.1.1.100 \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. 3) T\u01b0\u01a1ng t\u1ef1, m\u00e1y \u1ea3o VM (MAC2) tr\u00ean Host 4 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi m\u1ea1ng m\u00e0 c\u00f3 VXLAN 5001. 4) VTEP tr\u00ean Host 4 g\u1eedi b\u1ea3n tin IGMP join v\u00e0o m\u1ea1ng v\u00e0 join v\u00e0o nh\u00f3m multicast 239.1.1.100 \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. Host 2 v\u00e0 Host 3 VTEP kh\u00f4ng join nh\u00f3m multicast b\u1edfi v\u00ec ch\u00fang kh\u00f4ng c\u00f3 m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean n\u00f3 v\u00e0 c\u1ea7n k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. Ch\u1ec9 VTEP n\u00e0o c\u1ea7n tham gia v\u00e0o nh\u00f3m multicast m\u1edbi g\u1eedi request join v\u00e0o nh\u00f3m Multicast Packet flow: 1) M\u00e1y \u1ea3o VM (MAC1) tr\u00ean Host 1 sinh ra m\u1ed9t frame broadcast. 2) VTEP tr\u00ean Host 1 \u0111\u00f3ng g\u00f3i frame broadcast n\u00e0y v\u00e0o m\u1ed9t UDP header v\u1edbi IP \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 IP multicast 239.1.1.100 3) M\u1ea1ng v\u1eadt l\u00fd s\u1ebd chuy\u1ec3n c\u00e1c g\u00f3i tin n\u00e0y t\u1edbi Host 4 VTEP, v\u00ec n\u00f3 \u0111\u00e3 join v\u00e0o nh\u00f3m multicast 239.1.1.100. Host 2 v\u00e0 3 VTEP s\u1ebd kh\u00f4ng nh\u1eadn \u0111\u01b0\u1ee3c frame broadcast n\u00e0y. 4) VTEP tr\u00ean Host 4 \u0111\u1ea7u ti\u00ean \u0111\u1ed1i chi\u1ebfu header \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i, n\u1ebfu 24 bit VNI tr\u00f9ng v\u1edbi ID c\u1ee7a VXLAN. N\u00f3 s\u1ebd decapsulated l\u1edbp g\u00f3i \u0111\u01b0\u1ee3c VTEP host 1 \u0111\u00f3ng v\u00e0o v\u00e0 chuy\u1ec3n t\u1edbi m\u00e1y \u1ea3o VM \u0111\u00edch (MAC2).","title":"2.1.  VM g\u1eedi request tham gia v\u00e0o group multicast"},{"location":"Openstack_Research/Neutron/7. VXLAN/#22_vtep_hoc_va_tao_bang_forwarding","text":"Ban \u0111\u1ea7u, m\u1ed7i VTEP sau khi \u0111\u00e3 join v\u00e0o nh\u00f3m IP multicast \u0111\u1ec1u c\u00f3 m\u1ed9t b\u1ea3ng forwarding table nh\u01b0 sau: C\u00e1c b\u01b0\u1edbc sau s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 VTEP h\u1ecdc v\u00e0 ghi v\u00e0o b\u1ea3ng forwarding table: \u0110\u1ea7u ti\u00ean, m\u1ed9t b\u1ea3n tin ARP request \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb VM MAC1 \u0111\u1ec3 t\u00ecm \u0111\u1ecba ch\u1ec9 MAC c\u1ee7a m\u00e1y \u1ea3o \u0111\u00edch n\u00f3 c\u1ea7n g\u1eedi tin \u0111\u1ebfn VM MAC2 tr\u00ean Host 2. ARP request l\u00e0 b\u1ea3n tin broadcast. Host 2 VTEP \u2013 Forwarding table entry 1) VM tr\u00ean Host 1 g\u1eedi b\u1ea3n tin ARP request v\u1edbi \u0111\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u201cFFFFFFFFFFF\u201d 2) VTEP tr\u00ean Host 1 \u0111\u00f3ng g\u00f3i v\u00e0o frame Ethernet broadcast v\u00e0o m\u1ed9t UDP header v\u1edbi \u0111\u1ecba ch\u1ec9 IP \u0111\u00edch multicast v\u00e0 \u0111\u1ecba ch\u1ec9 IP ngu\u1ed3n 10.20.10.10 c\u1ee7a VTEP. 3) M\u1ea1ng v\u1eadt l\u00fd s\u1ebd chuy\u1ec3n g\u00f3i tin multicast t\u1edbi c\u00e1c host join v\u00e0o nh\u00f3m IP multicast \u201c239.1.1.10\u201d. 4) VTEP tr\u00ean Host 2 nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin \u0111\u00e3 \u0111\u00f3ng g\u00f3i. D\u1ef1a v\u00e0o outer v\u00e0 inner header, n\u00f3 s\u1ebd t\u1ea1o m\u1ed9t entry trong b\u1ea3ng forwarding ch\u1ec9 ra mapping gi\u1eefa MAC c\u1ee7a m\u00e1y VM MAC1 \u1ee9ng v\u1edbi VTEP ngu\u1ed3n v\u00e0 \u0111\u1ecba ch\u1ec9 IP c\u1ee7a n\u00f3. VTEP c\u0169ng ki\u1ec3m tra VNI c\u1ee7a g\u00f3i tin \u0111\u1ec3 quy\u1ebft \u0111\u1ecbnh s\u1ebd chuy\u1ec3n ti\u1ebfp g\u00f3i tin v\u00e0o trong cho m\u00e1y \u1ea3o VM b\u00ean trong n\u00f3 hay kh\u00f4ng. 5) G\u00f3i tin \u0111\u01b0\u1ee3c de-encapsulated v\u00e0 chuy\u1ec3n v\u00e0o t\u1edbi VM m\u00e0 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i t\u1edbi VXLAN 5001. H\u00ecnh sau minh h\u1ecda c\u00e1ch m\u00e0 VTEP t\u00ecm ki\u1ebfm th\u00f4ng tin trong forwarding table \u0111\u1ec3 g\u1eedi unicast tr\u1ea3 l\u1eddi l\u1ea1i t\u1eeb VM t\u1eeb VTEP 2: 1) M\u00e1y \u1ea3o VM MAC2 tr\u00ean Host 2 \u0111\u00e1p tr\u1ea3 l\u1ea1i b\u1ea3n tin ARP request b\u1eb1ng c\u00e1ch g\u1eedi unicast l\u1ea1i g\u00f3i tin v\u1edbi \u0111\u1ecba ch\u1ec9 MAC \u0111\u00edch l\u00e0 \u0111\u1ecba ch\u1ec9 MAC1 2) Sau khi nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin unicast \u0111\u00f3, VTEP tr\u00ean Host 2 th\u1ef1c hi\u1ec7n t\u00ecm ki\u1ebfm th\u00f4ng tin trong b\u1ea3ng forwarding table v\u00e0 l\u1ea5y \u0111\u01b0\u1ee3c th\u00f4ng tin \u1ee9ng v\u1edbi MAC \u0111\u00edch l\u00e0 MAC 1. VTEP s\u1ebd bi\u1ebft r\u1eb1ng ph\u1ea3i chuy\u1ec3n g\u00f3i tin t\u1edbi m\u00e1y \u1ea3o VM MAC 1 b\u1eb1ng c\u00e1ch g\u1eedi g\u00f3i tin t\u1edbi VTEP c\u00f3 \u0111\u1ecba ch\u1ec9 \u201c10.20.10.10\u201d. 3) VTEP t\u1ea1o b\u1ea3n tin unicast v\u1edbi \u0111\u1ecba ch\u1ec9 \u0111\u00edch l\u00e0 \u201c10.20.10.10\u201d v\u00e0 g\u1eedi n\u00f3 \u0111i. Tr\u00ean Host 1, VTEP s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin unicast v\u00e0 c\u0169ng h\u1ecdc \u0111\u01b0\u1ee3c v\u1ecb tr\u00ed c\u1ee7a VM MAC2 nh\u01b0 h\u00ecnh sau: Host 1 VTEP \u2013 Forwarding table entry 1) G\u00f3i tin \u0111\u01b0\u1ee3c chuy\u1ec3n t\u1edbi Host 1 2) VTEP tr\u00ean Host 1 nh\u1eadn \u0111\u01b0\u1ee3c g\u00f3i tin. D\u1ef1a tr\u00ean outer v\u00e0 inner header, n\u00f3 t\u1ea1o m\u1ed9t entry trong b\u1ea3ng forwarding \u00e1nh x\u1ea1 \u0111\u1ecba ch\u1ec9 MAC 2 v\u00e0 VTEP tr\u00ean Host 2. VTEP c\u0169ng check l\u1ea1i VNI v\u00e0 quy\u1ebft \u0111\u1ecbnh g\u1eedi frame v\u00e0o c\u00e1c VM b\u00ean trong. 3) G\u00f3i tin \u0111\u01b0\u1ee3c de-encapsulated v\u00e0 chuy\u1ec3n t\u1edbi ch\u00ednh x\u00e1c VM c\u00f3 MAC \u0111\u00edch tr\u00f9ng v\u00e0 n\u1eb1m trong VXLAN 5001. C\u00e1c b\u01b0\u1edbc tr\u00ean l\u00e0 qu\u00e1 tr\u00ecnh ho\u1ea1t \u0111\u1ed9ng trong VXLAN. Tham kh\u1ea3o th\u00eam m\u00f4 h\u00ecnh multiple VXLAN sau: https://blogs.vmware.com/vsphere/2013/05/vxlan-series-multiple-logical-networks-mapped-to-one-multicast-group-address-part-4.html","title":"2.2.  VTEP h\u1ecdc v\u00e0 t\u1ea1o b\u1ea3ng forwarding"},{"location":"Openstack_Research/Neutron/7. VXLAN/#4_tham_khao_them","text":"ovs-vsctl add-port br0 vxlan1 -- set interface vxlan1 type=vxlan options:remote_ip=192.168.30.139 options:key=flow options:dst_port=4789 ovs-appctl ofproto/trace br-tun in_port=vxlan-c0a84583 ip link add vxlan0 type vxlan id 38 group 239.30.1.2 dev ens224 dstport 4789 4.: https://github.com/hocchudong/thuctap012017/blob/master/TamNT/Virtualization/docs/4.Tim_hieu_VXLAN.md","title":"4. Tham kh\u1ea3o th\u00eam"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/","text":"T\u00ecm hi\u1ec3u OVS trong OPS \u00b6 1. OpenvSwtich trong OPS \u00b6 Trong OVS g\u1ed3m c\u00e1c kh\u00e1i ni\u1ec7m sau : br-init (integration Bridge) : 2 c\u00e1c VM s\u1eed d\u1ee5ng c\u00e1c virtual interface \u0111\u1ec3 k\u1ebft n\u1ed1i \u0111\u1ebfn birdge br-eth ( ethernet bridge ) : \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh frame c\u00f3 s\u1eed d\u1ee5ng VLAN_ID tr\u01b0\u1edbc khi chuy\u1ec3n ti\u1ebfp c\u00e1c frame br-tun ( tunnel interface ) : th\u00eam tunnel type v\u00e0o header br-ex ( external bridge ) : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i ra c\u00e1c m\u1ea1ng external. m\u1ea1ng external n\u00e0y l\u00e0 m\u1ea1ng ngo\u00e0i v\u1edbi c\u00e1c m\u1ea1ng \u0111\u1ee9ng sau br-ex, kh\u00f4ng c\u00f3 ngh\u0129a ho\u00e0n to\u00e0n l\u00e0 IP Public veth : s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i c\u00e1c bridge ( OVS to OVS, LB to OVS ) 2 2. OpenVswitch trong Openstack \u00b6 2.1 : M\u00f4i tr\u01b0\u1eddng Multi VLAN tr\u00ean Compute Node \u00b6 Trong m\u00f4 h\u00ecnh tr\u00ean bao g\u1ed3m : - qbr-ID: m\u1ed9t Linux Bridge \u0111\u1ee9ng gi\u1eefa VM v\u00e0 br-init, bao g\u1ed3m 2 port : - port tap - vnet : l\u00e0 TAP-driver, g\u1eafn tr\u1ef1c ti\u1ebfp v\u1edbi VM Network Card - port veth - qvb : c\u1ea7u n\u1ed1i gi\u1eefa Linux Bridge v\u00e0 Br_intu OVS br-init : g\u1ed3m c\u00f3 2 port : port veth - qvo : c\u1ea7u n\u1ed1i v\u1edbi Linux Bridge port veth : c\u1ea7u n\u1ed1i v\u1edbi br-external OVS br-ex : g\u1ed3m 2 port : port br-eth : c\u1ea7u n\u1ed1i v\u1edbi br-init port eth1 : physical interface c\u1ee7a compute node 2.2. M\u00f4 h\u00ecnh VXLAN - Self Service \u00b6 Trong m\u00f4 h\u00ecnh tr\u00ean bao g\u1ed3m : Tr\u00ean Compute Node : - qbr : Linux Bridge g\u1ed3m c\u00f3 2 port - port TAP - vmet : k\u1ebft n\u1ed1i v\u1edbi VM - port veth - qvb : k\u1ebft n\u1ed1i v\u1edbi br-int br-int : OVS g\u1ed3m c\u00f3 2 port port veth - qvo : k\u1ebft n\u1ed1i v\u1edbi Linux Bridge - qbr port veth - patch tun: k\u1ebft n\u1ed1i v\u1edbi br-tun br-tun : OVS g\u1ed3m c\u00f3 2 port port veth - patch-int : k\u1ebft n\u1ed1i v\u1edbi br-int port vxlan : k\u1ebft n\u1ed1i \u0111\u1ebfn overlay network Tr\u00ean Network Node br-tun : OVS g\u1ed3m c\u00f3 2 port port vxvlan : k\u1ebft n\u1ed1i v\u1edbi overlay nework br veth - br tun : k\u1ebft n\u1ed1i \u0111\u1ebfn br init br-init : OVS bao g\u1ed3m 3 port : port TAP : k\u1ebft n\u1ed1i \u0111\u1ebfn namespace DHCP port qr, qg : k\u1ebft n\u1ed1i \u0111\u1ebfn namespace Router br-provider : OVS g\u1ed3m c\u00f3 2 port port veth : k\u1ebft n\u1ed1i t\u1edbi router por ex : k\u1ebft n\u1ed1i v\u1edbi Physical Interface","title":"T\u00ecm hi\u1ec3u OVS trong OPS"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/#tim_hieu_ovs_trong_ops","text":"","title":"T\u00ecm hi\u1ec3u OVS trong OPS"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/#1_openvswtich_trong_ops","text":"Trong OVS g\u1ed3m c\u00e1c kh\u00e1i ni\u1ec7m sau : br-init (integration Bridge) : 2 c\u00e1c VM s\u1eed d\u1ee5ng c\u00e1c virtual interface \u0111\u1ec3 k\u1ebft n\u1ed1i \u0111\u1ebfn birdge br-eth ( ethernet bridge ) : \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh frame c\u00f3 s\u1eed d\u1ee5ng VLAN_ID tr\u01b0\u1edbc khi chuy\u1ec3n ti\u1ebfp c\u00e1c frame br-tun ( tunnel interface ) : th\u00eam tunnel type v\u00e0o header br-ex ( external bridge ) : \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i ra c\u00e1c m\u1ea1ng external. m\u1ea1ng external n\u00e0y l\u00e0 m\u1ea1ng ngo\u00e0i v\u1edbi c\u00e1c m\u1ea1ng \u0111\u1ee9ng sau br-ex, kh\u00f4ng c\u00f3 ngh\u0129a ho\u00e0n to\u00e0n l\u00e0 IP Public veth : s\u1eed d\u1ee5ng \u0111\u1ec3 k\u1ebft n\u1ed1i c\u00e1c bridge ( OVS to OVS, LB to OVS ) 2","title":"1. OpenvSwtich trong OPS"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/#2_openvswitch_trong_openstack","text":"","title":"2. OpenVswitch trong Openstack"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/#21_moi_truong_multi_vlan_tren_compute_node","text":"Trong m\u00f4 h\u00ecnh tr\u00ean bao g\u1ed3m : - qbr-ID: m\u1ed9t Linux Bridge \u0111\u1ee9ng gi\u1eefa VM v\u00e0 br-init, bao g\u1ed3m 2 port : - port tap - vnet : l\u00e0 TAP-driver, g\u1eafn tr\u1ef1c ti\u1ebfp v\u1edbi VM Network Card - port veth - qvb : c\u1ea7u n\u1ed1i gi\u1eefa Linux Bridge v\u00e0 Br_intu OVS br-init : g\u1ed3m c\u00f3 2 port : port veth - qvo : c\u1ea7u n\u1ed1i v\u1edbi Linux Bridge port veth : c\u1ea7u n\u1ed1i v\u1edbi br-external OVS br-ex : g\u1ed3m 2 port : port br-eth : c\u1ea7u n\u1ed1i v\u1edbi br-init port eth1 : physical interface c\u1ee7a compute node","title":"2.1 : M\u00f4i tr\u01b0\u1eddng Multi VLAN tr\u00ean Compute Node"},{"location":"Openstack_Research/Neutron/8. OpenvSwitch-OPS/#22_mo_hinh_vxlan_-_self_service","text":"Trong m\u00f4 h\u00ecnh tr\u00ean bao g\u1ed3m : Tr\u00ean Compute Node : - qbr : Linux Bridge g\u1ed3m c\u00f3 2 port - port TAP - vmet : k\u1ebft n\u1ed1i v\u1edbi VM - port veth - qvb : k\u1ebft n\u1ed1i v\u1edbi br-int br-int : OVS g\u1ed3m c\u00f3 2 port port veth - qvo : k\u1ebft n\u1ed1i v\u1edbi Linux Bridge - qbr port veth - patch tun: k\u1ebft n\u1ed1i v\u1edbi br-tun br-tun : OVS g\u1ed3m c\u00f3 2 port port veth - patch-int : k\u1ebft n\u1ed1i v\u1edbi br-int port vxlan : k\u1ebft n\u1ed1i \u0111\u1ebfn overlay network Tr\u00ean Network Node br-tun : OVS g\u1ed3m c\u00f3 2 port port vxvlan : k\u1ebft n\u1ed1i v\u1edbi overlay nework br veth - br tun : k\u1ebft n\u1ed1i \u0111\u1ebfn br init br-init : OVS bao g\u1ed3m 3 port : port TAP : k\u1ebft n\u1ed1i \u0111\u1ebfn namespace DHCP port qr, qg : k\u1ebft n\u1ed1i \u0111\u1ebfn namespace Router br-provider : OVS g\u1ed3m c\u00f3 2 port port veth : k\u1ebft n\u1ed1i t\u1edbi router por ex : k\u1ebft n\u1ed1i v\u1edbi Physical Interface","title":"2.2. M\u00f4 h\u00ecnh VXLAN - Self Service"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/","text":"T\u00ecm hi\u1ec3u flow packet khi s\u1eed d\u1ee5ng OpenvSwitch trong Openstack \u00b6 1. M\u00f4i tr\u01b0\u1eddng gi\u1ea3 l\u1eadp \u00b6 M\u00f4 h\u00ecnh B\u1eafc - Nam : li\u00ean h\u1ec7 gi\u1eefa c\u00e1c instance v\u00e0 m\u1ea1ng ngo\u00e0i ( h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd ) M\u00f4 h\u00ecnh \u0110\u00f4ng - T\u00e2y : li\u00ean h\u1ec7 gi\u1eefa c\u00e1c instance v\u1edbi nhau c\u00f9ng m\u1ea1ng ho\u1eb7c kh\u00e1c m\u1ea1ng. Gi\u1ea3 \u0111\u1ecbnh m\u00f4i tr\u01b0\u1eddng m\u1ea1ng nh\u01b0 sau : Provider - VLANID 101 Self-service network 1 - VNI 101 Self-service network 2 - VNI 102 Self-service route instance 1,2 2. M\u00f4 h\u00ecnh Self-Service \u00b6 2.1 . B\u1eafc - Nam , s\u1eed d\u1ee5ng fixed IP \u00b6 Tr\u00ean m\u00f4 h\u00ecnh n\u00e0y, network node s\u1ebd th\u1ef1c hi\u1ec7n th\u1ef1c hi\u1ec7n Source NAT \u0111\u1ec3 g\u1eedi traffic c\u1ee7a c\u00e1c instance ra m\u1ea1ng external Tr\u00ean Compute Node B1 : Packet t\u1eeb instance interface ( 1 ) \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp \u0111\u1ebfn veth pair ( 2 ) tr\u00ean Linux Bridge B2 : Security group tr\u00ean Linux Bridge s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter (3 ) B3 : Linux Bridge (4 ) chuy\u1ec3n ti\u1ebfp c\u00e1c frame \u0111\u1ebfn OVS integration bridge s\u1eed d\u1ee5ng veth pair B5 : T\u1ea1i \u0111\u00e2y ( 5 ) integration bridge th\u00eam tag VNI 101, x\u00e1c \u0111\u1ecbnh Tunnel ID B6 : OVS integration bridge veth port ( 6 ) s\u1ebd chuy\u1ec3n c\u00e1c packet \u0111\u1ebfn OVS Tunnel Bridge veth port ( 7 ) B7 : OVS tunnel bridge s\u1ebd \u0111\u00f3ng g\u00f3i c\u00e1c packet v\u1edbi VNI 101 ( 8 ) B8 : Physical interface ( 9 ) cho ph\u00e9p m\u1ea1ng overlay chuy\u1ec3n ti\u1ebfp c\u00e1c packet \u0111\u1ebfn network node ( 10 Tr\u00ean Network Node B1 : Tr\u00ean physical interface ( 11 ) c\u1ee7a network node cho ph\u00e9p c\u00e1c packet t\u1eeb overlay network \u0111i v\u00e0o OVS tunnel bridge ( 12 ) B2 : OVS Tunnel s\u1ebd th\u00eam Tunnel ID , v\u00e0 g\u1eafn m\u1ed9t VLAN ID cho c\u00e1c packet n\u00e0y B3 : OVS Tunnel veth port ( 13 ) s\u1ebd g\u1eedi packet t\u1edbi OVS integration veth port ( 14 ) B4 : OVS integration bridge port ( 15 ) s\u1ebd b\u1ecf c\u00e1c VLAN ID v\u00e0 chuy\u1ec3n ti\u1ebfp t\u1edbi router namespace ( 16 ) B5 : \u0110\u1ed1i v\u1edbi IPv4 : SNAT s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n t\u1ea1i \u0111\u00e2y , thay \u0111\u1ed5i \u0111\u1ecba ch\u1ec9 IP c\u1ee7a self-service network th\u00e0nh IP c\u1ee7a provider network ( 17 ) B6 : Router ( 18 ) chuy\u1ec3n ti\u1ebfp packet OVS integration bridge , sau \u0111\u00f3 s\u1ebd th\u00eam VLAN ID v\u00e0o packet B7 : OVS integration bridge patch port ( 19 ) s\u1ebd forward packet t\u1edbi OVS provider bridge phy-br-provider ( 20 ) B8 : OVS provider bridge port( 21 ) s\u1ebd forward packet ra physical interface ( 22 ) B9 : Physical interface s\u1ebd g\u1eedi packet ra ngo\u00e0i ( 23 ) 2.2 : B\u1eafc - Nam s\u1eed d\u1ee5ng Floating IP \u00b6 S\u1eed d\u1ee5ng SNAT \u0111\u1ec3 c\u00e1c m\u00e1y \u1ea3o giao ti\u1ebfp ra ngo\u00e0i v\u00e0 DNAT \u0111\u1ec3 m\u1ea1ng ngo\u00e0i giao ti\u1ebfp v\u1edbi instance Tr\u01b0\u1eddng h\u1ee3p d\u01b0\u1edbi \u0111\u00e2y t\u1eeb m\u1ed9t m\u00e1y t\u1eeb m\u1ea1ng ngo\u00e0i li\u00ean h\u1ec7 v\u1edbi instance Tr\u00ean Nodework Node B1 : T\u1eeb m\u1ea1ng ngo\u00e0i ( 1 ) g\u1eedi packet v\u00e0o provider physical interface ( 2 ) B2 : Provider physical interface ( 3 ) chuy\u1ec3n ti\u1ebfp packet \u0111\u1ebfn OVS provider bridge, sau \u0111\u00f3 s\u1ebd l\u1ea5y VLAN ID c\u1ee7a packet B3 : OVS provider bridge port ( 4 ) s\u1ebd forward packet sang OVS integration bridge port ( 5 ) B5 : OVS integration bridge port ( 6 ) s\u1ebd remove internal VLAN v\u00e0 chuy\u1ec3n packet \u0111\u1ebfn router namepsace. Sau \u0111\u00f3 th\u1ef1c hi\u1ec7n Destination NAT ( 7 ) B6 : Router ( 8 ) chuy\u1ec3n ti\u1ebfp c\u00e1c packet sang OVS integration bridge ( 9 ) B7 : T\u1ea1i OVS intergration bridge s\u1ebd th\u00eam c\u00e1c VLAN ID , sau \u0111\u00f3 s\u1ebd t\u00ecm Tunnel ID t\u01b0\u01a1ng \u1ee9ng B8 : OVS intergration bridge ( 10 ) chuy\u1ec3n c\u00e1c packet t\u1edbi OVS tunnel bridge ( 11 ) B9 : OVS tunnel bridge ( 12 ) s\u1eed d\u1ee5ng VNI cho header c\u00e1c packet B10 : Physical interface s\u1ebd cho ph\u00e9p c\u00e1c overlay network ( 13 ) g\u1eedi c\u00e1c packet \u0111\u1ebfn compute node ( 14 ) Tr\u00ean Compute Node : B1 : Physical interface ( 15 ) s\u1ebd chuy\u1ec3n ti\u1ebfp c\u00e1c packet \u0111\u1ebfn overlay network ( 16 ) B2 : OVS tunnel bridge s\u1ebd s\u1ebd s\u1eed d\u1ee5ng VLAN ID cho Tunnel ID t\u01b0\u01a1ng \u1ee9ng B3 : OVS tunnel bridge ( 17 ) s\u1ebd chuy\u1ec3n c\u00e1c packet sang OVS ingrateion bridge ( 18 ) s\u1eed d\u1ee5ng patch-int B4 : OVS integration bridge lo\u1ea1i b\u1ecf VLAN B5 : OVS integration bridge s\u1eed d\u1ee5ng securtity group ( 19 ) \u0111\u1ec3 filter c\u00e1c packet sau \u0111\u00f3 g\u1eedi sang Linux Bridge ( 20 ) th\u00f4ng qua veth pair B6 : Securtiy group s\u1ebd th\u1ef1c hi\u1ec7n filtering ( 21 ) B7 : Security group ( 22 ) s\u1ebd chuy\u1ec3n ti\u1ebfp goi tin \u0111\u1ebfn instance interface ( 23 ) 2.3 : \u0110\u00f4ng - T\u00e2y : c\u00e1c instance c\u00f9ng 1 m\u1ea1ng \u00b6 Tr\u00ean Compute 1 : B1 : instance interface ( 1 ) forward c\u00e1c packet t\u1edbi security group tr\u00ean ( Linux Bridge ) ( 2 ) th\u00f4ng qua veth pair B2 : securtity group ( 3 ) \u0111\u1ea3m nhi\u1ec7n filter t\u1ea1i \u0111\u00e2y B3 : Linux Bridge port( 4 ) forward packet t\u1edbi OVS integration ( 5 )nh\u1edd veth pair B4 : OVS ingration bridge th\u00eam VLAN ID v\u00e0o packet B5 : OVS integration bridge thay VLAN ID b\u1eb1ng Tunnel ID B6 : OVS integration bridge patch port ( 6 ) forward packet t\u1edbi OVS Tunnel bridge patch port ( 7 ) B7 : OVS tunnel bridge ( 8 ) g\u1eafn VNI v\u00e0o packet B8 : Underlay nework ( 9 ) cho ph\u00e9p overlay network ( 10 ) chuy\u1ec3n packet \u0111\u1ebfn network node Tr\u00ean Compute 2 B1 : Underlay network ( 11) cho ph\u00e9p overlay networking ( 12 ) forward t\u1edbi OVS bridge tunnel B2 : OVS tunnel bridge th\u00eam m\u1ed9t Tunnel ID v\u00e0o packet B3 : OVS tunnel bridge thay \u0111\u1ed5i Tunnel ID b\u1eb1ng VLAN ID t\u01b0\u01a1ng \u1ee9ng. B4 : OVS tunnel bridge patch port ( 13 ) forward packet t\u1edbi OVS integratation bridge patch tun port ( 14 ) B5 : OVS integration bridge b\u1ecf VLAN ( 15 ) forward packet \u0111\u1ebfn Linux bridge veth port ( 16 ) B6 : Security Group \u0111\u1ea3m nhi\u1ec7m filter packet ( 17 ) B7 : Linux bridge veth port ( 18 ) forward packet \u0111\u1ebfn instance interface ( 19 ) 2.4 : \u0110\u00f4ng - T\u00e2y : c\u00e1c instance kh\u00e1c m\u1ea1ng \u00b6 Tr\u00ean Compute Node : B1 : instance interface ( 1 ) forward packet \u0111\u1ebfn Linux Bridge port ( 2 ) th\u00f4ng qua veth pair B2 : Security group ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet B3 : Linux bridge port ( 4 ) s\u1ebd forward packet \u0111\u1ebfn OVS integration ( 5 ) th\u00f4ng qua veth pair B4 : OVS integration bridge s\u1ebd th\u00eam VLAN ID v\u00e0o c\u00e1c packet B5 : OVS integration bridge thay \u0111\u1ed5i c\u00e1c VLAN ID th\u00e0nh Tunnel ID B6 : OVS integration bridge patch-tun ( 6 ) forward packet t\u1edbi OVS tunnel bridge ( 7 ) patch-int B7 : OVS tunnel bridge ( 8 ) g\u00e1n VNI v\u00e0o c\u00e1c packet B8 : Underlay network ( 9 ) s\u1ebd cho ph\u00e9p overlay network g\u1eedi c\u00e1c packet \u0111\u1ebfn network node ( 10 ) Tr\u00ean Network Node B1 : Underlay network interface ( 11 ) cho ph\u00e9p overlay network forward packet t\u1edbi OVS tunnel bridge ( 12 ) B2 : OVS tunnel bridge lo\u1ea1i b\u1ecf VNI v\u00e0 tag Tunnel ID cho packet B3 : OVS tunnel bridge lo\u1ea1i b\u1ecf tag Tunnel ID b\u1eb1ng VLAN ID B4 : OVS tunnel bridge patch port ( 13 ) forward packet t\u1edbi OVS integration bridge patch-tun ( 14 ) B5 : OVS intergation bridge ( 15 ) x\u00f3a b\u1ecf VLAN ID c\u00e1c packet v\u00e0 forward l\u00ean interface c\u1ee7a self-service router ( 15 ) B6 : Router forward packet sang next-hop , gateway c\u1ee7a m\u1ea1ng th\u1ee9 2 th\u00f4ng qua router interface( 17 ) B7 : Router forward packet \u0111\u1ebfn OVS integration bridge port self-service ( 2 ) B8 : OVS integration bridge patch-tun ( 19 ) forward packet sang OVS tunnel bridge patch-ini patch port ( 20 ) B9 : OVS tunnel bridge ( 21 ) tag VNI cho c\u00e1c packet B10 : Underlay network ( 22 ) s\u1ebd cho ph\u00e9p overlay network ( 23 ) forward packet v\u1ec1 compute node Tr\u00ean Compute Node B1 : Underlay network ( 24 ) cho ph\u00e9p overlay network forward packet ( 25 ) t\u1edbi c\u00e1c OVS Tunnel Bridge B2 : OVS Tunnel Bridge g\u1edf b\u1ecf VNI v\u00e0 tag Tunnel ID B3 : OVS Tunnel Bridge thay th\u1ebf Tunnel ID thay th\u1ebf b\u1eb1ng VLAN ID B4 : OVS Tunnel Bridge port ( 26 ) forward packet t\u1edbi OVS integration bridge s\u1eed d\u1ee5ng patch port ( 27 ) B5 : OVS integration s\u1ebd remove VLAN tr\u00ean c\u00e1c packet B6 : OVS integration bridge port ( 28 ) forward packet t\u1edbi t\u1edbi Linux Bridge ( 29 ) s\u1eed d\u1ee5ng veth pair B7 : Security group ( 30 ) s\u1ebd filer c\u00e1c packet B8 : Linux Bridge ( 31 ) s\u1ebd forward packet t\u1edbi c\u00e1c instance interface ( 32 ) s\u1eed d\u1ee5ng veth pair","title":"T\u00ecm hi\u1ec3u flow packet khi s\u1eed d\u1ee5ng OpenvSwitch trong Openstack"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#tim_hieu_flow_packet_khi_su_dung_openvswitch_trong_openstack","text":"","title":"T\u00ecm hi\u1ec3u flow packet khi s\u1eed d\u1ee5ng OpenvSwitch trong Openstack"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#1_moi_truong_gia_lap","text":"M\u00f4 h\u00ecnh B\u1eafc - Nam : li\u00ean h\u1ec7 gi\u1eefa c\u00e1c instance v\u00e0 m\u1ea1ng ngo\u00e0i ( h\u1ea1 t\u1ea7ng m\u1ea1ng v\u1eadt l\u00fd ) M\u00f4 h\u00ecnh \u0110\u00f4ng - T\u00e2y : li\u00ean h\u1ec7 gi\u1eefa c\u00e1c instance v\u1edbi nhau c\u00f9ng m\u1ea1ng ho\u1eb7c kh\u00e1c m\u1ea1ng. Gi\u1ea3 \u0111\u1ecbnh m\u00f4i tr\u01b0\u1eddng m\u1ea1ng nh\u01b0 sau : Provider - VLANID 101 Self-service network 1 - VNI 101 Self-service network 2 - VNI 102 Self-service route instance 1,2","title":"1. M\u00f4i tr\u01b0\u1eddng gi\u1ea3 l\u1eadp"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#2_mo_hinh_self-service","text":"","title":"2. M\u00f4 h\u00ecnh Self-Service"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#21_bac_-_nam_su_dung_fixed_ip","text":"Tr\u00ean m\u00f4 h\u00ecnh n\u00e0y, network node s\u1ebd th\u1ef1c hi\u1ec7n th\u1ef1c hi\u1ec7n Source NAT \u0111\u1ec3 g\u1eedi traffic c\u1ee7a c\u00e1c instance ra m\u1ea1ng external Tr\u00ean Compute Node B1 : Packet t\u1eeb instance interface ( 1 ) \u0111\u01b0\u1ee3c chuy\u1ec3n ti\u1ebfp \u0111\u1ebfn veth pair ( 2 ) tr\u00ean Linux Bridge B2 : Security group tr\u00ean Linux Bridge s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter (3 ) B3 : Linux Bridge (4 ) chuy\u1ec3n ti\u1ebfp c\u00e1c frame \u0111\u1ebfn OVS integration bridge s\u1eed d\u1ee5ng veth pair B5 : T\u1ea1i \u0111\u00e2y ( 5 ) integration bridge th\u00eam tag VNI 101, x\u00e1c \u0111\u1ecbnh Tunnel ID B6 : OVS integration bridge veth port ( 6 ) s\u1ebd chuy\u1ec3n c\u00e1c packet \u0111\u1ebfn OVS Tunnel Bridge veth port ( 7 ) B7 : OVS tunnel bridge s\u1ebd \u0111\u00f3ng g\u00f3i c\u00e1c packet v\u1edbi VNI 101 ( 8 ) B8 : Physical interface ( 9 ) cho ph\u00e9p m\u1ea1ng overlay chuy\u1ec3n ti\u1ebfp c\u00e1c packet \u0111\u1ebfn network node ( 10 Tr\u00ean Network Node B1 : Tr\u00ean physical interface ( 11 ) c\u1ee7a network node cho ph\u00e9p c\u00e1c packet t\u1eeb overlay network \u0111i v\u00e0o OVS tunnel bridge ( 12 ) B2 : OVS Tunnel s\u1ebd th\u00eam Tunnel ID , v\u00e0 g\u1eafn m\u1ed9t VLAN ID cho c\u00e1c packet n\u00e0y B3 : OVS Tunnel veth port ( 13 ) s\u1ebd g\u1eedi packet t\u1edbi OVS integration veth port ( 14 ) B4 : OVS integration bridge port ( 15 ) s\u1ebd b\u1ecf c\u00e1c VLAN ID v\u00e0 chuy\u1ec3n ti\u1ebfp t\u1edbi router namespace ( 16 ) B5 : \u0110\u1ed1i v\u1edbi IPv4 : SNAT s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n t\u1ea1i \u0111\u00e2y , thay \u0111\u1ed5i \u0111\u1ecba ch\u1ec9 IP c\u1ee7a self-service network th\u00e0nh IP c\u1ee7a provider network ( 17 ) B6 : Router ( 18 ) chuy\u1ec3n ti\u1ebfp packet OVS integration bridge , sau \u0111\u00f3 s\u1ebd th\u00eam VLAN ID v\u00e0o packet B7 : OVS integration bridge patch port ( 19 ) s\u1ebd forward packet t\u1edbi OVS provider bridge phy-br-provider ( 20 ) B8 : OVS provider bridge port( 21 ) s\u1ebd forward packet ra physical interface ( 22 ) B9 : Physical interface s\u1ebd g\u1eedi packet ra ngo\u00e0i ( 23 )","title":"2.1 . B\u1eafc - Nam , s\u1eed d\u1ee5ng fixed IP"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#22_bac_-_nam_su_dung_floating_ip","text":"S\u1eed d\u1ee5ng SNAT \u0111\u1ec3 c\u00e1c m\u00e1y \u1ea3o giao ti\u1ebfp ra ngo\u00e0i v\u00e0 DNAT \u0111\u1ec3 m\u1ea1ng ngo\u00e0i giao ti\u1ebfp v\u1edbi instance Tr\u01b0\u1eddng h\u1ee3p d\u01b0\u1edbi \u0111\u00e2y t\u1eeb m\u1ed9t m\u00e1y t\u1eeb m\u1ea1ng ngo\u00e0i li\u00ean h\u1ec7 v\u1edbi instance Tr\u00ean Nodework Node B1 : T\u1eeb m\u1ea1ng ngo\u00e0i ( 1 ) g\u1eedi packet v\u00e0o provider physical interface ( 2 ) B2 : Provider physical interface ( 3 ) chuy\u1ec3n ti\u1ebfp packet \u0111\u1ebfn OVS provider bridge, sau \u0111\u00f3 s\u1ebd l\u1ea5y VLAN ID c\u1ee7a packet B3 : OVS provider bridge port ( 4 ) s\u1ebd forward packet sang OVS integration bridge port ( 5 ) B5 : OVS integration bridge port ( 6 ) s\u1ebd remove internal VLAN v\u00e0 chuy\u1ec3n packet \u0111\u1ebfn router namepsace. Sau \u0111\u00f3 th\u1ef1c hi\u1ec7n Destination NAT ( 7 ) B6 : Router ( 8 ) chuy\u1ec3n ti\u1ebfp c\u00e1c packet sang OVS integration bridge ( 9 ) B7 : T\u1ea1i OVS intergration bridge s\u1ebd th\u00eam c\u00e1c VLAN ID , sau \u0111\u00f3 s\u1ebd t\u00ecm Tunnel ID t\u01b0\u01a1ng \u1ee9ng B8 : OVS intergration bridge ( 10 ) chuy\u1ec3n c\u00e1c packet t\u1edbi OVS tunnel bridge ( 11 ) B9 : OVS tunnel bridge ( 12 ) s\u1eed d\u1ee5ng VNI cho header c\u00e1c packet B10 : Physical interface s\u1ebd cho ph\u00e9p c\u00e1c overlay network ( 13 ) g\u1eedi c\u00e1c packet \u0111\u1ebfn compute node ( 14 ) Tr\u00ean Compute Node : B1 : Physical interface ( 15 ) s\u1ebd chuy\u1ec3n ti\u1ebfp c\u00e1c packet \u0111\u1ebfn overlay network ( 16 ) B2 : OVS tunnel bridge s\u1ebd s\u1ebd s\u1eed d\u1ee5ng VLAN ID cho Tunnel ID t\u01b0\u01a1ng \u1ee9ng B3 : OVS tunnel bridge ( 17 ) s\u1ebd chuy\u1ec3n c\u00e1c packet sang OVS ingrateion bridge ( 18 ) s\u1eed d\u1ee5ng patch-int B4 : OVS integration bridge lo\u1ea1i b\u1ecf VLAN B5 : OVS integration bridge s\u1eed d\u1ee5ng securtity group ( 19 ) \u0111\u1ec3 filter c\u00e1c packet sau \u0111\u00f3 g\u1eedi sang Linux Bridge ( 20 ) th\u00f4ng qua veth pair B6 : Securtiy group s\u1ebd th\u1ef1c hi\u1ec7n filtering ( 21 ) B7 : Security group ( 22 ) s\u1ebd chuy\u1ec3n ti\u1ebfp goi tin \u0111\u1ebfn instance interface ( 23 )","title":"2.2 : B\u1eafc - Nam s\u1eed d\u1ee5ng Floating IP"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#23_ong_-_tay_cac_instance_cung_1_mang","text":"Tr\u00ean Compute 1 : B1 : instance interface ( 1 ) forward c\u00e1c packet t\u1edbi security group tr\u00ean ( Linux Bridge ) ( 2 ) th\u00f4ng qua veth pair B2 : securtity group ( 3 ) \u0111\u1ea3m nhi\u1ec7n filter t\u1ea1i \u0111\u00e2y B3 : Linux Bridge port( 4 ) forward packet t\u1edbi OVS integration ( 5 )nh\u1edd veth pair B4 : OVS ingration bridge th\u00eam VLAN ID v\u00e0o packet B5 : OVS integration bridge thay VLAN ID b\u1eb1ng Tunnel ID B6 : OVS integration bridge patch port ( 6 ) forward packet t\u1edbi OVS Tunnel bridge patch port ( 7 ) B7 : OVS tunnel bridge ( 8 ) g\u1eafn VNI v\u00e0o packet B8 : Underlay nework ( 9 ) cho ph\u00e9p overlay network ( 10 ) chuy\u1ec3n packet \u0111\u1ebfn network node Tr\u00ean Compute 2 B1 : Underlay network ( 11) cho ph\u00e9p overlay networking ( 12 ) forward t\u1edbi OVS bridge tunnel B2 : OVS tunnel bridge th\u00eam m\u1ed9t Tunnel ID v\u00e0o packet B3 : OVS tunnel bridge thay \u0111\u1ed5i Tunnel ID b\u1eb1ng VLAN ID t\u01b0\u01a1ng \u1ee9ng. B4 : OVS tunnel bridge patch port ( 13 ) forward packet t\u1edbi OVS integratation bridge patch tun port ( 14 ) B5 : OVS integration bridge b\u1ecf VLAN ( 15 ) forward packet \u0111\u1ebfn Linux bridge veth port ( 16 ) B6 : Security Group \u0111\u1ea3m nhi\u1ec7m filter packet ( 17 ) B7 : Linux bridge veth port ( 18 ) forward packet \u0111\u1ebfn instance interface ( 19 )","title":"2.3 : \u0110\u00f4ng - T\u00e2y : c\u00e1c instance c\u00f9ng 1 m\u1ea1ng"},{"location":"Openstack_Research/Neutron/9. OPS-Packet-Self-Service/#24_ong_-_tay_cac_instance_khac_mang","text":"Tr\u00ean Compute Node : B1 : instance interface ( 1 ) forward packet \u0111\u1ebfn Linux Bridge port ( 2 ) th\u00f4ng qua veth pair B2 : Security group ( 3 ) s\u1ebd \u0111\u1ea3m nhi\u1ec7m filter c\u00e1c packet B3 : Linux bridge port ( 4 ) s\u1ebd forward packet \u0111\u1ebfn OVS integration ( 5 ) th\u00f4ng qua veth pair B4 : OVS integration bridge s\u1ebd th\u00eam VLAN ID v\u00e0o c\u00e1c packet B5 : OVS integration bridge thay \u0111\u1ed5i c\u00e1c VLAN ID th\u00e0nh Tunnel ID B6 : OVS integration bridge patch-tun ( 6 ) forward packet t\u1edbi OVS tunnel bridge ( 7 ) patch-int B7 : OVS tunnel bridge ( 8 ) g\u00e1n VNI v\u00e0o c\u00e1c packet B8 : Underlay network ( 9 ) s\u1ebd cho ph\u00e9p overlay network g\u1eedi c\u00e1c packet \u0111\u1ebfn network node ( 10 ) Tr\u00ean Network Node B1 : Underlay network interface ( 11 ) cho ph\u00e9p overlay network forward packet t\u1edbi OVS tunnel bridge ( 12 ) B2 : OVS tunnel bridge lo\u1ea1i b\u1ecf VNI v\u00e0 tag Tunnel ID cho packet B3 : OVS tunnel bridge lo\u1ea1i b\u1ecf tag Tunnel ID b\u1eb1ng VLAN ID B4 : OVS tunnel bridge patch port ( 13 ) forward packet t\u1edbi OVS integration bridge patch-tun ( 14 ) B5 : OVS intergation bridge ( 15 ) x\u00f3a b\u1ecf VLAN ID c\u00e1c packet v\u00e0 forward l\u00ean interface c\u1ee7a self-service router ( 15 ) B6 : Router forward packet sang next-hop , gateway c\u1ee7a m\u1ea1ng th\u1ee9 2 th\u00f4ng qua router interface( 17 ) B7 : Router forward packet \u0111\u1ebfn OVS integration bridge port self-service ( 2 ) B8 : OVS integration bridge patch-tun ( 19 ) forward packet sang OVS tunnel bridge patch-ini patch port ( 20 ) B9 : OVS tunnel bridge ( 21 ) tag VNI cho c\u00e1c packet B10 : Underlay network ( 22 ) s\u1ebd cho ph\u00e9p overlay network ( 23 ) forward packet v\u1ec1 compute node Tr\u00ean Compute Node B1 : Underlay network ( 24 ) cho ph\u00e9p overlay network forward packet ( 25 ) t\u1edbi c\u00e1c OVS Tunnel Bridge B2 : OVS Tunnel Bridge g\u1edf b\u1ecf VNI v\u00e0 tag Tunnel ID B3 : OVS Tunnel Bridge thay th\u1ebf Tunnel ID thay th\u1ebf b\u1eb1ng VLAN ID B4 : OVS Tunnel Bridge port ( 26 ) forward packet t\u1edbi OVS integration bridge s\u1eed d\u1ee5ng patch port ( 27 ) B5 : OVS integration s\u1ebd remove VLAN tr\u00ean c\u00e1c packet B6 : OVS integration bridge port ( 28 ) forward packet t\u1edbi t\u1edbi Linux Bridge ( 29 ) s\u1eed d\u1ee5ng veth pair B7 : Security group ( 30 ) s\u1ebd filer c\u00e1c packet B8 : Linux Bridge ( 31 ) s\u1ebd forward packet t\u1edbi c\u00e1c instance interface ( 32 ) s\u1eed d\u1ee5ng veth pair","title":"2.4 : \u0110\u00f4ng - T\u00e2y : c\u00e1c instance kh\u00e1c m\u1ea1ng"},{"location":"Openstack_Research/Nova/1.Introduction-nova/","text":"1. Openstack Compute -Nova \u00b6 1.1 : Kh\u00e1i ni\u1ec7m \u00b6 OpenStack Nova l\u00e0 m\u1ed9t project core trong Openstack, nh\u1eb1m m\u1ee5c \u0111\u00edch c\u1ea5p ph\u00e9p c\u00e1c t\u00e0i nguy\u00ean v\u00e0 qu\u1ea3n l\u00fd s\u1ed1 l\u01b0\u1ee3ng l\u1edbn m\u00e1y \u1ea3o . Compute s\u1eafp x\u1ebfp c\u00e1c m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean c\u00e1c node b\u1eb1ng c\u00e1ch l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c driver \u1ea3o h\u00f3a , cung c\u1ea5p ph\u1ea7n m\u1edf r\u1ed9ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c compoment kh\u00e1c c\u1ee7a Openstack Openstack Compute y\u00eau c\u1ea7u m\u1ed9t s\u1ed1 service kh\u00e1c \u0111\u1ec3 th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 task c\u01a1 b\u1ea3n : Indentify service \u0111\u1ec3 x\u00e1c th\u1ef1c, Glance \u0111\u1ec3 s\u1eed d\u1ee5ng c\u00e1c image cho c\u00e1c instance, Neutron \u0111\u1ec3 cung c\u1ea5p m\u1ea1ng \u1ea3o ho\u1eb7c v\u1eadt l\u00fd cho c\u00e1c compute instance Ngo\u00e0i ra c\u00f2n c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c service kh\u00e1c : block storage, disk, baremetal compute instance Openstack Compute cung c\u1ea5p m\u1ed9t s\u1ed1 ph\u01b0\u01a1ng th\u1ee9c \u0111\u1ec3 l\u00e0m vi\u1ec7c : - Horizon : cung c\u1ea5p Web-Based cho ng\u01b0\u1eddi d\u00f9ng , l\u00e0m vi\u1ec7c th\u00f4ng qua API - Openstack Client : l\u00e0 m\u1ed9t CLI to\u00e0n c\u1ee5c c\u1ee7a Openstack. S\u1eed d\u1ee5ng API n\u00e0y c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c kh\u00f4ng ch\u1ec9 v\u1edbi nova m\u00e0 m\u1edbi c\u00e1c service kh\u00e1c - Nova Client : CLI \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi nova, c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng thay th\u1ebf Openstack Client 1.2. Openstack Compute Architecture \u00b6 Nova y\u00eau c\u1ea7u nhi\u1ec1u process tr\u00ean server , m\u1ed7i process \u0111\u1ea3m nhi\u1ec7m m\u1ed9t function ri\u00eang, t\u1ea1o n\u00ean c\u1ea5u tr\u00fac nova. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi Nova th\u00f4ng qua c\u00e1c REST API , trong khi \u0111\u00f3 c\u00e1c compoments trong Nova giao ti\u00eap v\u1edbi nhau th\u00f4ng qua c\u00e1c b\u1ea3n tin theo c\u01a1 ch\u1ebf RPC Nova API Server x\u1eed l\u00fd c\u00e1c y\u00eau c\u1ea7u , th\u00f4ng th\u01b0\u1eddng s\u1ebd l\u00e0m vi\u1ec7c read/write v\u1edbi database, sau \u0111\u00f3 c\u00e1c Compment Nova s\u1ebd giao ti\u1ebfp qua RPC v\u00e0 repesonse . C\u00e1c b\u1ea3n tin RFC th\u1ef1c hi\u1ec7n th\u00f4ng qua th\u01b0 vi\u1ec7n oslo.messaging , C\u00e1c th\u00e0nh ph\u1ea7n trong Nova Trong \u0111\u00f3 : - Openstack-indentify-service : l\u00e0m vi\u1ec7c v\u1edbi keystone ... \u0111\u1ec3 x\u00e1c th\u1ef1c request - Openstack-nova-api : X\u1eed l\u00fd c\u00e1c y\u00eau c\u1ea7u v\u00e0 cung c\u1ea5p quy\u1ec1n truy c\u1eadp v\u00e0o c\u00e1c d\u1ecbch v\u1ee5 trong Nova (ch\u1eb3ng h\u1ea1n nh\u01b0 kh\u1edfi \u0111\u1ed9ng m\u1ed9t th\u1ec3 hi\u1ec7n). - Openstack-nova-sheduler : x\u00e1c \u0111\u1ecbnh host \u0111\u1ec3 ch\u1ee9a m\u00e1y \u1ea3o - Openstack-nova-cert : cung c\u1ea5p ph\u1ea7n qu\u1ea3n l\u00fd Certificate khi l\u00e0m vi\u1ec7c v\u1edbi EC2 API - Openstack-nova-compute : kh\u1edfi t\u1ea1o , qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a c\u00e1c m\u00e1y \u1ea3o, t\u01b0\u01a1ng t\u00e1c v\u1edbi hypervisorc API \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o, g\u1eedi g\u1eedi tr\u1ea1ng th\u00e1i m\u00e1y \u1ea3o v\u00e0o Database - Openstack-nova-consoleauth : \u1ee7y quy\u1ec1n user cho ph\u00e9p \u0111i t\u1edbi console proxy - Openstack-nova-network : X\u1eed l\u00fd , t\u00ednh to\u00e1n c\u00e1c v\u1ea5n \u0111\u1ec1 v\u1ec1 network, x\u1eed l\u00fd nhi\u1ec1u task v\u00ed d\u1ee5 nh\u01b0 g\u1eafn IP cho m\u1ed9t m\u00e1y \u1ea3o m\u1edbi , v\u00e0 \u00e1p d\u1ee5ng c\u00e1c network security rule cho c\u00e1c m\u1ea3y \u1ea3o - Openstack-nova-placement-api : cung c\u1ea5p API cho ph\u00e9p nh\u00ecn t\u1ed5ng quan v\u1ec1 c\u00e1c resouce \u0111ang r\u1ea3nh tr\u00ean c\u00e1c Compute Node v\u00e0 l\u1eadp k\u1ebf ho\u1ea1ch \u0111\u1ec3 t\u1ea1o m\u00e1y \u1ea3o.v\u00ed d\u1ee5 nh\u01b0 IP floating, Disk , RAM, CPU - Openstack-nova-novncproxy : cung c\u1ea5p VNC proxy , cho ph\u00e9p ng\u01b0\u1eddi d\u00f9ng console m\u00e1y \u1ea3o th\u00f4ng qua brower - Openstack-nova-scheduler : x\u00e1c nh\u1eadn y\u00eau c\u1ea7u t\u1ea1o m\u1edbi m\u00e1y \u1ea3o , nh\u1eadn th\u00f4ng tin v\u00e0 \u0111\u1eb7t l\u1ecbch t\u1ea1o m\u00e1y \u1ea3o m\u1edbi tr\u00ean node c\u1ee5 th\u1ec3 - Openstack-nova-conductor : Trung gian t\u01b0\u01a1ng t\u00e1c gi\u1eefa nova-compute service v\u00e0 databases. N\u00f3 lo\u1ea1i b\u1ecf truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o cloud databases \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n v\u1edfi nova-compute service nh\u1eb1m m\u1ee5c \u0111\u00edch b\u1ea3o m\u1eadt, tr\u00e1nh tr\u01b0\u1eddng h\u1ee3p m\u00e1y \u1ea3o b\u1ecb x\u00f3a m\u00e0 kh\u00f4ng c\u00f3 ch\u1ee7 \u00fd c\u1ee7a ng\u01b0\u1eddi d\u00f9ng. - rabbitmq-server : cung c\u1ea5p server l\u00e0m nhi\u1ec7m v\u1ee5 x\u00e2y d\u1ef1ng h\u00e0ng \u0111\u1ee3i message AMQP. Server n\u00e0y (c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi Block Storage) x\u1eed l\u00fd vi\u1ec7c qu\u1ea3n l\u00fd giao d\u1ecbch OpenStack, bao g\u1ed3m x\u1ebfp h\u00e0ng, ph\u00e2n ph\u1ed1i, b\u1ea3o m\u1eadt, qu\u1ea3n l\u00fd, ph\u00e2n c\u1ee5m v\u00e0 li\u00ean k\u1ebft. - libvirtd : m\u1ed9t tr\u00ecnh \u0111i\u1ec1u khi\u1ec3n cho hypervisor, qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi m\u00e1y \u1ea3o th\u00f4ng qua c\u00e1c message API - KVM Linux hypervisor : h\u1ed7 tr\u1ee3 libvirt ,s\u1eed d\u1ee5ng KVM Module trong hypervisor. C\u00e1c hypervisor t\u1ea1o ra c\u00e1c m\u00e1y \u1ea3o v\u00e0 cho ph\u00e9p di chuy\u1ec3n tr\u1ef1c ti\u1ebfp t\u1eeb n\u00fat n\u00e0y sang n\u00fat kh\u00e1c. - Database : cung c\u1ea5p realtime tr\u1ea1ng th\u00e1i m\u1ea3y \u1ea3o - nova-volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c \u1ed5 \u0111\u0129a \u1ea3o c\u1ee7a c\u00e1c instance 1.3. Ph\u00e2n chia Compute Host trong Nova \u00b6 Cell cho ph\u00e9o m\u1edf r\u1ed9ng Compute Cloud m\u00e0 kh\u00f4ng c\u1ea7n m\u1edf r\u1ed9ng database v\u00e0 message queue. Khi celel \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng, c\u00e1c hosts trong Openstack Compute \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 v\u00e0o m\u1ed9t nh\u00f3m t\u00ean cells . Cell \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh theo ki\u1ec3u tree. Top-level cell l\u00e0 m\u1ed9t host ch\u1ea1y nova-api, kh\u00f4ng c\u00f3 nova-compute. C\u00e1c child top-level s\u1ebd \u0111\u1ea3m nhi\u1ec7m ch\u1ea1y c\u00e1c nova-* ngo\u1ea1i tr\u1eeb nova-api. M\u1ed7i cell l\u00e0 m\u1ed9t t\u1eadp l\u1edbn, trong \u0111\u00f3 c\u00e1c child cell s\u1ebd ch\u01b0a c\u00e1c database v\u00e0 message queue c\u1ee7a n\u00f3","title":"1.  Openstack Compute -Nova"},{"location":"Openstack_Research/Nova/1.Introduction-nova/#1_openstack_compute_-nova","text":"","title":"1.  Openstack Compute -Nova"},{"location":"Openstack_Research/Nova/1.Introduction-nova/#11_khai_niem","text":"OpenStack Nova l\u00e0 m\u1ed9t project core trong Openstack, nh\u1eb1m m\u1ee5c \u0111\u00edch c\u1ea5p ph\u00e9p c\u00e1c t\u00e0i nguy\u00ean v\u00e0 qu\u1ea3n l\u00fd s\u1ed1 l\u01b0\u1ee3ng l\u1edbn m\u00e1y \u1ea3o . Compute s\u1eafp x\u1ebfp c\u00e1c m\u00e1y \u1ea3o ch\u1ea1y tr\u00ean c\u00e1c node b\u1eb1ng c\u00e1ch l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c driver \u1ea3o h\u00f3a , cung c\u1ea5p ph\u1ea7n m\u1edf r\u1ed9ng \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c compoment kh\u00e1c c\u1ee7a Openstack Openstack Compute y\u00eau c\u1ea7u m\u1ed9t s\u1ed1 service kh\u00e1c \u0111\u1ec3 th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 task c\u01a1 b\u1ea3n : Indentify service \u0111\u1ec3 x\u00e1c th\u1ef1c, Glance \u0111\u1ec3 s\u1eed d\u1ee5ng c\u00e1c image cho c\u00e1c instance, Neutron \u0111\u1ec3 cung c\u1ea5p m\u1ea1ng \u1ea3o ho\u1eb7c v\u1eadt l\u00fd cho c\u00e1c compute instance Ngo\u00e0i ra c\u00f2n c\u00f3 th\u1ec3 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c service kh\u00e1c : block storage, disk, baremetal compute instance Openstack Compute cung c\u1ea5p m\u1ed9t s\u1ed1 ph\u01b0\u01a1ng th\u1ee9c \u0111\u1ec3 l\u00e0m vi\u1ec7c : - Horizon : cung c\u1ea5p Web-Based cho ng\u01b0\u1eddi d\u00f9ng , l\u00e0m vi\u1ec7c th\u00f4ng qua API - Openstack Client : l\u00e0 m\u1ed9t CLI to\u00e0n c\u1ee5c c\u1ee7a Openstack. S\u1eed d\u1ee5ng API n\u00e0y c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c kh\u00f4ng ch\u1ec9 v\u1edbi nova m\u00e0 m\u1edbi c\u00e1c service kh\u00e1c - Nova Client : CLI \u0111\u01b0\u1ee3c cung c\u1ea5p b\u1edfi nova, c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng thay th\u1ebf Openstack Client","title":"1.1 : Kh\u00e1i ni\u1ec7m"},{"location":"Openstack_Research/Nova/1.Introduction-nova/#12_openstack_compute_architecture","text":"Nova y\u00eau c\u1ea7u nhi\u1ec1u process tr\u00ean server , m\u1ed7i process \u0111\u1ea3m nhi\u1ec7m m\u1ed9t function ri\u00eang, t\u1ea1o n\u00ean c\u1ea5u tr\u00fac nova. Ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 giao ti\u1ebfp v\u1edbi Nova th\u00f4ng qua c\u00e1c REST API , trong khi \u0111\u00f3 c\u00e1c compoments trong Nova giao ti\u00eap v\u1edbi nhau th\u00f4ng qua c\u00e1c b\u1ea3n tin theo c\u01a1 ch\u1ebf RPC Nova API Server x\u1eed l\u00fd c\u00e1c y\u00eau c\u1ea7u , th\u00f4ng th\u01b0\u1eddng s\u1ebd l\u00e0m vi\u1ec7c read/write v\u1edbi database, sau \u0111\u00f3 c\u00e1c Compment Nova s\u1ebd giao ti\u1ebfp qua RPC v\u00e0 repesonse . C\u00e1c b\u1ea3n tin RFC th\u1ef1c hi\u1ec7n th\u00f4ng qua th\u01b0 vi\u1ec7n oslo.messaging , C\u00e1c th\u00e0nh ph\u1ea7n trong Nova Trong \u0111\u00f3 : - Openstack-indentify-service : l\u00e0m vi\u1ec7c v\u1edbi keystone ... \u0111\u1ec3 x\u00e1c th\u1ef1c request - Openstack-nova-api : X\u1eed l\u00fd c\u00e1c y\u00eau c\u1ea7u v\u00e0 cung c\u1ea5p quy\u1ec1n truy c\u1eadp v\u00e0o c\u00e1c d\u1ecbch v\u1ee5 trong Nova (ch\u1eb3ng h\u1ea1n nh\u01b0 kh\u1edfi \u0111\u1ed9ng m\u1ed9t th\u1ec3 hi\u1ec7n). - Openstack-nova-sheduler : x\u00e1c \u0111\u1ecbnh host \u0111\u1ec3 ch\u1ee9a m\u00e1y \u1ea3o - Openstack-nova-cert : cung c\u1ea5p ph\u1ea7n qu\u1ea3n l\u00fd Certificate khi l\u00e0m vi\u1ec7c v\u1edbi EC2 API - Openstack-nova-compute : kh\u1edfi t\u1ea1o , qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u1ee7a c\u00e1c m\u00e1y \u1ea3o, t\u01b0\u01a1ng t\u00e1c v\u1edbi hypervisorc API \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o, g\u1eedi g\u1eedi tr\u1ea1ng th\u00e1i m\u00e1y \u1ea3o v\u00e0o Database - Openstack-nova-consoleauth : \u1ee7y quy\u1ec1n user cho ph\u00e9p \u0111i t\u1edbi console proxy - Openstack-nova-network : X\u1eed l\u00fd , t\u00ednh to\u00e1n c\u00e1c v\u1ea5n \u0111\u1ec1 v\u1ec1 network, x\u1eed l\u00fd nhi\u1ec1u task v\u00ed d\u1ee5 nh\u01b0 g\u1eafn IP cho m\u1ed9t m\u00e1y \u1ea3o m\u1edbi , v\u00e0 \u00e1p d\u1ee5ng c\u00e1c network security rule cho c\u00e1c m\u1ea3y \u1ea3o - Openstack-nova-placement-api : cung c\u1ea5p API cho ph\u00e9p nh\u00ecn t\u1ed5ng quan v\u1ec1 c\u00e1c resouce \u0111ang r\u1ea3nh tr\u00ean c\u00e1c Compute Node v\u00e0 l\u1eadp k\u1ebf ho\u1ea1ch \u0111\u1ec3 t\u1ea1o m\u00e1y \u1ea3o.v\u00ed d\u1ee5 nh\u01b0 IP floating, Disk , RAM, CPU - Openstack-nova-novncproxy : cung c\u1ea5p VNC proxy , cho ph\u00e9p ng\u01b0\u1eddi d\u00f9ng console m\u00e1y \u1ea3o th\u00f4ng qua brower - Openstack-nova-scheduler : x\u00e1c nh\u1eadn y\u00eau c\u1ea7u t\u1ea1o m\u1edbi m\u00e1y \u1ea3o , nh\u1eadn th\u00f4ng tin v\u00e0 \u0111\u1eb7t l\u1ecbch t\u1ea1o m\u00e1y \u1ea3o m\u1edbi tr\u00ean node c\u1ee5 th\u1ec3 - Openstack-nova-conductor : Trung gian t\u01b0\u01a1ng t\u00e1c gi\u1eefa nova-compute service v\u00e0 databases. N\u00f3 lo\u1ea1i b\u1ecf truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o cloud databases \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n v\u1edfi nova-compute service nh\u1eb1m m\u1ee5c \u0111\u00edch b\u1ea3o m\u1eadt, tr\u00e1nh tr\u01b0\u1eddng h\u1ee3p m\u00e1y \u1ea3o b\u1ecb x\u00f3a m\u00e0 kh\u00f4ng c\u00f3 ch\u1ee7 \u00fd c\u1ee7a ng\u01b0\u1eddi d\u00f9ng. - rabbitmq-server : cung c\u1ea5p server l\u00e0m nhi\u1ec7m v\u1ee5 x\u00e2y d\u1ef1ng h\u00e0ng \u0111\u1ee3i message AMQP. Server n\u00e0y (c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi Block Storage) x\u1eed l\u00fd vi\u1ec7c qu\u1ea3n l\u00fd giao d\u1ecbch OpenStack, bao g\u1ed3m x\u1ebfp h\u00e0ng, ph\u00e2n ph\u1ed1i, b\u1ea3o m\u1eadt, qu\u1ea3n l\u00fd, ph\u00e2n c\u1ee5m v\u00e0 li\u00ean k\u1ebft. - libvirtd : m\u1ed9t tr\u00ecnh \u0111i\u1ec1u khi\u1ec3n cho hypervisor, qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi m\u00e1y \u1ea3o th\u00f4ng qua c\u00e1c message API - KVM Linux hypervisor : h\u1ed7 tr\u1ee3 libvirt ,s\u1eed d\u1ee5ng KVM Module trong hypervisor. C\u00e1c hypervisor t\u1ea1o ra c\u00e1c m\u00e1y \u1ea3o v\u00e0 cho ph\u00e9p di chuy\u1ec3n tr\u1ef1c ti\u1ebfp t\u1eeb n\u00fat n\u00e0y sang n\u00fat kh\u00e1c. - Database : cung c\u1ea5p realtime tr\u1ea1ng th\u00e1i m\u1ea3y \u1ea3o - nova-volume : qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c \u1ed5 \u0111\u0129a \u1ea3o c\u1ee7a c\u00e1c instance","title":"1.2. Openstack Compute Architecture"},{"location":"Openstack_Research/Nova/1.Introduction-nova/#13_phan_chia_compute_host_trong_nova","text":"Cell cho ph\u00e9o m\u1edf r\u1ed9ng Compute Cloud m\u00e0 kh\u00f4ng c\u1ea7n m\u1edf r\u1ed9ng database v\u00e0 message queue. Khi celel \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng, c\u00e1c hosts trong Openstack Compute \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 v\u00e0o m\u1ed9t nh\u00f3m t\u00ean cells . Cell \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh theo ki\u1ec3u tree. Top-level cell l\u00e0 m\u1ed9t host ch\u1ea1y nova-api, kh\u00f4ng c\u00f3 nova-compute. C\u00e1c child top-level s\u1ebd \u0111\u1ea3m nhi\u1ec7m ch\u1ea1y c\u00e1c nova-* ngo\u1ea1i tr\u1eeb nova-api. M\u1ed7i cell l\u00e0 m\u1ed9t t\u1eadp l\u1edbn, trong \u0111\u00f3 c\u00e1c child cell s\u1ebd ch\u01b0a c\u00e1c database v\u00e0 message queue c\u1ee7a n\u00f3","title":"1.3. Ph\u00e2n chia Compute Host trong Nova"},{"location":"Openstack_Research/Nova/2. Install-nova/","text":"C\u00e0i \u0111\u1eb7t Nova - Openstack Compute \u00b6 C\u1eadp nh\u1eadt : 11:07 /25/12/2018 \u00b6 1. M\u00f4 h\u00ecnh tri\u1ec3n khai \u00b6 C\u00e0i \u0111\u1eb7t Openstack Queens Repository yum install -y centos-release-openstack-queens yum upgrade yum install -y python-openstackclient M\u1eb7c \u0111\u1ecbnh tr\u00ean Centos v\u00e0 RHEL \u0111\u00e3 b\u1eadt SElinux , c\u00e0i \u0111\u1eb7t openstack-selinux \u0111\u1ec3 apply c\u00e1c policies cho c\u00e1c Openstack Service yum install openstack-selinux -y Disable SeLinux /etc/selinux/config Sau do reboot server This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted 2. C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng tr\u00ean Controller Node \u00b6 2.1. Gi\u1edbi thi\u1ec7u Rabbitmq \u00b6 Openstack s\u1eed d\u1ee5ng h\u00e0ng ch\u1edd tin nh\u1eafn \u0111\u1ec3 \u0111i\u1ec1u ph\u1ed1i c\u00e1c request gi\u1eefa c\u00e1c service v\u1edbi nhau . Th\u00f4ng th\u01b0\u1eddng c\u00e1c d\u1ecbch v\u1ee5 h\u00e0ng ch\u1edd s\u1ebd \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean Controller Node . Openstack h\u1ed7 tr\u1ee3 nhi\u1ec1u h\u00e0ng ch\u1edd v\u00ed d\u1ee5 RabbitMQ , Qpid , v\u00e0 ZeroMQ . Th\u00f4ng th\u01b0\u1eddng s\u1ebd tri\u1ec3n khai Rabiitmq \u0111\u1ec3 x\u00e2y d\u1ef1ng h\u00e0ng ch\u1edd do h\u1ed7 tr\u1ee3 tr\u00ean nhi\u1ec1u Linux distribution RabbitMQ l\u00e0 m\u1ed9t message broker ( message-oriented middleware) s\u1eed d\u1ee5ng giao th\u1ee9c AMQP - Advanced Message Queue Protocol (\u0110\u00e2y l\u00e0 giao th\u1ee9c ph\u1ed5 bi\u1ebfn, th\u1ef1c t\u1ebf rabbitmq h\u1ed7 tr\u1ee3 nhi\u1ec1u giao th\u1ee9c). RabbitMQ \u0111\u01b0\u1ee3c l\u1eadp tr\u00ecnh b\u1eb1ng ng\u00f4n ng\u1eef Erlang. RabbitMQ cung c\u1ea5p cho l\u1eadp tr\u00ecnh vi\u00ean m\u1ed9t ph\u01b0\u01a1ng ti\u1ec7n trung gian \u0111\u1ec3 giao ti\u1ebfp gi\u1eefa nhi\u1ec1u th\u00e0nh ph\u1ea7n trong m\u1ed9t h\u1ec7 th\u1ed1ng l\u1edbn ( V\u00ed d\u1ee5 openstack - M\u1ed9t c\u00f4ng ngh\u1ec7 r\u1ea5t th\u00fa v\u1ecb hi v\u1ecdng m\u1ed9t ng\u00e0y n\u00e0o \u0111\u00f3 t\u00f4i \u0111\u1ee7 s\u1ee9c \u0111\u1ec3 vi\u1ebft v\u00e0i b\u00e0i v\u1ec1 ch\u1ee7 \u0111\u1ec1 n\u00e0y ). RabbitMQ s\u1ebd nh\u1eadn message \u0111\u1ebfn t\u1eeb c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c nhau trong h\u1ec7 th\u1ed1ng, l\u01b0u tr\u1eef ch\u00fang an to\u00e0n tr\u01b0\u1edbc khi \u0111\u1ea9y \u0111\u1ebfn \u0111\u00edch. Trong RabbitMQ backing store \u0111\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 vi\u1ebft c\u00e1c message v\u00e0o disk 2.1. C\u00e0i \u0111\u1eb7t Rabbitmq Server \u00b6 C\u00e0i \u0111\u1eb7t package yum install rabbitmq-server Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 v\u00e0 kh\u1edfi tao ng\u01b0\u1eddi d\u00f9ng [root@localhost ~]# systemctl start rabbitmq-server [root@localhost ~]# systemctl enable rabbitmq-server [root@localhost ~]# rabbitmqctl add_user openstack rabbitmq_123 [root@localhost ~]# rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\" 2.3. C\u00e0i \u0111\u1eb7t NTP Server \u00b6 yum install chrony sed -i \"s/server.*/server 0.asia.pool.ntp.org iburst/g\" /etc/chrony.conf > /dev/nul echo \"allow 192.168.69.0/24\" >> /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service M\u1ed9t soos NTP Server server 0.asia.pool.ntp.org server 1.asia.pool.ntp.org server 2.asia.pool.ntp.org server 3.asia.pool.ntp.org C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=ntp --permanent firewall-cmd --reload Sau khi c\u00e0i \u0111\u1eb7t NTP tr\u00ean c\u00e1c node kh\u00e1c chronyc sources chronyc tracking 3. C\u00e0i \u0111\u1eb7t Nova Service tr\u00ean Controller Node \u00b6 3.1. Kh\u1edfi t\u1ea1o DB , Keystone User v\u00e0 Service \u00b6 Kh\u1edfi t\u1ea1o DB cho nova mysql -u root --password=123@123Aa <<EOF CREATE DATABASE nova_api; CREATE DATABASE nova; CREATE DATABASE nova_cell0; GRANT ALL PRIVILEGES on nova_api.* to 'nova'@'localhost' identified by \"nova_123\"; GRANT ALL PRIVILEGES on nova_api.* to 'nova'@'%' identified by \"nova_123\"; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova_123'; EOF Kh\u1edfi t\u1ea1o nova user v\u00e0 nova service source ~/admin-openrc openstack user create --domain default --password=nova_123 nova openstack role add --project service --user nova admin openstack service create --name nova --description \"Compute Service \" compute Kh\u1edfi t\u1ea1o Nova API Endpoint openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1 Kh\u1edfi t\u1ea1o Placement user v\u00e0 Placement Service openstack user create --domain default --password=placement_123 placement openstack role add --project service --user placement admin openstack service create --name placement --description \"PLacement API\" placement Kh\u1edfi t\u1ea1o Placement API Endpoint openstack endpoint create --region RegionOne placement public http://controller:8778 openstack endpoint create --region RegionOne placement internal http://controller:8778 openstack endpoint create --region RegionOne placement admin http://controller:8778 3.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Nova \u00b6 C\u00e0i \u0111\u1eb7t package yum install openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy \\ openstack-nova-scheduler openstack-nova-placement-api -y C\u1ea5u h\u00ecnh nova v\u00e0 placement cat <<EOF > /etc/nova/nova.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller enabled_apis = osapi_compute,metadata use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver [api_database] connection = mysql+pymysql://nova:nova_123@controller/nova_api [database] connection = mysql+pymysql://nova:nova_123@controller/nova [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = nova_123 [vnc] enabled = true server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.130 [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] os_region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = placement_123 EOF echo \" <Directory /usr/bin> <IfVersion >= 2.4> Require all granted </IfVersion> <IfVersion < 2.4> Order allow,deny Allow from all </IfVersion> </Directory> \" >> /etc/httpd/conf.d/00-nova-placement-api.conf systemctl restart httpd Kh\u1edfi t\u1ea1o d\u1eef li\u1ec7u tr\u00ean Database su -s /bin/sh -c \"nova-manage api_db sync\" nova su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova su -s /bin/sh -c \"nova-manage db sync\" nova Note : n\u1ebfu \u0111\u00e3 config \u0111\u00fang password , user m\u00e0 v\u1eabn xu\u1ea5t hi\u1ec7n l\u1ed7i th\u00ec b\u1ecf qua l\u1ed7i \u0111\u00f3 . Ki\u1ec3m trang b\u1ea3ng cell host connector [root@localhost nova]# nova-manage cell_v2 list_cells /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarning +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ | Name | UUID | Transport URL | Database Connection | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ | cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 | | cell1 | 75e677d7-2250-4efc-b720-21e9a17219a1 | rabbit://openstack:****@controller | mysql+pymysql://nova:****@controller/nova | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service systemctl start openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service ``` - C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port={11211/tcp,5672/tcp} --permanent firewall-cmd --add-port=8778/tcp --permanent firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8773/tcp,8775/tcp} --permanent firewall-cmd --reload ## 4. C\u00e0i \u0111\u1eb7t tr\u00ean Compute Node - Ki\u1ec3m tra \u1ea3o h\u00f3a tr\u00ean Compute Node ```bash [root@localhost ~]# egrep -c '(vmx|svm)' /proc/cpuinfo 2 C\u1ea5u h\u00ecnh file hosts echo \" 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute2 192.168.69.133 cinder \" >> /etc/hosts \u0110\u1ed3ng b\u1ed9 NTP yum install chrony sed -i \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl restart chronyd.servic C\u00e0i \u0111\u1eb7t Openstack Package v\u00e0 Nova yum install centos-release-openstack-queens -y yum install openstack-nova-compute -y C\u1ea5u h\u00ecnh Nova ( ch\u00fa \u00fd option : server_proxyclient_address : ) cat <<EOF > /etc/nova/nova.conf [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:rabbitmq_123@controller use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = nova_123 [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.131 novncproxy_base_url = http://192.168.30.130:6080/vnc_auto.html [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] os_region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = placement_123 [libvirt] virt_type = kvm hw_machine_type = x86_64=pc-i440fx-rhel7.2.0 EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable libvirtd.service openstack-nova-compute.service systemctl start libvirtd.service openstack-nova-compute.service Tr\u1edf v\u1ec1 Controller Node th\u00eam Host v\u00e0o Cell Table openstack compute service list --service nova-compute root@localhost ~]# openstack compute service list --service nova-compute +----+--------------+-----------------------+------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+--------------+-----------------------+------+---------+-------+----------------------------+ | 6 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-11-07T06:40:46.000000 | +----+--------------+-----------------------+------+---------+-------+----------------------------+ su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=5900-5999/tcp --permanent firewall-cmd --reload","title":"C\u00e0i \u0111\u1eb7t Nova - Openstack Compute"},{"location":"Openstack_Research/Nova/2. Install-nova/#cai_at_nova_-_openstack_compute","text":"","title":"C\u00e0i \u0111\u1eb7t Nova - Openstack Compute"},{"location":"Openstack_Research/Nova/2. Install-nova/#cap_nhat_1107_25122018","text":"","title":"C\u1eadp nh\u1eadt : 11:07 /25/12/2018"},{"location":"Openstack_Research/Nova/2. Install-nova/#1_mo_hinh_trien_khai","text":"C\u00e0i \u0111\u1eb7t Openstack Queens Repository yum install -y centos-release-openstack-queens yum upgrade yum install -y python-openstackclient M\u1eb7c \u0111\u1ecbnh tr\u00ean Centos v\u00e0 RHEL \u0111\u00e3 b\u1eadt SElinux , c\u00e0i \u0111\u1eb7t openstack-selinux \u0111\u1ec3 apply c\u00e1c policies cho c\u00e1c Openstack Service yum install openstack-selinux -y Disable SeLinux /etc/selinux/config Sau do reboot server This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted","title":"1. M\u00f4 h\u00ecnh tri\u1ec3n khai"},{"location":"Openstack_Research/Nova/2. Install-nova/#2_cai_at_moi_truong_tren_controller_node","text":"","title":"2. C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng tr\u00ean Controller Node"},{"location":"Openstack_Research/Nova/2. Install-nova/#21_gioi_thieu_rabbitmq","text":"Openstack s\u1eed d\u1ee5ng h\u00e0ng ch\u1edd tin nh\u1eafn \u0111\u1ec3 \u0111i\u1ec1u ph\u1ed1i c\u00e1c request gi\u1eefa c\u00e1c service v\u1edbi nhau . Th\u00f4ng th\u01b0\u1eddng c\u00e1c d\u1ecbch v\u1ee5 h\u00e0ng ch\u1edd s\u1ebd \u0111\u01b0\u1ee3c ch\u1ea1y tr\u00ean Controller Node . Openstack h\u1ed7 tr\u1ee3 nhi\u1ec1u h\u00e0ng ch\u1edd v\u00ed d\u1ee5 RabbitMQ , Qpid , v\u00e0 ZeroMQ . Th\u00f4ng th\u01b0\u1eddng s\u1ebd tri\u1ec3n khai Rabiitmq \u0111\u1ec3 x\u00e2y d\u1ef1ng h\u00e0ng ch\u1edd do h\u1ed7 tr\u1ee3 tr\u00ean nhi\u1ec1u Linux distribution RabbitMQ l\u00e0 m\u1ed9t message broker ( message-oriented middleware) s\u1eed d\u1ee5ng giao th\u1ee9c AMQP - Advanced Message Queue Protocol (\u0110\u00e2y l\u00e0 giao th\u1ee9c ph\u1ed5 bi\u1ebfn, th\u1ef1c t\u1ebf rabbitmq h\u1ed7 tr\u1ee3 nhi\u1ec1u giao th\u1ee9c). RabbitMQ \u0111\u01b0\u1ee3c l\u1eadp tr\u00ecnh b\u1eb1ng ng\u00f4n ng\u1eef Erlang. RabbitMQ cung c\u1ea5p cho l\u1eadp tr\u00ecnh vi\u00ean m\u1ed9t ph\u01b0\u01a1ng ti\u1ec7n trung gian \u0111\u1ec3 giao ti\u1ebfp gi\u1eefa nhi\u1ec1u th\u00e0nh ph\u1ea7n trong m\u1ed9t h\u1ec7 th\u1ed1ng l\u1edbn ( V\u00ed d\u1ee5 openstack - M\u1ed9t c\u00f4ng ngh\u1ec7 r\u1ea5t th\u00fa v\u1ecb hi v\u1ecdng m\u1ed9t ng\u00e0y n\u00e0o \u0111\u00f3 t\u00f4i \u0111\u1ee7 s\u1ee9c \u0111\u1ec3 vi\u1ebft v\u00e0i b\u00e0i v\u1ec1 ch\u1ee7 \u0111\u1ec1 n\u00e0y ). RabbitMQ s\u1ebd nh\u1eadn message \u0111\u1ebfn t\u1eeb c\u00e1c th\u00e0nh ph\u1ea7n kh\u00e1c nhau trong h\u1ec7 th\u1ed1ng, l\u01b0u tr\u1eef ch\u00fang an to\u00e0n tr\u01b0\u1edbc khi \u0111\u1ea9y \u0111\u1ebfn \u0111\u00edch. Trong RabbitMQ backing store \u0111\u1ea3m nhi\u1ec7m nhi\u1ec7m v\u1ee5 vi\u1ebft c\u00e1c message v\u00e0o disk","title":"2.1. Gi\u1edbi thi\u1ec7u Rabbitmq"},{"location":"Openstack_Research/Nova/2. Install-nova/#21_cai_at_rabbitmq_server","text":"C\u00e0i \u0111\u1eb7t package yum install rabbitmq-server Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 v\u00e0 kh\u1edfi tao ng\u01b0\u1eddi d\u00f9ng [root@localhost ~]# systemctl start rabbitmq-server [root@localhost ~]# systemctl enable rabbitmq-server [root@localhost ~]# rabbitmqctl add_user openstack rabbitmq_123 [root@localhost ~]# rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\"","title":"2.1. C\u00e0i \u0111\u1eb7t Rabbitmq Server"},{"location":"Openstack_Research/Nova/2. Install-nova/#23_cai_at_ntp_server","text":"yum install chrony sed -i \"s/server.*/server 0.asia.pool.ntp.org iburst/g\" /etc/chrony.conf > /dev/nul echo \"allow 192.168.69.0/24\" >> /etc/chrony.conf systemctl enable chronyd.service systemctl start chronyd.service M\u1ed9t soos NTP Server server 0.asia.pool.ntp.org server 1.asia.pool.ntp.org server 2.asia.pool.ntp.org server 3.asia.pool.ntp.org C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-service=ntp --permanent firewall-cmd --reload Sau khi c\u00e0i \u0111\u1eb7t NTP tr\u00ean c\u00e1c node kh\u00e1c chronyc sources chronyc tracking","title":"2.3. C\u00e0i \u0111\u1eb7t NTP Server"},{"location":"Openstack_Research/Nova/2. Install-nova/#3_cai_at_nova_service_tren_controller_node","text":"","title":"3. C\u00e0i \u0111\u1eb7t Nova Service tr\u00ean Controller Node"},{"location":"Openstack_Research/Nova/2. Install-nova/#31_khoi_tao_db_keystone_user_va_service","text":"Kh\u1edfi t\u1ea1o DB cho nova mysql -u root --password=123@123Aa <<EOF CREATE DATABASE nova_api; CREATE DATABASE nova; CREATE DATABASE nova_cell0; GRANT ALL PRIVILEGES on nova_api.* to 'nova'@'localhost' identified by \"nova_123\"; GRANT ALL PRIVILEGES on nova_api.* to 'nova'@'%' identified by \"nova_123\"; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'nova_123'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova_123'; EOF Kh\u1edfi t\u1ea1o nova user v\u00e0 nova service source ~/admin-openrc openstack user create --domain default --password=nova_123 nova openstack role add --project service --user nova admin openstack service create --name nova --description \"Compute Service \" compute Kh\u1edfi t\u1ea1o Nova API Endpoint openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1 Kh\u1edfi t\u1ea1o Placement user v\u00e0 Placement Service openstack user create --domain default --password=placement_123 placement openstack role add --project service --user placement admin openstack service create --name placement --description \"PLacement API\" placement Kh\u1edfi t\u1ea1o Placement API Endpoint openstack endpoint create --region RegionOne placement public http://controller:8778 openstack endpoint create --region RegionOne placement internal http://controller:8778 openstack endpoint create --region RegionOne placement admin http://controller:8778","title":"3.1. Kh\u1edfi t\u1ea1o DB , Keystone User v\u00e0 Service"},{"location":"Openstack_Research/Nova/2. Install-nova/#32_cai_at_cau_hinh_nova","text":"C\u00e0i \u0111\u1eb7t package yum install openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy \\ openstack-nova-scheduler openstack-nova-placement-api -y C\u1ea5u h\u00ecnh nova v\u00e0 placement cat <<EOF > /etc/nova/nova.conf [DEFAULT] transport_url = rabbit://openstack:rabbitmq_123@controller enabled_apis = osapi_compute,metadata use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver [api_database] connection = mysql+pymysql://nova:nova_123@controller/nova_api [database] connection = mysql+pymysql://nova:nova_123@controller/nova [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = nova_123 [vnc] enabled = true server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.130 [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] os_region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = placement_123 EOF echo \" <Directory /usr/bin> <IfVersion >= 2.4> Require all granted </IfVersion> <IfVersion < 2.4> Order allow,deny Allow from all </IfVersion> </Directory> \" >> /etc/httpd/conf.d/00-nova-placement-api.conf systemctl restart httpd Kh\u1edfi t\u1ea1o d\u1eef li\u1ec7u tr\u00ean Database su -s /bin/sh -c \"nova-manage api_db sync\" nova su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova su -s /bin/sh -c \"nova-manage db sync\" nova Note : n\u1ebfu \u0111\u00e3 config \u0111\u00fang password , user m\u00e0 v\u1eabn xu\u1ea5t hi\u1ec7n l\u1ed7i th\u00ec b\u1ecf qua l\u1ed7i \u0111\u00f3 . Ki\u1ec3m trang b\u1ea3ng cell host connector [root@localhost nova]# nova-manage cell_v2 list_cells /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarning +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ | Name | UUID | Transport URL | Database Connection | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ | cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 | | cell1 | 75e677d7-2250-4efc-b720-21e9a17219a1 | rabbit://openstack:****@controller | mysql+pymysql://nova:****@controller/nova | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+ Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service systemctl start openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service ``` - C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port={11211/tcp,5672/tcp} --permanent firewall-cmd --add-port=8778/tcp --permanent firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8773/tcp,8775/tcp} --permanent firewall-cmd --reload ## 4. C\u00e0i \u0111\u1eb7t tr\u00ean Compute Node - Ki\u1ec3m tra \u1ea3o h\u00f3a tr\u00ean Compute Node ```bash [root@localhost ~]# egrep -c '(vmx|svm)' /proc/cpuinfo 2 C\u1ea5u h\u00ecnh file hosts echo \" 192.168.69.130 controller 192.168.69.131 compute1 192.168.69.132 compute2 192.168.69.133 cinder \" >> /etc/hosts \u0110\u1ed3ng b\u1ed9 NTP yum install chrony sed -i \"s/server.*/server controller iburst/g\" /etc/chrony.conf systemctl enable chronyd.service systemctl restart chronyd.servic C\u00e0i \u0111\u1eb7t Openstack Package v\u00e0 Nova yum install centos-release-openstack-queens -y yum install openstack-nova-compute -y C\u1ea5u h\u00ecnh Nova ( ch\u00fa \u00fd option : server_proxyclient_address : ) cat <<EOF > /etc/nova/nova.conf [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:rabbitmq_123@controller use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = nova_123 [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.69.131 novncproxy_base_url = http://192.168.30.130:6080/vnc_auto.html [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] os_region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = placement_123 [libvirt] virt_type = kvm hw_machine_type = x86_64=pc-i440fx-rhel7.2.0 EOF Kh\u1edfi \u0111\u1ed9ng d\u1ecbch v\u1ee5 systemctl enable libvirtd.service openstack-nova-compute.service systemctl start libvirtd.service openstack-nova-compute.service Tr\u1edf v\u1ec1 Controller Node th\u00eam Host v\u00e0o Cell Table openstack compute service list --service nova-compute root@localhost ~]# openstack compute service list --service nova-compute +----+--------------+-----------------------+------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+--------------+-----------------------+------+---------+-------+----------------------------+ | 6 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-11-07T06:40:46.000000 | +----+--------------+-----------------------+------+---------+-------+----------------------------+ su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova C\u1ea5u h\u00ecnh FirewallD firewall-cmd --add-port=5900-5999/tcp --permanent firewall-cmd --reload","title":"3.2 . C\u00e0i \u0111\u1eb7t, c\u1ea5u h\u00ecnh Nova"},{"location":"Openstack_Research/Nova/3.Nova-Client&Curl/","text":"S\u1eed d\u1ee5ng Nova \u00b6 1. S\u1eed d\u1ee5ng Nova th\u00f4ng qua Openstack CLI \u00b6 openstack flavor create --id auto --ram <dung l\u01b0\u1ee3ng ram> --disk <dung l\u01b0\u1ee3ng disk> --vcpu <s\u1ed1 l\u01b0\u1ee3ng cpu> --public <t\u00ean flavor> dung l\u01b0\u1ee3ng ram t\u00ednh theo \u0111\u01a1n v\u1ecb MB dung l\u01b0\u1ee3ng disk t\u00ednh theo \u0111\u01a1n v\u1ecb GB Li\u1ec7t k\u00ea flavors openstack flavor list show chi ti\u1ebft 1 flavor openstack flavor show <t\u00ean ho\u1eb7c ID c\u1ee7a flavor> X\u00f3a b\u1ecf 1 flavor openstack flavor delete <name or id c\u1ee7a flavor> T\u1ea1o keypair openstack keypair create [--public-key <file> | --private-key <file>] <name> List t\u1ea5t c\u1ea3 c\u00e1c key pair c\u00f3 trong openstack. openstack keypair list X\u00f3a b\u1ecf 1 keypair openstack keypair delete <t\u00ean keypair> T\u1ea1o m\u00e1y \u1ea3o t\u1eeb image openstack server create --flavor <t\u00ean flavor> --image <t\u00ean image> \\ --nic net-id=<id c\u1ee7a network> --security-group <t\u00ean security group> \\ --key-name <t\u00ean keypair> <t\u00ean vm> T\u1ea1o m\u00e1y \u1ea3o t\u1eeb volume openstack server create --flavor <t\u00ean flavor> --volume <t\u00ean volume> \\ --nic net-id=<id c\u1ee7a network> --security-group <t\u00ean security group> \\ --key-name <t\u00ean keypair> <t\u00ean vm> X\u00f3a m\u00e1y \u1ea3o openstack server delete <t\u00ean VM> T\u1eaft m\u00e1y \u1ea3o openstack server stop <t\u00ean VM> B\u1eadt m\u00e1y \u1ea3o openstack server start <t\u00ean VM> reboot m\u1ed9t VM \u0111ang ch\u1ea1y. openstack server reboot <t\u00ean VM> List t\u1ea5t c\u1ea3 VM openstack server list T\u1ea1o m\u1edbi snapshot openstack snapshot create <t\u00ean snapshot> <t\u00ean m\u00e1y \u1ea3o> Hi\u1ec3n th\u1ecb danh s\u00e1ch c\u00e1c snapshot openstack snapshot list X\u00f3a snapshot openstack snapshot delete <t\u00ean ho\u1eb7c ID c\u1ee7a snapshot> Xem danh s\u00e1ch c\u00e1c hypervisor openstack hypervisor list 2 . L\u00e0m vi\u1ec7c v\u1edbi Nova qua CURL \u00b6 L\u1ea5y m\u00e3 token t\u1eeb Keystone curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } }}}}' \\ \"http://localhost:5000/v3/auth/tokens\" ; echo Li\u1ec7t k\u00ea danh s\u00e1ch Flavor [root@localhost nova]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:8774/v2.1/flavors | python -mjson.tool { \"flavors\": [ { \"id\": \"57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"links\": [ { \"href\": \"http://controller:8774/v2.1/flavors/57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"rel\": \"self\" }, { \"href\": \"http://controller:8774/flavors/57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"rel\": \"bookmark\" } ], \"name\": \"small\" } ] } Xem th\u00f4ng tin c\u00e1c Hypervisor [root@localhost nova]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:8774/v2.1/os-hypervisors/detail | python -mjson.tool { \"hypervisors\": [ { \"cpu_info\": \"{\\\"vendor\\\": \\\"Intel\\\", \\\"model\\\": \\\"SandyBridge\\\", \\\"arch\\\": \\\"x86_64\\\", \\\"features\\\": [\\\"pge\\\", \\\"avx\\\", \\\"clflush\\\", \\\"sep\\\", \\\"syscall\\\", \\\"tsc_adjust\\\", \\\"tsc-deadline\\\", \\\"msr\\\", \\\"xsave\\\", \\\"vmx\\\", \\\"cmov\\\", \\\"fpu\\\", \\\"pat\\\", \\\"arat\\\", \\\"lm\\\", \\\"tsc\\\", \\\"nx\\\", \\\"fxsr\\\", \\\"sse4.1\\\", \\\"pae\\\", \\\"sse4.2\\\", \\\"pclmuldq\\\", \\\"pcid\\\", \\\"vme\\\", \\\"mmx\\\", \\\"osxsave\\\", \\\"cx8\\\", \\\"mce\\\", \\\"de\\\", \\\"aes\\\", \\\"mca\\\", \\\"pse\\\", \\\"lahf_lm\\\", \\\"popcnt\\\", \\\"apic\\\", \\\"sse\\\", \\\"ds\\\", \\\"invtsc\\\", \\\"pni\\\", \\\"rdtscp\\\", \\\"sse2\\\", \\\"ss\\\", \\\"hypervisor\\\", \\\"ssse3\\\", \\\"cx16\\\", \\\"pse36\\\", \\\"mtrr\\\", \\\"x2apic\\\"], \\\"topology\\\": {\\\"cores\\\": 1, \\\"cells\\\": 1, \\\"threads\\\": 1, \\\"sockets\\\": 2}}\", \"current_workload\": 0, \"disk_available_least\": 33, \"free_disk_gb\": 35, \"free_ram_mb\": 3583, \"host_ip\": \"192.168.30.131\", \"hypervisor_hostname\": \"localhost.localdomain\", \"hypervisor_type\": \"QEMU\", \"hypervisor_version\": 2010000, \"id\": 1, \"local_gb\": 35, \"local_gb_used\": 0, \"memory_mb\": 4095, \"memory_mb_used\": 512, \"running_vms\": 0, \"service\": { \"disabled_reason\": null, \"host\": \"localhost.localdomain\", \"id\": 6 }, \"state\": \"up\", \"status\": \"enabled\", \"vcpus\": 2, \"vcpus_used\": 0 } ] }","title":"S\u1eed d\u1ee5ng Nova"},{"location":"Openstack_Research/Nova/3.Nova-Client&Curl/#su_dung_nova","text":"","title":"S\u1eed d\u1ee5ng Nova"},{"location":"Openstack_Research/Nova/3.Nova-Client&Curl/#1_su_dung_nova_thong_qua_openstack_cli","text":"openstack flavor create --id auto --ram <dung l\u01b0\u1ee3ng ram> --disk <dung l\u01b0\u1ee3ng disk> --vcpu <s\u1ed1 l\u01b0\u1ee3ng cpu> --public <t\u00ean flavor> dung l\u01b0\u1ee3ng ram t\u00ednh theo \u0111\u01a1n v\u1ecb MB dung l\u01b0\u1ee3ng disk t\u00ednh theo \u0111\u01a1n v\u1ecb GB Li\u1ec7t k\u00ea flavors openstack flavor list show chi ti\u1ebft 1 flavor openstack flavor show <t\u00ean ho\u1eb7c ID c\u1ee7a flavor> X\u00f3a b\u1ecf 1 flavor openstack flavor delete <name or id c\u1ee7a flavor> T\u1ea1o keypair openstack keypair create [--public-key <file> | --private-key <file>] <name> List t\u1ea5t c\u1ea3 c\u00e1c key pair c\u00f3 trong openstack. openstack keypair list X\u00f3a b\u1ecf 1 keypair openstack keypair delete <t\u00ean keypair> T\u1ea1o m\u00e1y \u1ea3o t\u1eeb image openstack server create --flavor <t\u00ean flavor> --image <t\u00ean image> \\ --nic net-id=<id c\u1ee7a network> --security-group <t\u00ean security group> \\ --key-name <t\u00ean keypair> <t\u00ean vm> T\u1ea1o m\u00e1y \u1ea3o t\u1eeb volume openstack server create --flavor <t\u00ean flavor> --volume <t\u00ean volume> \\ --nic net-id=<id c\u1ee7a network> --security-group <t\u00ean security group> \\ --key-name <t\u00ean keypair> <t\u00ean vm> X\u00f3a m\u00e1y \u1ea3o openstack server delete <t\u00ean VM> T\u1eaft m\u00e1y \u1ea3o openstack server stop <t\u00ean VM> B\u1eadt m\u00e1y \u1ea3o openstack server start <t\u00ean VM> reboot m\u1ed9t VM \u0111ang ch\u1ea1y. openstack server reboot <t\u00ean VM> List t\u1ea5t c\u1ea3 VM openstack server list T\u1ea1o m\u1edbi snapshot openstack snapshot create <t\u00ean snapshot> <t\u00ean m\u00e1y \u1ea3o> Hi\u1ec3n th\u1ecb danh s\u00e1ch c\u00e1c snapshot openstack snapshot list X\u00f3a snapshot openstack snapshot delete <t\u00ean ho\u1eb7c ID c\u1ee7a snapshot> Xem danh s\u00e1ch c\u00e1c hypervisor openstack hypervisor list","title":"1. S\u1eed d\u1ee5ng Nova th\u00f4ng qua Openstack CLI"},{"location":"Openstack_Research/Nova/3.Nova-Client&Curl/#2_lam_viec_voi_nova_qua_curl","text":"L\u1ea5y m\u00e3 token t\u1eeb Keystone curl -i \\ -H \"Content-Type: application/json\" \\ -d ' { \"auth\": { \"identity\": { \"methods\": [\"password\"], \"password\": { \"user\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" }, \"password\": \"keystone_123@123Aa\" } } }, \"scope\": { \"project\": { \"name\": \"admin\", \"domain\": { \"id\": \"default\" } }}}}' \\ \"http://localhost:5000/v3/auth/tokens\" ; echo Li\u1ec7t k\u00ea danh s\u00e1ch Flavor [root@localhost nova]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:8774/v2.1/flavors | python -mjson.tool { \"flavors\": [ { \"id\": \"57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"links\": [ { \"href\": \"http://controller:8774/v2.1/flavors/57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"rel\": \"self\" }, { \"href\": \"http://controller:8774/flavors/57488dbd-a0f7-4a7f-ac55-687d85e7f4e4\", \"rel\": \"bookmark\" } ], \"name\": \"small\" } ] } Xem th\u00f4ng tin c\u00e1c Hypervisor [root@localhost nova]# curl -s -H \"X-Auth-Token: $TOKEN\" \\ > http://controller:8774/v2.1/os-hypervisors/detail | python -mjson.tool { \"hypervisors\": [ { \"cpu_info\": \"{\\\"vendor\\\": \\\"Intel\\\", \\\"model\\\": \\\"SandyBridge\\\", \\\"arch\\\": \\\"x86_64\\\", \\\"features\\\": [\\\"pge\\\", \\\"avx\\\", \\\"clflush\\\", \\\"sep\\\", \\\"syscall\\\", \\\"tsc_adjust\\\", \\\"tsc-deadline\\\", \\\"msr\\\", \\\"xsave\\\", \\\"vmx\\\", \\\"cmov\\\", \\\"fpu\\\", \\\"pat\\\", \\\"arat\\\", \\\"lm\\\", \\\"tsc\\\", \\\"nx\\\", \\\"fxsr\\\", \\\"sse4.1\\\", \\\"pae\\\", \\\"sse4.2\\\", \\\"pclmuldq\\\", \\\"pcid\\\", \\\"vme\\\", \\\"mmx\\\", \\\"osxsave\\\", \\\"cx8\\\", \\\"mce\\\", \\\"de\\\", \\\"aes\\\", \\\"mca\\\", \\\"pse\\\", \\\"lahf_lm\\\", \\\"popcnt\\\", \\\"apic\\\", \\\"sse\\\", \\\"ds\\\", \\\"invtsc\\\", \\\"pni\\\", \\\"rdtscp\\\", \\\"sse2\\\", \\\"ss\\\", \\\"hypervisor\\\", \\\"ssse3\\\", \\\"cx16\\\", \\\"pse36\\\", \\\"mtrr\\\", \\\"x2apic\\\"], \\\"topology\\\": {\\\"cores\\\": 1, \\\"cells\\\": 1, \\\"threads\\\": 1, \\\"sockets\\\": 2}}\", \"current_workload\": 0, \"disk_available_least\": 33, \"free_disk_gb\": 35, \"free_ram_mb\": 3583, \"host_ip\": \"192.168.30.131\", \"hypervisor_hostname\": \"localhost.localdomain\", \"hypervisor_type\": \"QEMU\", \"hypervisor_version\": 2010000, \"id\": 1, \"local_gb\": 35, \"local_gb_used\": 0, \"memory_mb\": 4095, \"memory_mb_used\": 512, \"running_vms\": 0, \"service\": { \"disabled_reason\": null, \"host\": \"localhost.localdomain\", \"id\": 6 }, \"state\": \"up\", \"status\": \"enabled\", \"vcpus\": 2, \"vcpus_used\": 0 } ] }","title":"2 . L\u00e0m vi\u1ec7c v\u1edbi Nova qua CURL"},{"location":"Openstack_Research/Nova/4. Nova-Instance-Work-flow/","text":"1. M\u1ed7i quan h\u1ec7 gi\u1eefa c\u00e1c Nova Service \u00b6 Nova-compute ch\u1ea1y tr\u00ean c\u00e1ch compute node 2. Compute service t\u01b0\u01a1ng t\u00e1c t\u1edbi c\u00e1c Hypervisor \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c instance v\u00e0 \u0111\u1ea3m b\u1ea3o state instance \u0111\u01b0\u1ee3c l\u01b0u trong Compute Database . C\u00e1c instance m\u1eb7c \u0111\u1ecbnh \u0111c l\u01b0u t\u1ea1i filesystem Compute Node t\u1ea1i /var/lib/nova/instances 2. Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o \u00b6 Workflow khi kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o: Client (c\u00f3 th\u1ec3 l\u00e0 Horizon ho\u1eb7c CLI) h\u1ecfi t\u1edbi keystone-api \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 generate ra token. N\u1ebfu qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c th\u00e0nh c\u00f4ng, client s\u1ebd g\u1eedi request kh\u1edfi ch\u1ea1y m\u00e1y \u1ea3o t\u1edbi nova-api. Gi\u1ed1ng c\u00e2u l\u1ec7nh nova boot . Nova service s\u1ebd ki\u1ec3m tra token v\u00e0 nh\u1eadn l\u1ea1i header v\u1edbi roles v\u00e0 permissions t\u1eeb keystone-api. Nova API g\u1eedi l\u1ec7nh t\u1edbi nova conductor ki\u1ec3m tra trong database conflicts hay kh\u00f4ng \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t entry m\u1edbi. Nova-api g\u1eedi RPC t\u1edbi nova-scheduler service \u0111\u1ec3 l\u00ean l\u1ecbch cho m\u00e1y \u1ea3o. Nova-scheduler l\u1ea5y request t\u1eeb message queue Nova-scheduler service s\u1ebd t\u00ecm compute host th\u00edch h\u1ee3p trong database th\u00f4ng qua filters v\u00e0 weights. L\u00fac n\u00e0y database s\u1ebd c\u1eadp nh\u1eadt l\u1ea1i entry c\u1ee7a m\u00e1y \u1ea3o v\u1edbi host ID ph\u00f9 h\u1ee3p nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb nova-scheduler. Sau \u0111\u00f3 scheduler s\u1ebd g\u1eedi RPC call t\u1edbi nova-compute \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o. nova-compute l\u1ea5y request t\u1eeb message queue. nova-compute h\u1ecfi nova-conductor \u0111\u1ec3 l\u1ea5y th\u00f4ng tin v\u1ec1 m\u00e1y \u1ea3o nh\u01b0 host ID, flavor. (nova-compute l\u1ea5y c\u00e1c th\u00f4ng tin n\u00e0y t\u1eeb database th\u00f4ng qua nova-conductor v\u00ec l\u00fd do b\u1ea3o m\u1eadt, tr\u00e1nh tr\u01b0\u1eddng h\u1ee3p nova-compute mang theo y\u00eau c\u1ea7u b\u1ea5t h\u1ee3p l\u1ec7 t\u1edbi instance entry trong database) nova-conductor l\u1ea5y request t\u1eeb message queue. nova-conductor l\u1ea5y th\u00f4ng tin m\u00e1y \u1ea3o t\u1eeb database. sau \u0111\u00f3 g\u1eedi v\u1ec1 cho nova-compute nova-compute l\u1ea5y th\u00f4ng tin m\u00e1y \u1ea3o t\u1eeb queue. T\u1ea1i th\u1eddi \u0111i\u1ec3m n\u00e0y, compute host \u0111\u00e3 bi\u1ebft \u0111\u01b0\u1ee3c image n\u00e0o s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o. nova-compute s\u1ebd h\u1ecfi t\u1edbi glance-api \u0111\u1ec3 l\u1ea5y url c\u1ee7a image. Glance-api s\u1ebd x\u00e1c th\u1ef1c token v\u00e0 g\u1eedi l\u1ea1i metadata c\u1ee7a image trong \u0111\u00f3 bao g\u1ed3m c\u1ea3 url c\u1ee7a n\u00f3. Nova-compute s\u1ebd \u0111\u01b0a token t\u1edbi neutron-api v\u00e0 h\u1ecfi n\u00f3 v\u1ec1 network cho m\u00e1y \u1ea3o. Sau khi x\u00e1c th\u1ef1c token, neutron s\u1ebd ti\u1ebfn h\u00e0nh c\u1ea5u h\u00ecnh network. Nova-compute t\u01b0\u01a1ng t\u00e1c v\u1edbi cinder-api \u0111\u1ec3 g\u00e1n volume v\u00e0o m\u00e1y \u1ea3o. Nova-compute s\u1ebd generate d\u1eef li\u1ec7u cho Hypervisor v\u00e0 g\u1eedi th\u00f4ng tin th\u00f4ng qua libvirt. 3. C\u00e1c ki\u1ebfn tr\u00fac li\u00ean quan t\u1edbi m\u00e1y \u1ea3o \u00b6","title":"4. Nova Instance Work flow"},{"location":"Openstack_Research/Nova/4. Nova-Instance-Work-flow/#1_moi_quan_he_giua_cac_nova_service","text":"Nova-compute ch\u1ea1y tr\u00ean c\u00e1ch compute node 2. Compute service t\u01b0\u01a1ng t\u00e1c t\u1edbi c\u00e1c Hypervisor \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi c\u00e1c instance v\u00e0 \u0111\u1ea3m b\u1ea3o state instance \u0111\u01b0\u1ee3c l\u01b0u trong Compute Database . C\u00e1c instance m\u1eb7c \u0111\u1ecbnh \u0111c l\u01b0u t\u1ea1i filesystem Compute Node t\u1ea1i /var/lib/nova/instances","title":"1. M\u1ed7i quan h\u1ec7 gi\u1eefa c\u00e1c Nova Service"},{"location":"Openstack_Research/Nova/4. Nova-Instance-Work-flow/#2_khoi_tao_may_ao","text":"Workflow khi kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o: Client (c\u00f3 th\u1ec3 l\u00e0 Horizon ho\u1eb7c CLI) h\u1ecfi t\u1edbi keystone-api \u0111\u1ec3 x\u00e1c th\u1ef1c v\u00e0 generate ra token. N\u1ebfu qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c th\u00e0nh c\u00f4ng, client s\u1ebd g\u1eedi request kh\u1edfi ch\u1ea1y m\u00e1y \u1ea3o t\u1edbi nova-api. Gi\u1ed1ng c\u00e2u l\u1ec7nh nova boot . Nova service s\u1ebd ki\u1ec3m tra token v\u00e0 nh\u1eadn l\u1ea1i header v\u1edbi roles v\u00e0 permissions t\u1eeb keystone-api. Nova API g\u1eedi l\u1ec7nh t\u1edbi nova conductor ki\u1ec3m tra trong database conflicts hay kh\u00f4ng \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u1ed9t entry m\u1edbi. Nova-api g\u1eedi RPC t\u1edbi nova-scheduler service \u0111\u1ec3 l\u00ean l\u1ecbch cho m\u00e1y \u1ea3o. Nova-scheduler l\u1ea5y request t\u1eeb message queue Nova-scheduler service s\u1ebd t\u00ecm compute host th\u00edch h\u1ee3p trong database th\u00f4ng qua filters v\u00e0 weights. L\u00fac n\u00e0y database s\u1ebd c\u1eadp nh\u1eadt l\u1ea1i entry c\u1ee7a m\u00e1y \u1ea3o v\u1edbi host ID ph\u00f9 h\u1ee3p nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb nova-scheduler. Sau \u0111\u00f3 scheduler s\u1ebd g\u1eedi RPC call t\u1edbi nova-compute \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o. nova-compute l\u1ea5y request t\u1eeb message queue. nova-compute h\u1ecfi nova-conductor \u0111\u1ec3 l\u1ea5y th\u00f4ng tin v\u1ec1 m\u00e1y \u1ea3o nh\u01b0 host ID, flavor. (nova-compute l\u1ea5y c\u00e1c th\u00f4ng tin n\u00e0y t\u1eeb database th\u00f4ng qua nova-conductor v\u00ec l\u00fd do b\u1ea3o m\u1eadt, tr\u00e1nh tr\u01b0\u1eddng h\u1ee3p nova-compute mang theo y\u00eau c\u1ea7u b\u1ea5t h\u1ee3p l\u1ec7 t\u1edbi instance entry trong database) nova-conductor l\u1ea5y request t\u1eeb message queue. nova-conductor l\u1ea5y th\u00f4ng tin m\u00e1y \u1ea3o t\u1eeb database. sau \u0111\u00f3 g\u1eedi v\u1ec1 cho nova-compute nova-compute l\u1ea5y th\u00f4ng tin m\u00e1y \u1ea3o t\u1eeb queue. T\u1ea1i th\u1eddi \u0111i\u1ec3m n\u00e0y, compute host \u0111\u00e3 bi\u1ebft \u0111\u01b0\u1ee3c image n\u00e0o s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 ch\u1ea1y m\u00e1y \u1ea3o. nova-compute s\u1ebd h\u1ecfi t\u1edbi glance-api \u0111\u1ec3 l\u1ea5y url c\u1ee7a image. Glance-api s\u1ebd x\u00e1c th\u1ef1c token v\u00e0 g\u1eedi l\u1ea1i metadata c\u1ee7a image trong \u0111\u00f3 bao g\u1ed3m c\u1ea3 url c\u1ee7a n\u00f3. Nova-compute s\u1ebd \u0111\u01b0a token t\u1edbi neutron-api v\u00e0 h\u1ecfi n\u00f3 v\u1ec1 network cho m\u00e1y \u1ea3o. Sau khi x\u00e1c th\u1ef1c token, neutron s\u1ebd ti\u1ebfn h\u00e0nh c\u1ea5u h\u00ecnh network. Nova-compute t\u01b0\u01a1ng t\u00e1c v\u1edbi cinder-api \u0111\u1ec3 g\u00e1n volume v\u00e0o m\u00e1y \u1ea3o. Nova-compute s\u1ebd generate d\u1eef li\u1ec7u cho Hypervisor v\u00e0 g\u1eedi th\u00f4ng tin th\u00f4ng qua libvirt.","title":"2. Kh\u1edfi t\u1ea1o m\u00e1y \u1ea3o"},{"location":"Openstack_Research/Nova/4. Nova-Instance-Work-flow/#3_cac_kien_truc_lien_quan_toi_may_ao","text":"","title":"3. C\u00e1c ki\u1ebfn tr\u00fac li\u00ean quan t\u1edbi m\u00e1y \u1ea3o"},{"location":"Openstack_Research/Nova/5. Debug/","text":"Debug trong Nova \u00b6 LIVE MIGRATION : virsh qemu-monitor-command, virsh qemu-monitor-eve If the instance crashes \u2013 coredump : virsh dump Enable libvirt logging for understanding lower level interactions between libvirt and qemu libvirtd.conf log_filters=\"1:libvirt 1:qemu 1:conf 1:security 3:event 3:json 3:file 3:object 1:util 1:qemu_monitor\" log_outputs=\"1:file:/var/log/libvirt/libvirtd.log sed -i 's/debug=False/debug=True/g' /etc/nova/nova.conf sed -i 's/verbose=False/verbose=True/g' /etc/nova/nova.conf Get compute.log, conductor.log, scheduler.log for analysis","title":"5. Debug"},{"location":"Openstack_Research/Nova/5. Debug/#debug_trong_nova","text":"LIVE MIGRATION : virsh qemu-monitor-command, virsh qemu-monitor-eve If the instance crashes \u2013 coredump : virsh dump Enable libvirt logging for understanding lower level interactions between libvirt and qemu libvirtd.conf log_filters=\"1:libvirt 1:qemu 1:conf 1:security 3:event 3:json 3:file 3:object 1:util 1:qemu_monitor\" log_outputs=\"1:file:/var/log/libvirt/libvirtd.log sed -i 's/debug=False/debug=True/g' /etc/nova/nova.conf sed -i 's/verbose=False/verbose=True/g' /etc/nova/nova.conf Get compute.log, conductor.log, scheduler.log for analysis","title":"Debug trong Nova"},{"location":"Openstack_Research/Nova/6. Config-section/","text":"M\u1ed9t s\u1ed1 t\u00f9y ch\u1ecdn kh\u00e1c trong nova.conf \u00b6 1. [Default] \u00b6 Parameter = Value Description #password_length = 12 \u0111\u1ed9 d\u00e0i password t\u1ed1i thi\u1ec3u c\u1ee7a c\u00e1c t\u00e0i kho\u1ea3n admin trong instance #compute_driver = driver l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c hypervisor #default_ephemeral_format = c\u1ea5u h\u00ecnh \u0111\u1ecbnh d\u1ea1ng \u1ed5 \u0111\u0129a tr\u00ean local cho c\u00e1c instance #dhcp_lease_time = 86400 Th\u1eddi gian lease cho DHCP #dns_server = C\u1ea5u h\u00ecnh DNS Server #metadata_host = $my_ip Metadata Server 2. [wsgi] \u00b6 Parameter = Value Description #wsgi_log_format = %(client_ip)s \"%(request_line)s\" status: %(status_code)s len: %(body_length)s time: %(wall_seconds).7f Format cho c\u00e1c API request #ssl_ca_file = CA cho SSL #ssl_cert_file = CE cho SSL 3. [vnc] \u00b6 Parameter = Value Description #enabled = true Kh\u1edfi \u0111\u1ed9ng VNC #server_listen = 127.0.0.1 IP trong instance s\u1ebd nh\u1eadn request VNC 4. [key_manager] \u00b6 Parameter = Value Description #fixed_key = s\u1eed d\u1ee5ng secret key trong nova #backend = barbican c\u1ea5u h\u00ecnh backend cho fixed_key #auth_type = Lo\u1ea1i ch\u1ee9ng ch\u1ec9 x\u00e1c th\u1ef1c \u0111\u1ec3 t\u1ea1o #token = token \u0111\u1ec3 x\u00e1c th\u1ef1c","title":"M\u1ed9t s\u1ed1 t\u00f9y ch\u1ecdn kh\u00e1c trong nova.conf"},{"location":"Openstack_Research/Nova/6. Config-section/#mot_so_tuy_chon_khac_trong_novaconf","text":"","title":"M\u1ed9t s\u1ed1 t\u00f9y ch\u1ecdn kh\u00e1c trong nova.conf"},{"location":"Openstack_Research/Nova/6. Config-section/#1_default","text":"Parameter = Value Description #password_length = 12 \u0111\u1ed9 d\u00e0i password t\u1ed1i thi\u1ec3u c\u1ee7a c\u00e1c t\u00e0i kho\u1ea3n admin trong instance #compute_driver = driver l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c hypervisor #default_ephemeral_format = c\u1ea5u h\u00ecnh \u0111\u1ecbnh d\u1ea1ng \u1ed5 \u0111\u0129a tr\u00ean local cho c\u00e1c instance #dhcp_lease_time = 86400 Th\u1eddi gian lease cho DHCP #dns_server = C\u1ea5u h\u00ecnh DNS Server #metadata_host = $my_ip Metadata Server","title":"1. [Default]"},{"location":"Openstack_Research/Nova/6. Config-section/#2_wsgi","text":"Parameter = Value Description #wsgi_log_format = %(client_ip)s \"%(request_line)s\" status: %(status_code)s len: %(body_length)s time: %(wall_seconds).7f Format cho c\u00e1c API request #ssl_ca_file = CA cho SSL #ssl_cert_file = CE cho SSL","title":"2. [wsgi]"},{"location":"Openstack_Research/Nova/6. Config-section/#3_vnc","text":"Parameter = Value Description #enabled = true Kh\u1edfi \u0111\u1ed9ng VNC #server_listen = 127.0.0.1 IP trong instance s\u1ebd nh\u1eadn request VNC","title":"3. [vnc]"},{"location":"Openstack_Research/Nova/6. Config-section/#4_key_manager","text":"Parameter = Value Description #fixed_key = s\u1eed d\u1ee5ng secret key trong nova #backend = barbican c\u1ea5u h\u00ecnh backend cho fixed_key #auth_type = Lo\u1ea1i ch\u1ee9ng ch\u1ec9 x\u00e1c th\u1ef1c \u0111\u1ec3 t\u1ea1o #token = token \u0111\u1ec3 x\u00e1c th\u1ef1c","title":"4. [key_manager]"}]}